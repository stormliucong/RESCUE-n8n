{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09770488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e85706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/cptaswadu/RESCUE-n8n/insurance/Providers_Network_update.csv')\n",
    "real_list = df[\"In-network Provider\"].dropna().str.strip().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6101a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/cptaswadu/RESCUE-n8n/insurance')\n",
    "load_dotenv(dotenv_path='/home/cptaswadu/RESCUE-n8n/insurance/.env')\n",
    "openai_api_key = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "perplexity_api_key = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "client = OpenAI(api_key=openai_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927fadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_provider(name):\n",
    "    name = name.strip()\n",
    "\n",
    "    if \"Kansas City\" in name:\n",
    "        name = name.replace(\"Kansas City\", \"Kansas\")\n",
    "    \n",
    "    if name.endswith(\"(FFS)\"):\n",
    "        name = name.replace(\"(FFS)\", \"\").strip()\n",
    "\n",
    "    if \"Blue Shield of\" in name:\n",
    "        name = name.replace(\"Blue Shield of\", \"BS\")\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49718966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_llm_providers(message_list, real_list, prompt_name=None, experiment_id=None, save_dir=\"results\"):\n",
    "    def safe_response_with_retry(messages, max_retries=3):\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            try:\n",
    "                print(f\"üîÅ Attempt {attempt}...\")\n",
    "                response = client.responses.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    tools=[{\"type\": \"web_search_preview\"}],\n",
    "                    input=messages\n",
    "                )\n",
    "                return response.output_text.strip()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Attempt {attempt} failed: {e}\")\n",
    "        return None\n",
    "\n",
    "    response_text = safe_response_with_retry(message_list)\n",
    "    if not response_text:\n",
    "        return {\n",
    "            \"error\": \"All attempts failed.\",\n",
    "            \"Precision (%)\": 0,\n",
    "            \"Recall (%)\": 0\n",
    "        }\n",
    "\n",
    "    response_text = re.sub(r\"^```json\\s*\", \"\", response_text)\n",
    "    response_text = re.sub(r\"\\s*```$\", \"\", response_text)\n",
    "\n",
    "    if response_text.endswith(\",\"):\n",
    "        response_text = response_text.rstrip(\",\") + \"]}\"\n",
    "    elif response_text.endswith(\"[\"):\n",
    "        response_text += \"]}\"\n",
    "    elif \"Providers\" in response_text and \"source_url\" not in response_text:\n",
    "        response_text += ', \"source_url\": \"\"}'\n",
    "\n",
    "    try:\n",
    "        result = json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"‚ùå JSON decoding failed after all retries.\")\n",
    "        print(response_text[:500])\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        filename = f\"{prompt_name}_experiment{experiment_id}_failed.csv\"\n",
    "        path = os.path.join(save_dir, filename)\n",
    "        pd.DataFrame([{\"error\": \"invalid JSON\", \"raw_output\": response_text}]).to_csv(path, index=False)\n",
    "        print(f\"‚ö†Ô∏è Raw output saved to '{path}'\")\n",
    "\n",
    "        return {\n",
    "            \"error\": \"invalid JSON\",\n",
    "            \"Precision (%)\": 0,\n",
    "            \"Recall (%)\": 0\n",
    "        }\n",
    "\n",
    "    chatgpt_provider_list = result.get(\"Providers\", [])\n",
    "    normalized_chatgpt_list = [normalize_provider(name) for name in chatgpt_provider_list]\n",
    "\n",
    "    real_set = set(real_list)\n",
    "    chatgpt_set = set(normalized_chatgpt_list)\n",
    "    common = real_set & chatgpt_set\n",
    "    missing = real_set - chatgpt_set\n",
    "    extra = chatgpt_set - real_set\n",
    "\n",
    "    precision = len(common) / len(chatgpt_set) * 100 if chatgpt_set else 0\n",
    "    recall = len(common) / len(real_set) * 100 if real_set else 0\n",
    "\n",
    "    comparison_summary = {\n",
    "        \"prompt_name\": prompt_name,\n",
    "        \"experiment_id\": experiment_id,\n",
    "        \"real_list_count\": len(real_list),\n",
    "        \"chatgpt_list_count\": len(chatgpt_set),\n",
    "        \"common_count\": len(common),\n",
    "        \"missing_from_chatgpt_count\": len(missing),\n",
    "        \"extra_in_chatgpt_count\": len(extra),\n",
    "        \"Precision (%)\": round(precision, 2),\n",
    "        \"Recall (%)\": round(recall, 2)\n",
    "    }\n",
    "\n",
    "    if prompt_name and experiment_id is not None:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        filename = f\"{prompt_name}_experiment{experiment_id}.csv\"\n",
    "        path = os.path.join(save_dir, filename)\n",
    "        pd.DataFrame([comparison_summary]).to_csv(path, index=False)\n",
    "        print(f\"üìÅ Result saved to '{path}'\")\n",
    "\n",
    "    return comparison_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d372ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_gene_providers_baseline():\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant. Respond only in strict JSON format with no explanation or extra commentary.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"List all the medical insurance providers that are currently in-network with GeneDx. \"\n",
    "                \"Format your response as: \"\n",
    "                \"{\\\"Providers\\\": [list of provider names], \\\"source_url\\\": \\\"link to the official source\\\"}. \"\n",
    "                \"Only use information from official GeneDx or trusted affiliate websites.\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "def prompt_gene_providers_counted_311():\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an artificial intelligence assistant and you need to \"\n",
    "                \"engage in a helpful, detailed, polite conversation with a user.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"List all the 311 medical insurance providers that are currently in-network with GeneDx. \"\n",
    "                \"Output the result strictly in JSON format using the following structure: \"\n",
    "                \"{\\\"Providers\\\": [list of provider names], \\\"source_url\\\": \\\"link to the official source\\\"}. \"\n",
    "                \"Only include links from the official GeneDx website or affiliated trusted sources. \"\n",
    "                \"Do not include any introduction, explanation, or extra commentary ‚Äî only return the JSON object.\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def prompt_gene_providers_with_explicit_source():\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an artificial intelligence assistant and you need to \"\n",
    "                \"engage in a helpful, detailed, polite conversation with a user.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"List all the medical insurance providers that are currently in-network with GeneDx. \"\n",
    "                \"You may use the official GeneDx insurance network page at \"\n",
    "                \"https://www.genedx.com/commercial-insurance-in-network-contracts/ as the primary source of information. \"\n",
    "                \"Output the result strictly in JSON format using the following structure: \"\n",
    "                \"{\\\"Providers\\\": [list of provider names], \\\"source_url\\\": \\\"link to the official source\\\"}. \"\n",
    "                \"Only include links from the official GeneDx website or affiliated trusted sources. \"\n",
    "                \"Do not include any introduction, explanation, or extra commentary ‚Äî only return the JSON object.\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "prompt_bank = {\n",
    "    \"baseline\": prompt_gene_providers_baseline,\n",
    "    \"counted_311\": prompt_gene_providers_counted_311,\n",
    "    \"explicit_source\": prompt_gene_providers_with_explicit_source,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7372e94d",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7303c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Attempt 1...\n",
      "üìÅ Result saved to 'results/baseline_experiment1.csv'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt_name': 'baseline',\n",
       " 'experiment_id': 1,\n",
       " 'real_list_count': 311,\n",
       " 'chatgpt_list_count': 165,\n",
       " 'common_count': 53,\n",
       " 'missing_from_chatgpt_count': 257,\n",
       " 'extra_in_chatgpt_count': 112,\n",
       " 'Precision (%)': 32.12,\n",
       " 'Recall (%)': 17.1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_llm_providers(\n",
    "            message_list=prompt_gene_providers_baseline(),\n",
    "            real_list=real_list,\n",
    "            prompt_name=\"baseline\",\n",
    "            experiment_id=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6dc72ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Attempt 1...\n",
      "üìÅ Result saved to 'results/counted_311_experiment1.csv'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt_name': 'counted_311',\n",
       " 'experiment_id': 1,\n",
       " 'real_list_count': 311,\n",
       " 'chatgpt_list_count': 165,\n",
       " 'common_count': 53,\n",
       " 'missing_from_chatgpt_count': 257,\n",
       " 'extra_in_chatgpt_count': 112,\n",
       " 'Precision (%)': 32.12,\n",
       " 'Recall (%)': 17.1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_llm_providers(\n",
    "            message_list=prompt_gene_providers_counted_311(),\n",
    "            real_list=real_list,\n",
    "            prompt_name=\"counted_311\",\n",
    "            experiment_id=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c673f69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Attempt 1...\n",
      "üìÅ Result saved to 'results/explicit_source_experiment1.csv'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt_name': 'explicit_source',\n",
       " 'experiment_id': 1,\n",
       " 'real_list_count': 311,\n",
       " 'chatgpt_list_count': 169,\n",
       " 'common_count': 150,\n",
       " 'missing_from_chatgpt_count': 160,\n",
       " 'extra_in_chatgpt_count': 19,\n",
       " 'Precision (%)': 88.76,\n",
       " 'Recall (%)': 48.39}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_llm_providers(\n",
    "            message_list=prompt_gene_providers_with_explicit_source(),\n",
    "            real_list=real_list,\n",
    "            prompt_name=\"explicit_source\",\n",
    "            experiment_id=1\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
