{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca4a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from urllib.parse import urlparse\n",
    "import hashlib\n",
    "import pdfkit\n",
    "import requests\n",
    "from playwright.sync_api import sync_playwright\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote_plus\n",
    "from itertools import product\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25ee41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/cptaswadu/RESCUE-n8n/insurance'\n",
    "load_dotenv(dotenv_path=os.path.join(path, \".env\"))\n",
    "openai_api_key = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "perplexity_api_key = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "chatgpt_client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865c8622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inputs(case_ex_path, ground_truth_path):\n",
    "    with open(case_ex_path, \"r\") as f:\n",
    "        case_ex = json.load(f)\n",
    "\n",
    "    with open(ground_truth_path, \"r\") as f:\n",
    "        ground_truth = json.load(f)\n",
    "\n",
    "    return case_ex, ground_truth\n",
    "\n",
    "case_path = \"/home/cptaswadu/RESCUE-n8n/insurance/dataset/case_ex.json\"\n",
    "truth_path = \"/home/cptaswadu/RESCUE-n8n/insurance/dataset/ground_truth.json\"\n",
    "\n",
    "case_ex, ground_truth = load_inputs(case_path, truth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ed679e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json_response(response_text):\n",
    "    original = response_text.strip()\n",
    "\n",
    "    # Step 0: Check for hallucinated greeting (Perplexity fallback)\n",
    "    if \"how can I assist you\" in original.lower() or \"insurance-related questions\" in original.lower():\n",
    "        raise ValueError(\"Perplexity returned generic assistant response instead of JSON.\")\n",
    "\n",
    "    # Step 1: Try direct parsing\n",
    "    try:\n",
    "        return json.loads(original)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # Step 2: Remove code block wrappers\n",
    "    cleaned = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", original, flags=re.IGNORECASE).strip()\n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # Step 3: Try to extract the first {...} JSON-like block\n",
    "    match = re.search(r\"(\\{[\\s\\S]*?\\})\", original)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group(1))\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "    raise ValueError(\"No valid JSON found in the response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acda675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_policy_summarize(patient_info_text, model=\"chatgpt\", chatgpt_client=None, perplexity_api_key=None, max_retries=3):\n",
    "    prompt = f\"\"\"\n",
    "You are a clinical insurance assistant specializing in genetic testing coverage.\n",
    "\n",
    "You will be provided with:\n",
    "1. Patient clinical information (including clinical history, insurance provider, and location).\n",
    "2. Your task is to first find the most relevant and up-to-date official insurance policy document that addresses **genetic testing coverage** for this patient.\n",
    "3. Then, read and extract ONLY the key policy criteria that apply to this patient's specific situation.\n",
    "\n",
    "==== PATIENT INFORMATION ====\n",
    "{patient_info_text}\n",
    "\n",
    "Instructions:\n",
    "\n",
    "ðŸ”¹ Step 1: Search\n",
    "- Identify the **most relevant official URL** of the insurance policy document based on the patientâ€™s insurance provider, genetic test type, and state of residence.\n",
    "- The document must include criteria such as: **medical necessity**, **clinical guidelines**, **age restrictions**, **prior authorization requirements**, or **test-specific coverage rules**.\n",
    "- If no relevant document is found, respond with: \"No policy found.\"\n",
    "- If a document is found, return its **direct URL** under: `policy_url`\n",
    "\n",
    "ðŸ”¹ Step 2: Extract Relevant Rules\n",
    "- Read the document at the retrieved `policy_url`.\n",
    "- Extract and summarize only the meaningful coverage criteria that apply to **this specific patient** based on their clinical profile.\n",
    "- Focus on:\n",
    "  - Age requirements\n",
    "  - Medical necessity definition\n",
    "  - Clinical guideline adherence (e.g., ACMG, NCCN)\n",
    "  - Prior authorization requirements\n",
    "  - Any other genetic test-specific coverage conditions\n",
    "- Exclude navigation menus, legal disclaimers, and irrelevant sections.\n",
    "- If no relevant rules are found or the page doesn't load, return: \"No relevant coverage criteria found.\"\n",
    "\n",
    "Return your answer in the following JSON format:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"policy_url\": \"[INSERT POLICY URL OR 'No policy found']\",\n",
    "  \"policy_summary\": \"[INSERT SUMMARY TEXT OR 'No relevant coverage criteria found']\"\n",
    "}}\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a clinical insurance assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    def call_chatgpt():\n",
    "        response = chatgpt_client.responses.create(\n",
    "            model=\"gpt-4o\",\n",
    "            input=messages,\n",
    "            tools=[{\"type\": \"web_search_preview\"}]\n",
    "        )\n",
    "        return response.output_text.strip()\n",
    "\n",
    "    def call_perplexity():\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {perplexity_api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        data = {\n",
    "            \"model\": \"sonar-pro\",\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        res = requests.post(url, headers=headers, json=data)\n",
    "        return res.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            print(f\"ðŸ” Attempt {attempt} ({model})...\")\n",
    "            result_text = call_perplexity() if model == \"perplexity\" else call_chatgpt()\n",
    "            print(\"ðŸ”Ž Raw result from LLM:\\n\", result_text)\n",
    "\n",
    "            result_json = clean_json_response(result_text)\n",
    "            if \"policy_url\" not in result_json or \"policy_summary\" not in result_json:\n",
    "                raise ValueError(\"Missing expected keys in response.\")\n",
    "\n",
    "            return result_json\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Attempt {attempt} failed: {e}\")\n",
    "\n",
    "    return {\n",
    "        \"policy_url\": \"No policy found\",\n",
    "        \"policy_summary\": \"No relevant coverage criteria found\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f95b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_question_block(q, indent=2):\n",
    "    indent_str = \" \" * indent\n",
    "    question_line = f\"{q['question']}\"\n",
    "\n",
    "    if q.get(\"options\") == [\"Free text answer\"]:\n",
    "        question_line += f\"\\n{indent_str}(Free text answer allowed.)\"\n",
    "    else:\n",
    "        question_line += f\"\\n{indent_str}Options: {', '.join(q['options'])}\"\n",
    "\n",
    "        if \"additional_if_yes\" in q:\n",
    "            question_line += f\"\\n{indent_str}  If 'Yes':\"\n",
    "            for item in q[\"additional_if_yes\"]:\n",
    "                if isinstance(item, str):\n",
    "                    question_line += f\"\\n{indent_str}    - {item}\"\n",
    "                elif isinstance(item, dict):\n",
    "                    question_line += f\"\\n{indent_str}    - {format_question_block(item, indent + 6)}\"\n",
    "\n",
    "        if \"additional_if_no\" in q:\n",
    "            question_line += f\"\\n{indent_str}  If 'No':\"\n",
    "            for item in q[\"additional_if_no\"]:\n",
    "                if isinstance(item, str):\n",
    "                    question_line += f\"\\n{indent_str}    - {item}\"\n",
    "                elif isinstance(item, dict):\n",
    "                    question_line += f\"\\n{indent_str}    - {format_question_block(item, indent + 6)}\"\n",
    "\n",
    "    return question_line\n",
    "\n",
    "\n",
    "def format_questions(questions_list):\n",
    "    return \"\\n\\n\".join([\n",
    "        f\"{q['id']}. {format_question_block(q)}\"\n",
    "        for q in questions_list\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43ad9e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qna(case_id, patient_info_text, policy_url, policy_summary, questions_list,\n",
    "            qna_model=\"chatgpt\", chatgpt_client=None, perplexity_api_key=None,\n",
    "            search_model=\"chatgpt\"):\n",
    "\n",
    "    questions_formatted = format_questions(questions_list)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a clinical insurance assistant specializing in genetic testing coverage policies.\n",
    "\n",
    "You will be given:\n",
    "1. Patient clinical information (very important for decision making)\n",
    "2. Summarized policy coverage criteria text (use this when available)\n",
    "\n",
    "Instructions:\n",
    "- If a useful policy summary is provided, prioritize it when answering.\n",
    "- If the policy summary says \"No relevant coverage criteria found\", you must read and extract policy content directly from the policy_url using your web search tool.\n",
    "- For each question:\n",
    "    - Answer \"Yes\" or \"No\" based on the policy criteria and patient information.\n",
    "    - If the question is a Free text question, provide a free text answer.\n",
    "    - Strictly choose the answer from the options provided.\n",
    "    - If options are provided, choose ONLY from those options.\n",
    "    - If the question says \"(Free text answer allowed)\", you may write your answer freely.\n",
    "    - If the question says \"If Yes, ALSO select from ...\" and you answered \"Yes\", you MUST also select from those follow-up options.\n",
    "    - If the question says \"If No, ALSO select from ...\" and you answered \"No\", you MUST also select from those follow-up options.\n",
    "- Use the patient's clinical context carefully if the policy is vague.\n",
    "- Output answers in JSON format ONLY, with no explanation.\n",
    "\n",
    "==== PATIENT INFORMATION ====\n",
    "{patient_info_text}\n",
    "\n",
    "==== SUMMARIZED POLICY COVERAGE CRITERIA (from URL: {policy_url}) ====\n",
    "{policy_summary}\n",
    "\n",
    "==== QUESTIONS ====\n",
    "{questions_formatted}\n",
    "\n",
    "Output your answers in JSON format only.\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a clinical insurance assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    def call_chatgpt():\n",
    "        response = chatgpt_client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            temperature=0\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    def call_chatgpt_websearch():\n",
    "        response = chatgpt_client.responses.create(\n",
    "            model=\"gpt-4o\",\n",
    "            input=messages,\n",
    "            tools=[{\"type\": \"web_search_preview\"}]\n",
    "        )\n",
    "        return response.output_text.strip()\n",
    "\n",
    "    def call_perplexity():\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {perplexity_api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        data = {\n",
    "            \"model\": \"sonar-pro\",\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        res = requests.post(url, headers=headers, json=data)\n",
    "        if res.status_code == 200:\n",
    "            return res.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        else:\n",
    "            raise Exception(f\"Perplexity error: {res.status_code} - {res.text}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"ðŸ§  Running QnA ({qna_model})...\")\n",
    "        if qna_model == \"chatgpt\" and policy_summary.lower().strip() == \"no relevant coverage criteria found\":\n",
    "            result_content = call_chatgpt_websearch()\n",
    "        elif qna_model == \"chatgpt\":\n",
    "            result_content = call_chatgpt()\n",
    "        else:\n",
    "            result_content = call_perplexity()\n",
    "        result_json = clean_json_response(result_content)\n",
    "\n",
    "        final_result = {}\n",
    "        for k, v in result_json.items():\n",
    "            if k == \"policy_url\":\n",
    "                continue\n",
    "            if \"_selection\" in k or \"_details\" in k:\n",
    "                base_key = k.replace(\"_selection\", \"\").replace(\"_details\", \"\")\n",
    "                final_result[f\"{base_key}_followup\"] = [v] if isinstance(v, str) else v\n",
    "            else:\n",
    "                final_result[k] = v\n",
    "\n",
    "        result_dir = f\"/home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/{search_model}_{qna_model}\"\n",
    "        os.makedirs(result_dir, exist_ok=True)\n",
    "        filename = os.path.join(result_dir, f\"{case_id}_qna_result.json\")\n",
    "\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(final_result, f, indent=2)\n",
    "\n",
    "        print(f\"âœ… QnA result saved to {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"â— JSON parsing error:\", e)\n",
    "        final_result = {\n",
    "            \"error\": \"JSON parsing failed\",\n",
    "            \"raw_content\": result_content\n",
    "        }\n",
    "\n",
    "    print(\"QnA Result JSON:\", final_result)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c73b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_file_path = \"/home/cptaswadu/RESCUE-n8n/insurance/dataset/Insurance_Genetic_Testing_QA.json\"\n",
    "\n",
    "with open(questions_file_path, \"r\") as f:\n",
    "    questions_data = json.load(f)\n",
    "\n",
    "questions_list = questions_data[\"questions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3234aaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Starting experiments for: chatgpt_chatgpt\n",
      "\n",
      "\n",
      "=== Running for Case1 ===\n",
      "ðŸ” Attempt 1 (chatgpt)...\n",
      "ðŸ”Ž Raw result from LLM:\n",
      " ```json\n",
      "{\n",
      "  \"policy_url\": \"https://www.uhcprovider.com/en/prior-auth-advance-notification/genetic-molecular-lab.html\",\n",
      "  \"policy_summary\": \"UnitedHealthcare's policy considers Whole Exome Sequencing (WES) medically necessary for patients with unexplained congenital or neurodevelopmental disorders when:\\n\\n- **Age Requirement**: The patient is under 18 years of age.\\n\\n- **Medical Necessity**: A genetic etiology is strongly suspected based on clinical presentation, including:\\n  - Multiple congenital anomalies affecting different organ systems.\\n  - Moderate to profound intellectual disability diagnosed by 18 years of age.\\n  - Global developmental delay.\\n  - Epileptic encephalopathy with onset before 3 years of age.\\n  - Two or more of the following: congenital anomaly, significant hearing or visual impairment diagnosed by 18 years of age, laboratory abnormalities suggestive of an inborn error of metabolism, autism spectrum disorder, or neuropsychiatric condition.\\n\\n- **Clinical Guidelines**: The patient's clinical history should strongly suggest a genetic cause, and the results of WES are expected to directly influence medical management.\\n\\n- **Prior Authorization**: Prior authorization is required for genetic and molecular testing performed in outpatient settings for UnitedHealthcare commercial plans.\\n\\nThese criteria align with UnitedHealthcare's coverage policies for genetic testing.\"\n",
      "}\n",
      "```\n",
      "ðŸ§  Running QnA (chatgpt)...\n",
      "âœ… QnA result saved to /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/chatgpt_chatgpt/Case1_qna_result.json\n",
      "QnA Result JSON: {'Q0': 'Whole Exome Sequencing (WES)', 'Q1': 'Yes', 'Q2': 'Yes', 'Q3': 'Yes', 'Q4': 'Yes', 'Q4.1': 'Yes', 'Q4.1.1': 'None of the above', 'Q5': 'Yes', 'Q6': 'No', 'Q7': 'Yes', 'Q8': 'No', 'Q9': 'Yes', 'Q9.1': 'Yes', 'Q10': 'No', 'Q10.1': 'Diagnostic', 'Q11': 'Not specified', 'Q12': 'No', 'Q13': 'Yes', 'Q14': 'Not listed', 'Q15': 'No', 'Q16': 'Yes', 'Q17': \"The policy requires prior authorization for genetic and molecular testing performed in outpatient settings. Ensure that the test is ordered by an approved specialist, and submit the necessary documentation demonstrating medical necessity, including the patient's clinical history and previous genetic testing results. Follow the insurer's specific submission process for prior authorization.\"}\n",
      "\n",
      "ðŸš€ Starting experiments for: chatgpt_perplexity\n",
      "\n",
      "\n",
      "=== Running for Case1 ===\n",
      "ðŸ” Attempt 1 (chatgpt)...\n",
      "ðŸ”Ž Raw result from LLM:\n",
      " ```json\n",
      "{\n",
      "  \"policy_url\": \"https://www.uhcprovider.com/en/health-plans-by-state/new-jersey-health-plans/nj-comm-plan-home/nj-cp-policies/medicaid-community-state-policies-nj.html\",\n",
      "  \"policy_summary\": \"UnitedHealthcare's policy on Whole Exome and Whole Genome Sequencing (Non-Oncology Conditions) for New Jersey Community Plan members, effective July 1, 2024, includes the following criteria:\\n\\n- **Medical Necessity**: Whole Exome Sequencing (WES) is considered medically necessary for individuals with unexplained congenital or neurodevelopmental disorders when:\\n  - The individual has been evaluated by a board-certified clinician with expertise in clinical genetics and has been counseled about the potential risks of genetic testing.\\n  - The WES results will directly impact patient management and clinical outcome for the individual being tested.\\n  - A genetic etiology is the most likely explanation for the phenotype.\\n\\n- **Prior Authorization**: Prior authorization is required for genetic testing services. Failure to obtain prior authorization may result in reduced benefits.\\n\\n- **Age Requirements**: The policy applies to individuals with unexplained congenital or neurodevelopmental disorders, which can include pediatric patients.\\n\\n- **Test-Specific Coverage Conditions**: If WES has been previously performed, further genetic tests involving only exome analyses are considered investigational. Whole Genome Sequencing (WGS) is considered investigational for all situations not described in the policy.\\n\\nGiven the patient's clinical history of neurodevelopmental delay, seizures, and a family history of neurodevelopmental disorders, WES may be considered medically necessary under this policy. It is essential to obtain prior authorization before proceeding with the testing.\"\n",
      "}\n",
      "```\n",
      "ðŸ§  Running QnA (perplexity)...\n",
      "âœ… QnA result saved to /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/chatgpt_perplexity/Case1_qna_result.json\n",
      "QnA Result JSON: {'Q0': 'Whole Exome Sequencing (WES); gene content: all protein-coding regions of the genome.', 'Q1': 'Yes', 'Q2': 'Yes', 'Q3': 'Yes', 'Q4': 'No', 'Q5': 'Yes', 'Q6': 'No', 'Q7': 'Yes', 'Q8': 'No', 'Q9': 'Yes', 'Q10': 'No', 'Q10_followup': 'Diagnostic', 'Q11': 'Yes', 'Q12': 'No', 'Q13': 'Yes', 'Q14': 'Not listed', 'Q15': 'No', 'Q16': 'Yes', 'Q17': 'Obtain prior authorization before testing. Ensure documentation of medical necessity, including clinical evaluation by a board-certified genetics specialist, genetic counseling, negative prior chromosomal microarray, and how WES will impact management. Submit claim with supporting clinical notes and prior authorization approval.'}\n",
      "\n",
      "ðŸš€ Starting experiments for: perplexity_chatgpt\n",
      "\n",
      "\n",
      "=== Running for Case1 ===\n",
      "ðŸ” Attempt 1 (perplexity)...\n",
      "ðŸ”Ž Raw result from LLM:\n",
      " ```json\n",
      "{\n",
      "  \"policy_url\": \"https://www.uhcprovider.com/content/dam/provider/docs/public/prior-auth/genetic-paan-faq.pdf\",\n",
      "  \"policy_summary\": \"For UnitedHealthcare Choice Plus members, prior authorization is required for whole exome sequencing (WES) and other advanced genetic and molecular tests. Genetic counseling is not required before approval, but is recommended. Coverage for WES is considered when the test is medically necessary, which typically includes: (1) the patient has a neurodevelopmental disorder (such as developmental delay and/or seizures) with no diagnosis after standard testing (e.g., negative chromosomal microarray), (2) the results are expected to impact clinical management, and (3) the test is ordered by a qualified provider. There are no specific age restrictions for WES in pediatric patients with unexplained neurodevelopmental disorders. The policy follows current clinical guidelines (such as ACMG) for medical necessity. Prior authorization must be obtained before testing.\"\n",
      "}\n",
      "```\n",
      "ðŸ§  Running QnA (chatgpt)...\n",
      "âœ… QnA result saved to /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/perplexity_chatgpt/Case1_qna_result.json\n",
      "QnA Result JSON: {'Q0': 'Whole exome sequencing (WES)', 'Q1': 'Yes', 'Q2': 'Yes', 'Q3': 'Yes', 'Q4': 'Yes', 'Q4.1': 'Yes', 'Q4.1.1': 'ACMG', 'Q5': 'Yes', 'Q6': 'No', 'Q7': 'Yes', 'Q8': 'No', 'Q9': 'Yes', 'Q9.1': 'Yes', 'Q10': 'No', 'Q10.1': 'Diagnostic', 'Q11': 'No', 'Q12': 'No', 'Q13': 'Yes', 'Q14': 'Not listed', 'Q15': 'No', 'Q16': 'Yes', 'Q17': \"Prior authorization must be obtained before testing. Submit the request with supporting documentation of medical necessity, including the patient's clinical presentation and previous test results.\"}\n",
      "\n",
      "ðŸš€ Starting experiments for: perplexity_perplexity\n",
      "\n",
      "\n",
      "=== Running for Case1 ===\n",
      "ðŸ” Attempt 1 (perplexity)...\n",
      "ðŸ”Ž Raw result from LLM:\n",
      " Based on the patient information provided, I need to determine UnitedHealthcare's coverage policy for whole exome sequencing for an 8-year-old with neurodevelopmental delay and seizures.\n",
      "\n",
      "After reviewing the search results, I can provide the following information about UnitedHealthcare's genetic testing coverage that would apply to this patient:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"policy_url\": \"No policy found\",\n",
      "  \"policy_summary\": \"Based on UnitedHealthcare's policy effective April 1, 2023, whole-genome sequencing (WGS) is considered 'medically necessary' when a patient has not previously received chromosome microarray analysis (CMA) or whole-exome sequencing (WES), has clinical features that are nonspecific and do not fit a well-defined syndrome for a specific targeted gene test, and presents a clinical history that strongly suggests a genetic cause. The patient must also have one or more of the following features: multiple congenital anomalies affecting different organ systems; moderate, severe, or profound intellectual disability diagnosed by 18 years of age; or global developmental delay or epileptic encephalopathy with onset before 3 years of age. This policy applies to UHC commercial benefit plans and individual exchange benefit plans in all states except Colorado, Massachusetts, Nevada, and New York. The patient in question, an 8-year-old with neurodevelopmental delay and seizures who has already had a negative CMA, appears to meet several of these criteria, particularly the epileptic encephalopathy with onset before age 3 and/or global developmental delay criteria. However, it should be noted that the search results specifically mention coverage for whole-genome sequencing rather than whole-exome sequencing, which is what has been requested for this patient.\"\n",
      "}\n",
      "```\n",
      "ðŸ§  Running QnA (perplexity)...\n",
      "âœ… QnA result saved to /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/perplexity_perplexity/Case1_qna_result.json\n",
      "QnA Result JSON: {'Q0': 'Whole exome sequencing (WES) to investigate potential genetic causes of neurodevelopmental delay and seizures', 'Q1': 'Yes', 'Q2': 'Yes', 'Q3': 'Yes', 'Q4': 'No', 'Q5': 'Yes', 'Q6': 'No', 'Q7': 'Yes', 'Q8': 'No', 'Q9': 'Yes', 'Q10': 'No', 'Q10_followup': 'Diagnostic', 'Q11': 'Yes', 'Q12': 'No', 'Q13': 'Yes', 'Q14': 'Not listed', 'Q15': 'No', 'Q16': 'Yes', 'Q17': \"Based on the policy, the following steps should be followed: 1) Ensure prior authorization is obtained before conducting the test; 2) Document that the patient meets medical necessity criteria including neurodevelopmental delay, seizures, and negative prior CMA testing; 3) Include documentation from the genetic counselor who ordered the test; 4) Submit clinical notes documenting the family history of neurodevelopmental disorders; 5) Include the results of the previous chromosomal microarray test showing it was negative; 6) Provide justification for how the test results will impact clinical management of the patient's condition.\"}\n"
     ]
    }
   ],
   "source": [
    "def run_all_model_combinations(case_ex, questions_list, chatgpt_client, perplexity_api_key):\n",
    "    model_options = [\"chatgpt\", \"perplexity\"]\n",
    "    combinations = list(product(model_options, repeat=2))\n",
    "\n",
    "    for search_model, qna_model in combinations:\n",
    "        print(f\"\\nðŸš€ Starting experiments for: {search_model}_{qna_model}\\n\")\n",
    "\n",
    "        for case in case_ex:\n",
    "            case_id = case[\"id\"]\n",
    "            patient_info = case[\"patient_info\"]\n",
    "\n",
    "            print(f\"\\n=== Running for {case_id} ===\")\n",
    "\n",
    "            try:\n",
    "                policy_data = find_policy_summarize(\n",
    "                    patient_info_text=patient_info,\n",
    "                    model=search_model,\n",
    "                    chatgpt_client=chatgpt_client,\n",
    "                    perplexity_api_key=perplexity_api_key\n",
    "                )\n",
    "\n",
    "                policy_url = policy_data.get(\"policy_url\", \"No policy found\")\n",
    "                policy_summary = policy_data.get(\"policy_summary\", \"No relevant coverage criteria found\")\n",
    "\n",
    "                run_qna(\n",
    "                    case_id=case_id,\n",
    "                    patient_info_text=patient_info,\n",
    "                    policy_url=policy_url,\n",
    "                    policy_summary=policy_summary,\n",
    "                    questions_list=questions_list,\n",
    "                    qna_model=qna_model,\n",
    "                    chatgpt_client=chatgpt_client,  \n",
    "                    perplexity_api_key=perplexity_api_key,\n",
    "                    search_model=search_model\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Failed for {case_id} in {search_model}_{qna_model}\")\n",
    "                traceback.print_exc()\n",
    "\n",
    "run_all_model_combinations(\n",
    "    case_ex=case_ex,\n",
    "    questions_list=questions_list,\n",
    "    chatgpt_client=chatgpt_client,  \n",
    "    perplexity_api_key=perplexity_api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f1aea3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merged CSV saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/chatgpt_perplexity.csv\n",
      "âœ… Merged CSV saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/chatgpt_chatgpt.csv\n",
      "âœ… Merged CSV saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/perplexity_chatgpt.csv\n",
      "âœ… Merged CSV saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/perplexity_perplexity.csv\n"
     ]
    }
   ],
   "source": [
    "def merge_qna_jsons_to_csv(folder_path, output_csv_path):\n",
    "    all_data = []\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\"_qna_result.json\"):\n",
    "            case_id = file.replace(\"_qna_result.json\", \"\")\n",
    "            json_path = os.path.join(folder_path, file)\n",
    "\n",
    "            with open(json_path, \"r\") as f:\n",
    "                try:\n",
    "                    result = json.load(f)\n",
    "                    flat_result = {\"case_id\": case_id}\n",
    "\n",
    "                    for k, v in result.items():\n",
    "                        if isinstance(v, list):\n",
    "                            flat_result[k] = \"; \".join(map(str, v))\n",
    "                        else:\n",
    "                            flat_result[k] = v\n",
    "\n",
    "                    all_data.append(flat_result)\n",
    "                except Exception as e:\n",
    "                    print(f\"â— Failed to parse {file}: {e}\")\n",
    "\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        print(f\"âœ… Merged CSV saved to: {output_csv_path}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ No valid QnA result files found in: {folder_path}\")\n",
    "\n",
    "def merge_all_combinations_to_csv(base_dir):\n",
    "    for folder_name in os.listdir(base_dir):\n",
    "        folder_path = os.path.join(base_dir, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            output_csv = os.path.join(base_dir, f\"{folder_name}.csv\")\n",
    "            merge_qna_jsons_to_csv(folder_path, output_csv)\n",
    "\n",
    "\n",
    "merge_all_combinations_to_csv(\n",
    "    base_dir=\"/home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6c28993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_converted_results_from_folder(folder_path):\n",
    "    converted_results = {}\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\"_qna_result.json\"):\n",
    "            case_id = file.replace(\"_qna_result.json\", \"\")\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"â— JSON decode error in {file}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                clean = {}\n",
    "                for k, v in data.items():\n",
    "                    if k.endswith(\"_followup\"):\n",
    "                        clean[k] = v if isinstance(v, list) else [v]\n",
    "                    else:\n",
    "                        clean[k] = v\n",
    "\n",
    "                converted_results[case_id] = clean\n",
    "    return converted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a08c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_qna_result(case_id, predicted_result, gold_result, folder_path=None):\n",
    "    records = []\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for qid in gold_result:\n",
    "        if not qid.startswith(\"Q\") or qid == \"policy_url\" or qid == \"Q17\" or \"_followup\" in qid:\n",
    "            continue\n",
    "\n",
    "        pred_answer = predicted_result.get(qid, \"\")\n",
    "        gold_answer = gold_result.get(qid, \"\")\n",
    "\n",
    "        if isinstance(pred_answer, list):\n",
    "            pred_answer = \", \".join(pred_answer)\n",
    "        if isinstance(gold_answer, list):\n",
    "            gold_answer = \", \".join(gold_answer)\n",
    "\n",
    "        pred_answer = pred_answer.strip()\n",
    "        gold_answer = gold_answer.strip()\n",
    "\n",
    "        is_correct = pred_answer == gold_answer\n",
    "        score = 1 if is_correct else 0\n",
    "\n",
    "        records.append({\n",
    "            \"Case\": case_id,\n",
    "            \"Question\": qid,\n",
    "            \"Predicted\": pred_answer,\n",
    "            \"Gold\": gold_answer,\n",
    "            \"Score\": score\n",
    "        })\n",
    "\n",
    "        total_count += 1\n",
    "        correct_count += score\n",
    "\n",
    "        followup_key = qid + \"_followup\"\n",
    "        pred_followup = predicted_result.get(followup_key, None)\n",
    "        gold_followup = gold_result.get(followup_key, None)\n",
    "\n",
    "        if is_correct and gold_followup is not None:\n",
    "            def normalize(ans):\n",
    "                if ans is None:\n",
    "                    return \"None\"\n",
    "                if isinstance(ans, list):\n",
    "                    return \", \".join([a if isinstance(a, str) else a.get(\"answer\", str(a)) for a in ans])\n",
    "                return ans if isinstance(ans, str) else str(ans)\n",
    "\n",
    "            pred_followup_norm = normalize(pred_followup)\n",
    "            gold_followup_norm = normalize(gold_followup)\n",
    "\n",
    "            pred_set = set(pred_followup_norm.split(\", \"))\n",
    "            gold_set = set(gold_followup_norm.split(\", \"))\n",
    "\n",
    "            followup_score = 1 if pred_set & gold_set else 0\n",
    "\n",
    "            records.append({\n",
    "                \"Case\": case_id,\n",
    "                \"Question\": followup_key,\n",
    "                \"Predicted\": pred_followup_norm,\n",
    "                \"Gold\": gold_followup_norm,\n",
    "                \"Score\": followup_score\n",
    "            })\n",
    "\n",
    "            total_count += 1\n",
    "            correct_count += followup_score\n",
    "\n",
    "    accuracy = correct_count / total_count * 100 if total_count > 0 else 0\n",
    "\n",
    "    records.append({\n",
    "        \"Case\": case_id,\n",
    "        \"Question\": \"TOTAL\",\n",
    "        \"Predicted\": f\"Correct: {correct_count}\",\n",
    "        \"Gold\": f\"Incorrect: {total_count - correct_count}\",\n",
    "        \"Score\": f\"Accuracy: {accuracy:.2f}%\"\n",
    "    })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # âœ… Save CSV if folder_path is given\n",
    "    if folder_path:\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        csv_path = os.path.join(folder_path, f\"evaluation_{case_id}.csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"ðŸ“„ Saved evaluation to {csv_path}\")\n",
    "\n",
    "    return df, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5413a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_folders_with_summary(base_dir, gold_answers, summary_output_csv):\n",
    "    eval_output_dir = os.path.join(base_dir, \"Evaluation\")\n",
    "    os.makedirs(eval_output_dir, exist_ok=True)\n",
    "\n",
    "    summary_records = []\n",
    "\n",
    "    for folder_name in os.listdir(base_dir):\n",
    "        folder_path = os.path.join(base_dir, folder_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nðŸ“Š Evaluating folder: {folder_name}\")\n",
    "\n",
    "        converted_results = load_converted_results_from_folder(folder_path)\n",
    "        all_dfs = []\n",
    "        accuracies = []\n",
    "\n",
    "        for case_id, pred_result in converted_results.items():\n",
    "            gold_result = gold_answers.get(case_id)\n",
    "            if gold_result is None:\n",
    "                continue\n",
    "\n",
    "            df_case, acc = evaluate_qna_result(case_id, pred_result, gold_result)\n",
    "            all_dfs.append(df_case)\n",
    "            accuracies.append(acc)\n",
    "\n",
    "        if all_dfs:\n",
    "            merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "            eval_csv_path = os.path.join(eval_output_dir, f\"{folder_name}.csv\")\n",
    "            merged_df.to_csv(eval_csv_path, index=False)\n",
    "            print(f\"âœ… Saved: {eval_csv_path}\")\n",
    "\n",
    "            \n",
    "            summary_records.append({\n",
    "                \"Model_Combination\": folder_name,\n",
    "                \"Mean_Accuracy\": f\"{sum(accuracies)/len(accuracies):.2f}%\" if accuracies else \"N/A\"\n",
    "            })\n",
    "\n",
    "    \n",
    "    if summary_records:\n",
    "        summary_df = pd.DataFrame(summary_records)\n",
    "        os.makedirs(os.path.dirname(summary_output_csv), exist_ok=True)\n",
    "        summary_df.to_csv(summary_output_csv, index=False)\n",
    "        print(f\"\\nâœ… Summary saved to: {summary_output_csv}\")\n",
    "        print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ec450ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Evaluating folder: chatgpt_perplexity\n",
      "âœ… Saved: /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/Evaluation/chatgpt_perplexity.csv\n",
      "\n",
      "ðŸ“Š Evaluating folder: Evaluation\n",
      "\n",
      "ðŸ“Š Evaluating folder: chatgpt_chatgpt\n",
      "âœ… Saved: /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/Evaluation/chatgpt_chatgpt.csv\n",
      "\n",
      "ðŸ“Š Evaluating folder: perplexity_chatgpt\n",
      "âœ… Saved: /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/Evaluation/perplexity_chatgpt.csv\n",
      "\n",
      "ðŸ“Š Evaluating folder: perplexity_perplexity\n",
      "âœ… Saved: /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/Evaluation/perplexity_perplexity.csv\n",
      "\n",
      "âœ… Summary saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/Evaluation/summary_accuracy.csv\n",
      "       Model_Combination Mean_Accuracy\n",
      "0     chatgpt_perplexity        78.95%\n",
      "1        chatgpt_chatgpt        75.00%\n",
      "2     perplexity_chatgpt        70.00%\n",
      "3  perplexity_perplexity        78.95%\n"
     ]
    }
   ],
   "source": [
    "evaluate_all_folders_with_summary(\n",
    "    base_dir=\"/home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna\",\n",
    "    gold_answers=ground_truth,\n",
    "    summary_output_csv=\"/home/cptaswadu/RESCUE-n8n/insurance/results/LLM_QnA/End-To-End/search_summarize_qna/Evaluation/summary_accuracy.csv\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
