'use strict';

var n8nWorkflow = require('n8n-workflow');
var Functions = require('../../Functions-C6Ii13Vz.js');

var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

var name = "fhirpath";
var version$1 = "3.11.0";
var description = "A FHIRPath engine";
var main = "src/fhirpath.js";
var dependencies = {
	"@lhncbc/ucum-lhc": "^5.0.0",
	antlr4: "~4.9.3",
	commander: "^2.18.0",
	"date-fns": "^1.30.1",
	"js-yaml": "^3.13.1"
};
var devDependencies = {
	"@babel/core": "^7.21.4",
	"@babel/eslint-parser": "^7.17.0",
	"@babel/preset-env": "^7.16.11",
	"babel-loader": "^8.2.3",
	benny: "^3.7.1",
	bestzip: "^2.2.0",
	"copy-webpack-plugin": "^6.0.3",
	cypress: "^10.3.0",
	eslint: "^8.10.0",
	fhir: "^4.10.3",
	grunt: "^1.5.2",
	"grunt-cli": "^1.4.3",
	"grunt-text-replace": "^0.4.0",
	"jasmine-spec-reporter": "^4.2.1",
	jest: "^27.3.1",
	"jit-grunt": "^0.10.0",
	lodash: "^4.17.21",
	open: "^8.4.0",
	rimraf: "^3.0.0",
	tmp: "0.0.33",
	webpack: "^5.11.1",
	"webpack-bundle-analyzer": "^4.4.2",
	"webpack-cli": "^4.9.1",
	xml2js: "^0.5.0",
	yargs: "^15.1.0"
};
var engines = {
	node: ">=8.9.0"
};
var scripts = {
	generateParser: "cd src/parser; rimraf ./generated/*; java -Xmx500M -cp \"../../antlr-4.9.3-complete.jar:$CLASSPATH\" org.antlr.v4.Tool -o generated -Dlanguage=JavaScript FHIRPath.g4; grunt updateParserRequirements",
	build: "cd browser-build && webpack && rimraf fhirpath.zip && bestzip fhirpath.zip LICENSE.md fhirpath.min.js fhirpath.r5.min.js fhirpath.r4.min.js fhirpath.stu3.min.js fhirpath.dstu2.min.js && rimraf  LICENSE.md",
	"test:unit": "node --use_strict node_modules/.bin/jest && TZ=America/New_York node --use_strict node_modules/.bin/jest && TZ=Europe/Paris node --use_strict node_modules/.bin/jest",
	"test:unit:debug": "echo 'open chrome chrome://inspect/' && node --inspect node_modules/.bin/jest --runInBand",
	"build:demo": "npm run build && cd demo && npm run build",
	"test:e2e": "npm run build:demo && cypress run",
	test: "npm run lint && npm run test:unit && npm run test:e2e && echo \"For tests specific to IE 11, open browser-build/test/index.html in IE 11, and confirm that the tests on that page pass.\"",
	lint: "eslint src/parser/index.js src/*.js converter/",
	"compare-performance": "node ./test/benchmark.js"
};
var bin = {
	fhirpath: "bin/fhirpath"
};
var repository = "github:HL7/fhirpath.js";
var license$1 = "SEE LICENSE in LICENSE.md";
var require$$0 = {
	name: name,
	version: version$1,
	description: description,
	main: main,
	dependencies: dependencies,
	devDependencies: devDependencies,
	engines: engines,
	scripts: scripts,
	bin: bin,
	repository: repository,
	license: license$1
};

var antlr4Index = {};

var atn$2 = {};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

function valueToString(v) {
    return v === null ? "null" : v;
}

function arrayToString(a) {
    return Array.isArray(a) ? ("[" + a.map(valueToString).join(", ") + "]") : "null";
}

String.prototype.seed = String.prototype.seed || Math.round(Math.random() * Math.pow(2, 32));

String.prototype.hashCode = function () {
    const key = this.toString();
    let h1b, k1;

    const remainder = key.length & 3; // key.length % 4
    const bytes = key.length - remainder;
    let h1 = String.prototype.seed;
    const c1 = 0xcc9e2d51;
    const c2 = 0x1b873593;
    let i = 0;

    while (i < bytes) {
        k1 =
            ((key.charCodeAt(i) & 0xff)) |
            ((key.charCodeAt(++i) & 0xff) << 8) |
            ((key.charCodeAt(++i) & 0xff) << 16) |
            ((key.charCodeAt(++i) & 0xff) << 24);
        ++i;

        k1 = ((((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16))) & 0xffffffff;
        k1 = (k1 << 15) | (k1 >>> 17);
        k1 = ((((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16))) & 0xffffffff;

        h1 ^= k1;
        h1 = (h1 << 13) | (h1 >>> 19);
        h1b = ((((h1 & 0xffff) * 5) + ((((h1 >>> 16) * 5) & 0xffff) << 16))) & 0xffffffff;
        h1 = (((h1b & 0xffff) + 0x6b64) + ((((h1b >>> 16) + 0xe654) & 0xffff) << 16));
    }

    k1 = 0;

    switch (remainder) {
        case 3:
            k1 ^= (key.charCodeAt(i + 2) & 0xff) << 16;
        case 2:
            k1 ^= (key.charCodeAt(i + 1) & 0xff) << 8;
        case 1:
            k1 ^= (key.charCodeAt(i) & 0xff);

            k1 = (((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16)) & 0xffffffff;
            k1 = (k1 << 15) | (k1 >>> 17);
            k1 = (((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16)) & 0xffffffff;
            h1 ^= k1;
    }

    h1 ^= key.length;

    h1 ^= h1 >>> 16;
    h1 = (((h1 & 0xffff) * 0x85ebca6b) + ((((h1 >>> 16) * 0x85ebca6b) & 0xffff) << 16)) & 0xffffffff;
    h1 ^= h1 >>> 13;
    h1 = ((((h1 & 0xffff) * 0xc2b2ae35) + ((((h1 >>> 16) * 0xc2b2ae35) & 0xffff) << 16))) & 0xffffffff;
    h1 ^= h1 >>> 16;

    return h1 >>> 0;
};

function standardEqualsFunction(a, b) {
    return a ? a.equals(b) : a==b;
}

function standardHashCodeFunction(a) {
    return a ? a.hashCode() : -1;
}

let Set$6 = class Set {
    constructor(hashFunction, equalsFunction) {
        this.data = {};
        this.hashFunction = hashFunction || standardHashCodeFunction;
        this.equalsFunction = equalsFunction || standardEqualsFunction;
    }

    add(value) {
        const hash = this.hashFunction(value);
        const key = "hash_" + hash;
        if (key in this.data) {
            const values = this.data[key];
            for (let i = 0; i < values.length; i++) {
                if (this.equalsFunction(value, values[i])) {
                    return values[i];
                }
            }
            values.push(value);
            return value;
        } else {
            this.data[key] = [value];
            return value;
        }
    }

    contains(value) {
        return this.get(value) != null;
    }

    get(value) {
        const hash = this.hashFunction(value);
        const key = "hash_" + hash;
        if (key in this.data) {
            const values = this.data[key];
            for (let i = 0; i < values.length; i++) {
                if (this.equalsFunction(value, values[i])) {
                    return values[i];
                }
            }
        }
        return null;
    }

    values() {
        let l = [];
        for (const key in this.data) {
            if (key.indexOf("hash_") === 0) {
                l = l.concat(this.data[key]);
            }
        }
        return l;
    }

    toString() {
        return arrayToString(this.values());
    }

    get length(){
        let l = 0;
        for (const key in this.data) {
            if (key.indexOf("hash_") === 0) {
                l = l + this.data[key].length;
            }
        }
        return l;
    }
};


let BitSet$4 = class BitSet {
    constructor() {
        this.data = [];
    }

    add(value) {
        this.data[value] = true;
    }

    or(set) {
        const bits = this;
        Object.keys(set.data).map(function (alt) {
            bits.add(alt);
        });
    }

    remove(value) {
        delete this.data[value];
    }

    contains(value) {
        return this.data[value] === true;
    }

    values() {
        return Object.keys(this.data);
    }

    minValue() {
        return Math.min.apply(null, this.values());
    }

    hashCode() {
        const hash = new Hash$5();
        hash.update(this.values());
        return hash.finish();
    }

    equals(other) {
        if (!(other instanceof BitSet)) {
            return false;
        }
        return this.hashCode() === other.hashCode();
    }

    toString() {
        return "{" + this.values().join(", ") + "}";
    }

    get length(){
        return this.values().length;
    }
};


let Map$4 = class Map {
    constructor(hashFunction, equalsFunction) {
        this.data = {};
        this.hashFunction = hashFunction || standardHashCodeFunction;
        this.equalsFunction = equalsFunction || standardEqualsFunction;
    }

    put(key, value) {
        const hashKey = "hash_" + this.hashFunction(key);
        if (hashKey in this.data) {
            const entries = this.data[hashKey];
            for (let i = 0; i < entries.length; i++) {
                const entry = entries[i];
                if (this.equalsFunction(key, entry.key)) {
                    const oldValue = entry.value;
                    entry.value = value;
                    return oldValue;
                }
            }
            entries.push({key:key, value:value});
            return value;
        } else {
            this.data[hashKey] = [{key:key, value:value}];
            return value;
        }
    }

    containsKey(key) {
        const hashKey = "hash_" + this.hashFunction(key);
        if(hashKey in this.data) {
            const entries = this.data[hashKey];
            for (let i = 0; i < entries.length; i++) {
                const entry = entries[i];
                if (this.equalsFunction(key, entry.key))
                    return true;
            }
        }
        return false;
    }

    get(key) {
        const hashKey = "hash_" + this.hashFunction(key);
        if(hashKey in this.data) {
            const entries = this.data[hashKey];
            for (let i = 0; i < entries.length; i++) {
                const entry = entries[i];
                if (this.equalsFunction(key, entry.key))
                    return entry.value;
            }
        }
        return null;
    }

    entries() {
        let l = [];
        for (const key in this.data) {
            if (key.indexOf("hash_") === 0) {
                l = l.concat(this.data[key]);
            }
        }
        return l;
    }

    getKeys() {
        return this.entries().map(function(e) {
            return e.key;
        });
    }

    getValues() {
        return this.entries().map(function(e) {
                return e.value;
        });
    }

    toString() {
        const ss = this.entries().map(function(entry) {
            return '{' + entry.key + ':' + entry.value + '}';
        });
        return '[' + ss.join(", ") + ']';
    }

    get length(){
        let l = 0;
        for (const hashKey in this.data) {
            if (hashKey.indexOf("hash_") === 0) {
                l = l + this.data[hashKey].length;
            }
        }
        return l;
    }
};


let AltDict$1 = class AltDict {
    constructor() {
        this.data = {};
    }

    get(key) {
        key = "k-" + key;
        if (key in this.data) {
            return this.data[key];
        } else {
            return null;
        }
    }

    put(key, value) {
        key = "k-" + key;
        this.data[key] = value;
    }

    values() {
        const data = this.data;
        const keys = Object.keys(this.data);
        return keys.map(function (key) {
            return data[key];
        });
    }
};


let DoubleDict$1 = class DoubleDict {
    constructor(defaultMapCtor) {
        this.defaultMapCtor = defaultMapCtor || Map$4;
        this.cacheMap = new this.defaultMapCtor();
    }

    get(a, b) {
        const d = this.cacheMap.get(a) || null;
        return d === null ? null : (d.get(b) || null);
    }

    set(a, b, o) {
        let d = this.cacheMap.get(a) || null;
        if (d === null) {
            d = new this.defaultMapCtor();
            this.cacheMap.put(a, d);
        }
        d.put(b, o);
    }
};

let Hash$5 = class Hash {
    constructor() {
        this.count = 0;
        this.hash = 0;
    }

    update() {
        for(let i=0;i<arguments.length;i++) {
            const value = arguments[i];
            if (value == null)
                continue;
            if(Array.isArray(value))
                this.update.apply(this, value);
            else {
                let k = 0;
                switch (typeof(value)) {
                    case 'undefined':
                    case 'function':
                        continue;
                    case 'number':
                    case 'boolean':
                        k = value;
                        break;
                    case 'string':
                        k = value.hashCode();
                        break;
                    default:
                        if(value.updateHashCode)
                            value.updateHashCode(this);
                        else
                            console.log("No updateHashCode for " + value.toString());
                        continue;
                }
                k = k * 0xCC9E2D51;
                k = (k << 15) | (k >>> (32 - 15));
                k = k * 0x1B873593;
                this.count = this.count + 1;
                let hash = this.hash ^ k;
                hash = (hash << 13) | (hash >>> (32 - 13));
                hash = hash * 5 + 0xE6546B64;
                this.hash = hash;
            }
        }
    }

    finish() {
        let hash = this.hash ^ (this.count * 4);
        hash = hash ^ (hash >>> 16);
        hash = hash * 0x85EBCA6B;
        hash = hash ^ (hash >>> 13);
        hash = hash * 0xC2B2AE35;
        hash = hash ^ (hash >>> 16);
        return hash;
    }
};

function hashStuff$2() {
    const hash = new Hash$5();
    hash.update.apply(hash, arguments);
    return hash.finish();
}


function escapeWhitespace(s, escapeSpaces) {
    s = s.replace(/\t/g, "\\t")
         .replace(/\n/g, "\\n")
         .replace(/\r/g, "\\r");
    if (escapeSpaces) {
        s = s.replace(/ /g, "\u00B7");
    }
    return s;
}

function titleCase(str) {
    return str.replace(/\w\S*/g, function (txt) {
        return txt.charAt(0).toUpperCase() + txt.substr(1);
    });
}

function equalArrays$2(a, b) {
    if (!Array.isArray(a) || !Array.isArray(b))
        return false;
    if (a === b)
        return true;
    if (a.length !== b.length)
        return false;
    for (let i = 0; i < a.length; i++) {
        if (a[i] === b[i])
            continue;
        if (!a[i].equals || !a[i].equals(b[i]))
            return false;
    }
    return true;
}

var Utils$4 = {
    Hash: Hash$5,
    Set: Set$6,
    Map: Map$4,
    BitSet: BitSet$4,
    AltDict: AltDict$1,
    DoubleDict: DoubleDict$1,
    hashStuff: hashStuff$2,
    escapeWhitespace,
    arrayToString,
    titleCase,
    equalArrays: equalArrays$2
};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

/**
 * A token has properties: text, type, line, character position in the line
 * (so we can ignore tabs), token channel, index, and source from which
 * we obtained this token.
 */
let Token$g = class Token {
	constructor() {
		this.source = null;
		this.type = null; // token type of the token
		this.channel = null; // The parser ignores everything not on DEFAULT_CHANNEL
		this.start = null; // optional; return -1 if not implemented.
		this.stop = null; // optional; return -1 if not implemented.
		this.tokenIndex = null; // from 0..n-1 of the token object in the input stream
		this.line = null; // line=1..n of the 1st character
		this.column = null; // beginning of the line at which it occurs, 0..n-1
		this._text = null; // text of the token.
	}

	getTokenSource() {
		return this.source[0];
	}

	getInputStream() {
		return this.source[1];
	}

	get text(){
		return this._text;
	}

	set text(text) {
		this._text = text;
	}
};

Token$g.INVALID_TYPE = 0;

/**
 * During lookahead operations, this "token" signifies we hit rule end ATN state
 * and did not follow it despite needing to.
 */
Token$g.EPSILON = -2;

Token$g.MIN_USER_TOKEN_TYPE = 1;

Token$g.EOF = -1;

/**
 * All tokens go to the parser (unless skip() is called in that rule)
 * on a particular "channel". The parser tunes to a particular channel
 * so that whitespace etc... can go to the parser on a "hidden" channel.
 */
Token$g.DEFAULT_CHANNEL = 0;

/**
 * Anything on different channel than DEFAULT_CHANNEL is not parsed
 * by parser.
 */
Token$g.HIDDEN_CHANNEL = 1;


let CommonToken$1 = class CommonToken extends Token$g {
	constructor(source, type, channel, start, stop) {
		super();
		this.source = source !== undefined ? source : CommonToken.EMPTY_SOURCE;
		this.type = type !== undefined ? type : null;
		this.channel = channel !== undefined ? channel : Token$g.DEFAULT_CHANNEL;
		this.start = start !== undefined ? start : -1;
		this.stop = stop !== undefined ? stop : -1;
		this.tokenIndex = -1;
		if (this.source[0] !== null) {
			this.line = source[0].line;
			this.column = source[0].column;
		} else {
			this.column = -1;
		}
	}

	/**
	 * Constructs a new {@link CommonToken} as a copy of another {@link Token}.
	 *
	 * <p>
	 * If {@code oldToken} is also a {@link CommonToken} instance, the newly
	 * constructed token will share a reference to the {@link //text} field and
	 * the {@link Pair} stored in {@link //source}. Otherwise, {@link //text} will
	 * be assigned the result of calling {@link //getText}, and {@link //source}
	 * will be constructed from the result of {@link Token//getTokenSource} and
	 * {@link Token//getInputStream}.</p>
	 *
	 * @param oldToken The token to copy.
	 */
	clone() {
		const t = new CommonToken(this.source, this.type, this.channel, this.start, this.stop);
		t.tokenIndex = this.tokenIndex;
		t.line = this.line;
		t.column = this.column;
		t.text = this.text;
		return t;
	}

	toString() {
		let txt = this.text;
		if (txt !== null) {
			txt = txt.replace(/\n/g, "\\n").replace(/\r/g, "\\r").replace(/\t/g, "\\t");
		} else {
			txt = "<no text>";
		}
		return "[@" + this.tokenIndex + "," + this.start + ":" + this.stop + "='" +
				txt + "',<" + this.type + ">" +
				(this.channel > 0 ? ",channel=" + this.channel : "") + "," +
				this.line + ":" + this.column + "]";
	}

	get text(){
		if (this._text !== null) {
			return this._text;
		}
		const input = this.getInputStream();
		if (input === null) {
			return null;
		}
		const n = input.size;
		if (this.start < n && this.stop < n) {
			return input.getText(this.start, this.stop);
		} else {
			return "<EOF>";
		}
	}

	set text(text) {
		this._text = text;
	}
};

/**
 * An empty {@link Pair} which is used as the default value of
 * {@link //source} for tokens that do not have a source.
 */
CommonToken$1.EMPTY_SOURCE = [ null, null ];

var Token_1 = {
	Token: Token$g,
	CommonToken: CommonToken$1
};

var ATNConfig$4 = {};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

/**
 * The following images show the relation of states and
 * {@link ATNState//transitions} for various grammar constructs.
 *
 * <ul>
 *
 * <li>Solid edges marked with an &//0949; indicate a required
 * {@link EpsilonTransition}.</li>
 *
 * <li>Dashed edges indicate locations where any transition derived from
 * {@link Transition} might appear.</li>
 *
 * <li>Dashed nodes are place holders for either a sequence of linked
 * {@link BasicState} states or the inclusion of a block representing a nested
 * construct in one of the forms below.</li>
 *
 * <li>Nodes showing multiple outgoing alternatives with a {@code ...} support
 * any number of alternatives (one or more). Nodes without the {@code ...} only
 * support the exact number of alternatives shown in the diagram.</li>
 *
 * </ul>
 *
 * <h2>Basic Blocks</h2>
 *
 * <h3>Rule</h3>
 *
 * <embed src="images/Rule.svg" type="image/svg+xml"/>
 *
 * <h3>Block of 1 or more alternatives</h3>
 *
 * <embed src="images/Block.svg" type="image/svg+xml"/>
 *
 * <h2>Greedy Loops</h2>
 *
 * <h3>Greedy Closure: {@code (...)*}</h3>
 *
 * <embed src="images/ClosureGreedy.svg" type="image/svg+xml"/>
 *
 * <h3>Greedy Positive Closure: {@code (...)+}</h3>
 *
 * <embed src="images/PositiveClosureGreedy.svg" type="image/svg+xml"/>
 *
 * <h3>Greedy Optional: {@code (...)?}</h3>
 *
 * <embed src="images/OptionalGreedy.svg" type="image/svg+xml"/>
 *
 * <h2>Non-Greedy Loops</h2>
 *
 * <h3>Non-Greedy Closure: {@code (...)*?}</h3>
 *
 * <embed src="images/ClosureNonGreedy.svg" type="image/svg+xml"/>
 *
 * <h3>Non-Greedy Positive Closure: {@code (...)+?}</h3>
 *
 * <embed src="images/PositiveClosureNonGreedy.svg" type="image/svg+xml"/>
 *
 * <h3>Non-Greedy Optional: {@code (...)??}</h3>
 *
 * <embed src="images/OptionalNonGreedy.svg" type="image/svg+xml"/>
 */
let ATNState$3 = class ATNState {
    constructor() {
        // Which ATN are we in?
        this.atn = null;
        this.stateNumber = ATNState.INVALID_STATE_NUMBER;
        this.stateType = null;
        this.ruleIndex = 0; // at runtime, we don't have Rule objects
        this.epsilonOnlyTransitions = false;
        // Track the transitions emanating from this ATN state.
        this.transitions = [];
        // Used to cache lookahead during parsing, not used during construction
        this.nextTokenWithinRule = null;
    }

    toString() {
        return this.stateNumber;
    }

    equals(other) {
        if (other instanceof ATNState) {
            return this.stateNumber===other.stateNumber;
        } else {
            return false;
        }
    }

    isNonGreedyExitState() {
        return false;
    }

    addTransition(trans, index) {
        if(index===undefined) {
            index = -1;
        }
        if (this.transitions.length===0) {
            this.epsilonOnlyTransitions = trans.isEpsilon;
        } else if(this.epsilonOnlyTransitions !== trans.isEpsilon) {
            this.epsilonOnlyTransitions = false;
        }
        if (index===-1) {
            this.transitions.push(trans);
        } else {
            this.transitions.splice(index, 1, trans);
        }
    }
};

// constants for serialization
ATNState$3.INVALID_TYPE = 0;
ATNState$3.BASIC = 1;
ATNState$3.RULE_START = 2;
ATNState$3.BLOCK_START = 3;
ATNState$3.PLUS_BLOCK_START = 4;
ATNState$3.STAR_BLOCK_START = 5;
ATNState$3.TOKEN_START = 6;
ATNState$3.RULE_STOP = 7;
ATNState$3.BLOCK_END = 8;
ATNState$3.STAR_LOOP_BACK = 9;
ATNState$3.STAR_LOOP_ENTRY = 10;
ATNState$3.PLUS_LOOP_BACK = 11;
ATNState$3.LOOP_END = 12;

ATNState$3.serializationNames = [
            "INVALID",
            "BASIC",
            "RULE_START",
            "BLOCK_START",
            "PLUS_BLOCK_START",
            "STAR_BLOCK_START",
            "TOKEN_START",
            "RULE_STOP",
            "BLOCK_END",
            "STAR_LOOP_BACK",
            "STAR_LOOP_ENTRY",
            "PLUS_LOOP_BACK",
            "LOOP_END" ];

ATNState$3.INVALID_STATE_NUMBER = -1;


let BasicState$1 = class BasicState extends ATNState$3 {
    constructor() {
        super();
        this.stateType = ATNState$3.BASIC;
    }
};

let DecisionState$2 = class DecisionState extends ATNState$3 {
    constructor() {
        super();
        this.decision = -1;
        this.nonGreedy = false;
        return this;
    }
};

/**
 *  The start of a regular {@code (...)} block
 */
let BlockStartState$1 = class BlockStartState extends DecisionState$2 {
    constructor() {
        super();
        this.endState = null;
        return this;
    }
};

let BasicBlockStartState$1 = class BasicBlockStartState extends BlockStartState$1 {
    constructor() {
        super();
        this.stateType = ATNState$3.BLOCK_START;
        return this;
    }
};

/**
 * Terminal node of a simple {@code (a|b|c)} block
 */
let BlockEndState$1 = class BlockEndState extends ATNState$3 {
    constructor() {
        super();
        this.stateType = ATNState$3.BLOCK_END;
        this.startState = null;
        return this;
    }
};

/**
 * The last node in the ATN for a rule, unless that rule is the start symbol.
 * In that case, there is one transition to EOF. Later, we might encode
 * references to all calls to this rule to compute FOLLOW sets for
 * error handling
 */
let RuleStopState$5 = class RuleStopState extends ATNState$3 {
    constructor() {
        super();
        this.stateType = ATNState$3.RULE_STOP;
        return this;
    }
};

let RuleStartState$1 = class RuleStartState extends ATNState$3 {
    constructor() {
        super();
        this.stateType = ATNState$3.RULE_START;
        this.stopState = null;
        this.isPrecedenceRule = false;
        return this;
    }
};

/**
 * Decision state for {@code A+} and {@code (A|B)+}.  It has two transitions:
 * one to the loop back to start of the block and one to exit.
 */
let PlusLoopbackState$1 = class PlusLoopbackState extends DecisionState$2 {
    constructor() {
        super();
        this.stateType = ATNState$3.PLUS_LOOP_BACK;
        return this;
    }
};

/**
 * Start of {@code (A|B|...)+} loop. Technically a decision state, but
 * we don't use for code generation; somebody might need it, so I'm defining
 * it for completeness. In reality, the {@link PlusLoopbackState} node is the
 * real decision-making note for {@code A+}
 */
let PlusBlockStartState$1 = class PlusBlockStartState extends BlockStartState$1 {
    constructor() {
        super();
        this.stateType = ATNState$3.PLUS_BLOCK_START;
        this.loopBackState = null;
        return this;
    }
};

/**
 * The block that begins a closure loop
 */
let StarBlockStartState$1 = class StarBlockStartState extends BlockStartState$1 {
    constructor() {
        super();
        this.stateType = ATNState$3.STAR_BLOCK_START;
        return this;
    }
};

let StarLoopbackState$1 = class StarLoopbackState extends ATNState$3 {
    constructor() {
        super();
        this.stateType = ATNState$3.STAR_LOOP_BACK;
        return this;
    }
};

let StarLoopEntryState$2 = class StarLoopEntryState extends DecisionState$2 {
    constructor() {
        super();
        this.stateType = ATNState$3.STAR_LOOP_ENTRY;
        this.loopBackState = null;
        // Indicates whether this state can benefit from a precedence DFA during SLL decision making.
        this.isPrecedenceDecision = null;
        return this;
    }
};

/**
 * Mark the end of a * or + loop
 */
let LoopEndState$1 = class LoopEndState extends ATNState$3 {
    constructor() {
        super();
        this.stateType = ATNState$3.LOOP_END;
        this.loopBackState = null;
        return this;
    }
};

/**
 * The Tokens rule start state linking to each lexer rule start state
 */
let TokensStartState$1 = class TokensStartState extends DecisionState$2 {
    constructor() {
        super();
        this.stateType = ATNState$3.TOKEN_START;
        return this;
    }
};

var ATNState_1 = {
    ATNState: ATNState$3,
    BasicState: BasicState$1,
    DecisionState: DecisionState$2,
    BlockStartState: BlockStartState$1,
    BlockEndState: BlockEndState$1,
    LoopEndState: LoopEndState$1,
    RuleStartState: RuleStartState$1,
    RuleStopState: RuleStopState$5,
    TokensStartState: TokensStartState$1,
    PlusLoopbackState: PlusLoopbackState$1,
    StarLoopbackState: StarLoopbackState$1,
    StarLoopEntryState: StarLoopEntryState$2,
    PlusBlockStartState: PlusBlockStartState$1,
    StarBlockStartState: StarBlockStartState$1,
    BasicBlockStartState: BasicBlockStartState$1
};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const { Set: Set$5, Hash: Hash$4, equalArrays: equalArrays$1 } = Utils$4;

/**
 * A tree structure used to record the semantic context in which
 * an ATN configuration is valid.  It's either a single predicate,
 * a conjunction {@code p1&&p2}, or a sum of products {@code p1||p2}.
 *
 * <p>I have scoped the {@link AND}, {@link OR}, and {@link Predicate} subclasses of
 * {@link SemanticContext} within the scope of this outer class.</p>
 */
let SemanticContext$4 = class SemanticContext {

	hashCode() {
		const hash = new Hash$4();
		this.updateHashCode(hash);
		return hash.finish();
	}

	/**
	 * For context independent predicates, we evaluate them without a local
	 * context (i.e., null context). That way, we can evaluate them without
	 * having to create proper rule-specific context during prediction (as
	 * opposed to the parser, which creates them naturally). In a practical
	 * sense, this avoids a cast exception from RuleContext to myruleContext.
	 *
	 * <p>For context dependent predicates, we must pass in a local context so that
	 * references such as $arg evaluate properly as _localctx.arg. We only
	 * capture context dependent predicates in the context in which we begin
	 * prediction, so we passed in the outer context here in case of context
	 * dependent predicate evaluation.</p>
	 */
	evaluate(parser, outerContext) {}

	/**
	 * Evaluate the precedence predicates for the context and reduce the result.
	 *
	 * @param parser The parser instance.
	 * @param outerContext The current parser context object.
	 * @return The simplified semantic context after precedence predicates are
	 * evaluated, which will be one of the following values.
	 * <ul>
	 * <li>{@link //NONE}: if the predicate simplifies to {@code true} after
	 * precedence predicates are evaluated.</li>
	 * <li>{@code null}: if the predicate simplifies to {@code false} after
	 * precedence predicates are evaluated.</li>
	 * <li>{@code this}: if the semantic context is not changed as a result of
	 * precedence predicate evaluation.</li>
	 * <li>A non-{@code null} {@link SemanticContext}: the new simplified
	 * semantic context after precedence predicates are evaluated.</li>
	 * </ul>
	 */
	evalPrecedence(parser, outerContext) {
		return this;
	}

	static andContext(a, b) {
		if (a === null || a === SemanticContext.NONE) {
			return b;
		}
		if (b === null || b === SemanticContext.NONE) {
			return a;
		}
		const result = new AND(a, b);
		if (result.opnds.length === 1) {
			return result.opnds[0];
		} else {
			return result;
		}
	}

	static orContext(a, b) {
		if (a === null) {
			return b;
		}
		if (b === null) {
			return a;
		}
		if (a === SemanticContext.NONE || b === SemanticContext.NONE) {
			return SemanticContext.NONE;
		}
		const result = new OR(a, b);
		if (result.opnds.length === 1) {
			return result.opnds[0];
		} else {
			return result;
		}
	}
};


let Predicate$1 = class Predicate extends SemanticContext$4 {

	constructor(ruleIndex, predIndex, isCtxDependent) {
		super();
		this.ruleIndex = ruleIndex === undefined ? -1 : ruleIndex;
		this.predIndex = predIndex === undefined ? -1 : predIndex;
		this.isCtxDependent = isCtxDependent === undefined ? false : isCtxDependent; // e.g., $i ref in pred
	}

	evaluate(parser, outerContext) {
		const localctx = this.isCtxDependent ? outerContext : null;
		return parser.sempred(localctx, this.ruleIndex, this.predIndex);
	}

	updateHashCode(hash) {
		hash.update(this.ruleIndex, this.predIndex, this.isCtxDependent);
	}

	equals(other) {
		if (this === other) {
			return true;
		} else if (!(other instanceof Predicate)) {
			return false;
		} else {
			return this.ruleIndex === other.ruleIndex &&
					this.predIndex === other.predIndex &&
					this.isCtxDependent === other.isCtxDependent;
		}
	}

	toString() {
		return "{" + this.ruleIndex + ":" + this.predIndex + "}?";
	}
};

/**
 * The default {@link SemanticContext}, which is semantically equivalent to
 * a predicate of the form {@code {true}?}
 */
SemanticContext$4.NONE = new Predicate$1();


let PrecedencePredicate$1 = class PrecedencePredicate extends SemanticContext$4 {

	constructor(precedence) {
		super();
		this.precedence = precedence === undefined ? 0 : precedence;
	}

	evaluate(parser, outerContext) {
		return parser.precpred(outerContext, this.precedence);
	}

	evalPrecedence(parser, outerContext) {
		if (parser.precpred(outerContext, this.precedence)) {
			return SemanticContext$4.NONE;
		} else {
			return null;
		}
	}

	compareTo(other) {
		return this.precedence - other.precedence;
	}

	updateHashCode(hash) {
		hash.update(this.precedence);
	}

	equals(other) {
		if (this === other) {
			return true;
		} else if (!(other instanceof PrecedencePredicate)) {
			return false;
		} else {
			return this.precedence === other.precedence;
		}
	}

	toString() {
		return "{" + this.precedence + ">=prec}?";
	}

	static filterPrecedencePredicates(set) {
		const result = [];
		set.values().map( function(context) {
			if (context instanceof PrecedencePredicate) {
				result.push(context);
			}
		});
		return result;
	}
};

class AND extends SemanticContext$4 {
	/**
	 * A semantic context which is true whenever none of the contained contexts
	 * is false
	 */
	constructor(a, b) {
		super();
		const operands = new Set$5();
		if (a instanceof AND) {
			a.opnds.map(function(o) {
				operands.add(o);
			});
		} else {
			operands.add(a);
		}
		if (b instanceof AND) {
			b.opnds.map(function(o) {
				operands.add(o);
			});
		} else {
			operands.add(b);
		}
		const precedencePredicates = PrecedencePredicate$1.filterPrecedencePredicates(operands);
		if (precedencePredicates.length > 0) {
			// interested in the transition with the lowest precedence
			let reduced = null;
			precedencePredicates.map( function(p) {
				if(reduced===null || p.precedence<reduced.precedence) {
					reduced = p;
				}
			});
			operands.add(reduced);
		}
		this.opnds = Array.from(operands.values());
	}

	equals(other) {
		if (this === other) {
			return true;
		} else if (!(other instanceof AND)) {
			return false;
		} else {
			return equalArrays$1(this.opnds, other.opnds);
		}
	}

	updateHashCode(hash) {
		hash.update(this.opnds, "AND");
	}

	/**
	 * {@inheritDoc}
	 *
	 * <p>
	 * The evaluation of predicates by this context is short-circuiting, but
	 * unordered.</p>
	 */
	evaluate(parser, outerContext) {
		for (let i = 0; i < this.opnds.length; i++) {
			if (!this.opnds[i].evaluate(parser, outerContext)) {
				return false;
			}
		}
		return true;
	}

	evalPrecedence(parser, outerContext) {
		let differs = false;
		const operands = [];
		for (let i = 0; i < this.opnds.length; i++) {
			const context = this.opnds[i];
			const evaluated = context.evalPrecedence(parser, outerContext);
			differs |= (evaluated !== context);
			if (evaluated === null) {
				// The AND context is false if any element is false
				return null;
			} else if (evaluated !== SemanticContext$4.NONE) {
				// Reduce the result by skipping true elements
				operands.push(evaluated);
			}
		}
		if (!differs) {
			return this;
		}
		if (operands.length === 0) {
			// all elements were true, so the AND context is true
			return SemanticContext$4.NONE;
		}
		let result = null;
		operands.map(function(o) {
			result = result === null ? o : SemanticContext$4.andContext(result, o);
		});
		return result;
	}

	toString() {
		const s = this.opnds.map(o => o.toString());
		return (s.length > 3 ? s.slice(3) : s).join("&&");
	}
}


class OR extends SemanticContext$4 {
	/**
	 * A semantic context which is true whenever at least one of the contained
	 * contexts is true
	 */
	constructor(a, b) {
		super();
		const operands = new Set$5();
		if (a instanceof OR) {
			a.opnds.map(function(o) {
				operands.add(o);
			});
		} else {
			operands.add(a);
		}
		if (b instanceof OR) {
			b.opnds.map(function(o) {
				operands.add(o);
			});
		} else {
			operands.add(b);
		}

		const precedencePredicates = PrecedencePredicate$1.filterPrecedencePredicates(operands);
		if (precedencePredicates.length > 0) {
			// interested in the transition with the highest precedence
			const s = precedencePredicates.sort(function(a, b) {
				return a.compareTo(b);
			});
			const reduced = s[s.length-1];
			operands.add(reduced);
		}
		this.opnds = Array.from(operands.values());
	}

	equals(other) {
		if (this === other) {
			return true;
		} else if (!(other instanceof OR)) {
			return false;
		} else {
			return equalArrays$1(this.opnds, other.opnds);
		}
	}

	updateHashCode(hash) {
		hash.update(this.opnds, "OR");
	}

	/**
	 * <p>
	 * The evaluation of predicates by this context is short-circuiting, but
	 * unordered.</p>
	 */
	evaluate(parser, outerContext) {
		for (let i = 0; i < this.opnds.length; i++) {
			if (this.opnds[i].evaluate(parser, outerContext)) {
				return true;
			}
		}
		return false;
	}

	evalPrecedence(parser, outerContext) {
		let differs = false;
		const operands = [];
		for (let i = 0; i < this.opnds.length; i++) {
			const context = this.opnds[i];
			const evaluated = context.evalPrecedence(parser, outerContext);
			differs |= (evaluated !== context);
			if (evaluated === SemanticContext$4.NONE) {
				// The OR context is true if any element is true
				return SemanticContext$4.NONE;
			} else if (evaluated !== null) {
				// Reduce the result by skipping false elements
				operands.push(evaluated);
			}
		}
		if (!differs) {
			return this;
		}
		if (operands.length === 0) {
			// all elements were false, so the OR context is false
			return null;
		}
		const result = null;
		return result;
	}

	toString() {
		const s = this.opnds.map(o => o.toString());
		return (s.length > 3 ? s.slice(3) : s).join("||");
	}
}

var SemanticContext_1 = {
	SemanticContext: SemanticContext$4,
	PrecedencePredicate: PrecedencePredicate$1,
	Predicate: Predicate$1
};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {DecisionState: DecisionState$1} = ATNState_1;
const {SemanticContext: SemanticContext$3} = SemanticContext_1;
const {Hash: Hash$3} = Utils$4;


function checkParams(params, isCfg) {
	if(params===null) {
		const result = { state:null, alt:null, context:null, semanticContext:null };
		if(isCfg) {
			result.reachesIntoOuterContext = 0;
		}
		return result;
	} else {
		const props = {};
		props.state = params.state || null;
		props.alt = (params.alt === undefined) ? null : params.alt;
		props.context = params.context || null;
		props.semanticContext = params.semanticContext || null;
		if(isCfg) {
			props.reachesIntoOuterContext = params.reachesIntoOuterContext || 0;
			props.precedenceFilterSuppressed = params.precedenceFilterSuppressed || false;
		}
		return props;
	}
}

let ATNConfig$3 = class ATNConfig {
    /**
     * @param {Object} params A tuple: (ATN state, predicted alt, syntactic, semantic context).
     * The syntactic context is a graph-structured stack node whose
     * path(s) to the root is the rule invocation(s)
     * chain used to arrive at the state.  The semantic context is
     * the tree of semantic predicates encountered before reaching
     * an ATN state
     */
    constructor(params, config) {
        this.checkContext(params, config);
        params = checkParams(params);
        config = checkParams(config, true);
        // The ATN state associated with this configuration///
        this.state = params.state!==null ? params.state : config.state;
        // What alt (or lexer rule) is predicted by this configuration///
        this.alt = params.alt!==null ? params.alt : config.alt;
        /**
         * The stack of invoking states leading to the rule/states associated
         * with this config.  We track only those contexts pushed during
         * execution of the ATN simulator
         */
        this.context = params.context!==null ? params.context : config.context;
        this.semanticContext = params.semanticContext!==null ? params.semanticContext :
            (config.semanticContext!==null ? config.semanticContext : SemanticContext$3.NONE);
        // TODO: make it a boolean then
        /**
         * We cannot execute predicates dependent upon local context unless
         * we know for sure we are in the correct context. Because there is
         * no way to do this efficiently, we simply cannot evaluate
         * dependent predicates unless we are in the rule that initially
         * invokes the ATN simulator.
         * closure() tracks the depth of how far we dip into the
         * outer context: depth &gt; 0.  Note that it may not be totally
         * accurate depth since I don't ever decrement
         */
        this.reachesIntoOuterContext = config.reachesIntoOuterContext;
        this.precedenceFilterSuppressed = config.precedenceFilterSuppressed;
    }

    checkContext(params, config) {
        if((params.context===null || params.context===undefined) &&
                (config===null || config.context===null || config.context===undefined)) {
            this.context = null;
        }
    }

    hashCode() {
        const hash = new Hash$3();
        this.updateHashCode(hash);
        return hash.finish();
    }

    updateHashCode(hash) {
        hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext);
    }

    /**
     * An ATN configuration is equal to another if both have
     * the same state, they predict the same alternative, and
     * syntactic/semantic contexts are the same
     */
    equals(other) {
        if (this === other) {
            return true;
        } else if (! (other instanceof ATNConfig)) {
            return false;
        } else {
            return this.state.stateNumber===other.state.stateNumber &&
                this.alt===other.alt &&
                (this.context===null ? other.context===null : this.context.equals(other.context)) &&
                this.semanticContext.equals(other.semanticContext) &&
                this.precedenceFilterSuppressed===other.precedenceFilterSuppressed;
        }
    }

    hashCodeForConfigSet() {
        const hash = new Hash$3();
        hash.update(this.state.stateNumber, this.alt, this.semanticContext);
        return hash.finish();
    }

    equalsForConfigSet(other) {
        if (this === other) {
            return true;
        } else if (! (other instanceof ATNConfig)) {
            return false;
        } else {
            return this.state.stateNumber===other.state.stateNumber &&
                this.alt===other.alt &&
                this.semanticContext.equals(other.semanticContext);
        }
    }

    toString() {
        return "(" + this.state + "," + this.alt +
            (this.context!==null ? ",[" + this.context.toString() + "]" : "") +
            (this.semanticContext !== SemanticContext$3.NONE ?
                    ("," + this.semanticContext.toString())
                    : "") +
            (this.reachesIntoOuterContext>0 ?
                    (",up=" + this.reachesIntoOuterContext)
                    : "") + ")";
    }
};


let LexerATNConfig$1 = class LexerATNConfig extends ATNConfig$3 {
    constructor(params, config) {
        super(params, config);

        // This is the backing field for {@link //getLexerActionExecutor}.
        const lexerActionExecutor = params.lexerActionExecutor || null;
        this.lexerActionExecutor = lexerActionExecutor || (config!==null ? config.lexerActionExecutor : null);
        this.passedThroughNonGreedyDecision = config!==null ? this.checkNonGreedyDecision(config, this.state) : false;
        this.hashCodeForConfigSet = LexerATNConfig.prototype.hashCode;
        this.equalsForConfigSet = LexerATNConfig.prototype.equals;
        return this;
    }

    updateHashCode(hash) {
        hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext, this.passedThroughNonGreedyDecision, this.lexerActionExecutor);
    }

    equals(other) {
        return this === other ||
                (other instanceof LexerATNConfig &&
                this.passedThroughNonGreedyDecision === other.passedThroughNonGreedyDecision &&
                (this.lexerActionExecutor ? this.lexerActionExecutor.equals(other.lexerActionExecutor) : !other.lexerActionExecutor) &&
                super.equals(other));
    }

    checkNonGreedyDecision(source, target) {
        return source.passedThroughNonGreedyDecision ||
            (target instanceof DecisionState$1) && target.nonGreedy;
    }
};


ATNConfig$4.ATNConfig = ATNConfig$3;
ATNConfig$4.LexerATNConfig = LexerATNConfig$1;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Token: Token$f} = Token_1;

/* stop is not included! */
let Interval$7 = class Interval {

	constructor(start, stop) {
		this.start = start;
		this.stop = stop;
	}

	clone() {
		return new Interval(this.start, this.stop);
	}

	contains(item) {
		return item >= this.start && item < this.stop;
	}

	toString() {
		if(this.start===this.stop-1) {
			return this.start.toString();
		} else {
			return this.start.toString() + ".." + (this.stop-1).toString();
		}
	}

	get length(){
		return this.stop - this.start;
	}
};


let IntervalSet$5 = class IntervalSet {
	constructor() {
		this.intervals = null;
		this.readOnly = false;
	}

	first(v) {
		if (this.intervals === null || this.intervals.length===0) {
			return Token$f.INVALID_TYPE;
		} else {
			return this.intervals[0].start;
		}
	}

	addOne(v) {
		this.addInterval(new Interval$7(v, v + 1));
	}

	addRange(l, h) {
		this.addInterval(new Interval$7(l, h + 1));
	}

	addInterval(toAdd) {
		if (this.intervals === null) {
			this.intervals = [];
			this.intervals.push(toAdd.clone());
		} else {
			// find insert pos
			for (let pos = 0; pos < this.intervals.length; pos++) {
				const existing = this.intervals[pos];
				// distinct range -> insert
				if (toAdd.stop < existing.start) {
					this.intervals.splice(pos, 0, toAdd);
					return;
				}
				// contiguous range -> adjust
				else if (toAdd.stop === existing.start) {
					this.intervals[pos] = new Interval$7(toAdd.start, existing.stop);
					return;
				}
				// overlapping range -> adjust and reduce
				else if (toAdd.start <= existing.stop) {
					this.intervals[pos] = new Interval$7(Math.min(existing.start, toAdd.start), Math.max(existing.stop, toAdd.stop));
					this.reduce(pos);
					return;
				}
			}
			// greater than any existing
			this.intervals.push(toAdd.clone());
		}
	}

	addSet(other) {
		if (other.intervals !== null) {
			other.intervals.forEach( toAdd => this.addInterval(toAdd), this);
		}
		return this;
	}

	reduce(pos) {
		// only need to reduce if pos is not the last
		if (pos < this.intervals.length - 1) {
			const current = this.intervals[pos];
			const next = this.intervals[pos + 1];
			// if next contained in current
			if (current.stop >= next.stop) {
				this.intervals.splice(pos + 1, 1);
				this.reduce(pos);
			} else if (current.stop >= next.start) {
				this.intervals[pos] = new Interval$7(current.start, next.stop);
				this.intervals.splice(pos + 1, 1);
			}
		}
	}

	complement(start, stop) {
		const result = new IntervalSet();
		result.addInterval(new Interval$7(start, stop + 1));
		if(this.intervals !== null)
			this.intervals.forEach(toRemove => result.removeRange(toRemove));
		return result;
	}

	contains(item) {
		if (this.intervals === null) {
			return false;
		} else {
			for (let k = 0; k < this.intervals.length; k++) {
				if(this.intervals[k].contains(item)) {
					return true;
				}
			}
			return false;
		}
	}

	removeRange(toRemove) {
		if(toRemove.start===toRemove.stop-1) {
			this.removeOne(toRemove.start);
		} else if (this.intervals !== null) {
			let pos = 0;
			for(let n=0; n<this.intervals.length; n++) {
				const existing = this.intervals[pos];
				// intervals are ordered
				if (toRemove.stop<=existing.start) {
					return;
				}
				// check for including range, split it
				else if(toRemove.start>existing.start && toRemove.stop<existing.stop) {
					this.intervals[pos] = new Interval$7(existing.start, toRemove.start);
					const x = new Interval$7(toRemove.stop, existing.stop);
					this.intervals.splice(pos, 0, x);
					return;
				}
				// check for included range, remove it
				else if(toRemove.start<=existing.start && toRemove.stop>=existing.stop) {
					this.intervals.splice(pos, 1);
					pos = pos - 1; // need another pass
				}
				// check for lower boundary
				else if(toRemove.start<existing.stop) {
					this.intervals[pos] = new Interval$7(existing.start, toRemove.start);
				}
				// check for upper boundary
				else if(toRemove.stop<existing.stop) {
					this.intervals[pos] = new Interval$7(toRemove.stop, existing.stop);
				}
				pos += 1;
			}
		}
	}

	removeOne(value) {
		if (this.intervals !== null) {
			for (let i = 0; i < this.intervals.length; i++) {
				const existing = this.intervals[i];
				// intervals are ordered
				if (value < existing.start) {
					return;
				}
				// check for single value range
				else if (value === existing.start && value === existing.stop - 1) {
					this.intervals.splice(i, 1);
					return;
				}
				// check for lower boundary
				else if (value === existing.start) {
					this.intervals[i] = new Interval$7(existing.start + 1, existing.stop);
					return;
				}
				// check for upper boundary
				else if (value === existing.stop - 1) {
					this.intervals[i] = new Interval$7(existing.start, existing.stop - 1);
					return;
				}
				// split existing range
				else if (value < existing.stop - 1) {
					const replace = new Interval$7(existing.start, value);
					existing.start = value + 1;
					this.intervals.splice(i, 0, replace);
					return;
				}
			}
		}
	}

	toString(literalNames, symbolicNames, elemsAreChar) {
		literalNames = literalNames || null;
		symbolicNames = symbolicNames || null;
		elemsAreChar = elemsAreChar || false;
		if (this.intervals === null) {
			return "{}";
		} else if(literalNames!==null || symbolicNames!==null) {
			return this.toTokenString(literalNames, symbolicNames);
		} else if(elemsAreChar) {
			return this.toCharString();
		} else {
			return this.toIndexString();
		}
	}

	toCharString() {
		const names = [];
		for (let i = 0; i < this.intervals.length; i++) {
			const existing = this.intervals[i];
			if(existing.stop===existing.start+1) {
				if ( existing.start===Token$f.EOF ) {
					names.push("<EOF>");
				} else {
					names.push("'" + String.fromCharCode(existing.start) + "'");
				}
			} else {
				names.push("'" + String.fromCharCode(existing.start) + "'..'" + String.fromCharCode(existing.stop-1) + "'");
			}
		}
		if (names.length > 1) {
			return "{" + names.join(", ") + "}";
		} else {
			return names[0];
		}
	}

	toIndexString() {
		const names = [];
		for (let i = 0; i < this.intervals.length; i++) {
			const existing = this.intervals[i];
			if(existing.stop===existing.start+1) {
				if ( existing.start===Token$f.EOF ) {
					names.push("<EOF>");
				} else {
					names.push(existing.start.toString());
				}
			} else {
				names.push(existing.start.toString() + ".." + (existing.stop-1).toString());
			}
		}
		if (names.length > 1) {
			return "{" + names.join(", ") + "}";
		} else {
			return names[0];
		}
	}

	toTokenString(literalNames, symbolicNames) {
		const names = [];
		for (let i = 0; i < this.intervals.length; i++) {
			const existing = this.intervals[i];
			for (let j = existing.start; j < existing.stop; j++) {
				names.push(this.elementName(literalNames, symbolicNames, j));
			}
		}
		if (names.length > 1) {
			return "{" + names.join(", ") + "}";
		} else {
			return names[0];
		}
	}

	elementName(literalNames, symbolicNames, token) {
		if (token === Token$f.EOF) {
			return "<EOF>";
		} else if (token === Token$f.EPSILON) {
			return "<EPSILON>";
		} else {
			return literalNames[token] || symbolicNames[token];
		}
	}

	get length(){
		return this.intervals.map( interval => interval.length ).reduce((acc, val) => acc + val);
	}
};

var IntervalSet_1 = {
	Interval: Interval$7,
	IntervalSet: IntervalSet$5
};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Token: Token$e} = Token_1;
const {IntervalSet: IntervalSet$4} = IntervalSet_1;
const {Predicate, PrecedencePredicate} = SemanticContext_1;

/**
 * An ATN transition between any two ATN states.  Subclasses define
 * atom, set, epsilon, action, predicate, rule transitions.
 *
 * <p>This is a one way link.  It emanates from a state (usually via a list of
 * transitions) and has a target state.</p>
 *
 * <p>Since we never have to change the ATN transitions once we construct it,
 * we can fix these transitions as specific classes. The DFA transitions
 * on the other hand need to update the labels as it adds transitions to
 * the states. We'll use the term Edge for the DFA to distinguish them from
 * ATN transitions.</p>
 */
let Transition$3 = class Transition {
    constructor(target) {
        // The target of this transition.
        if (target===undefined || target===null) {
            throw "target cannot be null.";
        }
        this.target = target;
        // Are we epsilon, action, sempred?
        this.isEpsilon = false;
        this.label = null;
    }
};

// constants for serialization

Transition$3.EPSILON = 1;
Transition$3.RANGE = 2;
Transition$3.RULE = 3;
// e.g., {isType(input.LT(1))}?
Transition$3.PREDICATE = 4;
Transition$3.ATOM = 5;
Transition$3.ACTION = 6;
// ~(A|B) or ~atom, wildcard, which convert to next 2
Transition$3.SET = 7;
Transition$3.NOT_SET = 8;
Transition$3.WILDCARD = 9;
Transition$3.PRECEDENCE = 10;

Transition$3.serializationNames = [
            "INVALID",
            "EPSILON",
            "RANGE",
            "RULE",
            "PREDICATE",
            "ATOM",
            "ACTION",
            "SET",
            "NOT_SET",
            "WILDCARD",
            "PRECEDENCE"
        ];

Transition$3.serializationTypes = {
        EpsilonTransition: Transition$3.EPSILON,
        RangeTransition: Transition$3.RANGE,
        RuleTransition: Transition$3.RULE,
        PredicateTransition: Transition$3.PREDICATE,
        AtomTransition: Transition$3.ATOM,
        ActionTransition: Transition$3.ACTION,
        SetTransition: Transition$3.SET,
        NotSetTransition: Transition$3.NOT_SET,
        WildcardTransition: Transition$3.WILDCARD,
        PrecedencePredicateTransition: Transition$3.PRECEDENCE
    };


// TODO: make all transitions sets? no, should remove set edges

let AtomTransition$2 = class AtomTransition extends Transition$3 {
    constructor(target, label) {
        super(target);
        // The token type or character value; or, signifies special label.
        this.label_ = label;
        this.label = this.makeLabel();
        this.serializationType = Transition$3.ATOM;
    }

    makeLabel() {
        const s = new IntervalSet$4();
        s.addOne(this.label_);
        return s;
    }

    matches(symbol, minVocabSymbol, maxVocabSymbol) {
        return this.label_ === symbol;
    }

    toString() {
        return this.label_;
    }
};


let RuleTransition$3 = class RuleTransition extends Transition$3 {
    constructor(ruleStart, ruleIndex, precedence, followState) {
        super(ruleStart);
        // ptr to the rule definition object for this rule ref
        this.ruleIndex = ruleIndex;
        this.precedence = precedence;
        // what node to begin computations following ref to rule
        this.followState = followState;
        this.serializationType = Transition$3.RULE;
        this.isEpsilon = true;
    }

    matches(symbol, minVocabSymbol, maxVocabSymbol) {
        return false;
    }
};

let EpsilonTransition$1 = class EpsilonTransition extends Transition$3 {
    constructor(target, outermostPrecedenceReturn) {
        super(target);
        this.serializationType = Transition$3.EPSILON;
        this.isEpsilon = true;
        this.outermostPrecedenceReturn = outermostPrecedenceReturn;
    }

    matches(symbol, minVocabSymbol, maxVocabSymbol) {
        return false;
    }

    toString() {
        return "epsilon";
    }
};


let RangeTransition$1 = class RangeTransition extends Transition$3 {
    constructor(target, start, stop) {
        super(target);
        this.serializationType = Transition$3.RANGE;
        this.start = start;
        this.stop = stop;
        this.label = this.makeLabel();
    }

    makeLabel() {
        const s = new IntervalSet$4();
        s.addRange(this.start, this.stop);
        return s;
    }

    matches(symbol, minVocabSymbol, maxVocabSymbol) {
        return symbol >= this.start && symbol <= this.stop;
    }

    toString() {
        return "'" + String.fromCharCode(this.start) + "'..'" + String.fromCharCode(this.stop) + "'";
    }
};


let AbstractPredicateTransition$1 = class AbstractPredicateTransition extends Transition$3 {
    constructor(target) {
        super(target);
    }
};

let PredicateTransition$2 = class PredicateTransition extends AbstractPredicateTransition$1 {
    constructor(target, ruleIndex, predIndex, isCtxDependent) {
        super(target);
        this.serializationType = Transition$3.PREDICATE;
        this.ruleIndex = ruleIndex;
        this.predIndex = predIndex;
        this.isCtxDependent = isCtxDependent; // e.g., $i ref in pred
        this.isEpsilon = true;
    }

    matches(symbol, minVocabSymbol, maxVocabSymbol) {
        return false;
    }

    getPredicate() {
        return new Predicate(this.ruleIndex, this.predIndex, this.isCtxDependent);
    }

    toString() {
        return "pred_" + this.ruleIndex + ":" + this.predIndex;
    }
};


let ActionTransition$2 = class ActionTransition extends Transition$3 {
    constructor(target, ruleIndex, actionIndex, isCtxDependent) {
        super(target);
        this.serializationType = Transition$3.ACTION;
        this.ruleIndex = ruleIndex;
        this.actionIndex = actionIndex===undefined ? -1 : actionIndex;
        this.isCtxDependent = isCtxDependent===undefined ? false : isCtxDependent; // e.g., $i ref in pred
        this.isEpsilon = true;
    }

    matches(symbol, minVocabSymbol, maxVocabSymbol) {
        return false;
    }

    toString() {
        return "action_" + this.ruleIndex + ":" + this.actionIndex;
    }
};


// A transition containing a set of values.
let SetTransition$2 = class SetTransition extends Transition$3 {
    constructor(target, set) {
        super(target);
        this.serializationType = Transition$3.SET;
        if (set !==undefined && set !==null) {
            this.label = set;
        } else {
            this.label = new IntervalSet$4();
            this.label.addOne(Token$e.INVALID_TYPE);
        }
    }

    matches(symbol, minVocabSymbol, maxVocabSymbol) {
        return this.label.contains(symbol);
    }

    toString() {
        return this.label.toString();
    }
};

let NotSetTransition$3 = class NotSetTransition extends SetTransition$2 {
    constructor(target, set) {
        super(target, set);
        this.serializationType = Transition$3.NOT_SET;
    }

    matches(symbol, minVocabSymbol, maxVocabSymbol) {
        return symbol >= minVocabSymbol && symbol <= maxVocabSymbol &&
                !super.matches(symbol, minVocabSymbol, maxVocabSymbol);
    }

    toString() {
        return '~' + super.toString();
    }
};

let WildcardTransition$2 = class WildcardTransition extends Transition$3 {
    constructor(target) {
        super(target);
        this.serializationType = Transition$3.WILDCARD;
    }

    matches(symbol, minVocabSymbol, maxVocabSymbol) {
        return symbol >= minVocabSymbol && symbol <= maxVocabSymbol;
    }

    toString() {
        return ".";
    }
};

let PrecedencePredicateTransition$1 = class PrecedencePredicateTransition extends AbstractPredicateTransition$1 {
    constructor(target, precedence) {
        super(target);
        this.serializationType = Transition$3.PRECEDENCE;
        this.precedence = precedence;
        this.isEpsilon = true;
    }

    matches(symbol, minVocabSymbol, maxVocabSymbol) {
        return false;
    }

    getPredicate() {
        return new PrecedencePredicate(this.precedence);
    }

    toString() {
        return this.precedence + " >= _p";
    }
};

var Transition_1 = {
    Transition: Transition$3,
    AtomTransition: AtomTransition$2,
    SetTransition: SetTransition$2,
    NotSetTransition: NotSetTransition$3,
    RuleTransition: RuleTransition$3,
    ActionTransition: ActionTransition$2,
    EpsilonTransition: EpsilonTransition$1,
    RangeTransition: RangeTransition$1,
    WildcardTransition: WildcardTransition$2,
    PredicateTransition: PredicateTransition$2,
    PrecedencePredicateTransition: PrecedencePredicateTransition$1,
    AbstractPredicateTransition: AbstractPredicateTransition$1
};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Token: Token$d} = Token_1;
const {Interval: Interval$6} = IntervalSet_1;
const INVALID_INTERVAL$2 = new Interval$6(-1, -2);

/**
 * The basic notion of a tree has a parent, a payload, and a list of children.
 * It is the most abstract interface for all the trees used by ANTLR.
 */
let Tree$2 = class Tree {};

class SyntaxTree extends Tree$2 {
	constructor() {
		super();
	}
}

class ParseTree extends SyntaxTree {
	constructor() {
		super();
	}
}

let RuleNode$2 = class RuleNode extends ParseTree {
	constructor() {
		super();
	}

	getRuleContext(){
		throw new Error("missing interface implementation")
	}
};

let TerminalNode$3 = class TerminalNode extends ParseTree {
	constructor() {
		super();
	}
};

let ErrorNode$2 = class ErrorNode extends TerminalNode$3 {
	constructor() {
		super();
	}
};

class ParseTreeVisitor {
	visit(ctx) {
		 if (Array.isArray(ctx)) {
			return ctx.map(function(child) {
				return child.accept(this);
			}, this);
		} else {
			return ctx.accept(this);
		}
	}

	visitChildren(ctx) {
		if (ctx.children) {
			return this.visit(ctx.children);
		} else {
			return null;
		}
	}

	visitTerminal(node) {
	}

	visitErrorNode(node) {
	}
}

let ParseTreeListener$1 = class ParseTreeListener {
	visitTerminal(node) {
	}

	visitErrorNode(node) {
	}

	enterEveryRule(node) {
	}

	exitEveryRule(node) {
	}
};

let TerminalNodeImpl$1 = class TerminalNodeImpl extends TerminalNode$3 {
	constructor(symbol) {
		super();
		this.parentCtx = null;
		this.symbol = symbol;
	}

	getChild(i) {
		return null;
	}

	getSymbol() {
		return this.symbol;
	}

	getParent() {
		return this.parentCtx;
	}

	getPayload() {
		return this.symbol;
	}

	getSourceInterval() {
		if (this.symbol === null) {
			return INVALID_INTERVAL$2;
		}
		const tokenIndex = this.symbol.tokenIndex;
		return new Interval$6(tokenIndex, tokenIndex);
	}

	getChildCount() {
		return 0;
	}

	accept(visitor) {
		return visitor.visitTerminal(this);
	}

	getText() {
		return this.symbol.text;
	}

	toString() {
		if (this.symbol.type === Token$d.EOF) {
			return "<EOF>";
		} else {
			return this.symbol.text;
		}
	}
};


/**
 * Represents a token that was consumed during resynchronization
 * rather than during a valid match operation. For example,
 * we will create this kind of a node during single token insertion
 * and deletion as well as during "consume until error recovery set"
 * upon no viable alternative exceptions.
 */
let ErrorNodeImpl$1 = class ErrorNodeImpl extends TerminalNodeImpl$1 {
	constructor(token) {
		super(token);
	}

	isErrorNode() {
		return true;
	}

	accept(visitor) {
		return visitor.visitErrorNode(this);
	}
};

class ParseTreeWalker {

	/**
	 * Performs a walk on the given parse tree starting at the root and going down recursively
	 * with depth-first search. On each node, {@link ParseTreeWalker//enterRule} is called before
	 * recursively walking down into child nodes, then
	 * {@link ParseTreeWalker//exitRule} is called after the recursive call to wind up.
	 * @param listener The listener used by the walker to process grammar rules
	 * @param t The parse tree to be walked on
	 */
	walk(listener, t) {
		const errorNode = t instanceof ErrorNode$2 ||
				(t.isErrorNode !== undefined && t.isErrorNode());
		if (errorNode) {
			listener.visitErrorNode(t);
		} else if (t instanceof TerminalNode$3) {
			listener.visitTerminal(t);
		} else {
			this.enterRule(listener, t);
			for (let i = 0; i < t.getChildCount(); i++) {
				const child = t.getChild(i);
				this.walk(listener, child);
			}
			this.exitRule(listener, t);
		}
	}

	/**
	 * Enters a grammar rule by first triggering the generic event {@link ParseTreeListener//enterEveryRule}
	 * then by triggering the event specific to the given parse tree node
	 * @param listener The listener responding to the trigger events
	 * @param r The grammar rule containing the rule context
	 */
	enterRule(listener, r) {
		const ctx = r.getRuleContext();
		listener.enterEveryRule(ctx);
		ctx.enterRule(listener);
	}

	/**
	 * Exits a grammar rule by first triggering the event specific to the given parse tree node
	 * then by triggering the generic event {@link ParseTreeListener//exitEveryRule}
	 * @param listener The listener responding to the trigger events
	 * @param r The grammar rule containing the rule context
	 */
	exitRule(listener, r) {
		const ctx = r.getRuleContext();
		ctx.exitRule(listener);
		listener.exitEveryRule(ctx);
	}
}

ParseTreeWalker.DEFAULT = new ParseTreeWalker();

var Tree_1 = {
	RuleNode: RuleNode$2,
	ErrorNode: ErrorNode$2,
	TerminalNode: TerminalNode$3,
	ErrorNodeImpl: ErrorNodeImpl$1,
	TerminalNodeImpl: TerminalNodeImpl$1,
	ParseTreeListener: ParseTreeListener$1,
	ParseTreeVisitor,
	ParseTreeWalker,
	INVALID_INTERVAL: INVALID_INTERVAL$2
};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const Utils$3 = Utils$4;
const {Token: Token$c} = Token_1;
const {ErrorNode: ErrorNode$1, TerminalNode: TerminalNode$2, RuleNode: RuleNode$1} = Tree_1;

/** A set of utility routines useful for all kinds of ANTLR trees. */
const Trees$2 = {
    /**
     * Print out a whole tree in LISP form. {@link //getNodeText} is used on the
     *  node payloads to get the text for the nodes.  Detect
     *  parse trees and extract data appropriately.
     */
    toStringTree: function(tree, ruleNames, recog) {
        ruleNames = ruleNames || null;
        recog = recog || null;
        if(recog!==null) {
            ruleNames = recog.ruleNames;
        }
        let s = Trees$2.getNodeText(tree, ruleNames);
        s = Utils$3.escapeWhitespace(s, false);
        const c = tree.getChildCount();
        if(c===0) {
            return s;
        }
        let res = "(" + s + ' ';
        if(c>0) {
            s = Trees$2.toStringTree(tree.getChild(0), ruleNames);
            res = res.concat(s);
        }
        for(let i=1;i<c;i++) {
            s = Trees$2.toStringTree(tree.getChild(i), ruleNames);
            res = res.concat(' ' + s);
        }
        res = res.concat(")");
        return res;
    },

    getNodeText: function(t, ruleNames, recog) {
        ruleNames = ruleNames || null;
        recog = recog || null;
        if(recog!==null) {
            ruleNames = recog.ruleNames;
        }
        if(ruleNames!==null) {
            if (t instanceof RuleNode$1) {
                const context = t.getRuleContext();
                const altNumber = context.getAltNumber();
                // use const value of ATN.INVALID_ALT_NUMBER to avoid circular dependency
                if ( altNumber != 0 ) {
                    return ruleNames[t.ruleIndex]+":"+altNumber;
                }
                return ruleNames[t.ruleIndex];
            } else if ( t instanceof ErrorNode$1) {
                return t.toString();
            } else if(t instanceof TerminalNode$2) {
                if(t.symbol!==null) {
                    return t.symbol.text;
                }
            }
        }
        // no recog for rule names
        const payload = t.getPayload();
        if (payload instanceof Token$c ) {
            return payload.text;
        }
        return t.getPayload().toString();
    },

    /**
     * Return ordered list of all children of this node
     */
    getChildren: function(t) {
        const list = [];
        for(let i=0;i<t.getChildCount();i++) {
            list.push(t.getChild(i));
        }
        return list;
    },

    /**
     * Return a list of all ancestors of this node.  The first node of
     * list is the root and the last is the parent of this node.
     */
    getAncestors: function(t) {
        let ancestors = [];
        t = t.getParent();
        while(t!==null) {
            ancestors = [t].concat(ancestors);
            t = t.getParent();
        }
        return ancestors;
    },

    findAllTokenNodes: function(t, ttype) {
        return Trees$2.findAllNodes(t, ttype, true);
    },

    findAllRuleNodes: function(t, ruleIndex) {
        return Trees$2.findAllNodes(t, ruleIndex, false);
    },

    findAllNodes: function(t, index, findTokens) {
        const nodes = [];
        Trees$2._findAllNodes(t, index, findTokens, nodes);
        return nodes;
    },

    _findAllNodes: function(t, index, findTokens, nodes) {
        // check this node (the root) first
        if(findTokens && (t instanceof TerminalNode$2)) {
            if(t.symbol.type===index) {
                nodes.push(t);
            }
        } else if(!findTokens && (t instanceof RuleNode$1)) {
            if(t.ruleIndex===index) {
                nodes.push(t);
            }
        }
        // check children
        for(let i=0;i<t.getChildCount();i++) {
            Trees$2._findAllNodes(t.getChild(i), index, findTokens, nodes);
        }
    },

    descendants: function(t) {
        let nodes = [t];
        for(let i=0;i<t.getChildCount();i++) {
            nodes = nodes.concat(Trees$2.descendants(t.getChild(i)));
        }
        return nodes;
    }
};

var Trees_1 = Trees$2;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {RuleNode} = Tree_1;
const {INVALID_INTERVAL: INVALID_INTERVAL$1} = Tree_1;
const Trees$1 = Trees_1;

let RuleContext$3 = class RuleContext extends RuleNode {
	/** A rule context is a record of a single rule invocation. It knows
	 * which context invoked it, if any. If there is no parent context, then
	 * naturally the invoking state is not valid.  The parent link
	 * provides a chain upwards from the current rule invocation to the root
	 * of the invocation tree, forming a stack. We actually carry no
	 * information about the rule associated with this context (except
	 * when parsing). We keep only the state number of the invoking state from
	 * the ATN submachine that invoked this. Contrast this with the s
	 * pointer inside ParserRuleContext that tracks the current state
	 * being "executed" for the current rule.
	 *
	 * The parent contexts are useful for computing lookahead sets and
	 * getting error information.
	 *
	 * These objects are used during parsing and prediction.
	 * For the special case of parsers, we use the subclass
	 * ParserRuleContext.
	 *
	 * @see ParserRuleContext
	 */
	constructor(parent, invokingState) {
		// What context invoked this rule?
		super();
		this.parentCtx = parent || null;
		/**
		 * What state invoked the rule associated with this context?
		 * The "return address" is the followState of invokingState
		 * If parent is null, this should be -1.
		 */
		this.invokingState = invokingState || -1;
	}

	depth() {
		let n = 0;
		let p = this;
		while (p !== null) {
			p = p.parentCtx;
			n += 1;
		}
		return n;
	}

	/**
	 * A context is empty if there is no invoking state; meaning nobody call
	 * current context.
	 */
	isEmpty() {
		return this.invokingState === -1;
	}

// satisfy the ParseTree / SyntaxTree interface
	getSourceInterval() {
		return INVALID_INTERVAL$1;
	}

	getRuleContext() {
		return this;
	}

	getPayload() {
		return this;
	}

	/**
	 * Return the combined text of all child nodes. This method only considers
	 * tokens which have been added to the parse tree.
	 * <p>
	 * Since tokens on hidden channels (e.g. whitespace or comments) are not
	 * added to the parse trees, they will not appear in the output of this
	 * method.
	 */
	getText() {
		if (this.getChildCount() === 0) {
			return "";
		} else {
			return this.children.map(function(child) {
				return child.getText();
			}).join("");
		}
	}

	/**
	 * For rule associated with this parse tree internal node, return
	 * the outer alternative number used to match the input. Default
	 * implementation does not compute nor store this alt num. Create
	 * a subclass of ParserRuleContext with backing field and set
	 * option contextSuperClass.
	 * to set it.
	 */
	getAltNumber() {
	    // use constant value of ATN.INVALID_ALT_NUMBER to avoid circular dependency
	    return 0;
    }

	/**
	 * Set the outer alternative number for this context node. Default
	 * implementation does nothing to avoid backing field overhead for
	 * trees that don't need it.  Create
	 * a subclass of ParserRuleContext with backing field and set
	 * option contextSuperClass.
	 */
	setAltNumber(altNumber) { }

	getChild(i) {
		return null;
	}

	getChildCount() {
		return 0;
	}

	accept(visitor) {
		return visitor.visitChildren(this);
	}

	/**
	 * Print out a whole tree, not just a node, in LISP format
	 * (root child1 .. childN). Print just a node if this is a leaf.
	 */
	toStringTree(ruleNames, recog) {
		return Trees$1.toStringTree(this, ruleNames, recog);
	}

	toString(ruleNames, stop) {
		ruleNames = ruleNames || null;
		stop = stop || null;
		let p = this;
		let s = "[";
		while (p !== null && p !== stop) {
			if (ruleNames === null) {
				if (!p.isEmpty()) {
					s += p.invokingState;
				}
			} else {
				const ri = p.ruleIndex;
				const ruleName = (ri >= 0 && ri < ruleNames.length) ? ruleNames[ri]
						: "" + ri;
				s += ruleName;
			}
			if (p.parentCtx !== null && (ruleNames !== null || !p.parentCtx.isEmpty())) {
				s += " ";
			}
			p = p.parentCtx;
		}
		s += "]";
		return s;
	}
};

var RuleContext_1 = RuleContext$3;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const RuleContext$2 = RuleContext_1;
const {Hash: Hash$2, Map: Map$3, equalArrays} = Utils$4;

let PredictionContext$3 = class PredictionContext {

	constructor(cachedHashCode) {
		this.cachedHashCode = cachedHashCode;
	}

	/**
	 * Stores the computed hash code of this {@link PredictionContext}. The hash
	 * code is computed in parts to match the following reference algorithm.
	 *
	 * <pre>
	 * private int referenceHashCode() {
	 * int hash = {@link MurmurHash//initialize MurmurHash.initialize}({@link
	 * //INITIAL_HASH});
	 *
	 * for (int i = 0; i &lt; {@link //size()}; i++) {
	 * hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link //getParent
	 * getParent}(i));
	 * }
	 *
	 * for (int i = 0; i &lt; {@link //size()}; i++) {
	 * hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link
	 * //getReturnState getReturnState}(i));
	 * }
	 *
	 * hash = {@link MurmurHash//finish MurmurHash.finish}(hash, 2// {@link
	 * //size()});
	 * return hash;
	 * }
	 * </pre>
	 * This means only the {@link //EMPTY} context is in set.
	 */
	isEmpty() {
		return this === PredictionContext.EMPTY;
	}

	hasEmptyPath() {
		return this.getReturnState(this.length - 1) === PredictionContext.EMPTY_RETURN_STATE;
	}

	hashCode() {
		return this.cachedHashCode;
	}

	updateHashCode(hash) {
		hash.update(this.cachedHashCode);
	}
};

/**
 * Represents {@code $} in local context prediction, which means wildcard.
 * {@code//+x =//}.
 */
PredictionContext$3.EMPTY = null;

/**
 * Represents {@code $} in an array in full context mode, when {@code $}
 * doesn't mean wildcard: {@code $ + x = [$,x]}. Here,
 * {@code $} = {@link //EMPTY_RETURN_STATE}.
 */
PredictionContext$3.EMPTY_RETURN_STATE = 0x7FFFFFFF;

PredictionContext$3.globalNodeCount = 1;
PredictionContext$3.id = PredictionContext$3.globalNodeCount;


/*
function calculateHashString(parent, returnState) {
	return "" + parent + returnState;
}
*/

/**
 * Used to cache {@link PredictionContext} objects. Its used for the shared
 * context cash associated with contexts in DFA states. This cache
 * can be used for both lexers and parsers.
 */
class PredictionContextCache {

	constructor() {
		this.cache = new Map$3();
	}

	/**
	 * Add a context to the cache and return it. If the context already exists,
	 * return that one instead and do not add a new context to the cache.
	 * Protect shared cache from unsafe thread access.
	 */
	add(ctx) {
		if (ctx === PredictionContext$3.EMPTY) {
			return PredictionContext$3.EMPTY;
		}
		const existing = this.cache.get(ctx) || null;
		if (existing !== null) {
			return existing;
		}
		this.cache.put(ctx, ctx);
		return ctx;
	}

	get(ctx) {
		return this.cache.get(ctx) || null;
	}

	get length(){
		return this.cache.length;
	}
}


let SingletonPredictionContext$3 = class SingletonPredictionContext extends PredictionContext$3 {

	constructor(parent, returnState) {
		let hashCode = 0;
		const hash = new Hash$2();
		if(parent !== null) {
			hash.update(parent, returnState);
		} else {
			hash.update(1);
		}
		hashCode = hash.finish();
		super(hashCode);
		this.parentCtx = parent;
		this.returnState = returnState;
	}

	getParent(index) {
		return this.parentCtx;
	}

	getReturnState(index) {
		return this.returnState;
	}

	equals(other) {
		if (this === other) {
			return true;
		} else if (!(other instanceof SingletonPredictionContext)) {
			return false;
		} else if (this.hashCode() !== other.hashCode()) {
			return false; // can't be same if hash is different
		} else {
			if(this.returnState !== other.returnState)
				return false;
			else if(this.parentCtx==null)
				return other.parentCtx==null
			else
				return this.parentCtx.equals(other.parentCtx);
		}
	}

	toString() {
		const up = this.parentCtx === null ? "" : this.parentCtx.toString();
		if (up.length === 0) {
			if (this.returnState === PredictionContext$3.EMPTY_RETURN_STATE) {
				return "$";
			} else {
				return "" + this.returnState;
			}
		} else {
			return "" + this.returnState + " " + up;
		}
	}

	get length(){
		return 1;
	}

	static create(parent, returnState) {
		if (returnState === PredictionContext$3.EMPTY_RETURN_STATE && parent === null) {
			// someone can pass in the bits of an array ctx that mean $
			return PredictionContext$3.EMPTY;
		} else {
			return new SingletonPredictionContext(parent, returnState);
		}
	}
};

class EmptyPredictionContext extends SingletonPredictionContext$3 {

	constructor() {
		super(null, PredictionContext$3.EMPTY_RETURN_STATE);
	}

	isEmpty() {
		return true;
	}

	getParent(index) {
		return null;
	}

	getReturnState(index) {
		return this.returnState;
	}

	equals(other) {
		return this === other;
	}

	toString() {
		return "$";
	}
}


PredictionContext$3.EMPTY = new EmptyPredictionContext();

class ArrayPredictionContext extends PredictionContext$3 {

	constructor(parents, returnStates) {
		/**
		 * Parent can be null only if full ctx mode and we make an array
		 * from {@link //EMPTY} and non-empty. We merge {@link //EMPTY} by using
		 * null parent and
		 * returnState == {@link //EMPTY_RETURN_STATE}.
		 */
		const h = new Hash$2();
		h.update(parents, returnStates);
		const hashCode = h.finish();
		super(hashCode);
		this.parents = parents;
		this.returnStates = returnStates;
		return this;
	}

	isEmpty() {
		// since EMPTY_RETURN_STATE can only appear in the last position, we
		// don't need to verify that size==1
		return this.returnStates[0] === PredictionContext$3.EMPTY_RETURN_STATE;
	}

	getParent(index) {
		return this.parents[index];
	}

	getReturnState(index) {
		return this.returnStates[index];
	}

	equals(other) {
		if (this === other) {
			return true;
		} else if (!(other instanceof ArrayPredictionContext)) {
			return false;
		} else if (this.hashCode() !== other.hashCode()) {
			return false; // can't be same if hash is different
		} else {
			return equalArrays(this.returnStates, other.returnStates) &&
				equalArrays(this.parents, other.parents);
		}
	}

	toString() {
		if (this.isEmpty()) {
			return "[]";
		} else {
			let s = "[";
			for (let i = 0; i < this.returnStates.length; i++) {
				if (i > 0) {
					s = s + ", ";
				}
				if (this.returnStates[i] === PredictionContext$3.EMPTY_RETURN_STATE) {
					s = s + "$";
					continue;
				}
				s = s + this.returnStates[i];
				if (this.parents[i] !== null) {
					s = s + " " + this.parents[i];
				} else {
					s = s + "null";
				}
			}
			return s + "]";
		}
	}

	get length(){
		return this.returnStates.length;
	}
}


/**
 * Convert a {@link RuleContext} tree to a {@link PredictionContext} graph.
 * Return {@link //EMPTY} if {@code outerContext} is empty or null.
 */
function predictionContextFromRuleContext$2(atn, outerContext) {
	if (outerContext === undefined || outerContext === null) {
		outerContext = RuleContext$2.EMPTY;
	}
	// if we are in RuleContext of start rule, s, then PredictionContext
	// is EMPTY. Nobody called us. (if we are empty, return empty)
	if (outerContext.parentCtx === null || outerContext === RuleContext$2.EMPTY) {
		return PredictionContext$3.EMPTY;
	}
	// If we have a parent, convert it to a PredictionContext graph
	const parent = predictionContextFromRuleContext$2(atn, outerContext.parentCtx);
	const state = atn.states[outerContext.invokingState];
	const transition = state.transitions[0];
	return SingletonPredictionContext$3.create(parent, transition.followState.stateNumber);
}
/*
function calculateListsHashString(parents, returnStates) {
	const s = "";
	parents.map(function(p) {
		s = s + p;
	});
	returnStates.map(function(r) {
		s = s + r;
	});
	return s;
}
*/
function merge$1(a, b, rootIsWildcard, mergeCache) {
	// share same graph if both same
	if (a === b) {
		return a;
	}
	if (a instanceof SingletonPredictionContext$3 && b instanceof SingletonPredictionContext$3) {
		return mergeSingletons(a, b, rootIsWildcard, mergeCache);
	}
	// At least one of a or b is array
	// If one is $ and rootIsWildcard, return $ as// wildcard
	if (rootIsWildcard) {
		if (a instanceof EmptyPredictionContext) {
			return a;
		}
		if (b instanceof EmptyPredictionContext) {
			return b;
		}
	}
	// convert singleton so both are arrays to normalize
	if (a instanceof SingletonPredictionContext$3) {
		a = new ArrayPredictionContext([a.getParent()], [a.returnState]);
	}
	if (b instanceof SingletonPredictionContext$3) {
		b = new ArrayPredictionContext([b.getParent()], [b.returnState]);
	}
	return mergeArrays(a, b, rootIsWildcard, mergeCache);
}

/**
 * Merge two {@link SingletonPredictionContext} instances.
 *
 * <p>Stack tops equal, parents merge is same; return left graph.<br>
 * <embed src="images/SingletonMerge_SameRootSamePar.svg"
 * type="image/svg+xml"/></p>
 *
 * <p>Same stack top, parents differ; merge parents giving array node, then
 * remainders of those graphs. A new root node is created to point to the
 * merged parents.<br>
 * <embed src="images/SingletonMerge_SameRootDiffPar.svg"
 * type="image/svg+xml"/></p>
 *
 * <p>Different stack tops pointing to same parent. Make array node for the
 * root where both element in the root point to the same (original)
 * parent.<br>
 * <embed src="images/SingletonMerge_DiffRootSamePar.svg"
 * type="image/svg+xml"/></p>
 *
 * <p>Different stack tops pointing to different parents. Make array node for
 * the root where each element points to the corresponding original
 * parent.<br>
 * <embed src="images/SingletonMerge_DiffRootDiffPar.svg"
 * type="image/svg+xml"/></p>
 *
 * @param a the first {@link SingletonPredictionContext}
 * @param b the second {@link SingletonPredictionContext}
 * @param rootIsWildcard {@code true} if this is a local-context merge,
 * otherwise false to indicate a full-context merge
 * @param mergeCache
 */
function mergeSingletons(a, b, rootIsWildcard, mergeCache) {
	if (mergeCache !== null) {
		let previous = mergeCache.get(a, b);
		if (previous !== null) {
			return previous;
		}
		previous = mergeCache.get(b, a);
		if (previous !== null) {
			return previous;
		}
	}

	const rootMerge = mergeRoot(a, b, rootIsWildcard);
	if (rootMerge !== null) {
		if (mergeCache !== null) {
			mergeCache.set(a, b, rootMerge);
		}
		return rootMerge;
	}
	if (a.returnState === b.returnState) {
		const parent = merge$1(a.parentCtx, b.parentCtx, rootIsWildcard, mergeCache);
		// if parent is same as existing a or b parent or reduced to a parent,
		// return it
		if (parent === a.parentCtx) {
			return a; // ax + bx = ax, if a=b
		}
		if (parent === b.parentCtx) {
			return b; // ax + bx = bx, if a=b
		}
		// else: ax + ay = a'[x,y]
		// merge parents x and y, giving array node with x,y then remainders
		// of those graphs. dup a, a' points at merged array
		// new joined parent so create new singleton pointing to it, a'
		const spc = SingletonPredictionContext$3.create(parent, a.returnState);
		if (mergeCache !== null) {
			mergeCache.set(a, b, spc);
		}
		return spc;
	} else { // a != b payloads differ
		// see if we can collapse parents due to $+x parents if local ctx
		let singleParent = null;
		if (a === b || (a.parentCtx !== null && a.parentCtx === b.parentCtx)) { // ax +
																				// bx =
																				// [a,b]x
			singleParent = a.parentCtx;
		}
		if (singleParent !== null) { // parents are same
			// sort payloads and use same parent
			const payloads = [ a.returnState, b.returnState ];
			if (a.returnState > b.returnState) {
				payloads[0] = b.returnState;
				payloads[1] = a.returnState;
			}
			const parents = [ singleParent, singleParent ];
			const apc = new ArrayPredictionContext(parents, payloads);
			if (mergeCache !== null) {
				mergeCache.set(a, b, apc);
			}
			return apc;
		}
		// parents differ and can't merge them. Just pack together
		// into array; can't merge.
		// ax + by = [ax,by]
		const payloads = [ a.returnState, b.returnState ];
		let parents = [ a.parentCtx, b.parentCtx ];
		if (a.returnState > b.returnState) { // sort by payload
			payloads[0] = b.returnState;
			payloads[1] = a.returnState;
			parents = [ b.parentCtx, a.parentCtx ];
		}
		const a_ = new ArrayPredictionContext(parents, payloads);
		if (mergeCache !== null) {
			mergeCache.set(a, b, a_);
		}
		return a_;
	}
}

/**
 * Handle case where at least one of {@code a} or {@code b} is
 * {@link //EMPTY}. In the following diagrams, the symbol {@code $} is used
 * to represent {@link //EMPTY}.
 *
 * <h2>Local-Context Merges</h2>
 *
 * <p>These local-context merge operations are used when {@code rootIsWildcard}
 * is true.</p>
 *
 * <p>{@link //EMPTY} is superset of any graph; return {@link //EMPTY}.<br>
 * <embed src="images/LocalMerge_EmptyRoot.svg" type="image/svg+xml"/></p>
 *
 * <p>{@link //EMPTY} and anything is {@code //EMPTY}, so merged parent is
 * {@code //EMPTY}; return left graph.<br>
 * <embed src="images/LocalMerge_EmptyParent.svg" type="image/svg+xml"/></p>
 *
 * <p>Special case of last merge if local context.<br>
 * <embed src="images/LocalMerge_DiffRoots.svg" type="image/svg+xml"/></p>
 *
 * <h2>Full-Context Merges</h2>
 *
 * <p>These full-context merge operations are used when {@code rootIsWildcard}
 * is false.</p>
 *
 * <p><embed src="images/FullMerge_EmptyRoots.svg" type="image/svg+xml"/></p>
 *
 * <p>Must keep all contexts; {@link //EMPTY} in array is a special value (and
 * null parent).<br>
 * <embed src="images/FullMerge_EmptyRoot.svg" type="image/svg+xml"/></p>
 *
 * <p><embed src="images/FullMerge_SameRoot.svg" type="image/svg+xml"/></p>
 *
 * @param a the first {@link SingletonPredictionContext}
 * @param b the second {@link SingletonPredictionContext}
 * @param rootIsWildcard {@code true} if this is a local-context merge,
 * otherwise false to indicate a full-context merge
 */
function mergeRoot(a, b, rootIsWildcard) {
	if (rootIsWildcard) {
		if (a === PredictionContext$3.EMPTY) {
			return PredictionContext$3.EMPTY; // // + b =//
		}
		if (b === PredictionContext$3.EMPTY) {
			return PredictionContext$3.EMPTY; // a +// =//
		}
	} else {
		if (a === PredictionContext$3.EMPTY && b === PredictionContext$3.EMPTY) {
			return PredictionContext$3.EMPTY; // $ + $ = $
		} else if (a === PredictionContext$3.EMPTY) { // $ + x = [$,x]
			const payloads = [ b.returnState,
					PredictionContext$3.EMPTY_RETURN_STATE ];
			const parents = [ b.parentCtx, null ];
			return new ArrayPredictionContext(parents, payloads);
		} else if (b === PredictionContext$3.EMPTY) { // x + $ = [$,x] ($ is always first if present)
			const payloads = [ a.returnState, PredictionContext$3.EMPTY_RETURN_STATE ];
			const parents = [ a.parentCtx, null ];
			return new ArrayPredictionContext(parents, payloads);
		}
	}
	return null;
}

/**
 * Merge two {@link ArrayPredictionContext} instances.
 *
 * <p>Different tops, different parents.<br>
 * <embed src="images/ArrayMerge_DiffTopDiffPar.svg" type="image/svg+xml"/></p>
 *
 * <p>Shared top, same parents.<br>
 * <embed src="images/ArrayMerge_ShareTopSamePar.svg" type="image/svg+xml"/></p>
 *
 * <p>Shared top, different parents.<br>
 * <embed src="images/ArrayMerge_ShareTopDiffPar.svg" type="image/svg+xml"/></p>
 *
 * <p>Shared top, all shared parents.<br>
 * <embed src="images/ArrayMerge_ShareTopSharePar.svg"
 * type="image/svg+xml"/></p>
 *
 * <p>Equal tops, merge parents and reduce top to
 * {@link SingletonPredictionContext}.<br>
 * <embed src="images/ArrayMerge_EqualTop.svg" type="image/svg+xml"/></p>
 */
function mergeArrays(a, b, rootIsWildcard, mergeCache) {
	if (mergeCache !== null) {
		let previous = mergeCache.get(a, b);
		if (previous !== null) {
			return previous;
		}
		previous = mergeCache.get(b, a);
		if (previous !== null) {
			return previous;
		}
	}
	// merge sorted payloads a + b => M
	let i = 0; // walks a
	let j = 0; // walks b
	let k = 0; // walks target M array

	let mergedReturnStates = [];
	let mergedParents = [];
	// walk and merge to yield mergedParents, mergedReturnStates
	while (i < a.returnStates.length && j < b.returnStates.length) {
		const a_parent = a.parents[i];
		const b_parent = b.parents[j];
		if (a.returnStates[i] === b.returnStates[j]) {
			// same payload (stack tops are equal), must yield merged singleton
			const payload = a.returnStates[i];
			// $+$ = $
			const bothDollars = payload === PredictionContext$3.EMPTY_RETURN_STATE &&
					a_parent === null && b_parent === null;
			const ax_ax = (a_parent !== null && b_parent !== null && a_parent === b_parent); // ax+ax
																							// ->
																							// ax
			if (bothDollars || ax_ax) {
				mergedParents[k] = a_parent; // choose left
				mergedReturnStates[k] = payload;
			} else { // ax+ay -> a'[x,y]
				mergedParents[k] = merge$1(a_parent, b_parent, rootIsWildcard, mergeCache);
				mergedReturnStates[k] = payload;
			}
			i += 1; // hop over left one as usual
			j += 1; // but also skip one in right side since we merge
		} else if (a.returnStates[i] < b.returnStates[j]) { // copy a[i] to M
			mergedParents[k] = a_parent;
			mergedReturnStates[k] = a.returnStates[i];
			i += 1;
		} else { // b > a, copy b[j] to M
			mergedParents[k] = b_parent;
			mergedReturnStates[k] = b.returnStates[j];
			j += 1;
		}
		k += 1;
	}
	// copy over any payloads remaining in either array
	if (i < a.returnStates.length) {
		for (let p = i; p < a.returnStates.length; p++) {
			mergedParents[k] = a.parents[p];
			mergedReturnStates[k] = a.returnStates[p];
			k += 1;
		}
	} else {
		for (let p = j; p < b.returnStates.length; p++) {
			mergedParents[k] = b.parents[p];
			mergedReturnStates[k] = b.returnStates[p];
			k += 1;
		}
	}
	// trim merged if we combined a few that had same stack tops
	if (k < mergedParents.length) { // write index < last position; trim
		if (k === 1) { // for just one merged element, return singleton top
			const a_ = SingletonPredictionContext$3.create(mergedParents[0],
					mergedReturnStates[0]);
			if (mergeCache !== null) {
				mergeCache.set(a, b, a_);
			}
			return a_;
		}
		mergedParents = mergedParents.slice(0, k);
		mergedReturnStates = mergedReturnStates.slice(0, k);
	}

	const M = new ArrayPredictionContext(mergedParents, mergedReturnStates);

	// if we created same array as a or b, return that instead
	// TODO: track whether this is possible above during merge sort for speed
	if (M === a) {
		if (mergeCache !== null) {
			mergeCache.set(a, b, a);
		}
		return a;
	}
	if (M === b) {
		if (mergeCache !== null) {
			mergeCache.set(a, b, b);
		}
		return b;
	}
	combineCommonParents(mergedParents);

	if (mergeCache !== null) {
		mergeCache.set(a, b, M);
	}
	return M;
}

/**
 * Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}
 * ones.
 */
function combineCommonParents(parents) {
	const uniqueParents = new Map$3();

	for (let p = 0; p < parents.length; p++) {
		const parent = parents[p];
		if (!(uniqueParents.containsKey(parent))) {
			uniqueParents.put(parent, parent);
		}
	}
	for (let q = 0; q < parents.length; q++) {
		parents[q] = uniqueParents.get(parents[q]);
	}
}

function getCachedPredictionContext$1(context, contextCache, visited) {
	if (context.isEmpty()) {
		return context;
	}
	let existing = visited.get(context) || null;
	if (existing !== null) {
		return existing;
	}
	existing = contextCache.get(context);
	if (existing !== null) {
		visited.put(context, existing);
		return existing;
	}
	let changed = false;
	let parents = [];
	for (let i = 0; i < parents.length; i++) {
		const parent = getCachedPredictionContext$1(context.getParent(i), contextCache, visited);
		if (changed || parent !== context.getParent(i)) {
			if (!changed) {
				parents = [];
				for (let j = 0; j < context.length; j++) {
					parents[j] = context.getParent(j);
				}
				changed = true;
			}
			parents[i] = parent;
		}
	}
	if (!changed) {
		contextCache.add(context);
		visited.put(context, context);
		return context;
	}
	let updated = null;
	if (parents.length === 0) {
		updated = PredictionContext$3.EMPTY;
	} else if (parents.length === 1) {
		updated = SingletonPredictionContext$3.create(parents[0], context
				.getReturnState(0));
	} else {
		updated = new ArrayPredictionContext(parents, context.returnStates);
	}
	contextCache.add(updated);
	visited.put(updated, updated);
	visited.put(context, updated);

	return updated;
}

var PredictionContext_1 = {
	merge: merge$1,
	PredictionContext: PredictionContext$3,
	PredictionContextCache,
	SingletonPredictionContext: SingletonPredictionContext$3,
	predictionContextFromRuleContext: predictionContextFromRuleContext$2,
	getCachedPredictionContext: getCachedPredictionContext$1
};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Set: Set$4, BitSet: BitSet$3} = Utils$4;
const {Token: Token$b} = Token_1;
const {ATNConfig: ATNConfig$2} = ATNConfig$4;
const {IntervalSet: IntervalSet$3} = IntervalSet_1;
const {RuleStopState: RuleStopState$4} = ATNState_1;
const {RuleTransition: RuleTransition$2, NotSetTransition: NotSetTransition$2, WildcardTransition: WildcardTransition$1, AbstractPredicateTransition} = Transition_1;
const {predictionContextFromRuleContext: predictionContextFromRuleContext$1, PredictionContext: PredictionContext$2, SingletonPredictionContext: SingletonPredictionContext$2} = PredictionContext_1;

let LL1Analyzer$1 = class LL1Analyzer {
    constructor(atn) {
        this.atn = atn;
    }

    /**
     * Calculates the SLL(1) expected lookahead set for each outgoing transition
     * of an {@link ATNState}. The returned array has one element for each
     * outgoing transition in {@code s}. If the closure from transition
     * <em>i</em> leads to a semantic predicate before matching a symbol, the
     * element at index <em>i</em> of the result will be {@code null}.
     *
     * @param s the ATN state
     * @return the expected symbols for each outgoing transition of {@code s}.
     */
    getDecisionLookahead(s) {
        if (s === null) {
            return null;
        }
        const count = s.transitions.length;
        const look = [];
        for(let alt=0; alt< count; alt++) {
            look[alt] = new IntervalSet$3();
            const lookBusy = new Set$4();
            const seeThruPreds = false; // fail to get lookahead upon pred
            this._LOOK(s.transition(alt).target, null, PredictionContext$2.EMPTY,
                  look[alt], lookBusy, new BitSet$3(), seeThruPreds, false);
            // Wipe out lookahead for this alternative if we found nothing
            // or we had a predicate when we !seeThruPreds
            if (look[alt].length===0 || look[alt].contains(LL1Analyzer.HIT_PRED)) {
                look[alt] = null;
            }
        }
        return look;
    }

    /**
     * Compute set of tokens that can follow {@code s} in the ATN in the
     * specified {@code ctx}.
     *
     * <p>If {@code ctx} is {@code null} and the end of the rule containing
     * {@code s} is reached, {@link Token//EPSILON} is added to the result set.
     * If {@code ctx} is not {@code null} and the end of the outermost rule is
     * reached, {@link Token//EOF} is added to the result set.</p>
     *
     * @param s the ATN state
     * @param stopState the ATN state to stop at. This can be a
     * {@link BlockEndState} to detect epsilon paths through a closure.
     * @param ctx the complete parser context, or {@code null} if the context
     * should be ignored
     *
     * @return The set of tokens that can follow {@code s} in the ATN in the
     * specified {@code ctx}.
     */
    LOOK(s, stopState, ctx) {
        const r = new IntervalSet$3();
        const seeThruPreds = true; // ignore preds; get all lookahead
        ctx = ctx || null;
        const lookContext = ctx!==null ? predictionContextFromRuleContext$1(s.atn, ctx) : null;
        this._LOOK(s, stopState, lookContext, r, new Set$4(), new BitSet$3(), seeThruPreds, true);
        return r;
    }

    /**
     * Compute set of tokens that can follow {@code s} in the ATN in the
     * specified {@code ctx}.
     *
     * <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the
     * rule containing {@code s} is reached, {@link Token//EPSILON} is added to
     * the result set. If {@code ctx} is not {@code null} and {@code addEOF} is
     * {@code true} and {@code stopState} or the end of the outermost rule is
     * reached, {@link Token//EOF} is added to the result set.</p>
     *
     * @param s the ATN state.
     * @param stopState the ATN state to stop at. This can be a
     * {@link BlockEndState} to detect epsilon paths through a closure.
     * @param ctx The outer context, or {@code null} if the outer context should
     * not be used.
     * @param look The result lookahead set.
     * @param lookBusy A set used for preventing epsilon closures in the ATN
     * from causing a stack overflow. Outside code should pass
     * {@code new Set<ATNConfig>} for this argument.
     * @param calledRuleStack A set used for preventing left recursion in the
     * ATN from causing a stack overflow. Outside code should pass
     * {@code new BitSet()} for this argument.
     * @param seeThruPreds {@code true} to true semantic predicates as
     * implicitly {@code true} and "see through them", otherwise {@code false}
     * to treat semantic predicates as opaque and add {@link //HIT_PRED} to the
     * result if one is encountered.
     * @param addEOF Add {@link Token//EOF} to the result if the end of the
     * outermost context is reached. This parameter has no effect if {@code ctx}
     * is {@code null}.
     */
    _LOOK(s, stopState , ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF) {
        const c = new ATNConfig$2({state:s, alt:0, context: ctx}, null);
        if (lookBusy.contains(c)) {
            return;
        }
        lookBusy.add(c);
        if (s === stopState) {
            if (ctx ===null) {
                look.addOne(Token$b.EPSILON);
                return;
            } else if (ctx.isEmpty() && addEOF) {
                look.addOne(Token$b.EOF);
                return;
            }
        }
        if (s instanceof RuleStopState$4 ) {
            if (ctx ===null) {
                look.addOne(Token$b.EPSILON);
                return;
            } else if (ctx.isEmpty() && addEOF) {
                look.addOne(Token$b.EOF);
                return;
            }
            if (ctx !== PredictionContext$2.EMPTY) {
                const removed = calledRuleStack.contains(s.ruleIndex);
                try {
                    calledRuleStack.remove(s.ruleIndex);
                    // run thru all possible stack tops in ctx
                    for (let i = 0; i < ctx.length; i++) {
                        const returnState = this.atn.states[ctx.getReturnState(i)];
                        this._LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);
                    }
                }finally {
                    if (removed) {
                        calledRuleStack.add(s.ruleIndex);
                    }
                }
                return;
            }
        }
        for(let j=0; j<s.transitions.length; j++) {
            const t = s.transitions[j];
            if (t.constructor === RuleTransition$2) {
                if (calledRuleStack.contains(t.target.ruleIndex)) {
                    continue;
                }
                const newContext = SingletonPredictionContext$2.create(ctx, t.followState.stateNumber);
                try {
                    calledRuleStack.add(t.target.ruleIndex);
                    this._LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);
                } finally {
                    calledRuleStack.remove(t.target.ruleIndex);
                }
            } else if (t instanceof AbstractPredicateTransition ) {
                if (seeThruPreds) {
                    this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);
                } else {
                    look.addOne(LL1Analyzer.HIT_PRED);
                }
            } else if( t.isEpsilon) {
                this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);
            } else if (t.constructor === WildcardTransition$1) {
                look.addRange( Token$b.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType );
            } else {
                let set = t.label;
                if (set !== null) {
                    if (t instanceof NotSetTransition$2) {
                        set = set.complement(Token$b.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType);
                    }
                    look.addSet(set);
                }
            }
        }
    }
};

/**
 * Special value added to the lookahead sets to indicate that we hit
 * a predicate during analysis if {@code seeThruPreds==false}.
 */
LL1Analyzer$1.HIT_PRED = Token$b.INVALID_TYPE;

var LL1Analyzer_1 = LL1Analyzer$1;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const LL1Analyzer = LL1Analyzer_1;
const {IntervalSet: IntervalSet$2} = IntervalSet_1;
const {Token: Token$a} = Token_1;

let ATN$5 = class ATN {

    constructor(grammarType , maxTokenType) {
        /**
         * Used for runtime deserialization of ATNs from strings
         * The type of the ATN.
        */
        this.grammarType = grammarType;
        // The maximum value for any symbol recognized by a transition in the ATN.
        this.maxTokenType = maxTokenType;
        this.states = [];
        /**
         * Each subrule/rule is a decision point and we must track them so we
         * can go back later and build DFA predictors for them.  This includes
         * all the rules, subrules, optional blocks, ()+, ()* etc...
         */
        this.decisionToState = [];
        // Maps from rule index to starting state number.
        this.ruleToStartState = [];
        // Maps from rule index to stop state number.
        this.ruleToStopState = null;
        this.modeNameToStartState = {};
        /**
         * For lexer ATNs, this maps the rule index to the resulting token type.
         * For parser ATNs, this maps the rule index to the generated bypass token
         * type if the {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}
         * deserialization option was specified; otherwise, this is {@code null}
         */
        this.ruleToTokenType = null;
        /**
         * For lexer ATNs, this is an array of {@link LexerAction} objects which may
         * be referenced by action transitions in the ATN
         */
        this.lexerActions = null;
        this.modeToStartState = [];
    }

    /**
     * Compute the set of valid tokens that can occur starting in state {@code s}.
     * If {@code ctx} is null, the set of tokens will not include what can follow
     * the rule surrounding {@code s}. In other words, the set will be
     * restricted to tokens reachable staying within {@code s}'s rule
     */
    nextTokensInContext(s, ctx) {
        const anal = new LL1Analyzer(this);
        return anal.LOOK(s, null, ctx);
    }

    /**
     * Compute the set of valid tokens that can occur starting in {@code s} and
     * staying in same rule. {@link Token//EPSILON} is in set if we reach end of
     * rule
     */
    nextTokensNoContext(s) {
        if (s.nextTokenWithinRule !== null ) {
            return s.nextTokenWithinRule;
        }
        s.nextTokenWithinRule = this.nextTokensInContext(s, null);
        s.nextTokenWithinRule.readOnly = true;
        return s.nextTokenWithinRule;
    }

    nextTokens(s, ctx) {
        if ( ctx===undefined ) {
            return this.nextTokensNoContext(s);
        } else {
            return this.nextTokensInContext(s, ctx);
        }
    }

    addState(state) {
        if ( state !== null ) {
            state.atn = this;
            state.stateNumber = this.states.length;
        }
        this.states.push(state);
    }

    removeState(state) {
        this.states[state.stateNumber] = null; // just free mem, don't shift states in list
    }

    defineDecisionState(s) {
        this.decisionToState.push(s);
        s.decision = this.decisionToState.length-1;
        return s.decision;
    }

    getDecisionState(decision) {
        if (this.decisionToState.length===0) {
            return null;
        } else {
            return this.decisionToState[decision];
        }
    }

    /**
     * Computes the set of input symbols which could follow ATN state number
     * {@code stateNumber} in the specified full {@code context}. This method
     * considers the complete parser context, but does not evaluate semantic
     * predicates (i.e. all predicates encountered during the calculation are
     * assumed true). If a path in the ATN exists from the starting state to the
     * {@link RuleStopState} of the outermost context without matching any
     * symbols, {@link Token//EOF} is added to the returned set.
     *
     * <p>If {@code context} is {@code null}, it is treated as
     * {@link ParserRuleContext//EMPTY}.</p>
     *
     * @param stateNumber the ATN state number
     * @param ctx the full parse context
     *
     * @return {IntervalSet} The set of potentially valid input symbols which could follow the
     * specified state in the specified context.
     *
     * @throws IllegalArgumentException if the ATN does not contain a state with
     * number {@code stateNumber}
     */
    getExpectedTokens(stateNumber, ctx ) {
        if ( stateNumber < 0 || stateNumber >= this.states.length ) {
            throw("Invalid state number.");
        }
        const s = this.states[stateNumber];
        let following = this.nextTokens(s);
        if (!following.contains(Token$a.EPSILON)) {
            return following;
        }
        const expected = new IntervalSet$2();
        expected.addSet(following);
        expected.removeOne(Token$a.EPSILON);
        while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token$a.EPSILON)) {
            const invokingState = this.states[ctx.invokingState];
            const rt = invokingState.transitions[0];
            following = this.nextTokens(rt.followState);
            expected.addSet(following);
            expected.removeOne(Token$a.EPSILON);
            ctx = ctx.parentCtx;
        }
        if (following.contains(Token$a.EPSILON)) {
            expected.addOne(Token$a.EOF);
        }
        return expected;
    }
};

ATN$5.INVALID_ALT_NUMBER = 0;

var ATN_1 = ATN$5;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

/**
 * Represents the type of recognizer an ATN applies to
 */
var ATNType$1 = {
    LEXER: 0,
    PARSER: 1
};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

let ATNDeserializationOptions$2 = class ATNDeserializationOptions {
	constructor(copyFrom) {
		if(copyFrom===undefined) {
			copyFrom = null;
		}
		this.readOnly = false;
		this.verifyATN = copyFrom===null ? true : copyFrom.verifyATN;
		this.generateRuleBypassTransitions = copyFrom===null ? false : copyFrom.generateRuleBypassTransitions;
	}
};

ATNDeserializationOptions$2.defaultOptions = new ATNDeserializationOptions$2();
ATNDeserializationOptions$2.defaultOptions.readOnly = true;

//    def __setattr__(self, key, value):
//        if key!="readOnly" and self.readOnly:
//            raise Exception("The object is read only.")
//        super(type(self), self).__setattr__(key,value)

var ATNDeserializationOptions_1 = ATNDeserializationOptions$2;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const LexerActionType$1 = {
    // The type of a {@link LexerChannelAction} action.
    CHANNEL: 0,
    // The type of a {@link LexerCustomAction} action
    CUSTOM: 1,
    // The type of a {@link LexerModeAction} action.
    MODE: 2,
    //The type of a {@link LexerMoreAction} action.
    MORE: 3,
    //The type of a {@link LexerPopModeAction} action.
    POP_MODE: 4,
    //The type of a {@link LexerPushModeAction} action.
    PUSH_MODE: 5,
    //The type of a {@link LexerSkipAction} action.
    SKIP: 6,
    //The type of a {@link LexerTypeAction} action.
    TYPE: 7
};

class LexerAction {
    constructor(action) {
        this.actionType = action;
        this.isPositionDependent = false;
    }

    hashCode() {
        const hash = new Hash();
        this.updateHashCode(hash);
        return hash.finish()
    }

    updateHashCode(hash) {
        hash.update(this.actionType);
    }

    equals(other) {
        return this === other;
    }
}


/**
 * Implements the {@code skip} lexer action by calling {@link Lexer//skip}.
 *
 * <p>The {@code skip} command does not have any parameters, so this action is
 * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>
 */
let LexerSkipAction$1 = class LexerSkipAction extends LexerAction {
    constructor() {
        super(LexerActionType$1.SKIP);
    }

    execute(lexer) {
        lexer.skip();
    }

    toString() {
        return "skip";
    }
};

// Provides a singleton instance of this parameterless lexer action.
LexerSkipAction$1.INSTANCE = new LexerSkipAction$1();

/**
 * Implements the {@code type} lexer action by calling {@link Lexer//setType}
 * with the assigned type
 */
let LexerTypeAction$1 = class LexerTypeAction extends LexerAction {
    constructor(type) {
        super(LexerActionType$1.TYPE);
        this.type = type;
    }

    execute(lexer) {
        lexer.type = this.type;
    }

    updateHashCode(hash) {
        hash.update(this.actionType, this.type);
    }

    equals(other) {
        if(this === other) {
            return true;
        } else if (! (other instanceof LexerTypeAction)) {
            return false;
        } else {
            return this.type === other.type;
        }
    }

    toString() {
        return "type(" + this.type + ")";
    }
};


/**
 * Implements the {@code pushMode} lexer action by calling
 * {@link Lexer//pushMode} with the assigned mode
 */
let LexerPushModeAction$1 = class LexerPushModeAction extends LexerAction {
    constructor(mode) {
        super(LexerActionType$1.PUSH_MODE);
        this.mode = mode;
    }

    /**
     * <p>This action is implemented by calling {@link Lexer//pushMode} with the
     * value provided by {@link //getMode}.</p>
     */
    execute(lexer) {
        lexer.pushMode(this.mode);
    }

    updateHashCode(hash) {
        hash.update(this.actionType, this.mode);
    }

    equals(other) {
        if (this === other) {
            return true;
        } else if (! (other instanceof LexerPushModeAction)) {
            return false;
        } else {
            return this.mode === other.mode;
        }
    }

    toString() {
        return "pushMode(" + this.mode + ")";
    }
};

/**
 * Implements the {@code popMode} lexer action by calling {@link Lexer//popMode}.
 *
 * <p>The {@code popMode} command does not have any parameters, so this action is
 * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>
 */
let LexerPopModeAction$1 = class LexerPopModeAction extends LexerAction {
    constructor() {
        super(LexerActionType$1.POP_MODE);
    }

    /**
     * <p>This action is implemented by calling {@link Lexer//popMode}.</p>
     */
    execute(lexer) {
        lexer.popMode();
    }

    toString() {
        return "popMode";
    }
};

LexerPopModeAction$1.INSTANCE = new LexerPopModeAction$1();

/**
 * Implements the {@code more} lexer action by calling {@link Lexer//more}.
 *
 * <p>The {@code more} command does not have any parameters, so this action is
 * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>
 */
let LexerMoreAction$1 = class LexerMoreAction extends LexerAction {
    constructor() {
        super(LexerActionType$1.MORE);
    }

    /**
     * <p>This action is implemented by calling {@link Lexer//popMode}.</p>
     */
    execute(lexer) {
        lexer.more();
    }

    toString() {
        return "more";
    }
};

LexerMoreAction$1.INSTANCE = new LexerMoreAction$1();


/**
 * Implements the {@code mode} lexer action by calling {@link Lexer//mode} with
 * the assigned mode
 */
let LexerModeAction$1 = class LexerModeAction extends LexerAction {
    constructor(mode) {
        super(LexerActionType$1.MODE);
        this.mode = mode;
    }

    /**
     * <p>This action is implemented by calling {@link Lexer//mode} with the
     * value provided by {@link //getMode}.</p>
     */
    execute(lexer) {
        lexer.mode(this.mode);
    }

    updateHashCode(hash) {
        hash.update(this.actionType, this.mode);
    }

    equals(other) {
        if (this === other) {
            return true;
        } else if (! (other instanceof LexerModeAction)) {
            return false;
        } else {
            return this.mode === other.mode;
        }
    }

    toString() {
        return "mode(" + this.mode + ")";
    }
};

/**
 * Executes a custom lexer action by calling {@link Recognizer//action} with the
 * rule and action indexes assigned to the custom action. The implementation of
 * a custom action is added to the generated code for the lexer in an override
 * of {@link Recognizer//action} when the grammar is compiled.
 *
 * <p>This class may represent embedded actions created with the <code>{...}</code>
 * syntax in ANTLR 4, as well as actions created for lexer commands where the
 * command argument could not be evaluated when the grammar was compiled.</p>
 */
let LexerCustomAction$1 = class LexerCustomAction extends LexerAction {
    /**
     * Constructs a custom lexer action with the specified rule and action
     * indexes.
     *
     * @param ruleIndex The rule index to use for calls to
     * {@link Recognizer//action}.
     * @param actionIndex The action index to use for calls to
     * {@link Recognizer//action}.
     */
    constructor(ruleIndex, actionIndex) {
        super(LexerActionType$1.CUSTOM);
        this.ruleIndex = ruleIndex;
        this.actionIndex = actionIndex;
        this.isPositionDependent = true;
    }

    /**
     * <p>Custom actions are implemented by calling {@link Lexer//action} with the
     * appropriate rule and action indexes.</p>
     */
    execute(lexer) {
        lexer.action(null, this.ruleIndex, this.actionIndex);
    }

    updateHashCode(hash) {
        hash.update(this.actionType, this.ruleIndex, this.actionIndex);
    }

    equals(other) {
        if (this === other) {
            return true;
        } else if (! (other instanceof LexerCustomAction)) {
            return false;
        } else {
            return this.ruleIndex === other.ruleIndex && this.actionIndex === other.actionIndex;
        }
    }
};

/**
 * Implements the {@code channel} lexer action by calling
 * {@link Lexer//setChannel} with the assigned channel.
 * Constructs a new {@code channel} action with the specified channel value.
 * @param channel The channel value to pass to {@link Lexer//setChannel}
 */
let LexerChannelAction$1 = class LexerChannelAction extends LexerAction {
    constructor(channel) {
        super(LexerActionType$1.CHANNEL);
        this.channel = channel;
    }

    /**
     * <p>This action is implemented by calling {@link Lexer//setChannel} with the
     * value provided by {@link //getChannel}.</p>
     */
    execute(lexer) {
        lexer._channel = this.channel;
    }

    updateHashCode(hash) {
        hash.update(this.actionType, this.channel);
    }

    equals(other) {
        if (this === other) {
            return true;
        } else if (! (other instanceof LexerChannelAction)) {
            return false;
        } else {
            return this.channel === other.channel;
        }
    }

    toString() {
        return "channel(" + this.channel + ")";
    }
};


/**
 * This implementation of {@link LexerAction} is used for tracking input offsets
 * for position-dependent actions within a {@link LexerActionExecutor}.
 *
 * <p>This action is not serialized as part of the ATN, and is only required for
 * position-dependent lexer actions which appear at a location other than the
 * end of a rule. For more information about DFA optimizations employed for
 * lexer actions, see {@link LexerActionExecutor//append} and
 * {@link LexerActionExecutor//fixOffsetBeforeMatch}.</p>
 *
 * Constructs a new indexed custom action by associating a character offset
 * with a {@link LexerAction}.
 *
 * <p>Note: This class is only required for lexer actions for which
 * {@link LexerAction//isPositionDependent} returns {@code true}.</p>
 *
 * @param offset The offset into the input {@link CharStream}, relative to
 * the token start index, at which the specified lexer action should be
 * executed.
 * @param action The lexer action to execute at a particular offset in the
 * input {@link CharStream}.
 */
let LexerIndexedCustomAction$1 = class LexerIndexedCustomAction extends LexerAction {
    constructor(offset, action) {
        super(action.actionType);
        this.offset = offset;
        this.action = action;
        this.isPositionDependent = true;
    }

    /**
     * <p>This method calls {@link //execute} on the result of {@link //getAction}
     * using the provided {@code lexer}.</p>
     */
    execute(lexer) {
        // assume the input stream position was properly set by the calling code
        this.action.execute(lexer);
    }

    updateHashCode(hash) {
        hash.update(this.actionType, this.offset, this.action);
    }

    equals(other) {
        if (this === other) {
            return true;
        } else if (! (other instanceof LexerIndexedCustomAction)) {
            return false;
        } else {
            return this.offset === other.offset && this.action === other.action;
        }
    }
};

var LexerAction_1 = {
    LexerActionType: LexerActionType$1,
    LexerSkipAction: LexerSkipAction$1,
    LexerChannelAction: LexerChannelAction$1,
    LexerCustomAction: LexerCustomAction$1,
    LexerIndexedCustomAction: LexerIndexedCustomAction$1,
    LexerMoreAction: LexerMoreAction$1,
    LexerTypeAction: LexerTypeAction$1,
    LexerPushModeAction: LexerPushModeAction$1,
    LexerPopModeAction: LexerPopModeAction$1,
    LexerModeAction: LexerModeAction$1
};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Token: Token$9} = Token_1;
const ATN$4 = ATN_1;
const ATNType = ATNType$1;

const {
    ATNState: ATNState$2,
    BasicState,
    DecisionState,
    BlockStartState,
    BlockEndState,
    LoopEndState,
    RuleStartState,
    RuleStopState: RuleStopState$3,
    TokensStartState,
    PlusLoopbackState,
    StarLoopbackState,
    StarLoopEntryState: StarLoopEntryState$1,
    PlusBlockStartState,
    StarBlockStartState,
    BasicBlockStartState
} = ATNState_1;

const {
    Transition: Transition$2,
    AtomTransition: AtomTransition$1,
    SetTransition: SetTransition$1,
    NotSetTransition: NotSetTransition$1,
    RuleTransition: RuleTransition$1,
    RangeTransition,
    ActionTransition: ActionTransition$1,
    EpsilonTransition,
    WildcardTransition,
    PredicateTransition: PredicateTransition$1,
    PrecedencePredicateTransition
} = Transition_1;

const {IntervalSet: IntervalSet$1} = IntervalSet_1;
const ATNDeserializationOptions$1 = ATNDeserializationOptions_1;

const {
    LexerActionType,
    LexerSkipAction,
    LexerChannelAction,
    LexerCustomAction,
    LexerMoreAction,
    LexerTypeAction,
    LexerPushModeAction,
    LexerPopModeAction,
    LexerModeAction,
} = LexerAction_1;

// This is the earliest supported serialized UUID.
// stick to serialized version for now, we don't need a UUID instance
const BASE_SERIALIZED_UUID = "AADB8D7E-AEEF-4415-AD2B-8204D6CF042E";

//
// This UUID indicates the serialized ATN contains two sets of
// IntervalSets, where the second set's values are encoded as
// 32-bit integers to support the full Unicode SMP range up to U+10FFFF.
//
const ADDED_UNICODE_SMP = "59627784-3BE5-417A-B9EB-8131A7286089";

// This list contains all of the currently supported UUIDs, ordered by when
// the feature first appeared in this branch.
const SUPPORTED_UUIDS = [ BASE_SERIALIZED_UUID, ADDED_UNICODE_SMP ];

const SERIALIZED_VERSION = 3;

// This is the current serialized UUID.
const SERIALIZED_UUID = ADDED_UNICODE_SMP;

function initArray( length, value) {
	const tmp = [];
	tmp[length-1] = value;
	return tmp.map(function(i) {return value;});
}

let ATNDeserializer$1 = class ATNDeserializer {
    constructor(options) {

        if ( options=== undefined || options === null ) {
            options = ATNDeserializationOptions$1.defaultOptions;
        }
        this.deserializationOptions = options;
        this.stateFactories = null;
        this.actionFactories = null;
    }

    /**
     * Determines if a particular serialized representation of an ATN supports
     * a particular feature, identified by the {@link UUID} used for serializing
     * the ATN at the time the feature was first introduced.
     *
     * @param feature The {@link UUID} marking the first time the feature was
     * supported in the serialized ATN.
     * @param actualUuid The {@link UUID} of the actual serialized ATN which is
     * currently being deserialized.
     * @return {@code true} if the {@code actualUuid} value represents a
     * serialized ATN at or after the feature identified by {@code feature} was
     * introduced; otherwise, {@code false}.
    */
    isFeatureSupported(feature, actualUuid) {
        const idx1 = SUPPORTED_UUIDS.indexOf(feature);
        if (idx1<0) {
            return false;
        }
        const idx2 = SUPPORTED_UUIDS.indexOf(actualUuid);
        return idx2 >= idx1;
    }

    deserialize(data) {
        this.reset(data);
        this.checkVersion();
        this.checkUUID();
        const atn = this.readATN();
        this.readStates(atn);
        this.readRules(atn);
        this.readModes(atn);
        const sets = [];
        // First, deserialize sets with 16-bit arguments <= U+FFFF.
        this.readSets(atn, sets, this.readInt.bind(this));
        // Next, if the ATN was serialized with the Unicode SMP feature,
        // deserialize sets with 32-bit arguments <= U+10FFFF.
        if (this.isFeatureSupported(ADDED_UNICODE_SMP, this.uuid)) {
            this.readSets(atn, sets, this.readInt32.bind(this));
        }
        this.readEdges(atn, sets);
        this.readDecisions(atn);
        this.readLexerActions(atn);
        this.markPrecedenceDecisions(atn);
        this.verifyATN(atn);
        if (this.deserializationOptions.generateRuleBypassTransitions && atn.grammarType === ATNType.PARSER ) {
            this.generateRuleBypassTransitions(atn);
            // re-verify after modification
            this.verifyATN(atn);
        }
        return atn;
    }

    reset(data) {
        const adjust = function(c) {
            const v = c.charCodeAt(0);
            return v>1  ? v-2 : v + 65534;
        };
        const temp = data.split("").map(adjust);
        // don't adjust the first value since that's the version number
        temp[0] = data.charCodeAt(0);
        this.data = temp;
        this.pos = 0;
    }

    checkVersion() {
        const version = this.readInt();
        if ( version !== SERIALIZED_VERSION ) {
            throw ("Could not deserialize ATN with version " + version + " (expected " + SERIALIZED_VERSION + ").");
        }
    }

    checkUUID() {
        const uuid = this.readUUID();
        if (SUPPORTED_UUIDS.indexOf(uuid)<0) {
            throw (SERIALIZED_UUID);
        }
        this.uuid = uuid;
    }

    readATN() {
        const grammarType = this.readInt();
        const maxTokenType = this.readInt();
        return new ATN$4(grammarType, maxTokenType);
    }

    readStates(atn) {
        let j, pair, stateNumber;
        const  loopBackStateNumbers = [];
        const  endStateNumbers = [];
        const  nstates = this.readInt();
        for(let i=0; i<nstates; i++) {
            const  stype = this.readInt();
            // ignore bad type of states
            if (stype===ATNState$2.INVALID_TYPE) {
                atn.addState(null);
                continue;
            }
            let ruleIndex = this.readInt();
            if (ruleIndex === 0xFFFF) {
                ruleIndex = -1;
            }
            const  s = this.stateFactory(stype, ruleIndex);
            if (stype === ATNState$2.LOOP_END) { // special case
                const  loopBackStateNumber = this.readInt();
                loopBackStateNumbers.push([s, loopBackStateNumber]);
            } else if(s instanceof BlockStartState) {
                const  endStateNumber = this.readInt();
                endStateNumbers.push([s, endStateNumber]);
            }
            atn.addState(s);
        }
        // delay the assignment of loop back and end states until we know all the
        // state instances have been initialized
        for (j=0; j<loopBackStateNumbers.length; j++) {
            pair = loopBackStateNumbers[j];
            pair[0].loopBackState = atn.states[pair[1]];
        }

        for (j=0; j<endStateNumbers.length; j++) {
            pair = endStateNumbers[j];
            pair[0].endState = atn.states[pair[1]];
        }

        let numNonGreedyStates = this.readInt();
        for (j=0; j<numNonGreedyStates; j++) {
            stateNumber = this.readInt();
            atn.states[stateNumber].nonGreedy = true;
        }

        let numPrecedenceStates = this.readInt();
        for (j=0; j<numPrecedenceStates; j++) {
            stateNumber = this.readInt();
            atn.states[stateNumber].isPrecedenceRule = true;
        }
    }

    readRules(atn) {
        let i;
        const nrules = this.readInt();
        if (atn.grammarType === ATNType.LEXER ) {
            atn.ruleToTokenType = initArray(nrules, 0);
        }
        atn.ruleToStartState = initArray(nrules, 0);
        for (i=0; i<nrules; i++) {
            const s = this.readInt();
            atn.ruleToStartState[i] = atn.states[s];
            if ( atn.grammarType === ATNType.LEXER ) {
                let tokenType = this.readInt();
                if (tokenType === 0xFFFF) {
                    tokenType = Token$9.EOF;
                }
                atn.ruleToTokenType[i] = tokenType;
            }
        }
        atn.ruleToStopState = initArray(nrules, 0);
        for (i=0; i<atn.states.length; i++) {
            const state = atn.states[i];
            if (!(state instanceof RuleStopState$3)) {
                continue;
            }
            atn.ruleToStopState[state.ruleIndex] = state;
            atn.ruleToStartState[state.ruleIndex].stopState = state;
        }
    }

    readModes(atn) {
        const nmodes = this.readInt();
        for (let i=0; i<nmodes; i++) {
            let s = this.readInt();
            atn.modeToStartState.push(atn.states[s]);
        }
    }

    readSets(atn, sets, readUnicode) {
        const m = this.readInt();
        for (let i=0; i<m; i++) {
            const iset = new IntervalSet$1();
            sets.push(iset);
            const n = this.readInt();
            const containsEof = this.readInt();
            if (containsEof!==0) {
                iset.addOne(-1);
            }
            for (let j=0; j<n; j++) {
                const i1 = readUnicode();
                const i2 = readUnicode();
                iset.addRange(i1, i2);
            }
        }
    }

    readEdges(atn, sets) {
        let i, j, state, trans, target;
        const nedges = this.readInt();
        for (i=0; i<nedges; i++) {
            const src = this.readInt();
            const trg = this.readInt();
            const ttype = this.readInt();
            const arg1 = this.readInt();
            const arg2 = this.readInt();
            const arg3 = this.readInt();
            trans = this.edgeFactory(atn, ttype, src, trg, arg1, arg2, arg3, sets);
            const srcState = atn.states[src];
            srcState.addTransition(trans);
        }
        // edges for rule stop states can be derived, so they aren't serialized
        for (i=0; i<atn.states.length; i++) {
            state = atn.states[i];
            for (j=0; j<state.transitions.length; j++) {
                const t = state.transitions[j];
                if (!(t instanceof RuleTransition$1)) {
                    continue;
                }
                let outermostPrecedenceReturn = -1;
                if (atn.ruleToStartState[t.target.ruleIndex].isPrecedenceRule) {
                    if (t.precedence === 0) {
                        outermostPrecedenceReturn = t.target.ruleIndex;
                    }
                }

                trans = new EpsilonTransition(t.followState, outermostPrecedenceReturn);
                atn.ruleToStopState[t.target.ruleIndex].addTransition(trans);
            }
        }

        for (i=0; i<atn.states.length; i++) {
            state = atn.states[i];
            if (state instanceof BlockStartState) {
                // we need to know the end state to set its start state
                if (state.endState === null) {
                    throw ("IllegalState");
                }
                // block end states can only be associated to a single block start
                // state
                if ( state.endState.startState !== null) {
                    throw ("IllegalState");
                }
                state.endState.startState = state;
            }
            if (state instanceof PlusLoopbackState) {
                for (j=0; j<state.transitions.length; j++) {
                    target = state.transitions[j].target;
                    if (target instanceof PlusBlockStartState) {
                        target.loopBackState = state;
                    }
                }
            } else if (state instanceof StarLoopbackState) {
                for (j=0; j<state.transitions.length; j++) {
                    target = state.transitions[j].target;
                    if (target instanceof StarLoopEntryState$1) {
                        target.loopBackState = state;
                    }
                }
            }
        }
    }

    readDecisions(atn) {
        const ndecisions = this.readInt();
        for (let i=0; i<ndecisions; i++) {
            const s = this.readInt();
            const decState = atn.states[s];
            atn.decisionToState.push(decState);
            decState.decision = i;
        }
    }

    readLexerActions(atn) {
        if (atn.grammarType === ATNType.LEXER) {
            const count = this.readInt();
            atn.lexerActions = initArray(count, null);
            for (let i=0; i<count; i++) {
                const actionType = this.readInt();
                let data1 = this.readInt();
                if (data1 === 0xFFFF) {
                    data1 = -1;
                }
                let data2 = this.readInt();
                if (data2 === 0xFFFF) {
                    data2 = -1;
                }

                atn.lexerActions[i] = this.lexerActionFactory(actionType, data1, data2);
            }
        }
    }

    generateRuleBypassTransitions(atn) {
        let i;
        const count = atn.ruleToStartState.length;
        for(i=0; i<count; i++) {
            atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;
        }
        for(i=0; i<count; i++) {
            this.generateRuleBypassTransition(atn, i);
        }
    }

    generateRuleBypassTransition(atn, idx) {
        let i, state;
        const bypassStart = new BasicBlockStartState();
        bypassStart.ruleIndex = idx;
        atn.addState(bypassStart);

        const bypassStop = new BlockEndState();
        bypassStop.ruleIndex = idx;
        atn.addState(bypassStop);

        bypassStart.endState = bypassStop;
        atn.defineDecisionState(bypassStart);

        bypassStop.startState = bypassStart;

        let excludeTransition = null;
        let endState = null;

        if (atn.ruleToStartState[idx].isPrecedenceRule) {
            // wrap from the beginning of the rule to the StarLoopEntryState
            endState = null;
            for(i=0; i<atn.states.length; i++) {
                state = atn.states[i];
                if (this.stateIsEndStateFor(state, idx)) {
                    endState = state;
                    excludeTransition = state.loopBackState.transitions[0];
                    break;
                }
            }
            if (excludeTransition === null) {
                throw ("Couldn't identify final state of the precedence rule prefix section.");
            }
        } else {
            endState = atn.ruleToStopState[idx];
        }

        // all non-excluded transitions that currently target end state need to
        // target blockEnd instead
        for(i=0; i<atn.states.length; i++) {
            state = atn.states[i];
            for(let j=0; j<state.transitions.length; j++) {
                const transition = state.transitions[j];
                if (transition === excludeTransition) {
                    continue;
                }
                if (transition.target === endState) {
                    transition.target = bypassStop;
                }
            }
        }

        // all transitions leaving the rule start state need to leave blockStart
        // instead
        const ruleToStartState = atn.ruleToStartState[idx];
        const count = ruleToStartState.transitions.length;
        while ( count > 0) {
            bypassStart.addTransition(ruleToStartState.transitions[count-1]);
            ruleToStartState.transitions = ruleToStartState.transitions.slice(-1);
        }
        // link the new states
        atn.ruleToStartState[idx].addTransition(new EpsilonTransition(bypassStart));
        bypassStop.addTransition(new EpsilonTransition(endState));

        const matchState = new BasicState();
        atn.addState(matchState);
        matchState.addTransition(new AtomTransition$1(bypassStop, atn.ruleToTokenType[idx]));
        bypassStart.addTransition(new EpsilonTransition(matchState));
    }

    stateIsEndStateFor(state, idx) {
        if ( state.ruleIndex !== idx) {
            return null;
        }
        if (!( state instanceof StarLoopEntryState$1)) {
            return null;
        }
        const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;
        if (!( maybeLoopEndState instanceof LoopEndState)) {
            return null;
        }
        if (maybeLoopEndState.epsilonOnlyTransitions &&
            (maybeLoopEndState.transitions[0].target instanceof RuleStopState$3)) {
            return state;
        } else {
            return null;
        }
    }

    /**
     * Analyze the {@link StarLoopEntryState} states in the specified ATN to set
     * the {@link StarLoopEntryState//isPrecedenceDecision} field to the
     * correct value.
     * @param atn The ATN.
     */
    markPrecedenceDecisions(atn) {
        for(let i=0; i<atn.states.length; i++) {
            const state = atn.states[i];
            if (!( state instanceof StarLoopEntryState$1)) {
                continue;
            }
            // We analyze the ATN to determine if this ATN decision state is the
            // decision for the closure block that determines whether a
            // precedence rule should continue or complete.
            if ( atn.ruleToStartState[state.ruleIndex].isPrecedenceRule) {
                const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;
                if (maybeLoopEndState instanceof LoopEndState) {
                    if ( maybeLoopEndState.epsilonOnlyTransitions &&
                            (maybeLoopEndState.transitions[0].target instanceof RuleStopState$3)) {
                        state.isPrecedenceDecision = true;
                    }
                }
            }
        }
    }

    verifyATN(atn) {
        if (!this.deserializationOptions.verifyATN) {
            return;
        }
        // verify assumptions
        for(let i=0; i<atn.states.length; i++) {
            const state = atn.states[i];
            if (state === null) {
                continue;
            }
            this.checkCondition(state.epsilonOnlyTransitions || state.transitions.length <= 1);
            if (state instanceof PlusBlockStartState) {
                this.checkCondition(state.loopBackState !== null);
            } else  if (state instanceof StarLoopEntryState$1) {
                this.checkCondition(state.loopBackState !== null);
                this.checkCondition(state.transitions.length === 2);
                if (state.transitions[0].target instanceof StarBlockStartState) {
                    this.checkCondition(state.transitions[1].target instanceof LoopEndState);
                    this.checkCondition(!state.nonGreedy);
                } else if (state.transitions[0].target instanceof LoopEndState) {
                    this.checkCondition(state.transitions[1].target instanceof StarBlockStartState);
                    this.checkCondition(state.nonGreedy);
                } else {
                    throw("IllegalState");
                }
            } else if (state instanceof StarLoopbackState) {
                this.checkCondition(state.transitions.length === 1);
                this.checkCondition(state.transitions[0].target instanceof StarLoopEntryState$1);
            } else if (state instanceof LoopEndState) {
                this.checkCondition(state.loopBackState !== null);
            } else if (state instanceof RuleStartState) {
                this.checkCondition(state.stopState !== null);
            } else if (state instanceof BlockStartState) {
                this.checkCondition(state.endState !== null);
            } else if (state instanceof BlockEndState) {
                this.checkCondition(state.startState !== null);
            } else if (state instanceof DecisionState) {
                this.checkCondition(state.transitions.length <= 1 || state.decision >= 0);
            } else {
                this.checkCondition(state.transitions.length <= 1 || (state instanceof RuleStopState$3));
            }
        }
    }

    checkCondition(condition, message) {
        if (!condition) {
            if (message === undefined || message===null) {
                message = "IllegalState";
            }
            throw (message);
        }
    }

    readInt() {
        return this.data[this.pos++];
    }

    readInt32() {
        const low = this.readInt();
        const high = this.readInt();
        return low | (high << 16);
    }

    readLong() {
        const low = this.readInt32();
        const high = this.readInt32();
        return (low & 0x00000000FFFFFFFF) | (high << 32);
    }

    readUUID() {
        const bb = [];
        for(let i=7;i>=0;i--) {
            const int = this.readInt();
            /* jshint bitwise: false */
            bb[(2*i)+1] = int & 0xFF;
            bb[2*i] = (int >> 8) & 0xFF;
        }
        return byteToHex[bb[0]] + byteToHex[bb[1]] +
        byteToHex[bb[2]] + byteToHex[bb[3]] + '-' +
        byteToHex[bb[4]] + byteToHex[bb[5]] + '-' +
        byteToHex[bb[6]] + byteToHex[bb[7]] + '-' +
        byteToHex[bb[8]] + byteToHex[bb[9]] + '-' +
        byteToHex[bb[10]] + byteToHex[bb[11]] +
        byteToHex[bb[12]] + byteToHex[bb[13]] +
        byteToHex[bb[14]] + byteToHex[bb[15]];
    }

    edgeFactory(atn, type, src, trg, arg1, arg2, arg3, sets) {
        const target = atn.states[trg];
        switch(type) {
        case Transition$2.EPSILON:
            return new EpsilonTransition(target);
        case Transition$2.RANGE:
            return arg3 !== 0 ? new RangeTransition(target, Token$9.EOF, arg2) : new RangeTransition(target, arg1, arg2);
        case Transition$2.RULE:
            return new RuleTransition$1(atn.states[arg1], arg2, arg3, target);
        case Transition$2.PREDICATE:
            return new PredicateTransition$1(target, arg1, arg2, arg3 !== 0);
        case Transition$2.PRECEDENCE:
            return new PrecedencePredicateTransition(target, arg1);
        case Transition$2.ATOM:
            return arg3 !== 0 ? new AtomTransition$1(target, Token$9.EOF) : new AtomTransition$1(target, arg1);
        case Transition$2.ACTION:
            return new ActionTransition$1(target, arg1, arg2, arg3 !== 0);
        case Transition$2.SET:
            return new SetTransition$1(target, sets[arg1]);
        case Transition$2.NOT_SET:
            return new NotSetTransition$1(target, sets[arg1]);
        case Transition$2.WILDCARD:
            return new WildcardTransition(target);
        default:
            throw "The specified transition type: " + type + " is not valid.";
        }
    }

    stateFactory(type, ruleIndex) {
        if (this.stateFactories === null) {
            const sf = [];
            sf[ATNState$2.INVALID_TYPE] = null;
            sf[ATNState$2.BASIC] = () => new BasicState();
            sf[ATNState$2.RULE_START] = () => new RuleStartState();
            sf[ATNState$2.BLOCK_START] = () => new BasicBlockStartState();
            sf[ATNState$2.PLUS_BLOCK_START] = () => new PlusBlockStartState();
            sf[ATNState$2.STAR_BLOCK_START] = () => new StarBlockStartState();
            sf[ATNState$2.TOKEN_START] = () => new TokensStartState();
            sf[ATNState$2.RULE_STOP] = () => new RuleStopState$3();
            sf[ATNState$2.BLOCK_END] = () => new BlockEndState();
            sf[ATNState$2.STAR_LOOP_BACK] = () => new StarLoopbackState();
            sf[ATNState$2.STAR_LOOP_ENTRY] = () => new StarLoopEntryState$1();
            sf[ATNState$2.PLUS_LOOP_BACK] = () => new PlusLoopbackState();
            sf[ATNState$2.LOOP_END] = () => new LoopEndState();
            this.stateFactories = sf;
        }
        if (type>this.stateFactories.length || this.stateFactories[type] === null) {
            throw("The specified state type " + type + " is not valid.");
        } else {
            const s = this.stateFactories[type]();
            if (s!==null) {
                s.ruleIndex = ruleIndex;
                return s;
            }
        }
    }

    lexerActionFactory(type, data1, data2) {
        if (this.actionFactories === null) {
            const af = [];
            af[LexerActionType.CHANNEL] = (data1, data2) => new LexerChannelAction(data1);
            af[LexerActionType.CUSTOM] = (data1, data2) => new LexerCustomAction(data1, data2);
            af[LexerActionType.MODE] = (data1, data2) => new LexerModeAction(data1);
            af[LexerActionType.MORE] = (data1, data2) => LexerMoreAction.INSTANCE;
            af[LexerActionType.POP_MODE] = (data1, data2) => LexerPopModeAction.INSTANCE;
            af[LexerActionType.PUSH_MODE] = (data1, data2) => new LexerPushModeAction(data1);
            af[LexerActionType.SKIP] = (data1, data2) => LexerSkipAction.INSTANCE;
            af[LexerActionType.TYPE] = (data1, data2) => new LexerTypeAction(data1);
            this.actionFactories = af;
        }
        if (type>this.actionFactories.length || this.actionFactories[type] === null) {
            throw("The specified lexer action type " + type + " is not valid.");
        } else {
            return this.actionFactories[type](data1, data2);
        }
    }
};

function createByteToHex() {
	const bth = [];
	for (let i = 0; i < 256; i++) {
		bth[i] = (i + 0x100).toString(16).substr(1).toUpperCase();
	}
	return bth;
}

const byteToHex = createByteToHex();


var ATNDeserializer_1 = ATNDeserializer$1;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

/**
 * Provides an empty default implementation of {@link ANTLRErrorListener}. The
 * default implementation of each method does nothing, but can be overridden as
 * necessary.
 */
let ErrorListener$2 = class ErrorListener {
    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {
    }

    reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {
    }

    reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {
    }

    reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {
    }
};

/**
 * {@inheritDoc}
 *
 * <p>
 * This implementation prints messages to {@link System//err} containing the
 * values of {@code line}, {@code charPositionInLine}, and {@code msg} using
 * the following format.</p>
 *
 * <pre>
 * line <em>line</em>:<em>charPositionInLine</em> <em>msg</em>
 * </pre>
 *
 */
let ConsoleErrorListener$1 = class ConsoleErrorListener extends ErrorListener$2 {
    constructor() {
        super();
    }

    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {
        console.error("line " + line + ":" + column + " " + msg);
    }
};


/**
 * Provides a default instance of {@link ConsoleErrorListener}.
 */
ConsoleErrorListener$1.INSTANCE = new ConsoleErrorListener$1();

let ProxyErrorListener$1 = class ProxyErrorListener extends ErrorListener$2 {
    constructor(delegates) {
        super();
        if (delegates===null) {
            throw "delegates";
        }
        this.delegates = delegates;
        return this;
    }

    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {
        this.delegates.map(d => d.syntaxError(recognizer, offendingSymbol, line, column, msg, e));
    }

    reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {
        this.delegates.map(d => d.reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs));
    }

    reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {
        this.delegates.map(d => d.reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs));
    }

    reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {
        this.delegates.map(d => d.reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs));
    }
};

var ErrorListener_1 = {ErrorListener: ErrorListener$2, ConsoleErrorListener: ConsoleErrorListener$1, ProxyErrorListener: ProxyErrorListener$1};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Token: Token$8} = Token_1;
const {ConsoleErrorListener} = ErrorListener_1;
const {ProxyErrorListener} = ErrorListener_1;

let Recognizer$2 = class Recognizer {
    constructor() {
        this._listeners = [ ConsoleErrorListener.INSTANCE ];
        this._interp = null;
        this._stateNumber = -1;
    }

    checkVersion(toolVersion) {
        const runtimeVersion = "4.9.3";
        if (runtimeVersion!==toolVersion) {
            console.log("ANTLR runtime and generated code versions disagree: "+runtimeVersion+"!="+toolVersion);
        }
    }

    addErrorListener(listener) {
        this._listeners.push(listener);
    }

    removeErrorListeners() {
        this._listeners = [];
    }

    getLiteralNames() {
        return Object.getPrototypeOf(this).constructor.literalNames || [];
    }

    getSymbolicNames() {
        return Object.getPrototypeOf(this).constructor.symbolicNames || [];
    }

    getTokenNames() {
        if(!this.tokenNames) {
            const literalNames = this.getLiteralNames();
            const symbolicNames = this.getSymbolicNames();
            const length = literalNames.length > symbolicNames.length ? literalNames.length : symbolicNames.length;
            this.tokenNames = [];
            for(let i=0; i<length; i++) {
                this.tokenNames[i] = literalNames[i] || symbolicNames[i] || "<INVALID";
            }
        }
        return this.tokenNames;
    }

    getTokenTypeMap() {
        const tokenNames = this.getTokenNames();
        if (tokenNames===null) {
            throw("The current recognizer does not provide a list of token names.");
        }
        let result = this.tokenTypeMapCache[tokenNames];
        if(result===undefined) {
            result = tokenNames.reduce(function(o, k, i) { o[k] = i; });
            result.EOF = Token$8.EOF;
            this.tokenTypeMapCache[tokenNames] = result;
        }
        return result;
    }

    /**
     * Get a map from rule names to rule indexes.
     * <p>Used for XPath and tree pattern compilation.</p>
     */
    getRuleIndexMap() {
        const ruleNames = this.ruleNames;
        if (ruleNames===null) {
            throw("The current recognizer does not provide a list of rule names.");
        }
        let result = this.ruleIndexMapCache[ruleNames]; // todo: should it be Recognizer.ruleIndexMapCache ?
        if(result===undefined) {
            result = ruleNames.reduce(function(o, k, i) { o[k] = i; });
            this.ruleIndexMapCache[ruleNames] = result;
        }
        return result;
    }

    getTokenType(tokenName) {
        const ttype = this.getTokenTypeMap()[tokenName];
        if (ttype !==undefined) {
            return ttype;
        } else {
            return Token$8.INVALID_TYPE;
        }
    }

    // What is the error header, normally line/character position information?
    getErrorHeader(e) {
        const line = e.getOffendingToken().line;
        const column = e.getOffendingToken().column;
        return "line " + line + ":" + column;
    }

    /**
     * How should a token be displayed in an error message? The default
     * is to display just the text, but during development you might
     * want to have a lot of information spit out.  Override in that case
     * to use t.toString() (which, for CommonToken, dumps everything about
     * the token). This is better than forcing you to override a method in
     * your token objects because you don't have to go modify your lexer
     * so that it creates a new Java type.
     *
     * @deprecated This method is not called by the ANTLR 4 Runtime. Specific
     * implementations of {@link ANTLRErrorStrategy} may provide a similar
     * feature when necessary. For example, see
     * {@link DefaultErrorStrategy//getTokenErrorDisplay}.*/
    getTokenErrorDisplay(t) {
        if (t===null) {
            return "<no token>";
        }
        let s = t.text;
        if (s===null) {
            if (t.type===Token$8.EOF) {
                s = "<EOF>";
            } else {
                s = "<" + t.type + ">";
            }
        }
        s = s.replace("\n","\\n").replace("\r","\\r").replace("\t","\\t");
        return "'" + s + "'";
    }

    getErrorListenerDispatch() {
        return new ProxyErrorListener(this._listeners);
    }

    /**
     * subclass needs to override these if there are sempreds or actions
     * that the ATN interp needs to execute
     */
    sempred(localctx, ruleIndex, actionIndex) {
        return true;
    }

    precpred(localctx , precedence) {
        return true;
    }

    get state(){
        return this._stateNumber;
    }

    set state(state) {
        this._stateNumber = state;
    }
};

Recognizer$2.tokenTypeMapCache = {};
Recognizer$2.ruleIndexMapCache = {};

var Recognizer_1 = Recognizer$2;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const CommonToken = Token_1.CommonToken;

class TokenFactory {}

/**
 * This default implementation of {@link TokenFactory} creates
 * {@link CommonToken} objects.
 */
let CommonTokenFactory$1 = class CommonTokenFactory extends TokenFactory {
    constructor(copyText) {
        super();
        /**
         * Indicates whether {@link CommonToken//setText} should be called after
         * constructing tokens to explicitly set the text. This is useful for cases
         * where the input stream might not be able to provide arbitrary substrings
         * of text from the input after the lexer creates a token (e.g. the
         * implementation of {@link CharStream//getText} in
         * {@link UnbufferedCharStream} throws an
         * {@link UnsupportedOperationException}). Explicitly setting the token text
         * allows {@link Token//getText} to be called at any time regardless of the
         * input stream implementation.
         *
         * <p>
         * The default value is {@code false} to avoid the performance and memory
         * overhead of copying text for every token unless explicitly requested.</p>
         */
        this.copyText = copyText===undefined ? false : copyText;
    }

    create(source, type, text, channel, start, stop, line, column) {
        const t = new CommonToken(source, type, channel, start, stop);
        t.line = line;
        t.column = column;
        if (text !==null) {
            t.text = text;
        } else if (this.copyText && source[1] !==null) {
            t.text = source[1].getText(start,stop);
        }
        return t;
    }

    createThin(type, text) {
        const t = new CommonToken(null, type);
        t.text = text;
        return t;
    }
};

/**
 * The default {@link CommonTokenFactory} instance.
 *
 * <p>
 * This token factory does not explicitly copy token text when constructing
 * tokens.</p>
 */
CommonTokenFactory$1.DEFAULT = new CommonTokenFactory$1();

var CommonTokenFactory_1 = CommonTokenFactory$1;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

/**
 * The root of the ANTLR exception hierarchy. In general, ANTLR tracks just
 *  3 kinds of errors: prediction errors, failed predicate errors, and
 *  mismatched input errors. In each case, the parser knows where it is
 *  in the input, where it is in the ATN, the rule invocation stack,
 *  and what kind of problem occurred.
 */

const {PredicateTransition} = Transition_1;
const {Interval: Interval$5} = IntervalSet_1.Interval;

let RecognitionException$1 = class RecognitionException extends Error {
    constructor(params) {
        super(params.message);
        if (!!Error.captureStackTrace) {
            Error.captureStackTrace(this, RecognitionException);
        } else {
            new Error().stack;
        }
        this.message = params.message;
        this.recognizer = params.recognizer;
        this.input = params.input;
        this.ctx = params.ctx;
        /**
         * The current {@link Token} when an error occurred. Since not all streams
         * support accessing symbols by index, we have to track the {@link Token}
         * instance itself
        */
        this.offendingToken = null;
        /**
         * Get the ATN state number the parser was in at the time the error
         * occurred. For {@link NoViableAltException} and
         * {@link LexerNoViableAltException} exceptions, this is the
         * {@link DecisionState} number. For others, it is the state whose outgoing
         * edge we couldn't match.
         */
        this.offendingState = -1;
        if (this.recognizer!==null) {
            this.offendingState = this.recognizer.state;
        }
    }

    /**
     * Gets the set of input symbols which could potentially follow the
     * previously matched symbol at the time this exception was thrown.
     *
     * <p>If the set of expected tokens is not known and could not be computed,
     * this method returns {@code null}.</p>
     *
     * @return The set of token types that could potentially follow the current
     * state in the ATN, or {@code null} if the information is not available.
     */
    getExpectedTokens() {
        if (this.recognizer!==null) {
            return this.recognizer.atn.getExpectedTokens(this.offendingState, this.ctx);
        } else {
            return null;
        }
    }

    // <p>If the state number is not known, this method returns -1.</p>
    toString() {
        return this.message;
    }
};

let LexerNoViableAltException$2 = class LexerNoViableAltException extends RecognitionException$1 {
    constructor(lexer, input, startIndex, deadEndConfigs) {
        super({message: "", recognizer: lexer, input: input, ctx: null});
        this.startIndex = startIndex;
        this.deadEndConfigs = deadEndConfigs;
    }

    toString() {
        let symbol = "";
        if (this.startIndex >= 0 && this.startIndex < this.input.size) {
            symbol = this.input.getText(new Interval$5(this.startIndex,this.startIndex));
        }
        return "LexerNoViableAltException" + symbol;
    }
};


/**
 * Indicates that the parser could not decide which of two or more paths
 * to take based upon the remaining input. It tracks the starting token
 * of the offending input and also knows where the parser was
 * in the various paths when the error. Reported by reportNoViableAlternative()
 */
let NoViableAltException$2 = class NoViableAltException extends RecognitionException$1 {
    constructor(recognizer, input, startToken, offendingToken, deadEndConfigs, ctx) {
        ctx = ctx || recognizer._ctx;
        offendingToken = offendingToken || recognizer.getCurrentToken();
        startToken = startToken || recognizer.getCurrentToken();
        input = input || recognizer.getInputStream();
        super({message: "", recognizer: recognizer, input: input, ctx: ctx});
        // Which configurations did we try at input.index() that couldn't match
        // input.LT(1)?//
        this.deadEndConfigs = deadEndConfigs;
        // The token object at the start index; the input stream might
        // not be buffering tokens so get a reference to it. (At the
        // time the error occurred, of course the stream needs to keep a
        // buffer all of the tokens but later we might not have access to those.)
        this.startToken = startToken;
        this.offendingToken = offendingToken;
    }
};

/**
 * This signifies any kind of mismatched input exceptions such as
 * when the current input does not match the expected token.
*/
let InputMismatchException$1 = class InputMismatchException extends RecognitionException$1 {
    constructor(recognizer) {
        super({message: "", recognizer: recognizer, input: recognizer.getInputStream(), ctx: recognizer._ctx});
        this.offendingToken = recognizer.getCurrentToken();
    }
};

function formatMessage(predicate, message) {
    if (message !==null) {
        return message;
    } else {
        return "failed predicate: {" + predicate + "}?";
    }
}

/**
 * A semantic predicate failed during validation. Validation of predicates
 * occurs when normally parsing the alternative just like matching a token.
 * Disambiguating predicate evaluation occurs when we test a predicate during
 * prediction.
*/
let FailedPredicateException$1 = class FailedPredicateException extends RecognitionException$1 {
    constructor(recognizer, predicate, message) {
        super({
            message: formatMessage(predicate, message || null), recognizer: recognizer,
            input: recognizer.getInputStream(), ctx: recognizer._ctx
        });
        const s = recognizer._interp.atn.states[recognizer.state];
        const trans = s.transitions[0];
        if (trans instanceof PredicateTransition) {
            this.ruleIndex = trans.ruleIndex;
            this.predicateIndex = trans.predIndex;
        } else {
            this.ruleIndex = 0;
            this.predicateIndex = 0;
        }
        this.predicate = predicate;
        this.offendingToken = recognizer.getCurrentToken();
    }
};


let ParseCancellationException$1 = class ParseCancellationException extends Error{
    constructor() {
        super();
        Error.captureStackTrace(this, ParseCancellationException);
    }
};

var Errors = {
    RecognitionException: RecognitionException$1,
    NoViableAltException: NoViableAltException$2,
    LexerNoViableAltException: LexerNoViableAltException$2,
    InputMismatchException: InputMismatchException$1,
    FailedPredicateException: FailedPredicateException$1,
    ParseCancellationException: ParseCancellationException$1
};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Token: Token$7} = Token_1;
const Recognizer$1 = Recognizer_1;
const CommonTokenFactory = CommonTokenFactory_1;
const {RecognitionException} = Errors;
const {LexerNoViableAltException: LexerNoViableAltException$1} = Errors;

/**
 * A lexer is recognizer that draws input symbols from a character stream.
 * lexer grammars result in a subclass of this object. A Lexer object
 * uses simplified match() and error recovery mechanisms in the interest of speed.
 */
let Lexer$4 = class Lexer extends Recognizer$1 {
	constructor(input) {
		super();
		this._input = input;
		this._factory = CommonTokenFactory.DEFAULT;
		this._tokenFactorySourcePair = [ this, input ];

		this._interp = null; // child classes must populate this

		/**
		 * The goal of all lexer rules/methods is to create a token object.
		 * this is an instance variable as multiple rules may collaborate to
		 * create a single token. nextToken will return this object after
		 * matching lexer rule(s). If you subclass to allow multiple token
		 * emissions, then set this to the last token to be matched or
		 * something nonnull so that the auto token emit mechanism will not
		 * emit another token.
		 */
		this._token = null;

		/**
		 * What character index in the stream did the current token start at?
		 * Needed, for example, to get the text for current token. Set at
		 * the start of nextToken.
		 */
		this._tokenStartCharIndex = -1;

		// The line on which the first character of the token resides///
		this._tokenStartLine = -1;

		// The character position of first character within the line///
		this._tokenStartColumn = -1;

		// Once we see EOF on char stream, next token will be EOF.
		// If you have DONE : EOF ; then you see DONE EOF.
		this._hitEOF = false;

		// The channel number for the current token///
		this._channel = Token$7.DEFAULT_CHANNEL;

		// The token type for the current token///
		this._type = Token$7.INVALID_TYPE;

		this._modeStack = [];
		this._mode = Lexer.DEFAULT_MODE;

		/**
		 * You can set the text for the current token to override what is in
		 * the input char buffer. Use setText() or can set this instance var.
		 */
		this._text = null;
	}

	reset() {
		// wack Lexer state variables
		if (this._input !== null) {
			this._input.seek(0); // rewind the input
		}
		this._token = null;
		this._type = Token$7.INVALID_TYPE;
		this._channel = Token$7.DEFAULT_CHANNEL;
		this._tokenStartCharIndex = -1;
		this._tokenStartColumn = -1;
		this._tokenStartLine = -1;
		this._text = null;

		this._hitEOF = false;
		this._mode = Lexer.DEFAULT_MODE;
		this._modeStack = [];

		this._interp.reset();
	}

// Return a token from this source; i.e., match a token on the char stream.
	nextToken() {
		if (this._input === null) {
			throw "nextToken requires a non-null input stream.";
		}

		/**
		 * Mark start location in char stream so unbuffered streams are
		 * guaranteed at least have text of current token
		 */
		const tokenStartMarker = this._input.mark();
		try {
			while (true) {
				if (this._hitEOF) {
					this.emitEOF();
					return this._token;
				}
				this._token = null;
				this._channel = Token$7.DEFAULT_CHANNEL;
				this._tokenStartCharIndex = this._input.index;
				this._tokenStartColumn = this._interp.column;
				this._tokenStartLine = this._interp.line;
				this._text = null;
				let continueOuter = false;
				while (true) {
					this._type = Token$7.INVALID_TYPE;
					let ttype = Lexer.SKIP;
					try {
						ttype = this._interp.match(this._input, this._mode);
					} catch (e) {
						if(e instanceof RecognitionException) {
							this.notifyListeners(e); // report error
							this.recover(e);
						} else {
							console.log(e.stack);
							throw e;
						}
					}
					if (this._input.LA(1) === Token$7.EOF) {
						this._hitEOF = true;
					}
					if (this._type === Token$7.INVALID_TYPE) {
						this._type = ttype;
					}
					if (this._type === Lexer.SKIP) {
						continueOuter = true;
						break;
					}
					if (this._type !== Lexer.MORE) {
						break;
					}
				}
				if (continueOuter) {
					continue;
				}
				if (this._token === null) {
					this.emit();
				}
				return this._token;
			}
		} finally {
			// make sure we release marker after match or
			// unbuffered char stream will keep buffering
			this._input.release(tokenStartMarker);
		}
	}

	/**
	 * Instruct the lexer to skip creating a token for current lexer rule
	 * and look for another token. nextToken() knows to keep looking when
	 * a lexer rule finishes with token set to SKIP_TOKEN. Recall that
	 * if token==null at end of any token rule, it creates one for you
	 * and emits it.
	 */
	skip() {
		this._type = Lexer.SKIP;
	}

	more() {
		this._type = Lexer.MORE;
	}

	mode(m) {
		this._mode = m;
	}

	pushMode(m) {
		if (this._interp.debug) {
			console.log("pushMode " + m);
		}
		this._modeStack.push(this._mode);
		this.mode(m);
	}

	popMode() {
		if (this._modeStack.length === 0) {
			throw "Empty Stack";
		}
		if (this._interp.debug) {
			console.log("popMode back to " + this._modeStack.slice(0, -1));
		}
		this.mode(this._modeStack.pop());
		return this._mode;
	}

	/**
	 * By default does not support multiple emits per nextToken invocation
	 * for efficiency reasons. Subclass and override this method, nextToken,
	 * and getToken (to push tokens into a list and pull from that list
	 * rather than a single variable as this implementation does).
	 */
	emitToken(token) {
		this._token = token;
	}

	/**
	 * The standard method called to automatically emit a token at the
	 * outermost lexical rule. The token object should point into the
	 * char buffer start..stop. If there is a text override in 'text',
	 * use that to set the token's text. Override this method to emit
	 * custom Token objects or provide a new factory.
	 */
	emit() {
		const t = this._factory.create(this._tokenFactorySourcePair, this._type,
				this._text, this._channel, this._tokenStartCharIndex, this
						.getCharIndex() - 1, this._tokenStartLine,
				this._tokenStartColumn);
		this.emitToken(t);
		return t;
	}

	emitEOF() {
		const cpos = this.column;
		const lpos = this.line;
		const eof = this._factory.create(this._tokenFactorySourcePair, Token$7.EOF,
				null, Token$7.DEFAULT_CHANNEL, this._input.index,
				this._input.index - 1, lpos, cpos);
		this.emitToken(eof);
		return eof;
	}

// What is the index of the current character of lookahead?///
	getCharIndex() {
		return this._input.index;
	}

	/**
	 * Return a list of all Token objects in input char stream.
	 * Forces load of all tokens. Does not include EOF token.
	 */
	getAllTokens() {
		const tokens = [];
		let t = this.nextToken();
		while (t.type !== Token$7.EOF) {
			tokens.push(t);
			t = this.nextToken();
		}
		return tokens;
	}

	notifyListeners(e) {
		const start = this._tokenStartCharIndex;
		const stop = this._input.index;
		const text = this._input.getText(start, stop);
		const msg = "token recognition error at: '" + this.getErrorDisplay(text) + "'";
		const listener = this.getErrorListenerDispatch();
		listener.syntaxError(this, null, this._tokenStartLine,
				this._tokenStartColumn, msg, e);
	}

	getErrorDisplay(s) {
		const d = [];
		for (let i = 0; i < s.length; i++) {
			d.push(s[i]);
		}
		return d.join('');
	}

	getErrorDisplayForChar(c) {
		if (c.charCodeAt(0) === Token$7.EOF) {
			return "<EOF>";
		} else if (c === '\n') {
			return "\\n";
		} else if (c === '\t') {
			return "\\t";
		} else if (c === '\r') {
			return "\\r";
		} else {
			return c;
		}
	}

	getCharErrorDisplay(c) {
		return "'" + this.getErrorDisplayForChar(c) + "'";
	}

	/**
	 * Lexers can normally match any char in it's vocabulary after matching
	 * a token, so do the easy thing and just kill a character and hope
	 * it all works out. You can instead use the rule invocation stack
	 * to do sophisticated error recovery if you are in a fragment rule.
	 */
	recover(re) {
		if (this._input.LA(1) !== Token$7.EOF) {
			if (re instanceof LexerNoViableAltException$1) {
				// skip a char and try again
				this._interp.consume(this._input);
			} else {
				// TODO: Do we lose character or line position information?
				this._input.consume();
			}
		}
	}

	get inputStream(){
		return this._input;
	}

	set inputStream(input) {
		this._input = null;
		this._tokenFactorySourcePair = [ this, this._input ];
		this.reset();
		this._input = input;
		this._tokenFactorySourcePair = [ this, this._input ];
	}

	get sourceName(){
		return this._input.sourceName;
	}

	get type(){
		return this._type;
	}

	set type(type) {
		this._type = type;
	}

	get line(){
		return this._interp.line;
	}

	set line(line) {
		this._interp.line = line;
	}

	get column(){
		return this._interp.column;
	}

	set column(column) {
		this._interp.column = column;
	}

	get text(){
		if (this._text !== null) {
			return this._text;
		} else {
			return this._interp.getText(this._input);
		}
	}

	set text(text) {
		this._text = text;
	}
};




Lexer$4.DEFAULT_MODE = 0;
Lexer$4.MORE = -2;
Lexer$4.SKIP = -3;

Lexer$4.DEFAULT_TOKEN_CHANNEL = Token$7.DEFAULT_CHANNEL;
Lexer$4.HIDDEN = Token$7.HIDDEN_CHANNEL;
Lexer$4.MIN_CHAR_VALUE = 0x0000;
Lexer$4.MAX_CHAR_VALUE = 0x10FFFF;

// Set the char stream and reset the lexer


var Lexer_1 = Lexer$4;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const ATN$3 = ATN_1;
const Utils$2 = Utils$4;
const {SemanticContext: SemanticContext$2} = SemanticContext_1;
const {merge} = PredictionContext_1;

function hashATNConfig(c) {
	return c.hashCodeForConfigSet();
}

function equalATNConfigs(a, b) {
	if ( a===b ) {
		return true;
	} else if ( a===null || b===null ) {
		return false;
	} else
       return a.equalsForConfigSet(b);
 }

/**
 * Specialized {@link Set}{@code <}{@link ATNConfig}{@code >} that can track
 * info about the set, with support for combining similar configurations using a
 * graph-structured stack
 */
let ATNConfigSet$5 = class ATNConfigSet {
	constructor(fullCtx) {
		/**
		 * The reason that we need this is because we don't want the hash map to use
		 * the standard hash code and equals. We need all configurations with the
		 * same
		 * {@code (s,i,_,semctx)} to be equal. Unfortunately, this key effectively
		 * doubles
		 * the number of objects associated with ATNConfigs. The other solution is
		 * to
		 * use a hash table that lets us specify the equals/hashcode operation.
		 * All configs but hashed by (s, i, _, pi) not including context. Wiped out
		 * when we go readonly as this set becomes a DFA state
		 */
		this.configLookup = new Utils$2.Set(hashATNConfig, equalATNConfigs);
		/**
		 * Indicates that this configuration set is part of a full context
		 * LL prediction. It will be used to determine how to merge $. With SLL
		 * it's a wildcard whereas it is not for LL context merge
		 */
		this.fullCtx = fullCtx === undefined ? true : fullCtx;
		/**
		 * Indicates that the set of configurations is read-only. Do not
		 * allow any code to manipulate the set; DFA states will point at
		 * the sets and they must not change. This does not protect the other
		 * fields; in particular, conflictingAlts is set after
		 * we've made this readonly
		 */
		this.readOnly = false;
		// Track the elements as they are added to the set; supports get(i)///
		this.configs = [];

		// TODO: these fields make me pretty uncomfortable but nice to pack up info
		// together, saves recomputation
		// TODO: can we track conflicts as they are added to save scanning configs
		// later?
		this.uniqueAlt = 0;
		this.conflictingAlts = null;

		/**
		 * Used in parser and lexer. In lexer, it indicates we hit a pred
		 * while computing a closure operation. Don't make a DFA state from this
		 */
		this.hasSemanticContext = false;
		this.dipsIntoOuterContext = false;

		this.cachedHashCode = -1;
	}

	/**
	 * Adding a new config means merging contexts with existing configs for
	 * {@code (s, i, pi, _)}, where {@code s} is the
	 * {@link ATNConfig//state}, {@code i} is the {@link ATNConfig//alt}, and
	 * {@code pi} is the {@link ATNConfig//semanticContext}. We use
	 * {@code (s,i,pi)} as key.
	 *
	 * <p>This method updates {@link //dipsIntoOuterContext} and
	 * {@link //hasSemanticContext} when necessary.</p>
	 */
	add(config, mergeCache) {
		if (mergeCache === undefined) {
			mergeCache = null;
		}
		if (this.readOnly) {
			throw "This set is readonly";
		}
		if (config.semanticContext !== SemanticContext$2.NONE) {
			this.hasSemanticContext = true;
		}
		if (config.reachesIntoOuterContext > 0) {
			this.dipsIntoOuterContext = true;
		}
		const existing = this.configLookup.add(config);
		if (existing === config) {
			this.cachedHashCode = -1;
			this.configs.push(config); // track order here
			return true;
		}
		// a previous (s,i,pi,_), merge with it and save result
		const rootIsWildcard = !this.fullCtx;
		const merged = merge(existing.context, config.context, rootIsWildcard, mergeCache);
		/**
		 * no need to check for existing.context, config.context in cache
		 * since only way to create new graphs is "call rule" and here. We
		 * cache at both places
		 */
		existing.reachesIntoOuterContext = Math.max( existing.reachesIntoOuterContext, config.reachesIntoOuterContext);
		// make sure to preserve the precedence filter suppression during the merge
		if (config.precedenceFilterSuppressed) {
			existing.precedenceFilterSuppressed = true;
		}
		existing.context = merged; // replace context; no need to alt mapping
		return true;
	}

	getStates() {
		const states = new Utils$2.Set();
		for (let i = 0; i < this.configs.length; i++) {
			states.add(this.configs[i].state);
		}
		return states;
	}

	getPredicates() {
		const preds = [];
		for (let i = 0; i < this.configs.length; i++) {
			const c = this.configs[i].semanticContext;
			if (c !== SemanticContext$2.NONE) {
				preds.push(c.semanticContext);
			}
		}
		return preds;
	}

	optimizeConfigs(interpreter) {
		if (this.readOnly) {
			throw "This set is readonly";
		}
		if (this.configLookup.length === 0) {
			return;
		}
		for (let i = 0; i < this.configs.length; i++) {
			const config = this.configs[i];
			config.context = interpreter.getCachedContext(config.context);
		}
	}

	addAll(coll) {
		for (let i = 0; i < coll.length; i++) {
			this.add(coll[i]);
		}
		return false;
	}

	equals(other) {
		return this === other ||
			(other instanceof ATNConfigSet &&
			Utils$2.equalArrays(this.configs, other.configs) &&
			this.fullCtx === other.fullCtx &&
			this.uniqueAlt === other.uniqueAlt &&
			this.conflictingAlts === other.conflictingAlts &&
			this.hasSemanticContext === other.hasSemanticContext &&
			this.dipsIntoOuterContext === other.dipsIntoOuterContext);
	}

	hashCode() {
		const hash = new Utils$2.Hash();
		hash.update(this.configs);
		return hash.finish();
	}

	updateHashCode(hash) {
		if (this.readOnly) {
			if (this.cachedHashCode === -1) {
				this.cachedHashCode = this.hashCode();
			}
			hash.update(this.cachedHashCode);
		} else {
			hash.update(this.hashCode());
		}
	}

	isEmpty() {
		return this.configs.length === 0;
	}

	contains(item) {
		if (this.configLookup === null) {
			throw "This method is not implemented for readonly sets.";
		}
		return this.configLookup.contains(item);
	}

	containsFast(item) {
		if (this.configLookup === null) {
			throw "This method is not implemented for readonly sets.";
		}
		return this.configLookup.containsFast(item);
	}

	clear() {
		if (this.readOnly) {
			throw "This set is readonly";
		}
		this.configs = [];
		this.cachedHashCode = -1;
		this.configLookup = new Utils$2.Set();
	}

	setReadonly(readOnly) {
		this.readOnly = readOnly;
		if (readOnly) {
			this.configLookup = null; // can't mod, no need for lookup cache
		}
	}

	toString() {
		return Utils$2.arrayToString(this.configs) +
			(this.hasSemanticContext ? ",hasSemanticContext=" + this.hasSemanticContext : "") +
			(this.uniqueAlt !== ATN$3.INVALID_ALT_NUMBER ? ",uniqueAlt=" + this.uniqueAlt : "") +
			(this.conflictingAlts !== null ? ",conflictingAlts=" + this.conflictingAlts : "") +
			(this.dipsIntoOuterContext ? ",dipsIntoOuterContext" : "");
	}

	get items(){
		return this.configs;
	}

	get length(){
		return this.configs.length;
	}
};


let OrderedATNConfigSet$1 = class OrderedATNConfigSet extends ATNConfigSet$5 {
	constructor() {
		super();
		this.configLookup = new Utils$2.Set();
	}
};

var ATNConfigSet_1 = {
	ATNConfigSet: ATNConfigSet$5,
	OrderedATNConfigSet: OrderedATNConfigSet$1
};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {ATNConfigSet: ATNConfigSet$4} = ATNConfigSet_1;
const {Hash: Hash$1, Set: Set$3} = Utils$4;

/**
 * Map a predicate to a predicted alternative.
 */
let PredPrediction$1 = class PredPrediction {
	constructor(pred, alt) {
		this.alt = alt;
		this.pred = pred;
	}

	toString() {
		return "(" + this.pred + ", " + this.alt + ")";
	}
};

/**
 * A DFA state represents a set of possible ATN configurations.
 * As Aho, Sethi, Ullman p. 117 says "The DFA uses its state
 * to keep track of all possible states the ATN can be in after
 * reading each input symbol. That is to say, after reading
 * input a1a2..an, the DFA is in a state that represents the
 * subset T of the states of the ATN that are reachable from the
 * ATN's start state along some path labeled a1a2..an."
 * In conventional NFA&rarr;DFA conversion, therefore, the subset T
 * would be a bitset representing the set of states the
 * ATN could be in. We need to track the alt predicted by each
 * state as well, however. More importantly, we need to maintain
 * a stack of states, tracking the closure operations as they
 * jump from rule to rule, emulating rule invocations (method calls).
 * I have to add a stack to simulate the proper lookahead sequences for
 * the underlying LL grammar from which the ATN was derived.
 *
 * <p>I use a set of ATNConfig objects not simple states. An ATNConfig
 * is both a state (ala normal conversion) and a RuleContext describing
 * the chain of rules (if any) followed to arrive at that state.</p>
 *
 * <p>A DFA state may have multiple references to a particular state,
 * but with different ATN contexts (with same or different alts)
 * meaning that state was reached via a different set of rule invocations.</p>
 */
let DFAState$4 = class DFAState {
	constructor(stateNumber, configs) {
		if (stateNumber === null) {
			stateNumber = -1;
		}
		if (configs === null) {
			configs = new ATNConfigSet$4();
		}
		this.stateNumber = stateNumber;
		this.configs = configs;
		/**
		 * {@code edges[symbol]} points to target of symbol. Shift up by 1 so (-1)
		 * {@link Token//EOF} maps to {@code edges[0]}.
		 */
		this.edges = null;
		this.isAcceptState = false;
		/**
		 * if accept state, what ttype do we match or alt do we predict?
		 * This is set to {@link ATN//INVALID_ALT_NUMBER} when {@link//predicates}
		 * {@code !=null} or {@link //requiresFullContext}.
		 */
		this.prediction = 0;
		this.lexerActionExecutor = null;
		/**
		 * Indicates that this state was created during SLL prediction that
		 * discovered a conflict between the configurations in the state. Future
		 * {@link ParserATNSimulator//execATN} invocations immediately jumped doing
		 * full context prediction if this field is true.
		 */
		this.requiresFullContext = false;
		/**
		 * During SLL parsing, this is a list of predicates associated with the
		 * ATN configurations of the DFA state. When we have predicates,
		 * {@link //requiresFullContext} is {@code false} since full context
		 * prediction evaluates predicates
		 * on-the-fly. If this is not null, then {@link //prediction} is
		 * {@link ATN//INVALID_ALT_NUMBER}.
		 *
		 * <p>We only use these for non-{@link //requiresFullContext} but
		 * conflicting states. That
		 * means we know from the context (it's $ or we don't dip into outer
		 * context) that it's an ambiguity not a conflict.</p>
		 *
		 * <p>This list is computed by {@link
		 * ParserATNSimulator//predicateDFAState}.</p>
		 */
		this.predicates = null;
		return this;
	}

	/**
	 * Get the set of all alts mentioned by all ATN configurations in this
	 * DFA state.
	 */
	getAltSet() {
		const alts = new Set$3();
		if (this.configs !== null) {
			for (let i = 0; i < this.configs.length; i++) {
				const c = this.configs[i];
				alts.add(c.alt);
			}
		}
		if (alts.length === 0) {
			return null;
		} else {
			return alts;
		}
	}

	/**
	 * Two {@link DFAState} instances are equal if their ATN configuration sets
	 * are the same. This method is used to see if a state already exists.
	 *
	 * <p>Because the number of alternatives and number of ATN configurations are
	 * finite, there is a finite number of DFA states that can be processed.
	 * This is necessary to show that the algorithm terminates.</p>
	 *
	 * <p>Cannot test the DFA state numbers here because in
	 * {@link ParserATNSimulator//addDFAState} we need to know if any other state
	 * exists that has this exact set of ATN configurations. The
	 * {@link //stateNumber} is irrelevant.</p>
	 */
	equals(other) {
		// compare set of ATN configurations in this set with other
		return this === other ||
				(other instanceof DFAState &&
					this.configs.equals(other.configs));
	}

	toString() {
		let s = "" + this.stateNumber + ":" + this.configs;
		if(this.isAcceptState) {
			s = s + "=>";
			if (this.predicates !== null)
				s = s + this.predicates;
			else
				s = s + this.prediction;
		}
		return s;
	}

	hashCode() {
		const hash = new Hash$1();
		hash.update(this.configs);
		return hash.finish();
	}
};

var DFAState_1 = { DFAState: DFAState$4, PredPrediction: PredPrediction$1 };

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {DFAState: DFAState$3} = DFAState_1;
const {ATNConfigSet: ATNConfigSet$3} = ATNConfigSet_1;
const {getCachedPredictionContext} = PredictionContext_1;
const {Map: Map$2} = Utils$4;

let ATNSimulator$2 = class ATNSimulator {
    constructor(atn, sharedContextCache) {
        /**
         * The context cache maps all PredictionContext objects that are ==
         * to a single cached copy. This cache is shared across all contexts
         * in all ATNConfigs in all DFA states.  We rebuild each ATNConfigSet
         * to use only cached nodes/graphs in addDFAState(). We don't want to
         * fill this during closure() since there are lots of contexts that
         * pop up but are not used ever again. It also greatly slows down closure().
         *
         * <p>This cache makes a huge difference in memory and a little bit in speed.
         * For the Java grammar on java.*, it dropped the memory requirements
         * at the end from 25M to 16M. We don't store any of the full context
         * graphs in the DFA because they are limited to local context only,
         * but apparently there's a lot of repetition there as well. We optimize
         * the config contexts before storing the config set in the DFA states
         * by literally rebuilding them with cached subgraphs only.</p>
         *
         * <p>I tried a cache for use during closure operations, that was
         * whacked after each adaptivePredict(). It cost a little bit
         * more time I think and doesn't save on the overall footprint
         * so it's not worth the complexity.</p>
         */
        this.atn = atn;
        this.sharedContextCache = sharedContextCache;
        return this;
    }

    getCachedContext(context) {
        if (this.sharedContextCache ===null) {
            return context;
        }
        const visited = new Map$2();
        return getCachedPredictionContext(context, this.sharedContextCache, visited);
    }
};

// Must distinguish between missing edge and edge we know leads nowhere///
ATNSimulator$2.ERROR = new DFAState$3(0x7FFFFFFF, new ATNConfigSet$3());


var ATNSimulator_1 = ATNSimulator$2;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {hashStuff: hashStuff$1} = Utils$4;
const {LexerIndexedCustomAction} = LexerAction_1;

let LexerActionExecutor$1 = class LexerActionExecutor {
	/**
	 * Represents an executor for a sequence of lexer actions which traversed during
	 * the matching operation of a lexer rule (token).
	 *
	 * <p>The executor tracks position information for position-dependent lexer actions
	 * efficiently, ensuring that actions appearing only at the end of the rule do
	 * not cause bloating of the {@link DFA} created for the lexer.</p>
	 */
	constructor(lexerActions) {
		this.lexerActions = lexerActions === null ? [] : lexerActions;
		/**
		 * Caches the result of {@link //hashCode} since the hash code is an element
		 * of the performance-critical {@link LexerATNConfig//hashCode} operation
		 */
		this.cachedHashCode = hashStuff$1(lexerActions); // "".join([str(la) for la in
		// lexerActions]))
		return this;
	}

	/**
	 * Creates a {@link LexerActionExecutor} which encodes the current offset
	 * for position-dependent lexer actions.
	 *
	 * <p>Normally, when the executor encounters lexer actions where
	 * {@link LexerAction//isPositionDependent} returns {@code true}, it calls
	 * {@link IntStream//seek} on the input {@link CharStream} to set the input
	 * position to the <em>end</em> of the current token. This behavior provides
	 * for efficient DFA representation of lexer actions which appear at the end
	 * of a lexer rule, even when the lexer rule matches a variable number of
	 * characters.</p>
	 *
	 * <p>Prior to traversing a match transition in the ATN, the current offset
	 * from the token start index is assigned to all position-dependent lexer
	 * actions which have not already been assigned a fixed offset. By storing
	 * the offsets relative to the token start index, the DFA representation of
	 * lexer actions which appear in the middle of tokens remains efficient due
	 * to sharing among tokens of the same length, regardless of their absolute
	 * position in the input stream.</p>
	 *
	 * <p>If the current executor already has offsets assigned to all
	 * position-dependent lexer actions, the method returns {@code this}.</p>
	 *
	 * @param offset The current offset to assign to all position-dependent
	 * lexer actions which do not already have offsets assigned.
	 *
	 * @return {LexerActionExecutor} A {@link LexerActionExecutor} which stores input stream offsets
	 * for all position-dependent lexer actions.
	 */
	fixOffsetBeforeMatch(offset) {
		let updatedLexerActions = null;
		for (let i = 0; i < this.lexerActions.length; i++) {
			if (this.lexerActions[i].isPositionDependent &&
					!(this.lexerActions[i] instanceof LexerIndexedCustomAction)) {
				if (updatedLexerActions === null) {
					updatedLexerActions = this.lexerActions.concat([]);
				}
				updatedLexerActions[i] = new LexerIndexedCustomAction(offset,
						this.lexerActions[i]);
			}
		}
		if (updatedLexerActions === null) {
			return this;
		} else {
			return new LexerActionExecutor(updatedLexerActions);
		}
	}

	/**
	 * Execute the actions encapsulated by this executor within the context of a
	 * particular {@link Lexer}.
	 *
	 * <p>This method calls {@link IntStream//seek} to set the position of the
	 * {@code input} {@link CharStream} prior to calling
	 * {@link LexerAction//execute} on a position-dependent action. Before the
	 * method returns, the input position will be restored to the same position
	 * it was in when the method was invoked.</p>
	 *
	 * @param lexer The lexer instance.
	 * @param input The input stream which is the source for the current token.
	 * When this method is called, the current {@link IntStream//index} for
	 * {@code input} should be the start of the following token, i.e. 1
	 * character past the end of the current token.
	 * @param startIndex The token start index. This value may be passed to
	 * {@link IntStream//seek} to set the {@code input} position to the beginning
	 * of the token.
	 */
	execute(lexer, input, startIndex) {
		let requiresSeek = false;
		const stopIndex = input.index;
		try {
			for (let i = 0; i < this.lexerActions.length; i++) {
				let lexerAction = this.lexerActions[i];
				if (lexerAction instanceof LexerIndexedCustomAction) {
					const offset = lexerAction.offset;
					input.seek(startIndex + offset);
					lexerAction = lexerAction.action;
					requiresSeek = (startIndex + offset) !== stopIndex;
				} else if (lexerAction.isPositionDependent) {
					input.seek(stopIndex);
					requiresSeek = false;
				}
				lexerAction.execute(lexer);
			}
		} finally {
			if (requiresSeek) {
				input.seek(stopIndex);
			}
		}
	}

	hashCode() {
		return this.cachedHashCode;
	}

	updateHashCode(hash) {
		hash.update(this.cachedHashCode);
	}

	equals(other) {
		if (this === other) {
			return true;
		} else if (!(other instanceof LexerActionExecutor)) {
			return false;
		} else if (this.cachedHashCode != other.cachedHashCode) {
			return false;
		} else if (this.lexerActions.length != other.lexerActions.length) {
			return false;
		} else {
			const numActions = this.lexerActions.length;
			for (let idx = 0; idx < numActions; ++idx) {
				if (!this.lexerActions[idx].equals(other.lexerActions[idx])) {
					return false;
				}
			}
			return true;
		}
	}

	/**
	 * Creates a {@link LexerActionExecutor} which executes the actions for
	 * the input {@code lexerActionExecutor} followed by a specified
	 * {@code lexerAction}.
	 *
	 * @param lexerActionExecutor The executor for actions already traversed by
	 * the lexer while matching a token within a particular
	 * {@link LexerATNConfig}. If this is {@code null}, the method behaves as
	 * though it were an empty executor.
	 * @param lexerAction The lexer action to execute after the actions
	 * specified in {@code lexerActionExecutor}.
	 *
	 * @return {LexerActionExecutor} A {@link LexerActionExecutor} for executing the combine actions
	 * of {@code lexerActionExecutor} and {@code lexerAction}.
	 */
	static append(lexerActionExecutor, lexerAction) {
		if (lexerActionExecutor === null) {
			return new LexerActionExecutor([ lexerAction ]);
		}
		const lexerActions = lexerActionExecutor.lexerActions.concat([ lexerAction ]);
		return new LexerActionExecutor(lexerActions);
	}
};


var LexerActionExecutor_1 = LexerActionExecutor$1;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Token: Token$6} = Token_1;
const Lexer$3 = Lexer_1;
const ATN$2 = ATN_1;
const ATNSimulator$1 = ATNSimulator_1;
const {DFAState: DFAState$2} = DFAState_1;
const {OrderedATNConfigSet} = ATNConfigSet_1;
const {PredictionContext: PredictionContext$1} = PredictionContext_1;
const {SingletonPredictionContext: SingletonPredictionContext$1} = PredictionContext_1;
const {RuleStopState: RuleStopState$2} = ATNState_1;
const {LexerATNConfig} = ATNConfig$4;
const {Transition: Transition$1} = Transition_1;
const LexerActionExecutor = LexerActionExecutor_1;
const {LexerNoViableAltException} = Errors;

function resetSimState(sim) {
	sim.index = -1;
	sim.line = 0;
	sim.column = -1;
	sim.dfaState = null;
}

class SimState {
	constructor() {
		resetSimState(this);
	}

	reset() {
		resetSimState(this);
	}
}

class LexerATNSimulator extends ATNSimulator$1 {
	/**
	 * When we hit an accept state in either the DFA or the ATN, we
	 * have to notify the character stream to start buffering characters
	 * via {@link IntStream//mark} and record the current state. The current sim state
	 * includes the current index into the input, the current line,
	 * and current character position in that line. Note that the Lexer is
	 * tracking the starting line and characterization of the token. These
	 * variables track the "state" of the simulator when it hits an accept state.
	 *
	 * <p>We track these variables separately for the DFA and ATN simulation
	 * because the DFA simulation often has to fail over to the ATN
	 * simulation. If the ATN simulation fails, we need the DFA to fall
	 * back to its previously accepted state, if any. If the ATN succeeds,
	 * then the ATN does the accept and the DFA simulator that invoked it
	 * can simply return the predicted token type.</p>
	 */
	constructor(recog, atn, decisionToDFA, sharedContextCache) {
		super(atn, sharedContextCache);
		this.decisionToDFA = decisionToDFA;
		this.recog = recog;
		/**
		 * The current token's starting index into the character stream.
		 * Shared across DFA to ATN simulation in case the ATN fails and the
		 * DFA did not have a previous accept state. In this case, we use the
		 * ATN-generated exception object
		 */
		this.startIndex = -1;
		// line number 1..n within the input///
		this.line = 1;
		/**
		 * The index of the character relative to the beginning of the line
		 * 0..n-1
		 */
		this.column = 0;
		this.mode = Lexer$3.DEFAULT_MODE;
		/**
		 * Used during DFA/ATN exec to record the most recent accept configuration
		 * info
		 */
		this.prevAccept = new SimState();
	}

	copyState(simulator) {
		this.column = simulator.column;
		this.line = simulator.line;
		this.mode = simulator.mode;
		this.startIndex = simulator.startIndex;
	}

	match(input, mode) {
		this.match_calls += 1;
		this.mode = mode;
		const mark = input.mark();
		try {
			this.startIndex = input.index;
			this.prevAccept.reset();
			const dfa = this.decisionToDFA[mode];
			if (dfa.s0 === null) {
				return this.matchATN(input);
			} else {
				return this.execATN(input, dfa.s0);
			}
		} finally {
			input.release(mark);
		}
	}

	reset() {
		this.prevAccept.reset();
		this.startIndex = -1;
		this.line = 1;
		this.column = 0;
		this.mode = Lexer$3.DEFAULT_MODE;
	}

	matchATN(input) {
		const startState = this.atn.modeToStartState[this.mode];

		if (LexerATNSimulator.debug) {
			console.log("matchATN mode " + this.mode + " start: " + startState);
		}
		const old_mode = this.mode;
		const s0_closure = this.computeStartState(input, startState);
		const suppressEdge = s0_closure.hasSemanticContext;
		s0_closure.hasSemanticContext = false;

		const next = this.addDFAState(s0_closure);
		if (!suppressEdge) {
			this.decisionToDFA[this.mode].s0 = next;
		}

		const predict = this.execATN(input, next);

		if (LexerATNSimulator.debug) {
			console.log("DFA after matchATN: " + this.decisionToDFA[old_mode].toLexerString());
		}
		return predict;
	}

	execATN(input, ds0) {
		if (LexerATNSimulator.debug) {
			console.log("start state closure=" + ds0.configs);
		}
		if (ds0.isAcceptState) {
			// allow zero-length tokens
			this.captureSimState(this.prevAccept, input, ds0);
		}
		let t = input.LA(1);
		let s = ds0; // s is current/from DFA state

		while (true) { // while more work
			if (LexerATNSimulator.debug) {
				console.log("execATN loop starting closure: " + s.configs);
			}

			/**
			 * As we move src->trg, src->trg, we keep track of the previous trg to
			 * avoid looking up the DFA state again, which is expensive.
			 * If the previous target was already part of the DFA, we might
			 * be able to avoid doing a reach operation upon t. If s!=null,
			 * it means that semantic predicates didn't prevent us from
			 * creating a DFA state. Once we know s!=null, we check to see if
			 * the DFA state has an edge already for t. If so, we can just reuse
			 * it's configuration set; there's no point in re-computing it.
			 * This is kind of like doing DFA simulation within the ATN
			 * simulation because DFA simulation is really just a way to avoid
			 * computing reach/closure sets. Technically, once we know that
			 * we have a previously added DFA state, we could jump over to
			 * the DFA simulator. But, that would mean popping back and forth
			 * a lot and making things more complicated algorithmically.
			 * This optimization makes a lot of sense for loops within DFA.
			 * A character will take us back to an existing DFA state
			 * that already has lots of edges out of it. e.g., .* in comments.
			 * print("Target for:" + str(s) + " and:" + str(t))
			 */
			let target = this.getExistingTargetState(s, t);
			// print("Existing:" + str(target))
			if (target === null) {
				target = this.computeTargetState(input, s, t);
				// print("Computed:" + str(target))
			}
			if (target === ATNSimulator$1.ERROR) {
				break;
			}
			// If this is a consumable input element, make sure to consume before
			// capturing the accept state so the input index, line, and char
			// position accurately reflect the state of the interpreter at the
			// end of the token.
			if (t !== Token$6.EOF) {
				this.consume(input);
			}
			if (target.isAcceptState) {
				this.captureSimState(this.prevAccept, input, target);
				if (t === Token$6.EOF) {
					break;
				}
			}
			t = input.LA(1);
			s = target; // flip; current DFA target becomes new src/from state
		}
		return this.failOrAccept(this.prevAccept, input, s.configs, t);
	}

	/**
	 * Get an existing target state for an edge in the DFA. If the target state
	 * for the edge has not yet been computed or is otherwise not available,
	 * this method returns {@code null}.
	 *
	 * @param s The current DFA state
	 * @param t The next input symbol
	 * @return The existing target DFA state for the given input symbol
	 * {@code t}, or {@code null} if the target state for this edge is not
	 * already cached
	 */
	getExistingTargetState(s, t) {
		if (s.edges === null || t < LexerATNSimulator.MIN_DFA_EDGE || t > LexerATNSimulator.MAX_DFA_EDGE) {
			return null;
		}

		let target = s.edges[t - LexerATNSimulator.MIN_DFA_EDGE];
		if(target===undefined) {
			target = null;
		}
		if (LexerATNSimulator.debug && target !== null) {
			console.log("reuse state " + s.stateNumber + " edge to " + target.stateNumber);
		}
		return target;
	}

	/**
	 * Compute a target state for an edge in the DFA, and attempt to add the
	 * computed state and corresponding edge to the DFA.
	 *
	 * @param input The input stream
	 * @param s The current DFA state
	 * @param t The next input symbol
	 *
	 * @return The computed target DFA state for the given input symbol
	 * {@code t}. If {@code t} does not lead to a valid DFA state, this method
	 * returns {@link //ERROR}.
	 */
	computeTargetState(input, s, t) {
		const reach = new OrderedATNConfigSet();
		// if we don't find an existing DFA state
		// Fill reach starting from closure, following t transitions
		this.getReachableConfigSet(input, s.configs, reach, t);

		if (reach.items.length === 0) { // we got nowhere on t from s
			if (!reach.hasSemanticContext) {
				// we got nowhere on t, don't throw out this knowledge; it'd
				// cause a failover from DFA later.
				this.addDFAEdge(s, t, ATNSimulator$1.ERROR);
			}
			// stop when we can't match any more char
			return ATNSimulator$1.ERROR;
		}
		// Add an edge from s to target DFA found/created for reach
		return this.addDFAEdge(s, t, null, reach);
	}

	failOrAccept(prevAccept, input, reach, t) {
		if (this.prevAccept.dfaState !== null) {
			const lexerActionExecutor = prevAccept.dfaState.lexerActionExecutor;
			this.accept(input, lexerActionExecutor, this.startIndex,
					prevAccept.index, prevAccept.line, prevAccept.column);
			return prevAccept.dfaState.prediction;
		} else {
			// if no accept and EOF is first char, return EOF
			if (t === Token$6.EOF && input.index === this.startIndex) {
				return Token$6.EOF;
			}
			throw new LexerNoViableAltException(this.recog, input, this.startIndex, reach);
		}
	}

	/**
	 * Given a starting configuration set, figure out all ATN configurations
	 * we can reach upon input {@code t}. Parameter {@code reach} is a return
	 * parameter.
	 */
	getReachableConfigSet(input, closure,
			reach, t) {
		// this is used to skip processing for configs which have a lower priority
		// than a config that already reached an accept state for the same rule
		let skipAlt = ATN$2.INVALID_ALT_NUMBER;
		for (let i = 0; i < closure.items.length; i++) {
			const cfg = closure.items[i];
			const currentAltReachedAcceptState = (cfg.alt === skipAlt);
			if (currentAltReachedAcceptState && cfg.passedThroughNonGreedyDecision) {
				continue;
			}
			if (LexerATNSimulator.debug) {
				console.log("testing %s at %s\n", this.getTokenName(t), cfg
						.toString(this.recog, true));
			}
			for (let j = 0; j < cfg.state.transitions.length; j++) {
				const trans = cfg.state.transitions[j]; // for each transition
				const target = this.getReachableTarget(trans, t);
				if (target !== null) {
					let lexerActionExecutor = cfg.lexerActionExecutor;
					if (lexerActionExecutor !== null) {
						lexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index - this.startIndex);
					}
					const treatEofAsEpsilon = (t === Token$6.EOF);
					const config = new LexerATNConfig({state:target, lexerActionExecutor:lexerActionExecutor}, cfg);
					if (this.closure(input, config, reach,
							currentAltReachedAcceptState, true, treatEofAsEpsilon)) {
						// any remaining configs for this alt have a lower priority
						// than the one that just reached an accept state.
						skipAlt = cfg.alt;
					}
				}
			}
		}
	}

	accept(input, lexerActionExecutor,
			   startIndex, index, line, charPos) {
		   if (LexerATNSimulator.debug) {
			   console.log("ACTION %s\n", lexerActionExecutor);
		   }
		   // seek to after last char in token
		   input.seek(index);
		   this.line = line;
		   this.column = charPos;
		   if (lexerActionExecutor !== null && this.recog !== null) {
			   lexerActionExecutor.execute(this.recog, input, startIndex);
		   }
	   }

	getReachableTarget(trans, t) {
		if (trans.matches(t, 0, Lexer$3.MAX_CHAR_VALUE)) {
			return trans.target;
		} else {
			return null;
		}
	}

	computeStartState(input, p) {
		const initialContext = PredictionContext$1.EMPTY;
		const configs = new OrderedATNConfigSet();
		for (let i = 0; i < p.transitions.length; i++) {
			const target = p.transitions[i].target;
			const cfg = new LexerATNConfig({state:target, alt:i+1, context:initialContext}, null);
			this.closure(input, cfg, configs, false, false, false);
		}
		return configs;
	}

	/**
	 * Since the alternatives within any lexer decision are ordered by
	 * preference, this method stops pursuing the closure as soon as an accept
	 * state is reached. After the first accept state is reached by depth-first
	 * search from {@code config}, all other (potentially reachable) states for
	 * this rule would have a lower priority.
	 *
	 * @return {Boolean} {@code true} if an accept state is reached, otherwise
	 * {@code false}.
	 */
	closure(input, config, configs,
			currentAltReachedAcceptState, speculative, treatEofAsEpsilon) {
		let cfg = null;
		if (LexerATNSimulator.debug) {
			console.log("closure(" + config.toString(this.recog, true) + ")");
		}
		if (config.state instanceof RuleStopState$2) {
			if (LexerATNSimulator.debug) {
				if (this.recog !== null) {
					console.log("closure at %s rule stop %s\n", this.recog.ruleNames[config.state.ruleIndex], config);
				} else {
					console.log("closure at rule stop %s\n", config);
				}
			}
			if (config.context === null || config.context.hasEmptyPath()) {
				if (config.context === null || config.context.isEmpty()) {
					configs.add(config);
					return true;
				} else {
					configs.add(new LexerATNConfig({ state:config.state, context:PredictionContext$1.EMPTY}, config));
					currentAltReachedAcceptState = true;
				}
			}
			if (config.context !== null && !config.context.isEmpty()) {
				for (let i = 0; i < config.context.length; i++) {
					if (config.context.getReturnState(i) !== PredictionContext$1.EMPTY_RETURN_STATE) {
						const newContext = config.context.getParent(i); // "pop" return state
						const returnState = this.atn.states[config.context.getReturnState(i)];
						cfg = new LexerATNConfig({ state:returnState, context:newContext }, config);
						currentAltReachedAcceptState = this.closure(input, cfg,
								configs, currentAltReachedAcceptState, speculative,
								treatEofAsEpsilon);
					}
				}
			}
			return currentAltReachedAcceptState;
		}
		// optimization
		if (!config.state.epsilonOnlyTransitions) {
			if (!currentAltReachedAcceptState || !config.passedThroughNonGreedyDecision) {
				configs.add(config);
			}
		}
		for (let j = 0; j < config.state.transitions.length; j++) {
			const trans = config.state.transitions[j];
			cfg = this.getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon);
			if (cfg !== null) {
				currentAltReachedAcceptState = this.closure(input, cfg, configs,
						currentAltReachedAcceptState, speculative, treatEofAsEpsilon);
			}
		}
		return currentAltReachedAcceptState;
	}

	// side-effect: can alter configs.hasSemanticContext
	getEpsilonTarget(input, config, trans,
			configs, speculative, treatEofAsEpsilon) {
		let cfg = null;
		if (trans.serializationType === Transition$1.RULE) {
			const newContext = SingletonPredictionContext$1.create(config.context, trans.followState.stateNumber);
			cfg = new LexerATNConfig( { state:trans.target, context:newContext}, config);
		} else if (trans.serializationType === Transition$1.PRECEDENCE) {
			throw "Precedence predicates are not supported in lexers.";
		} else if (trans.serializationType === Transition$1.PREDICATE) {
			// Track traversing semantic predicates. If we traverse,
			// we cannot add a DFA state for this "reach" computation
			// because the DFA would not test the predicate again in the
			// future. Rather than creating collections of semantic predicates
			// like v3 and testing them on prediction, v4 will test them on the
			// fly all the time using the ATN not the DFA. This is slower but
			// semantically it's not used that often. One of the key elements to
			// this predicate mechanism is not adding DFA states that see
			// predicates immediately afterwards in the ATN. For example,

			// a : ID {p1}? | ID {p2}? ;

			// should create the start state for rule 'a' (to save start state
			// competition), but should not create target of ID state. The
			// collection of ATN states the following ID references includes
			// states reached by traversing predicates. Since this is when we
			// test them, we cannot cash the DFA state target of ID.

			if (LexerATNSimulator.debug) {
				console.log("EVAL rule " + trans.ruleIndex + ":" + trans.predIndex);
			}
			configs.hasSemanticContext = true;
			if (this.evaluatePredicate(input, trans.ruleIndex, trans.predIndex, speculative)) {
				cfg = new LexerATNConfig({ state:trans.target}, config);
			}
		} else if (trans.serializationType === Transition$1.ACTION) {
			if (config.context === null || config.context.hasEmptyPath()) {
				// execute actions anywhere in the start rule for a token.
				//
				// TODO: if the entry rule is invoked recursively, some
				// actions may be executed during the recursive call. The
				// problem can appear when hasEmptyPath() is true but
				// isEmpty() is false. In this case, the config needs to be
				// split into two contexts - one with just the empty path
				// and another with everything but the empty path.
				// Unfortunately, the current algorithm does not allow
				// getEpsilonTarget to return two configurations, so
				// additional modifications are needed before we can support
				// the split operation.
				const lexerActionExecutor = LexerActionExecutor.append(config.lexerActionExecutor,
						this.atn.lexerActions[trans.actionIndex]);
				cfg = new LexerATNConfig({ state:trans.target, lexerActionExecutor:lexerActionExecutor }, config);
			} else {
				// ignore actions in referenced rules
				cfg = new LexerATNConfig( { state:trans.target}, config);
			}
		} else if (trans.serializationType === Transition$1.EPSILON) {
			cfg = new LexerATNConfig({ state:trans.target}, config);
		} else if (trans.serializationType === Transition$1.ATOM ||
					trans.serializationType === Transition$1.RANGE ||
					trans.serializationType === Transition$1.SET) {
			if (treatEofAsEpsilon) {
				if (trans.matches(Token$6.EOF, 0, Lexer$3.MAX_CHAR_VALUE)) {
					cfg = new LexerATNConfig( { state:trans.target }, config);
				}
			}
		}
		return cfg;
	}

	/**
	 * Evaluate a predicate specified in the lexer.
	 *
	 * <p>If {@code speculative} is {@code true}, this method was called before
	 * {@link //consume} for the matched character. This method should call
	 * {@link //consume} before evaluating the predicate to ensure position
	 * sensitive values, including {@link Lexer//getText}, {@link Lexer//getLine},
	 * and {@link Lexer//getcolumn}, properly reflect the current
	 * lexer state. This method should restore {@code input} and the simulator
	 * to the original state before returning (i.e. undo the actions made by the
	 * call to {@link //consume}.</p>
	 *
	 * @param input The input stream.
	 * @param ruleIndex The rule containing the predicate.
	 * @param predIndex The index of the predicate within the rule.
	 * @param speculative {@code true} if the current index in {@code input} is
	 * one character before the predicate's location.
	 *
	 * @return {@code true} if the specified predicate evaluates to
	 * {@code true}.
	 */
	evaluatePredicate(input, ruleIndex,
			predIndex, speculative) {
		// assume true if no recognizer was provided
		if (this.recog === null) {
			return true;
		}
		if (!speculative) {
			return this.recog.sempred(null, ruleIndex, predIndex);
		}
		const savedcolumn = this.column;
		const savedLine = this.line;
		const index = input.index;
		const marker = input.mark();
		try {
			this.consume(input);
			return this.recog.sempred(null, ruleIndex, predIndex);
		} finally {
			this.column = savedcolumn;
			this.line = savedLine;
			input.seek(index);
			input.release(marker);
		}
	}

	captureSimState(settings, input, dfaState) {
		settings.index = input.index;
		settings.line = this.line;
		settings.column = this.column;
		settings.dfaState = dfaState;
	}

	addDFAEdge(from_, tk, to, cfgs) {
		if (to === undefined) {
			to = null;
		}
		if (cfgs === undefined) {
			cfgs = null;
		}
		if (to === null && cfgs !== null) {
			// leading to this call, ATNConfigSet.hasSemanticContext is used as a
			// marker indicating dynamic predicate evaluation makes this edge
			// dependent on the specific input sequence, so the static edge in the
			// DFA should be omitted. The target DFAState is still created since
			// execATN has the ability to resynchronize with the DFA state cache
			// following the predicate evaluation step.
			//
			// TJP notes: next time through the DFA, we see a pred again and eval.
			// If that gets us to a previously created (but dangling) DFA
			// state, we can continue in pure DFA mode from there.
			// /
			const suppressEdge = cfgs.hasSemanticContext;
			cfgs.hasSemanticContext = false;

			to = this.addDFAState(cfgs);

			if (suppressEdge) {
				return to;
			}
		}
		// add the edge
		if (tk < LexerATNSimulator.MIN_DFA_EDGE || tk > LexerATNSimulator.MAX_DFA_EDGE) {
			// Only track edges within the DFA bounds
			return to;
		}
		if (LexerATNSimulator.debug) {
			console.log("EDGE " + from_ + " -> " + to + " upon " + tk);
		}
		if (from_.edges === null) {
			// make room for tokens 1..n and -1 masquerading as index 0
			from_.edges = [];
		}
		from_.edges[tk - LexerATNSimulator.MIN_DFA_EDGE] = to; // connect

		return to;
	}

	/**
	 * Add a new DFA state if there isn't one with this set of
	 * configurations already. This method also detects the first
	 * configuration containing an ATN rule stop state. Later, when
	 * traversing the DFA, we will know which rule to accept.
	 */
	addDFAState(configs) {
		const proposed = new DFAState$2(null, configs);
		let firstConfigWithRuleStopState = null;
		for (let i = 0; i < configs.items.length; i++) {
			const cfg = configs.items[i];
			if (cfg.state instanceof RuleStopState$2) {
				firstConfigWithRuleStopState = cfg;
				break;
			}
		}
		if (firstConfigWithRuleStopState !== null) {
			proposed.isAcceptState = true;
			proposed.lexerActionExecutor = firstConfigWithRuleStopState.lexerActionExecutor;
			proposed.prediction = this.atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];
		}
		const dfa = this.decisionToDFA[this.mode];
		const existing = dfa.states.get(proposed);
		if (existing!==null) {
			return existing;
		}
		const newState = proposed;
		newState.stateNumber = dfa.states.length;
		configs.setReadonly(true);
		newState.configs = configs;
		dfa.states.add(newState);
		return newState;
	}

	getDFA(mode) {
		return this.decisionToDFA[mode];
	}

// Get the text matched so far for the current token.
	getText(input) {
		// index is first lookahead char, don't include.
		return input.getText(this.startIndex, input.index - 1);
	}

	consume(input) {
		const curChar = input.LA(1);
		if (curChar === "\n".charCodeAt(0)) {
			this.line += 1;
			this.column = 0;
		} else {
			this.column += 1;
		}
		input.consume();
	}

	getTokenName(tt) {
		if (tt === -1) {
			return "EOF";
		} else {
			return "'" + String.fromCharCode(tt) + "'";
		}
	}
}

LexerATNSimulator.debug = false;
LexerATNSimulator.dfa_debug = false;

LexerATNSimulator.MIN_DFA_EDGE = 0;
LexerATNSimulator.MAX_DFA_EDGE = 127; // forces unicode to stay in ATN

LexerATNSimulator.match_calls = 0;

var LexerATNSimulator_1 = LexerATNSimulator;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Map: Map$1, BitSet: BitSet$2, AltDict, hashStuff} = Utils$4;
const ATN$1 = ATN_1;
const {RuleStopState: RuleStopState$1} = ATNState_1;
const {ATNConfigSet: ATNConfigSet$2} = ATNConfigSet_1;
const {ATNConfig: ATNConfig$1} = ATNConfig$4;
const {SemanticContext: SemanticContext$1} = SemanticContext_1;

/**
 * This enumeration defines the prediction modes available in ANTLR 4 along with
 * utility methods for analyzing configuration sets for conflicts and/or
 * ambiguities.
 */
const PredictionMode$1 = {
    /**
     * The SLL(*) prediction mode. This prediction mode ignores the current
     * parser context when making predictions. This is the fastest prediction
     * mode, and provides correct results for many grammars. This prediction
     * mode is more powerful than the prediction mode provided by ANTLR 3, but
     * may result in syntax errors for grammar and input combinations which are
     * not SLL.
     *
     * <p>
     * When using this prediction mode, the parser will either return a correct
     * parse tree (i.e. the same parse tree that would be returned with the
     * {@link //LL} prediction mode), or it will report a syntax error. If a
     * syntax error is encountered when using the {@link //SLL} prediction mode,
     * it may be due to either an actual syntax error in the input or indicate
     * that the particular combination of grammar and input requires the more
     * powerful {@link //LL} prediction abilities to complete successfully.</p>
     *
     * <p>
     * This prediction mode does not provide any guarantees for prediction
     * behavior for syntactically-incorrect inputs.</p>
     */
    SLL: 0,

    /**
     * The LL(*) prediction mode. This prediction mode allows the current parser
     * context to be used for resolving SLL conflicts that occur during
     * prediction. This is the fastest prediction mode that guarantees correct
     * parse results for all combinations of grammars with syntactically correct
     * inputs.
     *
     * <p>
     * When using this prediction mode, the parser will make correct decisions
     * for all syntactically-correct grammar and input combinations. However, in
     * cases where the grammar is truly ambiguous this prediction mode might not
     * report a precise answer for <em>exactly which</em> alternatives are
     * ambiguous.</p>
     *
     * <p>
     * This prediction mode does not provide any guarantees for prediction
     * behavior for syntactically-incorrect inputs.</p>
     */
    LL: 1,

    /**
     *
     * The LL(*) prediction mode with exact ambiguity detection. In addition to
     * the correctness guarantees provided by the {@link //LL} prediction mode,
     * this prediction mode instructs the prediction algorithm to determine the
     * complete and exact set of ambiguous alternatives for every ambiguous
     * decision encountered while parsing.
     *
     * <p>
     * This prediction mode may be used for diagnosing ambiguities during
     * grammar development. Due to the performance overhead of calculating sets
     * of ambiguous alternatives, this prediction mode should be avoided when
     * the exact results are not necessary.</p>
     *
     * <p>
     * This prediction mode does not provide any guarantees for prediction
     * behavior for syntactically-incorrect inputs.</p>
     */
    LL_EXACT_AMBIG_DETECTION: 2,

    /**
     *
     * Computes the SLL prediction termination condition.
     *
     * <p>
     * This method computes the SLL prediction termination condition for both of
     * the following cases.</p>
     *
     * <ul>
     * <li>The usual SLL+LL fallback upon SLL conflict</li>
     * <li>Pure SLL without LL fallback</li>
     * </ul>
     *
     * <p><strong>COMBINED SLL+LL PARSING</strong></p>
     *
     * <p>When LL-fallback is enabled upon SLL conflict, correct predictions are
     * ensured regardless of how the termination condition is computed by this
     * method. Due to the substantially higher cost of LL prediction, the
     * prediction should only fall back to LL when the additional lookahead
     * cannot lead to a unique SLL prediction.</p>
     *
     * <p>Assuming combined SLL+LL parsing, an SLL configuration set with only
     * conflicting subsets should fall back to full LL, even if the
     * configuration sets don't resolve to the same alternative (e.g.
     * {@code {1,2}} and {@code {3,4}}. If there is at least one non-conflicting
     * configuration, SLL could continue with the hopes that more lookahead will
     * resolve via one of those non-conflicting configurations.</p>
     *
     * <p>Here's the prediction termination rule them: SLL (for SLL+LL parsing)
     * stops when it sees only conflicting configuration subsets. In contrast,
     * full LL keeps going when there is uncertainty.</p>
     *
     * <p><strong>HEURISTIC</strong></p>
     *
     * <p>As a heuristic, we stop prediction when we see any conflicting subset
     * unless we see a state that only has one alternative associated with it.
     * The single-alt-state thing lets prediction continue upon rules like
     * (otherwise, it would admit defeat too soon):</p>
     *
     * <p>{@code [12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;}</p>
     *
     * <p>When the ATN simulation reaches the state before {@code ';'}, it has a
     * DFA state that looks like: {@code [12|1|[], 6|2|[], 12|2|[]]}. Naturally
     * {@code 12|1|[]} and {@code 12|2|[]} conflict, but we cannot stop
     * processing this node because alternative to has another way to continue,
     * via {@code [6|2|[]]}.</p>
     *
     * <p>It also let's us continue for this rule:</p>
     *
     * <p>{@code [1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;}</p>
     *
     * <p>After matching input A, we reach the stop state for rule A, state 1.
     * State 8 is the state right before B. Clearly alternatives 1 and 2
     * conflict and no amount of further lookahead will separate the two.
     * However, alternative 3 will be able to continue and so we do not stop
     * working on this state. In the previous example, we're concerned with
     * states associated with the conflicting alternatives. Here alt 3 is not
     * associated with the conflicting configs, but since we can continue
     * looking for input reasonably, don't declare the state done.</p>
     *
     * <p><strong>PURE SLL PARSING</strong></p>
     *
     * <p>To handle pure SLL parsing, all we have to do is make sure that we
     * combine stack contexts for configurations that differ only by semantic
     * predicate. From there, we can do the usual SLL termination heuristic.</p>
     *
     * <p><strong>PREDICATES IN SLL+LL PARSING</strong></p>
     *
     * <p>SLL decisions don't evaluate predicates until after they reach DFA stop
     * states because they need to create the DFA cache that works in all
     * semantic situations. In contrast, full LL evaluates predicates collected
     * during start state computation so it can ignore predicates thereafter.
     * This means that SLL termination detection can totally ignore semantic
     * predicates.</p>
     *
     * <p>Implementation-wise, {@link ATNConfigSet} combines stack contexts but not
     * semantic predicate contexts so we might see two configurations like the
     * following.</p>
     *
     * <p>{@code (s, 1, x, {}), (s, 1, x', {p})}</p>
     *
     * <p>Before testing these configurations against others, we have to merge
     * {@code x} and {@code x'} (without modifying the existing configurations).
     * For example, we test {@code (x+x')==x''} when looking for conflicts in
     * the following configurations.</p>
     *
     * <p>{@code (s, 1, x, {}), (s, 1, x', {p}), (s, 2, x'', {})}</p>
     *
     * <p>If the configuration set has predicates (as indicated by
     * {@link ATNConfigSet//hasSemanticContext}), this algorithm makes a copy of
     * the configurations to strip out all of the predicates so that a standard
     * {@link ATNConfigSet} will merge everything ignoring predicates.</p>
     */
    hasSLLConflictTerminatingPrediction: function( mode, configs) {
        // Configs in rule stop states indicate reaching the end of the decision
        // rule (local context) or end of start rule (full context). If all
        // configs meet this condition, then none of the configurations is able
        // to match additional input so we terminate prediction.
        //
        if (PredictionMode$1.allConfigsInRuleStopStates(configs)) {
            return true;
        }
        // pure SLL mode parsing
        if (mode === PredictionMode$1.SLL) {
            // Don't bother with combining configs from different semantic
            // contexts if we can fail over to full LL; costs more time
            // since we'll often fail over anyway.
            if (configs.hasSemanticContext) {
                // dup configs, tossing out semantic predicates
                const dup = new ATNConfigSet$2();
                for(let i=0;i<configs.items.length;i++) {
                    let c = configs.items[i];
                    c = new ATNConfig$1({semanticContext:SemanticContext$1.NONE}, c);
                    dup.add(c);
                }
                configs = dup;
            }
            // now we have combined contexts for configs with dissimilar preds
        }
        // pure SLL or combined SLL+LL mode parsing
        const altsets = PredictionMode$1.getConflictingAltSubsets(configs);
        return PredictionMode$1.hasConflictingAltSet(altsets) && !PredictionMode$1.hasStateAssociatedWithOneAlt(configs);
    },

    /**
     * Checks if any configuration in {@code configs} is in a
     * {@link RuleStopState}. Configurations meeting this condition have reached
     * the end of the decision rule (local context) or end of start rule (full
     * context).
     *
     * @param configs the configuration set to test
     * @return {@code true} if any configuration in {@code configs} is in a
     * {@link RuleStopState}, otherwise {@code false}
     */
    hasConfigInRuleStopState: function(configs) {
        for(let i=0;i<configs.items.length;i++) {
            const c = configs.items[i];
            if (c.state instanceof RuleStopState$1) {
                return true;
            }
        }
        return false;
    },

    /**
     * Checks if all configurations in {@code configs} are in a
     * {@link RuleStopState}. Configurations meeting this condition have reached
     * the end of the decision rule (local context) or end of start rule (full
     * context).
     *
     * @param configs the configuration set to test
     * @return {@code true} if all configurations in {@code configs} are in a
     * {@link RuleStopState}, otherwise {@code false}
     */
    allConfigsInRuleStopStates: function(configs) {
        for(let i=0;i<configs.items.length;i++) {
            const c = configs.items[i];
            if (!(c.state instanceof RuleStopState$1)) {
                return false;
            }
        }
        return true;
    },

    /**
     *
     * Full LL prediction termination.
     *
     * <p>Can we stop looking ahead during ATN simulation or is there some
     * uncertainty as to which alternative we will ultimately pick, after
     * consuming more input? Even if there are partial conflicts, we might know
     * that everything is going to resolve to the same minimum alternative. That
     * means we can stop since no more lookahead will change that fact. On the
     * other hand, there might be multiple conflicts that resolve to different
     * minimums. That means we need more look ahead to decide which of those
     * alternatives we should predict.</p>
     *
     * <p>The basic idea is to split the set of configurations {@code C}, into
     * conflicting subsets {@code (s, _, ctx, _)} and singleton subsets with
     * non-conflicting configurations. Two configurations conflict if they have
     * identical {@link ATNConfig//state} and {@link ATNConfig//context} values
     * but different {@link ATNConfig//alt} value, e.g. {@code (s, i, ctx, _)}
     * and {@code (s, j, ctx, _)} for {@code i!=j}.</p>
     *
     * <p>Reduce these configuration subsets to the set of possible alternatives.
     * You can compute the alternative subsets in one pass as follows:</p>
     *
     * <p>{@code A_s,ctx = {i | (s, i, ctx, _)}} for each configuration in
     * {@code C} holding {@code s} and {@code ctx} fixed.</p>
     *
     * <p>Or in pseudo-code, for each configuration {@code c} in {@code C}:</p>
     *
     * <pre>
     * map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not
     * alt and not pred
     * </pre>
     *
     * <p>The values in {@code map} are the set of {@code A_s,ctx} sets.</p>
     *
     * <p>If {@code |A_s,ctx|=1} then there is no conflict associated with
     * {@code s} and {@code ctx}.</p>
     *
     * <p>Reduce the subsets to singletons by choosing a minimum of each subset. If
     * the union of these alternative subsets is a singleton, then no amount of
     * more lookahead will help us. We will always pick that alternative. If,
     * however, there is more than one alternative, then we are uncertain which
     * alternative to predict and must continue looking for resolution. We may
     * or may not discover an ambiguity in the future, even if there are no
     * conflicting subsets this round.</p>
     *
     * <p>The biggest sin is to terminate early because it means we've made a
     * decision but were uncertain as to the eventual outcome. We haven't used
     * enough lookahead. On the other hand, announcing a conflict too late is no
     * big deal; you will still have the conflict. It's just inefficient. It
     * might even look until the end of file.</p>
     *
     * <p>No special consideration for semantic predicates is required because
     * predicates are evaluated on-the-fly for full LL prediction, ensuring that
     * no configuration contains a semantic context during the termination
     * check.</p>
     *
     * <p><strong>CONFLICTING CONFIGS</strong></p>
     *
     * <p>Two configurations {@code (s, i, x)} and {@code (s, j, x')}, conflict
     * when {@code i!=j} but {@code x=x'}. Because we merge all
     * {@code (s, i, _)} configurations together, that means that there are at
     * most {@code n} configurations associated with state {@code s} for
     * {@code n} possible alternatives in the decision. The merged stacks
     * complicate the comparison of configuration contexts {@code x} and
     * {@code x'}. Sam checks to see if one is a subset of the other by calling
     * merge and checking to see if the merged result is either {@code x} or
     * {@code x'}. If the {@code x} associated with lowest alternative {@code i}
     * is the superset, then {@code i} is the only possible prediction since the
     * others resolve to {@code min(i)} as well. However, if {@code x} is
     * associated with {@code j>i} then at least one stack configuration for
     * {@code j} is not in conflict with alternative {@code i}. The algorithm
     * should keep going, looking for more lookahead due to the uncertainty.</p>
     *
     * <p>For simplicity, I'm doing a equality check between {@code x} and
     * {@code x'} that lets the algorithm continue to consume lookahead longer
     * than necessary. The reason I like the equality is of course the
     * simplicity but also because that is the test you need to detect the
     * alternatives that are actually in conflict.</p>
     *
     * <p><strong>CONTINUE/STOP RULE</strong></p>
     *
     * <p>Continue if union of resolved alternative sets from non-conflicting and
     * conflicting alternative subsets has more than one alternative. We are
     * uncertain about which alternative to predict.</p>
     *
     * <p>The complete set of alternatives, {@code [i for (_,i,_)]}, tells us which
     * alternatives are still in the running for the amount of input we've
     * consumed at this point. The conflicting sets let us to strip away
     * configurations that won't lead to more states because we resolve
     * conflicts to the configuration with a minimum alternate for the
     * conflicting set.</p>
     *
     * <p><strong>CASES</strong></p>
     *
     * <ul>
     *
     * <li>no conflicts and more than 1 alternative in set =&gt; continue</li>
     *
     * <li> {@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s, 3, z)},
     * {@code (s', 1, y)}, {@code (s', 2, y)} yields non-conflicting set
     * {@code {3}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =
     * {@code {1,3}} =&gt; continue
     * </li>
     *
     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},
     * {@code (s', 2, y)}, {@code (s'', 1, z)} yields non-conflicting set
     * {@code {1}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =
     * {@code {1}} =&gt; stop and predict 1</li>
     *
     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},
     * {@code (s', 2, y)} yields conflicting, reduced sets {@code {1}} U
     * {@code {1}} = {@code {1}} =&gt; stop and predict 1, can announce
     * ambiguity {@code {1,2}}</li>
     *
     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 2, y)},
     * {@code (s', 3, y)} yields conflicting, reduced sets {@code {1}} U
     * {@code {2}} = {@code {1,2}} =&gt; continue</li>
     *
     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 3, y)},
     * {@code (s', 4, y)} yields conflicting, reduced sets {@code {1}} U
     * {@code {3}} = {@code {1,3}} =&gt; continue</li>
     *
     * </ul>
     *
     * <p><strong>EXACT AMBIGUITY DETECTION</strong></p>
     *
     * <p>If all states report the same conflicting set of alternatives, then we
     * know we have the exact ambiguity set.</p>
     *
     * <p><code>|A_<em>i</em>|&gt;1</code> and
     * <code>A_<em>i</em> = A_<em>j</em></code> for all <em>i</em>, <em>j</em>.</p>
     *
     * <p>In other words, we continue examining lookahead until all {@code A_i}
     * have more than one alternative and all {@code A_i} are the same. If
     * {@code A={{1,2}, {1,3}}}, then regular LL prediction would terminate
     * because the resolved set is {@code {1}}. To determine what the real
     * ambiguity is, we have to know whether the ambiguity is between one and
     * two or one and three so we keep going. We can only stop prediction when
     * we need exact ambiguity detection when the sets look like
     * {@code A={{1,2}}} or {@code {{1,2},{1,2}}}, etc...</p>
     */
    resolvesToJustOneViableAlt: function(altsets) {
        return PredictionMode$1.getSingleViableAlt(altsets);
    },

    /**
     * Determines if every alternative subset in {@code altsets} contains more
     * than one alternative.
     *
     * @param altsets a collection of alternative subsets
     * @return {@code true} if every {@link BitSet} in {@code altsets} has
     * {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}
     */
    allSubsetsConflict: function(altsets) {
        return ! PredictionMode$1.hasNonConflictingAltSet(altsets);
    },
    /**
     * Determines if any single alternative subset in {@code altsets} contains
     * exactly one alternative.
     *
     * @param altsets a collection of alternative subsets
     * @return {@code true} if {@code altsets} contains a {@link BitSet} with
     * {@link BitSet//cardinality cardinality} 1, otherwise {@code false}
     */
    hasNonConflictingAltSet: function(altsets) {
        for(let i=0;i<altsets.length;i++) {
            const alts = altsets[i];
            if (alts.length===1) {
                return true;
            }
        }
        return false;
    },


    /**
     * Determines if any single alternative subset in {@code altsets} contains
     * more than one alternative.
     *
     * @param altsets a collection of alternative subsets
     * @return {@code true} if {@code altsets} contains a {@link BitSet} with
     * {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}
     */
    hasConflictingAltSet: function(altsets) {
        for(let i=0;i<altsets.length;i++) {
            const alts = altsets[i];
            if (alts.length>1) {
                return true;
            }
        }
        return false;
    },


    /**
     * Determines if every alternative subset in {@code altsets} is equivalent.
     *
     * @param altsets a collection of alternative subsets
     * @return {@code true} if every member of {@code altsets} is equal to the
     * others, otherwise {@code false}
     */
    allSubsetsEqual: function(altsets) {
        let first = null;
        for(let i=0;i<altsets.length;i++) {
            const alts = altsets[i];
            if (first === null) {
                first = alts;
            } else if (alts!==first) {
                return false;
            }
        }
        return true;
    },


    /**
     * Returns the unique alternative predicted by all alternative subsets in
     * {@code altsets}. If no such alternative exists, this method returns
     * {@link ATN//INVALID_ALT_NUMBER}.
     *
     * @param altsets a collection of alternative subsets
     */
    getUniqueAlt: function(altsets) {
        const all = PredictionMode$1.getAlts(altsets);
        if (all.length===1) {
            return all.minValue();
        } else {
            return ATN$1.INVALID_ALT_NUMBER;
        }
    },

    /**
     * Gets the complete set of represented alternatives for a collection of
     * alternative subsets. This method returns the union of each {@link BitSet}
     * in {@code altsets}.
     *
     * @param altsets a collection of alternative subsets
     * @return the set of represented alternatives in {@code altsets}
     */
    getAlts: function(altsets) {
        const all = new BitSet$2();
        altsets.map( function(alts) { all.or(alts); });
        return all;
    },

    /**
     * This function gets the conflicting alt subsets from a configuration set.
     * For each configuration {@code c} in {@code configs}:
     *
     * <pre>
     * map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not
     * alt and not pred
     * </pre>
     */
    getConflictingAltSubsets: function(configs) {
        const configToAlts = new Map$1();
        configToAlts.hashFunction = function(cfg) { hashStuff(cfg.state.stateNumber, cfg.context); };
        configToAlts.equalsFunction = function(c1, c2) { return c1.state.stateNumber === c2.state.stateNumber && c1.context.equals(c2.context);};
        configs.items.map(function(cfg) {
            let alts = configToAlts.get(cfg);
            if (alts === null) {
                alts = new BitSet$2();
                configToAlts.put(cfg, alts);
            }
            alts.add(cfg.alt);
        });
        return configToAlts.getValues();
    },

    /**
     * Get a map from state to alt subset from a configuration set. For each
     * configuration {@code c} in {@code configs}:
     *
     * <pre>
     * map[c.{@link ATNConfig//state state}] U= c.{@link ATNConfig//alt alt}
     * </pre>
     */
    getStateToAltMap: function(configs) {
        const m = new AltDict();
        configs.items.map(function(c) {
            let alts = m.get(c.state);
            if (alts === null) {
                alts = new BitSet$2();
                m.put(c.state, alts);
            }
            alts.add(c.alt);
        });
        return m;
    },

    hasStateAssociatedWithOneAlt: function(configs) {
        const values = PredictionMode$1.getStateToAltMap(configs).values();
        for(let i=0;i<values.length;i++) {
            if (values[i].length===1) {
                return true;
            }
        }
        return false;
    },

    getSingleViableAlt: function(altsets) {
        let result = null;
        for(let i=0;i<altsets.length;i++) {
            const alts = altsets[i];
            const minAlt = alts.minValue();
            if(result===null) {
                result = minAlt;
            } else if(result!==minAlt) { // more than 1 viable alt
                return ATN$1.INVALID_ALT_NUMBER;
            }
        }
        return result;
    }
};

var PredictionMode_1 = PredictionMode$1;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const RuleContext$1 = RuleContext_1;
const Tree$1 = Tree_1;
const INVALID_INTERVAL = Tree$1.INVALID_INTERVAL;
const TerminalNode$1 = Tree$1.TerminalNode;
const TerminalNodeImpl = Tree$1.TerminalNodeImpl;
const ErrorNodeImpl = Tree$1.ErrorNodeImpl;
const Interval$4 = IntervalSet_1.Interval;

/**
 * A rule invocation record for parsing.
 *
 *  Contains all of the information about the current rule not stored in the
 *  RuleContext. It handles parse tree children list, Any ATN state
 *  tracing, and the default values available for rule indications:
 *  start, stop, rule index, current alt number, current
 *  ATN state.
 *
 *  Subclasses made for each rule and grammar track the parameters,
 *  return values, locals, and labels specific to that rule. These
 *  are the objects that are returned from rules.
 *
 *  Note text is not an actual field of a rule return value; it is computed
 *  from start and stop using the input stream's toString() method.  I
 *  could add a ctor to this so that we can pass in and store the input
 *  stream, but I'm not sure we want to do that.  It would seem to be undefined
 *  to get the .text property anyway if the rule matches tokens from multiple
 *  input streams.
 *
 *  I do not use getters for fields of objects that are used simply to
 *  group values such as this aggregate.  The getters/setters are there to
 *  satisfy the superclass interface.
 */
class ParserRuleContext extends RuleContext$1 {
	constructor(parent, invokingStateNumber) {
		parent = parent || null;
		invokingStateNumber = invokingStateNumber || null;
		super(parent, invokingStateNumber);
		this.ruleIndex = -1;
		/**
		 * If we are debugging or building a parse tree for a visitor,
		 * we need to track all of the tokens and rule invocations associated
		 * with this rule's context. This is empty for parsing w/o tree constr.
		 * operation because we don't the need to track the details about
		 * how we parse this rule.
		 */
		this.children = null;
		this.start = null;
		this.stop = null;
		/**
		 * The exception that forced this rule to return. If the rule successfully
		 * completed, this is {@code null}.
		 */
		this.exception = null;
	}

	// COPY a ctx (I'm deliberately not using copy constructor)
	copyFrom(ctx) {
		// from RuleContext
		this.parentCtx = ctx.parentCtx;
		this.invokingState = ctx.invokingState;
		this.children = null;
		this.start = ctx.start;
		this.stop = ctx.stop;
		// copy any error nodes to alt label node
		if(ctx.children) {
			this.children = [];
			// reset parent pointer for any error nodes
			ctx.children.map(function(child) {
				if (child instanceof ErrorNodeImpl) {
					this.children.push(child);
					child.parentCtx = this;
				}
			}, this);
		}
	}

	// Double dispatch methods for listeners
	enterRule(listener) {
	}

	exitRule(listener) {
	}

	// Does not set parent link; other add methods do that
	addChild(child) {
		if (this.children === null) {
			this.children = [];
		}
		this.children.push(child);
		return child;
	}

	/** Used by enterOuterAlt to toss out a RuleContext previously added as
	 * we entered a rule. If we have // label, we will need to remove
	 * generic ruleContext object.
	 */
	removeLastChild() {
		if (this.children !== null) {
			this.children.pop();
		}
	}

	addTokenNode(token) {
		const node = new TerminalNodeImpl(token);
		this.addChild(node);
		node.parentCtx = this;
		return node;
	}

	addErrorNode(badToken) {
		const node = new ErrorNodeImpl(badToken);
		this.addChild(node);
		node.parentCtx = this;
		return node;
	}

	getChild(i, type) {
		type = type || null;
		if (this.children === null || i < 0 || i >= this.children.length) {
			return null;
		}
		if (type === null) {
			return this.children[i];
		} else {
			for(let j=0; j<this.children.length; j++) {
				const child = this.children[j];
				if(child instanceof type) {
					if(i===0) {
						return child;
					} else {
						i -= 1;
					}
				}
			}
			return null;
		}
	}

	getToken(ttype, i) {
		if (this.children === null || i < 0 || i >= this.children.length) {
			return null;
		}
		for(let j=0; j<this.children.length; j++) {
			const child = this.children[j];
			if (child instanceof TerminalNode$1) {
				if (child.symbol.type === ttype) {
					if(i===0) {
						return child;
					} else {
						i -= 1;
					}
				}
			}
		}
		return null;
	}

	getTokens(ttype ) {
		if (this.children=== null) {
			return [];
		} else {
			const tokens = [];
			for(let j=0; j<this.children.length; j++) {
				const child = this.children[j];
				if (child instanceof TerminalNode$1) {
					if (child.symbol.type === ttype) {
						tokens.push(child);
					}
				}
			}
			return tokens;
		}
	}

	getTypedRuleContext(ctxType, i) {
		return this.getChild(i, ctxType);
	}

	getTypedRuleContexts(ctxType) {
		if (this.children=== null) {
			return [];
		} else {
			const contexts = [];
			for(let j=0; j<this.children.length; j++) {
				const child = this.children[j];
				if (child instanceof ctxType) {
					contexts.push(child);
				}
			}
			return contexts;
		}
	}

	getChildCount() {
		if (this.children=== null) {
			return 0;
		} else {
			return this.children.length;
		}
	}

	getSourceInterval() {
		if( this.start === null || this.stop === null) {
			return INVALID_INTERVAL;
		} else {
			return new Interval$4(this.start.tokenIndex, this.stop.tokenIndex);
		}
	}
}

RuleContext$1.EMPTY = new ParserRuleContext();

var ParserRuleContext_1 = ParserRuleContext;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const Utils$1 = Utils$4;
const {Set: Set$2, BitSet: BitSet$1, DoubleDict} = Utils$1;

const ATN = ATN_1;
const {ATNState: ATNState$1, RuleStopState} = ATNState_1;

const {ATNConfig} = ATNConfig$4;
const {ATNConfigSet: ATNConfigSet$1} = ATNConfigSet_1;
const {Token: Token$5} = Token_1;
const {DFAState: DFAState$1, PredPrediction} = DFAState_1;
const ATNSimulator = ATNSimulator_1;
const PredictionMode = PredictionMode_1;
const RuleContext = RuleContext_1;
const {SemanticContext} = SemanticContext_1;
const {PredictionContext} = PredictionContext_1;
const {Interval: Interval$3} = IntervalSet_1;
const {Transition, SetTransition, NotSetTransition, RuleTransition, ActionTransition} = Transition_1;
const {NoViableAltException: NoViableAltException$1} = Errors;
const {SingletonPredictionContext, predictionContextFromRuleContext} = PredictionContext_1;


/**
 * The embodiment of the adaptive LL(*), ALL(*), parsing strategy.
 *
 * <p>
 * The basic complexity of the adaptive strategy makes it harder to understand.
 * We begin with ATN simulation to build paths in a DFA. Subsequent prediction
 * requests go through the DFA first. If they reach a state without an edge for
 * the current symbol, the algorithm fails over to the ATN simulation to
 * complete the DFA path for the current input (until it finds a conflict state
 * or uniquely predicting state).</p>
 *
 * <p>
 * All of that is done without using the outer context because we want to create
 * a DFA that is not dependent upon the rule invocation stack when we do a
 * prediction. One DFA works in all contexts. We avoid using context not
 * necessarily because it's slower, although it can be, but because of the DFA
 * caching problem. The closure routine only considers the rule invocation stack
 * created during prediction beginning in the decision rule. For example, if
 * prediction occurs without invoking another rule's ATN, there are no context
 * stacks in the configurations. When lack of context leads to a conflict, we
 * don't know if it's an ambiguity or a weakness in the strong LL(*) parsing
 * strategy (versus full LL(*)).</p>
 *
 * <p>
 * When SLL yields a configuration set with conflict, we rewind the input and
 * retry the ATN simulation, this time using full outer context without adding
 * to the DFA. Configuration context stacks will be the full invocation stacks
 * from the start rule. If we get a conflict using full context, then we can
 * definitively say we have a true ambiguity for that input sequence. If we
 * don't get a conflict, it implies that the decision is sensitive to the outer
 * context. (It is not context-sensitive in the sense of context-sensitive
 * grammars.)</p>
 *
 * <p>
 * The next time we reach this DFA state with an SLL conflict, through DFA
 * simulation, we will again retry the ATN simulation using full context mode.
 * This is slow because we can't save the results and have to "interpret" the
 * ATN each time we get that input.</p>
 *
 * <p>
 * <strong>CACHING FULL CONTEXT PREDICTIONS</strong></p>
 *
 * <p>
 * We could cache results from full context to predicted alternative easily and
 * that saves a lot of time but doesn't work in presence of predicates. The set
 * of visible predicates from the ATN start state changes depending on the
 * context, because closure can fall off the end of a rule. I tried to cache
 * tuples (stack context, semantic context, predicted alt) but it was slower
 * than interpreting and much more complicated. Also required a huge amount of
 * memory. The goal is not to create the world's fastest parser anyway. I'd like
 * to keep this algorithm simple. By launching multiple threads, we can improve
 * the speed of parsing across a large number of files.</p>
 *
 * <p>
 * There is no strict ordering between the amount of input used by SLL vs LL,
 * which makes it really hard to build a cache for full context. Let's say that
 * we have input A B C that leads to an SLL conflict with full context X. That
 * implies that using X we might only use A B but we could also use A B C D to
 * resolve conflict. Input A B C D could predict alternative 1 in one position
 * in the input and A B C E could predict alternative 2 in another position in
 * input. The conflicting SLL configurations could still be non-unique in the
 * full context prediction, which would lead us to requiring more input than the
 * original A B C.	To make a	prediction cache work, we have to track	the exact
 * input	used during the previous prediction. That amounts to a cache that maps
 * X to a specific DFA for that context.</p>
 *
 * <p>
 * Something should be done for left-recursive expression predictions. They are
 * likely LL(1) + pred eval. Easier to do the whole SLL unless error and retry
 * with full LL thing Sam does.</p>
 *
 * <p>
 * <strong>AVOIDING FULL CONTEXT PREDICTION</strong></p>
 *
 * <p>
 * We avoid doing full context retry when the outer context is empty, we did not
 * dip into the outer context by falling off the end of the decision state rule,
 * or when we force SLL mode.</p>
 *
 * <p>
 * As an example of the not dip into outer context case, consider as super
 * constructor calls versus function calls. One grammar might look like
 * this:</p>
 *
 * <pre>
 * ctorBody
 *   : '{' superCall? stat* '}'
 *   ;
 * </pre>
 *
 * <p>
 * Or, you might see something like</p>
 *
 * <pre>
 * stat
 *   : superCall ';'
 *   | expression ';'
 *   | ...
 *   ;
 * </pre>
 *
 * <p>
 * In both cases I believe that no closure operations will dip into the outer
 * context. In the first case ctorBody in the worst case will stop at the '}'.
 * In the 2nd case it should stop at the ';'. Both cases should stay within the
 * entry rule and not dip into the outer context.</p>
 *
 * <p>
 * <strong>PREDICATES</strong></p>
 *
 * <p>
 * Predicates are always evaluated if present in either SLL or LL both. SLL and
 * LL simulation deals with predicates differently. SLL collects predicates as
 * it performs closure operations like ANTLR v3 did. It delays predicate
 * evaluation until it reaches and accept state. This allows us to cache the SLL
 * ATN simulation whereas, if we had evaluated predicates on-the-fly during
 * closure, the DFA state configuration sets would be different and we couldn't
 * build up a suitable DFA.</p>
 *
 * <p>
 * When building a DFA accept state during ATN simulation, we evaluate any
 * predicates and return the sole semantically valid alternative. If there is
 * more than 1 alternative, we report an ambiguity. If there are 0 alternatives,
 * we throw an exception. Alternatives without predicates act like they have
 * true predicates. The simple way to think about it is to strip away all
 * alternatives with false predicates and choose the minimum alternative that
 * remains.</p>
 *
 * <p>
 * When we start in the DFA and reach an accept state that's predicated, we test
 * those and return the minimum semantically viable alternative. If no
 * alternatives are viable, we throw an exception.</p>
 *
 * <p>
 * During full LL ATN simulation, closure always evaluates predicates and
 * on-the-fly. This is crucial to reducing the configuration set size during
 * closure. It hits a landmine when parsing with the Java grammar, for example,
 * without this on-the-fly evaluation.</p>
 *
 * <p>
 * <strong>SHARING DFA</strong></p>
 *
 * <p>
 * All instances of the same parser share the same decision DFAs through a
 * static field. Each instance gets its own ATN simulator but they share the
 * same {@link //decisionToDFA} field. They also share a
 * {@link PredictionContextCache} object that makes sure that all
 * {@link PredictionContext} objects are shared among the DFA states. This makes
 * a big size difference.</p>
 *
 * <p>
 * <strong>THREAD SAFETY</strong></p>
 *
 * <p>
 * The {@link ParserATNSimulator} locks on the {@link //decisionToDFA} field when
 * it adds a new DFA object to that array. {@link //addDFAEdge}
 * locks on the DFA for the current decision when setting the
 * {@link DFAState//edges} field. {@link //addDFAState} locks on
 * the DFA for the current decision when looking up a DFA state to see if it
 * already exists. We must make sure that all requests to add DFA states that
 * are equivalent result in the same shared DFA object. This is because lots of
 * threads will be trying to update the DFA at once. The
 * {@link //addDFAState} method also locks inside the DFA lock
 * but this time on the shared context cache when it rebuilds the
 * configurations' {@link PredictionContext} objects using cached
 * subgraphs/nodes. No other locking occurs, even during DFA simulation. This is
 * safe as long as we can guarantee that all threads referencing
 * {@code s.edge[t]} get the same physical target {@link DFAState}, or
 * {@code null}. Once into the DFA, the DFA simulation does not reference the
 * {@link DFA//states} map. It follows the {@link DFAState//edges} field to new
 * targets. The DFA simulator will either find {@link DFAState//edges} to be
 * {@code null}, to be non-{@code null} and {@code dfa.edges[t]} null, or
 * {@code dfa.edges[t]} to be non-null. The
 * {@link //addDFAEdge} method could be racing to set the field
 * but in either case the DFA simulator works; if {@code null}, and requests ATN
 * simulation. It could also race trying to get {@code dfa.edges[t]}, but either
 * way it will work because it's not doing a test and set operation.</p>
 *
 * <p>
 * <strong>Starting with SLL then failing to combined SLL/LL (Two-Stage
 * Parsing)</strong></p>
 *
 * <p>
 * Sam pointed out that if SLL does not give a syntax error, then there is no
 * point in doing full LL, which is slower. We only have to try LL if we get a
 * syntax error. For maximum speed, Sam starts the parser set to pure SLL
 * mode with the {@link BailErrorStrategy}:</p>
 *
 * <pre>
 * parser.{@link Parser//getInterpreter() getInterpreter()}.{@link //setPredictionMode setPredictionMode}{@code (}{@link PredictionMode//SLL}{@code )};
 * parser.{@link Parser//setErrorHandler setErrorHandler}(new {@link BailErrorStrategy}());
 * </pre>
 *
 * <p>
 * If it does not get a syntax error, then we're done. If it does get a syntax
 * error, we need to retry with the combined SLL/LL strategy.</p>
 *
 * <p>
 * The reason this works is as follows. If there are no SLL conflicts, then the
 * grammar is SLL (at least for that input set). If there is an SLL conflict,
 * the full LL analysis must yield a set of viable alternatives which is a
 * subset of the alternatives reported by SLL. If the LL set is a singleton,
 * then the grammar is LL but not SLL. If the LL set is the same size as the SLL
 * set, the decision is SLL. If the LL set has size &gt; 1, then that decision
 * is truly ambiguous on the current input. If the LL set is smaller, then the
 * SLL conflict resolution might choose an alternative that the full LL would
 * rule out as a possibility based upon better context information. If that's
 * the case, then the SLL parse will definitely get an error because the full LL
 * analysis says it's not viable. If SLL conflict resolution chooses an
 * alternative within the LL set, them both SLL and LL would choose the same
 * alternative because they both choose the minimum of multiple conflicting
 * alternatives.</p>
 *
 * <p>
 * Let's say we have a set of SLL conflicting alternatives {@code {1, 2, 3}} and
 * a smaller LL set called <em>s</em>. If <em>s</em> is {@code {2, 3}}, then SLL
 * parsing will get an error because SLL will pursue alternative 1. If
 * <em>s</em> is {@code {1, 2}} or {@code {1, 3}} then both SLL and LL will
 * choose the same alternative because alternative one is the minimum of either
 * set. If <em>s</em> is {@code {2}} or {@code {3}} then SLL will get a syntax
 * error. If <em>s</em> is {@code {1}} then SLL will succeed.</p>
 *
 * <p>
 * Of course, if the input is invalid, then we will get an error for sure in
 * both SLL and LL parsing. Erroneous input will therefore require 2 passes over
 * the input.</p>
 */
class ParserATNSimulator extends ATNSimulator {
    constructor(parser, atn, decisionToDFA, sharedContextCache) {
        super(atn, sharedContextCache);
        this.parser = parser;
        this.decisionToDFA = decisionToDFA;
        // SLL, LL, or LL + exact ambig detection?//
        this.predictionMode = PredictionMode.LL;
        // LAME globals to avoid parameters!!!!! I need these down deep in predTransition
        this._input = null;
        this._startIndex = 0;
        this._outerContext = null;
        this._dfa = null;
        /**
         * Each prediction operation uses a cache for merge of prediction contexts.
         *  Don't keep around as it wastes huge amounts of memory. DoubleKeyMap
         *  isn't synchronized but we're ok since two threads shouldn't reuse same
         *  parser/atnsim object because it can only handle one input at a time.
         *  This maps graphs a and b to merged result c. (a,b)&rarr;c. We can avoid
         *  the merge if we ever see a and b again.  Note that (b,a)&rarr;c should
         *  also be examined during cache lookup.
         */
        this.mergeCache = null;
        this.debug = false;
        this.debug_closure = false;
        this.debug_add = false;
        this.debug_list_atn_decisions = false;
        this.dfa_debug = false;
        this.retry_debug = false;
    }

    reset() {}

    adaptivePredict(input, decision, outerContext) {
        if (this.debug || this.debug_list_atn_decisions) {
            console.log("adaptivePredict decision " + decision +
                                   " exec LA(1)==" + this.getLookaheadName(input) +
                                   " line " + input.LT(1).line + ":" +
                                   input.LT(1).column);
        }
        this._input = input;
        this._startIndex = input.index;
        this._outerContext = outerContext;

        const dfa = this.decisionToDFA[decision];
        this._dfa = dfa;
        const m = input.mark();
        const index = input.index;

        // Now we are certain to have a specific decision's DFA
        // But, do we still need an initial state?
        try {
            let s0;
            if (dfa.precedenceDfa) {
                // the start state for a precedence DFA depends on the current
                // parser precedence, and is provided by a DFA method.
                s0 = dfa.getPrecedenceStartState(this.parser.getPrecedence());
            } else {
                // the start state for a "regular" DFA is just s0
                s0 = dfa.s0;
            }
            if (s0===null) {
                if (outerContext===null) {
                    outerContext = RuleContext.EMPTY;
                }
                if (this.debug || this.debug_list_atn_decisions) {
                    console.log("predictATN decision " + dfa.decision +
                                       " exec LA(1)==" + this.getLookaheadName(input) +
                                       ", outerContext=" + outerContext.toString(this.parser.ruleNames));
                }

                const fullCtx = false;
                let s0_closure = this.computeStartState(dfa.atnStartState, RuleContext.EMPTY, fullCtx);

                if( dfa.precedenceDfa) {
                    // If this is a precedence DFA, we use applyPrecedenceFilter
                    // to convert the computed start state to a precedence start
                    // state. We then use DFA.setPrecedenceStartState to set the
                    // appropriate start state for the precedence level rather
                    // than simply setting DFA.s0.
                    //
                    dfa.s0.configs = s0_closure; // not used for prediction but useful to know start configs anyway
                    s0_closure = this.applyPrecedenceFilter(s0_closure);
                    s0 = this.addDFAState(dfa, new DFAState$1(null, s0_closure));
                    dfa.setPrecedenceStartState(this.parser.getPrecedence(), s0);
                } else {
                    s0 = this.addDFAState(dfa, new DFAState$1(null, s0_closure));
                    dfa.s0 = s0;
                }
            }
            const alt = this.execATN(dfa, s0, input, index, outerContext);
            if (this.debug) {
                console.log("DFA after predictATN: " + dfa.toString(this.parser.literalNames, this.parser.symbolicNames));
            }
            return alt;
        } finally {
            this._dfa = null;
            this.mergeCache = null; // wack cache after each prediction
            input.seek(index);
            input.release(m);
        }
    }

    /**
     * Performs ATN simulation to compute a predicted alternative based
     *  upon the remaining input, but also updates the DFA cache to avoid
     *  having to traverse the ATN again for the same input sequence.
     *
     * There are some key conditions we're looking for after computing a new
     * set of ATN configs (proposed DFA state):
     *       if the set is empty, there is no viable alternative for current symbol
     *       does the state uniquely predict an alternative?
     *       does the state have a conflict that would prevent us from
     *         putting it on the work list?
     *
     * We also have some key operations to do:
     *       add an edge from previous DFA state to potentially new DFA state, D,
     *         upon current symbol but only if adding to work list, which means in all
     *         cases except no viable alternative (and possibly non-greedy decisions?)
     *       collecting predicates and adding semantic context to DFA accept states
     *       adding rule context to context-sensitive DFA accept states
     *       consuming an input symbol
     *       reporting a conflict
     *       reporting an ambiguity
     *       reporting a context sensitivity
     *       reporting insufficient predicates
     *
     * cover these cases:
     *    dead end
     *    single alt
     *    single alt + preds
     *    conflict
     *    conflict + preds
     *
     */
    execATN(dfa, s0, input, startIndex, outerContext ) {
        if (this.debug || this.debug_list_atn_decisions) {
            console.log("execATN decision " + dfa.decision +
                    " exec LA(1)==" + this.getLookaheadName(input) +
                    " line " + input.LT(1).line + ":" + input.LT(1).column);
        }
        let alt;
        let previousD = s0;

        if (this.debug) {
            console.log("s0 = " + s0);
        }
        let t = input.LA(1);
        while(true) { // while more work
            let D = this.getExistingTargetState(previousD, t);
            if(D===null) {
                D = this.computeTargetState(dfa, previousD, t);
            }
            if(D===ATNSimulator.ERROR) {
                // if any configs in previous dipped into outer context, that
                // means that input up to t actually finished entry rule
                // at least for SLL decision. Full LL doesn't dip into outer
                // so don't need special case.
                // We will get an error no matter what so delay until after
                // decision; better error message. Also, no reachable target
                // ATN states in SLL implies LL will also get nowhere.
                // If conflict in states that dip out, choose min since we
                // will get error no matter what.
                const e = this.noViableAlt(input, outerContext, previousD.configs, startIndex);
                input.seek(startIndex);
                alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousD.configs, outerContext);
                if(alt!==ATN.INVALID_ALT_NUMBER) {
                    return alt;
                } else {
                    throw e;
                }
            }
            if(D.requiresFullContext && this.predictionMode !== PredictionMode.SLL) {
                // IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)
                let conflictingAlts = null;
                if (D.predicates!==null) {
                    if (this.debug) {
                        console.log("DFA state has preds in DFA sim LL failover");
                    }
                    const conflictIndex = input.index;
                    if(conflictIndex !== startIndex) {
                        input.seek(startIndex);
                    }
                    conflictingAlts = this.evalSemanticContext(D.predicates, outerContext, true);
                    if (conflictingAlts.length===1) {
                        if(this.debug) {
                            console.log("Full LL avoided");
                        }
                        return conflictingAlts.minValue();
                    }
                    if (conflictIndex !== startIndex) {
                        // restore the index so reporting the fallback to full
                        // context occurs with the index at the correct spot
                        input.seek(conflictIndex);
                    }
                }
                if (this.dfa_debug) {
                    console.log("ctx sensitive state " + outerContext +" in " + D);
                }
                const fullCtx = true;
                const s0_closure = this.computeStartState(dfa.atnStartState, outerContext, fullCtx);
                this.reportAttemptingFullContext(dfa, conflictingAlts, D.configs, startIndex, input.index);
                alt = this.execATNWithFullContext(dfa, D, s0_closure, input, startIndex, outerContext);
                return alt;
            }
            if (D.isAcceptState) {
                if (D.predicates===null) {
                    return D.prediction;
                }
                const stopIndex = input.index;
                input.seek(startIndex);
                const alts = this.evalSemanticContext(D.predicates, outerContext, true);
                if (alts.length===0) {
                    throw this.noViableAlt(input, outerContext, D.configs, startIndex);
                } else if (alts.length===1) {
                    return alts.minValue();
                } else {
                    // report ambiguity after predicate evaluation to make sure the correct set of ambig alts is reported.
                    this.reportAmbiguity(dfa, D, startIndex, stopIndex, false, alts, D.configs);
                    return alts.minValue();
                }
            }
            previousD = D;

            if (t !== Token$5.EOF) {
                input.consume();
                t = input.LA(1);
            }
        }
    }

    /**
     * Get an existing target state for an edge in the DFA. If the target state
     * for the edge has not yet been computed or is otherwise not available,
     * this method returns {@code null}.
     *
     * @param previousD The current DFA state
     * @param t The next input symbol
     * @return The existing target DFA state for the given input symbol
     * {@code t}, or {@code null} if the target state for this edge is not
     * already cached
     */
    getExistingTargetState(previousD, t) {
        const edges = previousD.edges;
        if (edges===null) {
            return null;
        } else {
            return edges[t + 1] || null;
        }
    }

    /**
     * Compute a target state for an edge in the DFA, and attempt to add the
     * computed state and corresponding edge to the DFA.
     *
     * @param dfa The DFA
     * @param previousD The current DFA state
     * @param t The next input symbol
     *
     * @return The computed target DFA state for the given input symbol
     * {@code t}. If {@code t} does not lead to a valid DFA state, this method
     * returns {@link //ERROR
     */
    computeTargetState(dfa, previousD, t) {
       const reach = this.computeReachSet(previousD.configs, t, false);
        if(reach===null) {
            this.addDFAEdge(dfa, previousD, t, ATNSimulator.ERROR);
            return ATNSimulator.ERROR;
        }
        // create new target state; we'll add to DFA after it's complete
        let D = new DFAState$1(null, reach);

        const predictedAlt = this.getUniqueAlt(reach);

        if (this.debug) {
            const altSubSets = PredictionMode.getConflictingAltSubsets(reach);
            console.log("SLL altSubSets=" + Utils$1.arrayToString(altSubSets) +
                        /*", previous=" + previousD.configs + */
                        ", configs=" + reach +
                        ", predict=" + predictedAlt +
                        ", allSubsetsConflict=" +
                        PredictionMode.allSubsetsConflict(altSubSets) + ", conflictingAlts=" +
                        this.getConflictingAlts(reach));
        }
        if (predictedAlt!==ATN.INVALID_ALT_NUMBER) {
            // NO CONFLICT, UNIQUELY PREDICTED ALT
            D.isAcceptState = true;
            D.configs.uniqueAlt = predictedAlt;
            D.prediction = predictedAlt;
        } else if (PredictionMode.hasSLLConflictTerminatingPrediction(this.predictionMode, reach)) {
            // MORE THAN ONE VIABLE ALTERNATIVE
            D.configs.conflictingAlts = this.getConflictingAlts(reach);
            D.requiresFullContext = true;
            // in SLL-only mode, we will stop at this state and return the minimum alt
            D.isAcceptState = true;
            D.prediction = D.configs.conflictingAlts.minValue();
        }
        if (D.isAcceptState && D.configs.hasSemanticContext) {
            this.predicateDFAState(D, this.atn.getDecisionState(dfa.decision));
            if( D.predicates!==null) {
                D.prediction = ATN.INVALID_ALT_NUMBER;
            }
        }
        // all adds to dfa are done after we've created full D state
        D = this.addDFAEdge(dfa, previousD, t, D);
        return D;
    }

    predicateDFAState(dfaState, decisionState) {
        // We need to test all predicates, even in DFA states that
        // uniquely predict alternative.
        const nalts = decisionState.transitions.length;
        // Update DFA so reach becomes accept state with (predicate,alt)
        // pairs if preds found for conflicting alts
        const altsToCollectPredsFrom = this.getConflictingAltsOrUniqueAlt(dfaState.configs);
        const altToPred = this.getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, nalts);
        if (altToPred!==null) {
            dfaState.predicates = this.getPredicatePredictions(altsToCollectPredsFrom, altToPred);
            dfaState.prediction = ATN.INVALID_ALT_NUMBER; // make sure we use preds
        } else {
            // There are preds in configs but they might go away
            // when OR'd together like {p}? || NONE == NONE. If neither
            // alt has preds, resolve to min alt
            dfaState.prediction = altsToCollectPredsFrom.minValue();
        }
    }

// comes back with reach.uniqueAlt set to a valid alt
    execATNWithFullContext(dfa, D, // how far we got before failing over
                                         s0,
                                         input,
                                         startIndex,
                                         outerContext) {
        if (this.debug || this.debug_list_atn_decisions) {
            console.log("execATNWithFullContext "+s0);
        }
        const fullCtx = true;
        let foundExactAmbig = false;
        let reach;
        let previous = s0;
        input.seek(startIndex);
        let t = input.LA(1);
        let predictedAlt = -1;
        while (true) { // while more work
            reach = this.computeReachSet(previous, t, fullCtx);
            if (reach===null) {
                // if any configs in previous dipped into outer context, that
                // means that input up to t actually finished entry rule
                // at least for LL decision. Full LL doesn't dip into outer
                // so don't need special case.
                // We will get an error no matter what so delay until after
                // decision; better error message. Also, no reachable target
                // ATN states in SLL implies LL will also get nowhere.
                // If conflict in states that dip out, choose min since we
                // will get error no matter what.
                const e = this.noViableAlt(input, outerContext, previous, startIndex);
                input.seek(startIndex);
                const alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);
                if(alt!==ATN.INVALID_ALT_NUMBER) {
                    return alt;
                } else {
                    throw e;
                }
            }
            const altSubSets = PredictionMode.getConflictingAltSubsets(reach);
            if(this.debug) {
                console.log("LL altSubSets=" + altSubSets + ", predict=" +
                      PredictionMode.getUniqueAlt(altSubSets) + ", resolvesToJustOneViableAlt=" +
                      PredictionMode.resolvesToJustOneViableAlt(altSubSets));
            }
            reach.uniqueAlt = this.getUniqueAlt(reach);
            // unique prediction?
            if(reach.uniqueAlt!==ATN.INVALID_ALT_NUMBER) {
                predictedAlt = reach.uniqueAlt;
                break;
            } else if (this.predictionMode !== PredictionMode.LL_EXACT_AMBIG_DETECTION) {
                predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);
                if(predictedAlt !== ATN.INVALID_ALT_NUMBER) {
                    break;
                }
            } else {
                // In exact ambiguity mode, we never try to terminate early.
                // Just keeps scarfing until we know what the conflict is
                if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {
                    foundExactAmbig = true;
                    predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);
                    break;
                }
                // else there are multiple non-conflicting subsets or
                // we're not sure what the ambiguity is yet.
                // So, keep going.
            }
            previous = reach;
            if( t !== Token$5.EOF) {
                input.consume();
                t = input.LA(1);
            }
        }
        // If the configuration set uniquely predicts an alternative,
        // without conflict, then we know that it's a full LL decision
        // not SLL.
        if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER ) {
            this.reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index);
            return predictedAlt;
        }
        // We do not check predicates here because we have checked them
        // on-the-fly when doing full context prediction.

        //
        // In non-exact ambiguity detection mode, we might	actually be able to
        // detect an exact ambiguity, but I'm not going to spend the cycles
        // needed to check. We only emit ambiguity warnings in exact ambiguity
        // mode.
        //
        // For example, we might know that we have conflicting configurations.
        // But, that does not mean that there is no way forward without a
        // conflict. It's possible to have nonconflicting alt subsets as in:

        // altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]

        // from
        //
        //    [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),
        //     (13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]
        //
        // In this case, (17,1,[5 $]) indicates there is some next sequence that
        // would resolve this without conflict to alternative 1. Any other viable
        // next sequence, however, is associated with a conflict.  We stop
        // looking for input because no amount of further lookahead will alter
        // the fact that we should predict alternative 1.  We just can't say for
        // sure that there is an ambiguity without looking further.

        this.reportAmbiguity(dfa, D, startIndex, input.index, foundExactAmbig, null, reach);

        return predictedAlt;
    }

    computeReachSet(closure, t, fullCtx) {
        if (this.debug) {
            console.log("in computeReachSet, starting closure: " + closure);
        }
        if( this.mergeCache===null) {
            this.mergeCache = new DoubleDict();
        }
        const intermediate = new ATNConfigSet$1(fullCtx);

        // Configurations already in a rule stop state indicate reaching the end
        // of the decision rule (local context) or end of the start rule (full
        // context). Once reached, these configurations are never updated by a
        // closure operation, so they are handled separately for the performance
        // advantage of having a smaller intermediate set when calling closure.
        //
        // For full-context reach operations, separate handling is required to
        // ensure that the alternative matching the longest overall sequence is
        // chosen when multiple such configurations can match the input.

        let skippedStopStates = null;

        // First figure out where we can reach on input t
        for (let i=0; i<closure.items.length;i++) {
            const c = closure.items[i];
            if(this.debug) {
                console.log("testing " + this.getTokenName(t) + " at " + c);
            }
            if (c.state instanceof RuleStopState) {
                if (fullCtx || t === Token$5.EOF) {
                    if (skippedStopStates===null) {
                        skippedStopStates = [];
                    }
                    skippedStopStates.push(c);
                    if(this.debug_add) {
                        console.log("added " + c + " to skippedStopStates");
                    }
                }
                continue;
            }
            for(let j=0;j<c.state.transitions.length;j++) {
                const trans = c.state.transitions[j];
                const target = this.getReachableTarget(trans, t);
                if (target!==null) {
                    const cfg = new ATNConfig({state:target}, c);
                    intermediate.add(cfg, this.mergeCache);
                    if(this.debug_add) {
                        console.log("added " + cfg + " to intermediate");
                    }
                }
            }
        }
        // Now figure out where the reach operation can take us...
        let reach = null;

        // This block optimizes the reach operation for intermediate sets which
        // trivially indicate a termination state for the overall
        // adaptivePredict operation.
        //
        // The conditions assume that intermediate
        // contains all configurations relevant to the reach set, but this
        // condition is not true when one or more configurations have been
        // withheld in skippedStopStates, or when the current symbol is EOF.
        //
        if (skippedStopStates===null && t!==Token$5.EOF) {
            if (intermediate.items.length===1) {
                // Don't pursue the closure if there is just one state.
                // It can only have one alternative; just add to result
                // Also don't pursue the closure if there is unique alternative
                // among the configurations.
                reach = intermediate;
            } else if (this.getUniqueAlt(intermediate)!==ATN.INVALID_ALT_NUMBER) {
                // Also don't pursue the closure if there is unique alternative
                // among the configurations.
                reach = intermediate;
            }
        }
        // If the reach set could not be trivially determined, perform a closure
        // operation on the intermediate set to compute its initial value.
        //
        if (reach===null) {
            reach = new ATNConfigSet$1(fullCtx);
            const closureBusy = new Set$2();
            const treatEofAsEpsilon = t === Token$5.EOF;
            for (let k=0; k<intermediate.items.length;k++) {
                this.closure(intermediate.items[k], reach, closureBusy, false, fullCtx, treatEofAsEpsilon);
            }
        }
        if (t === Token$5.EOF) {
            // After consuming EOF no additional input is possible, so we are
            // only interested in configurations which reached the end of the
            // decision rule (local context) or end of the start rule (full
            // context). Update reach to contain only these configurations. This
            // handles both explicit EOF transitions in the grammar and implicit
            // EOF transitions following the end of the decision or start rule.
            //
            // When reach==intermediate, no closure operation was performed. In
            // this case, removeAllConfigsNotInRuleStopState needs to check for
            // reachable rule stop states as well as configurations already in
            // a rule stop state.
            //
            // This is handled before the configurations in skippedStopStates,
            // because any configurations potentially added from that list are
            // already guaranteed to meet this condition whether or not it's
            // required.
            //
            reach = this.removeAllConfigsNotInRuleStopState(reach, reach === intermediate);
        }
        // If skippedStopStates!==null, then it contains at least one
        // configuration. For full-context reach operations, these
        // configurations reached the end of the start rule, in which case we
        // only add them back to reach if no configuration during the current
        // closure operation reached such a state. This ensures adaptivePredict
        // chooses an alternative matching the longest overall sequence when
        // multiple alternatives are viable.
        //
        if (skippedStopStates!==null && ( (! fullCtx) || (! PredictionMode.hasConfigInRuleStopState(reach)))) {
            for (let l=0; l<skippedStopStates.length;l++) {
                reach.add(skippedStopStates[l], this.mergeCache);
            }
        }
        if (reach.items.length===0) {
            return null;
        } else {
            return reach;
        }
    }

    /**
     * Return a configuration set containing only the configurations from
     * {@code configs} which are in a {@link RuleStopState}. If all
     * configurations in {@code configs} are already in a rule stop state, this
     * method simply returns {@code configs}.
     *
     * <p>When {@code lookToEndOfRule} is true, this method uses
     * {@link ATN//nextTokens} for each configuration in {@code configs} which is
     * not already in a rule stop state to see if a rule stop state is reachable
     * from the configuration via epsilon-only transitions.</p>
     *
     * @param configs the configuration set to update
     * @param lookToEndOfRule when true, this method checks for rule stop states
     * reachable by epsilon-only transitions from each configuration in
     * {@code configs}.
     *
     * @return {@code configs} if all configurations in {@code configs} are in a
     * rule stop state, otherwise return a new configuration set containing only
     * the configurations from {@code configs} which are in a rule stop state
     */
    removeAllConfigsNotInRuleStopState(configs, lookToEndOfRule) {
        if (PredictionMode.allConfigsInRuleStopStates(configs)) {
            return configs;
        }
        const result = new ATNConfigSet$1(configs.fullCtx);
        for(let i=0; i<configs.items.length;i++) {
            const config = configs.items[i];
            if (config.state instanceof RuleStopState) {
                result.add(config, this.mergeCache);
                continue;
            }
            if (lookToEndOfRule && config.state.epsilonOnlyTransitions) {
                const nextTokens = this.atn.nextTokens(config.state);
                if (nextTokens.contains(Token$5.EPSILON)) {
                    const endOfRuleState = this.atn.ruleToStopState[config.state.ruleIndex];
                    result.add(new ATNConfig({state:endOfRuleState}, config), this.mergeCache);
                }
            }
        }
        return result;
    }

    computeStartState(p, ctx, fullCtx) {
        // always at least the implicit call to start rule
        const initialContext = predictionContextFromRuleContext(this.atn, ctx);
        const configs = new ATNConfigSet$1(fullCtx);
        for(let i=0;i<p.transitions.length;i++) {
            const target = p.transitions[i].target;
            const c = new ATNConfig({ state:target, alt:i+1, context:initialContext }, null);
            const closureBusy = new Set$2();
            this.closure(c, configs, closureBusy, true, fullCtx, false);
        }
        return configs;
    }

    /**
     * This method transforms the start state computed by
     * {@link //computeStartState} to the special start state used by a
     * precedence DFA for a particular precedence value. The transformation
     * process applies the following changes to the start state's configuration
     * set.
     *
     * <ol>
     * <li>Evaluate the precedence predicates for each configuration using
     * {@link SemanticContext//evalPrecedence}.</li>
     * <li>Remove all configurations which predict an alternative greater than
     * 1, for which another configuration that predicts alternative 1 is in the
     * same ATN state with the same prediction context. This transformation is
     * valid for the following reasons:
     * <ul>
     * <li>The closure block cannot contain any epsilon transitions which bypass
     * the body of the closure, so all states reachable via alternative 1 are
     * part of the precedence alternatives of the transformed left-recursive
     * rule.</li>
     * <li>The "primary" portion of a left recursive rule cannot contain an
     * epsilon transition, so the only way an alternative other than 1 can exist
     * in a state that is also reachable via alternative 1 is by nesting calls
     * to the left-recursive rule, with the outer calls not being at the
     * preferred precedence level.</li>
     * </ul>
     * </li>
     * </ol>
     *
     * <p>
     * The prediction context must be considered by this filter to address
     * situations like the following.
     * </p>
     * <code>
     * <pre>
     * grammar TA;
     * prog: statement* EOF;
     * statement: letterA | statement letterA 'b' ;
     * letterA: 'a';
     * </pre>
     * </code>
     * <p>
     * If the above grammar, the ATN state immediately before the token
     * reference {@code 'a'} in {@code letterA} is reachable from the left edge
     * of both the primary and closure blocks of the left-recursive rule
     * {@code statement}. The prediction context associated with each of these
     * configurations distinguishes between them, and prevents the alternative
     * which stepped out to {@code prog} (and then back in to {@code statement}
     * from being eliminated by the filter.
     * </p>
     *
     * @param configs The configuration set computed by
     * {@link //computeStartState} as the start state for the DFA.
     * @return The transformed configuration set representing the start state
     * for a precedence DFA at a particular precedence level (determined by
     * calling {@link Parser//getPrecedence})
     */
    applyPrecedenceFilter(configs) {
        let config;
        const statesFromAlt1 = [];
        const configSet = new ATNConfigSet$1(configs.fullCtx);
        for(let i=0; i<configs.items.length; i++) {
            config = configs.items[i];
            // handle alt 1 first
            if (config.alt !== 1) {
                continue;
            }
            const updatedContext = config.semanticContext.evalPrecedence(this.parser, this._outerContext);
            if (updatedContext===null) {
                // the configuration was eliminated
                continue;
            }
            statesFromAlt1[config.state.stateNumber] = config.context;
            if (updatedContext !== config.semanticContext) {
                configSet.add(new ATNConfig({semanticContext:updatedContext}, config), this.mergeCache);
            } else {
                configSet.add(config, this.mergeCache);
            }
        }
        for(let i=0; i<configs.items.length; i++) {
            config = configs.items[i];
            if (config.alt === 1) {
                // already handled
                continue;
            }
            // In the future, this elimination step could be updated to also
            // filter the prediction context for alternatives predicting alt>1
            // (basically a graph subtraction algorithm).
            if (!config.precedenceFilterSuppressed) {
                const context = statesFromAlt1[config.state.stateNumber] || null;
                if (context!==null && context.equals(config.context)) {
                    // eliminated
                    continue;
                }
            }
            configSet.add(config, this.mergeCache);
        }
        return configSet;
    }

    getReachableTarget(trans, ttype) {
        if (trans.matches(ttype, 0, this.atn.maxTokenType)) {
            return trans.target;
        } else {
            return null;
        }
    }

    getPredsForAmbigAlts(ambigAlts, configs, nalts) {
        // REACH=[1|1|[]|0:0, 1|2|[]|0:1]
        // altToPred starts as an array of all null contexts. The entry at index i
        // corresponds to alternative i. altToPred[i] may have one of three values:
        //   1. null: no ATNConfig c is found such that c.alt==i
        //   2. SemanticContext.NONE: At least one ATNConfig c exists such that
        //      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,
        //      alt i has at least one unpredicated config.
        //   3. Non-NONE Semantic Context: There exists at least one, and for all
        //      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.
        //
        // From this, it is clear that NONE||anything==NONE.
        //
        let altToPred = [];
        for(let i=0;i<configs.items.length;i++) {
            const c = configs.items[i];
            if(ambigAlts.contains( c.alt )) {
                altToPred[c.alt] = SemanticContext.orContext(altToPred[c.alt] || null, c.semanticContext);
            }
        }
        let nPredAlts = 0;
        for (let i =1;i< nalts+1;i++) {
            const pred = altToPred[i] || null;
            if (pred===null) {
                altToPred[i] = SemanticContext.NONE;
            } else if (pred !== SemanticContext.NONE) {
                nPredAlts += 1;
            }
        }
        // nonambig alts are null in altToPred
        if (nPredAlts===0) {
            altToPred = null;
        }
        if (this.debug) {
            console.log("getPredsForAmbigAlts result " + Utils$1.arrayToString(altToPred));
        }
        return altToPred;
    }

    getPredicatePredictions(ambigAlts, altToPred) {
        const pairs = [];
        let containsPredicate = false;
        for (let i=1; i<altToPred.length;i++) {
            const pred = altToPred[i];
            // unpredicated is indicated by SemanticContext.NONE
            if( ambigAlts!==null && ambigAlts.contains( i )) {
                pairs.push(new PredPrediction(pred, i));
            }
            if (pred !== SemanticContext.NONE) {
                containsPredicate = true;
            }
        }
        if (! containsPredicate) {
            return null;
        }
        return pairs;
    }

    /**
     * This method is used to improve the localization of error messages by
     * choosing an alternative rather than throwing a
     * {@link NoViableAltException} in particular prediction scenarios where the
     * {@link //ERROR} state was reached during ATN simulation.
     *
     * <p>
     * The default implementation of this method uses the following
     * algorithm to identify an ATN configuration which successfully parsed the
     * decision entry rule. Choosing such an alternative ensures that the
     * {@link ParserRuleContext} returned by the calling rule will be complete
     * and valid, and the syntax error will be reported later at a more
     * localized location.</p>
     *
     * <ul>
     * <li>If a syntactically valid path or paths reach the end of the decision rule and
     * they are semantically valid if predicated, return the min associated alt.</li>
     * <li>Else, if a semantically invalid but syntactically valid path exist
     * or paths exist, return the minimum associated alt.
     * </li>
     * <li>Otherwise, return {@link ATN//INVALID_ALT_NUMBER}.</li>
     * </ul>
     *
     * <p>
     * In some scenarios, the algorithm described above could predict an
     * alternative which will result in a {@link FailedPredicateException} in
     * the parser. Specifically, this could occur if the <em>only</em> configuration
     * capable of successfully parsing to the end of the decision rule is
     * blocked by a semantic predicate. By choosing this alternative within
     * {@link //adaptivePredict} instead of throwing a
     * {@link NoViableAltException}, the resulting
     * {@link FailedPredicateException} in the parser will identify the specific
     * predicate which is preventing the parser from successfully parsing the
     * decision rule, which helps developers identify and correct logic errors
     * in semantic predicates.
     * </p>
     *
     * @param configs The ATN configurations which were valid immediately before
     * the {@link //ERROR} state was reached
     * @param outerContext The is the \gamma_0 initial parser context from the paper
     * or the parser stack at the instant before prediction commences.
     *
     * @return The value to return from {@link //adaptivePredict}, or
     * {@link ATN//INVALID_ALT_NUMBER} if a suitable alternative was not
     * identified and {@link //adaptivePredict} should report an error instead
     */
    getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(configs, outerContext) {
        const cfgs = this.splitAccordingToSemanticValidity(configs, outerContext);
        const semValidConfigs = cfgs[0];
        const semInvalidConfigs = cfgs[1];
        let alt = this.getAltThatFinishedDecisionEntryRule(semValidConfigs);
        if (alt!==ATN.INVALID_ALT_NUMBER) { // semantically/syntactically viable path exists
            return alt;
        }
        // Is there a syntactically valid path with a failed pred?
        if (semInvalidConfigs.items.length>0) {
            alt = this.getAltThatFinishedDecisionEntryRule(semInvalidConfigs);
            if (alt!==ATN.INVALID_ALT_NUMBER) { // syntactically viable path exists
                return alt;
            }
        }
        return ATN.INVALID_ALT_NUMBER;
    }

    getAltThatFinishedDecisionEntryRule(configs) {
        const alts = [];
        for(let i=0;i<configs.items.length; i++) {
            const c = configs.items[i];
            if (c.reachesIntoOuterContext>0 || ((c.state instanceof RuleStopState) && c.context.hasEmptyPath())) {
                if(alts.indexOf(c.alt)<0) {
                    alts.push(c.alt);
                }
            }
        }
        if (alts.length===0) {
            return ATN.INVALID_ALT_NUMBER;
        } else {
            return Math.min.apply(null, alts);
        }
    }

    /**
     * Walk the list of configurations and split them according to
     * those that have preds evaluating to true/false.  If no pred, assume
     * true pred and include in succeeded set.  Returns Pair of sets.
     *
     * Create a new set so as not to alter the incoming parameter.
     *
     * Assumption: the input stream has been restored to the starting point
     * prediction, which is where predicates need to evaluate.*/
    splitAccordingToSemanticValidity( configs, outerContext) {
        const succeeded = new ATNConfigSet$1(configs.fullCtx);
        const failed = new ATNConfigSet$1(configs.fullCtx);
        for(let i=0;i<configs.items.length; i++) {
            const c = configs.items[i];
            if (c.semanticContext !== SemanticContext.NONE) {
                const predicateEvaluationResult = c.semanticContext.evaluate(this.parser, outerContext);
                if (predicateEvaluationResult) {
                    succeeded.add(c);
                } else {
                    failed.add(c);
                }
            } else {
                succeeded.add(c);
            }
        }
        return [succeeded, failed];
    }

    /**
     * Look through a list of predicate/alt pairs, returning alts for the
     * pairs that win. A {@code NONE} predicate indicates an alt containing an
     * unpredicated config which behaves as "always true." If !complete
     * then we stop at the first predicate that evaluates to true. This
     * includes pairs with null predicates.
     */
    evalSemanticContext(predPredictions, outerContext, complete) {
        const predictions = new BitSet$1();
        for(let i=0;i<predPredictions.length;i++) {
            const pair = predPredictions[i];
            if (pair.pred === SemanticContext.NONE) {
                predictions.add(pair.alt);
                if (! complete) {
                    break;
                }
                continue;
            }
            const predicateEvaluationResult = pair.pred.evaluate(this.parser, outerContext);
            if (this.debug || this.dfa_debug) {
                console.log("eval pred " + pair + "=" + predicateEvaluationResult);
            }
            if (predicateEvaluationResult) {
                if (this.debug || this.dfa_debug) {
                    console.log("PREDICT " + pair.alt);
                }
                predictions.add(pair.alt);
                if (! complete) {
                    break;
                }
            }
        }
        return predictions;
    }

// TODO: If we are doing predicates, there is no point in pursuing
//     closure operations if we reach a DFA state that uniquely predicts
//     alternative. We will not be caching that DFA state and it is a
//     waste to pursue the closure. Might have to advance when we do
//     ambig detection thought :(
//
    closure(config, configs, closureBusy, collectPredicates, fullCtx, treatEofAsEpsilon) {
        const initialDepth = 0;
        this.closureCheckingStopState(config, configs, closureBusy, collectPredicates,
                                 fullCtx, initialDepth, treatEofAsEpsilon);
    }

    closureCheckingStopState(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {
        if (this.debug || this.debug_closure) {
            console.log("closure(" + config.toString(this.parser,true) + ")");
            // console.log("configs(" + configs.toString() + ")");
            if(config.reachesIntoOuterContext>50) {
                throw "problem";
            }
        }
        if (config.state instanceof RuleStopState) {
            // We hit rule end. If we have context info, use it
            // run thru all possible stack tops in ctx
            if (! config.context.isEmpty()) {
                for (let i =0; i<config.context.length; i++) {
                    if (config.context.getReturnState(i) === PredictionContext.EMPTY_RETURN_STATE) {
                        if (fullCtx) {
                            configs.add(new ATNConfig({state:config.state, context:PredictionContext.EMPTY}, config), this.mergeCache);
                            continue;
                        } else {
                            // we have no context info, just chase follow links (if greedy)
                            if (this.debug) {
                                console.log("FALLING off rule " + this.getRuleName(config.state.ruleIndex));
                            }
                            this.closure_(config, configs, closureBusy, collectPredicates,
                                     fullCtx, depth, treatEofAsEpsilon);
                        }
                        continue;
                    }
                    const returnState = this.atn.states[config.context.getReturnState(i)];
                    const newContext = config.context.getParent(i); // "pop" return state
                    const parms = {state:returnState, alt:config.alt, context:newContext, semanticContext:config.semanticContext};
                    const c = new ATNConfig(parms, null);
                    // While we have context to pop back from, we may have
                    // gotten that context AFTER having falling off a rule.
                    // Make sure we track that we are now out of context.
                    c.reachesIntoOuterContext = config.reachesIntoOuterContext;
                    this.closureCheckingStopState(c, configs, closureBusy, collectPredicates, fullCtx, depth - 1, treatEofAsEpsilon);
                }
                return;
            } else if( fullCtx) {
                // reached end of start rule
                configs.add(config, this.mergeCache);
                return;
            } else {
                // else if we have no context info, just chase follow links (if greedy)
                if (this.debug) {
                    console.log("FALLING off rule " + this.getRuleName(config.state.ruleIndex));
                }
            }
        }
        this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);
    }

    // Do the actual work of walking epsilon edges//
    closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {
        const p = config.state;
        // optimization
        if (! p.epsilonOnlyTransitions) {
            configs.add(config, this.mergeCache);
            // make sure to not return here, because EOF transitions can act as
            // both epsilon transitions and non-epsilon transitions.
        }
        for(let i = 0;i<p.transitions.length; i++) {
            if(i === 0 && this.canDropLoopEntryEdgeInLeftRecursiveRule(config))
                continue;

            const t = p.transitions[i];
            const continueCollecting = collectPredicates && !(t instanceof ActionTransition);
            const c = this.getEpsilonTarget(config, t, continueCollecting, depth === 0, fullCtx, treatEofAsEpsilon);
            if (c!==null) {
                let newDepth = depth;
                if ( config.state instanceof RuleStopState) {
                    // target fell off end of rule; mark resulting c as having dipped into outer context
                    // We can't get here if incoming config was rule stop and we had context
                    // track how far we dip into outer context.  Might
                    // come in handy and we avoid evaluating context dependent
                    // preds if this is > 0.
                    if (this._dfa !== null && this._dfa.precedenceDfa) {
                        if (t.outermostPrecedenceReturn === this._dfa.atnStartState.ruleIndex) {
                            c.precedenceFilterSuppressed = true;
                        }
                    }

                    c.reachesIntoOuterContext += 1;
                    if (closureBusy.add(c)!==c) {
                        // avoid infinite recursion for right-recursive rules
                        continue;
                    }
                    configs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method
                    newDepth -= 1;
                    if (this.debug) {
                        console.log("dips into outer ctx: " + c);
                    }
                } else {
                    if (!t.isEpsilon && closureBusy.add(c)!==c){
                        // avoid infinite recursion for EOF* and EOF+
                        continue;
                    }
                    if (t instanceof RuleTransition) {
                        // latch when newDepth goes negative - once we step out of the entry context we can't return
                        if (newDepth >= 0) {
                            newDepth += 1;
                        }
                    }
                }
                this.closureCheckingStopState(c, configs, closureBusy, continueCollecting, fullCtx, newDepth, treatEofAsEpsilon);
            }
        }
    }

    canDropLoopEntryEdgeInLeftRecursiveRule(config) {
        // return False
        const p = config.state;
        // First check to see if we are in StarLoopEntryState generated during
        // left-recursion elimination. For efficiency, also check if
        // the context has an empty stack case. If so, it would mean
        // global FOLLOW so we can't perform optimization
        // Are we the special loop entry/exit state? or SLL wildcard
        if(p.stateType !== ATNState$1.STAR_LOOP_ENTRY)
            return false;
        if(p.stateType !== ATNState$1.STAR_LOOP_ENTRY || !p.isPrecedenceDecision ||
               config.context.isEmpty() || config.context.hasEmptyPath())
            return false;

        // Require all return states to return back to the same rule that p is in.
        const numCtxs = config.context.length;
        for(let i=0; i<numCtxs; i++) { // for each stack context
            const returnState = this.atn.states[config.context.getReturnState(i)];
            if (returnState.ruleIndex !== p.ruleIndex)
                return false;
        }

        const decisionStartState = p.transitions[0].target;
        const blockEndStateNum = decisionStartState.endState.stateNumber;
        const blockEndState = this.atn.states[blockEndStateNum];

        // Verify that the top of each stack context leads to loop entry/exit
        // state through epsilon edges and w/o leaving rule.
        for(let i=0; i<numCtxs; i++) { // for each stack context
            const returnStateNumber = config.context.getReturnState(i);
            const returnState = this.atn.states[returnStateNumber];
            // all states must have single outgoing epsilon edge
            if (returnState.transitions.length !== 1 || !returnState.transitions[0].isEpsilon)
                return false;

            // Look for prefix op case like 'not expr', (' type ')' expr
            const returnStateTarget = returnState.transitions[0].target;
            if ( returnState.stateType === ATNState$1.BLOCK_END && returnStateTarget === p )
                continue;

            // Look for 'expr op expr' or case where expr's return state is block end
            // of (...)* internal block; the block end points to loop back
            // which points to p but we don't need to check that
            if ( returnState === blockEndState )
                continue;

            // Look for ternary expr ? expr : expr. The return state points at block end,
            // which points at loop entry state
            if ( returnStateTarget === blockEndState )
                continue;

            // Look for complex prefix 'between expr and expr' case where 2nd expr's
            // return state points at block end state of (...)* internal block
            if (returnStateTarget.stateType === ATNState$1.BLOCK_END && returnStateTarget.transitions.length === 1
                    && returnStateTarget.transitions[0].isEpsilon && returnStateTarget.transitions[0].target === p)
                continue;

            // anything else ain't conforming
            return false;
        }
        return true;
    }

    getRuleName(index) {
        if (this.parser!==null && index>=0) {
            return this.parser.ruleNames[index];
        } else {
            return "<rule " + index + ">";
        }
    }

    getEpsilonTarget(config, t, collectPredicates, inContext, fullCtx, treatEofAsEpsilon) {
        switch(t.serializationType) {
        case Transition.RULE:
            return this.ruleTransition(config, t);
        case Transition.PRECEDENCE:
            return this.precedenceTransition(config, t, collectPredicates, inContext, fullCtx);
        case Transition.PREDICATE:
            return this.predTransition(config, t, collectPredicates, inContext, fullCtx);
        case Transition.ACTION:
            return this.actionTransition(config, t);
        case Transition.EPSILON:
            return new ATNConfig({state:t.target}, config);
        case Transition.ATOM:
        case Transition.RANGE:
        case Transition.SET:
            // EOF transitions act like epsilon transitions after the first EOF
            // transition is traversed
            if (treatEofAsEpsilon) {
                if (t.matches(Token$5.EOF, 0, 1)) {
                    return new ATNConfig({state: t.target}, config);
                }
            }
            return null;
        default:
            return null;
        }
    }

    actionTransition(config, t) {
        if (this.debug) {
            const index = t.actionIndex === -1 ? 65535 : t.actionIndex;
            console.log("ACTION edge " + t.ruleIndex + ":" + index);
        }
        return new ATNConfig({state:t.target}, config);
    }

    precedenceTransition(config, pt, collectPredicates, inContext, fullCtx) {
        if (this.debug) {
            console.log("PRED (collectPredicates=" + collectPredicates + ") " +
                    pt.precedence + ">=_p, ctx dependent=true");
            if (this.parser!==null) {
                console.log("context surrounding pred is " + Utils$1.arrayToString(this.parser.getRuleInvocationStack()));
            }
        }
        let c = null;
        if (collectPredicates && inContext) {
            if (fullCtx) {
                // In full context mode, we can evaluate predicates on-the-fly
                // during closure, which dramatically reduces the size of
                // the config sets. It also obviates the need to test predicates
                // later during conflict resolution.
                const currentPosition = this._input.index;
                this._input.seek(this._startIndex);
                const predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);
                this._input.seek(currentPosition);
                if (predSucceeds) {
                    c = new ATNConfig({state:pt.target}, config); // no pred context
                }
            } else {
                const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());
                c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);
            }
        } else {
            c = new ATNConfig({state:pt.target}, config);
        }
        if (this.debug) {
            console.log("config from pred transition=" + c);
        }
        return c;
    }

    predTransition(config, pt, collectPredicates, inContext, fullCtx) {
        if (this.debug) {
            console.log("PRED (collectPredicates=" + collectPredicates + ") " + pt.ruleIndex +
                    ":" + pt.predIndex + ", ctx dependent=" + pt.isCtxDependent);
            if (this.parser!==null) {
                console.log("context surrounding pred is " + Utils$1.arrayToString(this.parser.getRuleInvocationStack()));
            }
        }
        let c = null;
        if (collectPredicates && ((pt.isCtxDependent && inContext) || ! pt.isCtxDependent)) {
            if (fullCtx) {
                // In full context mode, we can evaluate predicates on-the-fly
                // during closure, which dramatically reduces the size of
                // the config sets. It also obviates the need to test predicates
                // later during conflict resolution.
                const currentPosition = this._input.index;
                this._input.seek(this._startIndex);
                const predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);
                this._input.seek(currentPosition);
                if (predSucceeds) {
                    c = new ATNConfig({state:pt.target}, config); // no pred context
                }
            } else {
                const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());
                c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);
            }
        } else {
            c = new ATNConfig({state:pt.target}, config);
        }
        if (this.debug) {
            console.log("config from pred transition=" + c);
        }
        return c;
    }

    ruleTransition(config, t) {
        if (this.debug) {
            console.log("CALL rule " + this.getRuleName(t.target.ruleIndex) + ", ctx=" + config.context);
        }
        const returnState = t.followState;
        const newContext = SingletonPredictionContext.create(config.context, returnState.stateNumber);
        return new ATNConfig({state:t.target, context:newContext}, config );
    }

    getConflictingAlts(configs) {
        const altsets = PredictionMode.getConflictingAltSubsets(configs);
        return PredictionMode.getAlts(altsets);
    }

    /**
     * Sam pointed out a problem with the previous definition, v3, of
     * ambiguous states. If we have another state associated with conflicting
     * alternatives, we should keep going. For example, the following grammar
     *
     * s : (ID | ID ID?) ';' ;
     *
     * When the ATN simulation reaches the state before ';', it has a DFA
     * state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally
     * 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node
     * because alternative to has another way to continue, via [6|2|[]].
     * The key is that we have a single state that has config's only associated
     * with a single alternative, 2, and crucially the state transitions
     * among the configurations are all non-epsilon transitions. That means
     * we don't consider any conflicts that include alternative 2. So, we
     * ignore the conflict between alts 1 and 2. We ignore a set of
     * conflicting alts when there is an intersection with an alternative
     * associated with a single alt state in the state&rarr;config-list map.
     *
     * It's also the case that we might have two conflicting configurations but
     * also a 3rd nonconflicting configuration for a different alternative:
     * [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:
     *
     * a : A | A | A B ;
     *
     * After matching input A, we reach the stop state for rule A, state 1.
     * State 8 is the state right before B. Clearly alternatives 1 and 2
     * conflict and no amount of further lookahead will separate the two.
     * However, alternative 3 will be able to continue and so we do not
     * stop working on this state. In the previous example, we're concerned
     * with states associated with the conflicting alternatives. Here alt
     * 3 is not associated with the conflicting configs, but since we can continue
     * looking for input reasonably, I don't declare the state done. We
     * ignore a set of conflicting alts when we have an alternative
     * that we still need to pursue
     */
    getConflictingAltsOrUniqueAlt(configs) {
        let conflictingAlts = null;
        if (configs.uniqueAlt!== ATN.INVALID_ALT_NUMBER) {
            conflictingAlts = new BitSet$1();
            conflictingAlts.add(configs.uniqueAlt);
        } else {
            conflictingAlts = configs.conflictingAlts;
        }
        return conflictingAlts;
    }

    getTokenName(t) {
        if (t===Token$5.EOF) {
            return "EOF";
        }
        if( this.parser!==null && this.parser.literalNames!==null) {
            if (t >= this.parser.literalNames.length && t >= this.parser.symbolicNames.length) {
                console.log("" + t + " ttype out of range: " + this.parser.literalNames);
                console.log("" + this.parser.getInputStream().getTokens());
            } else {
                const name = this.parser.literalNames[t] || this.parser.symbolicNames[t];
                return name + "<" + t + ">";
            }
        }
        return "" + t;
    }

    getLookaheadName(input) {
        return this.getTokenName(input.LA(1));
    }

    /**
     * Used for debugging in adaptivePredict around execATN but I cut
     * it out for clarity now that alg. works well. We can leave this
     * "dead" code for a bit
     */
    dumpDeadEndConfigs(nvae) {
        console.log("dead end configs: ");
        const decs = nvae.getDeadEndConfigs();
        for(let i=0; i<decs.length; i++) {
            const c = decs[i];
            let trans = "no edges";
            if (c.state.transitions.length>0) {
                const t = c.state.transitions[0];
                if (t instanceof AtomTransition) {
                    trans = "Atom "+ this.getTokenName(t.label);
                } else if (t instanceof SetTransition) {
                    const neg = (t instanceof NotSetTransition);
                    trans = (neg ? "~" : "") + "Set " + t.set;
                }
            }
            console.error(c.toString(this.parser, true) + ":" + trans);
        }
    }

    noViableAlt(input, outerContext, configs, startIndex) {
        return new NoViableAltException$1(this.parser, input, input.get(startIndex), input.LT(1), configs, outerContext);
    }

    getUniqueAlt(configs) {
        let alt = ATN.INVALID_ALT_NUMBER;
        for(let i=0;i<configs.items.length;i++) {
            const c = configs.items[i];
            if (alt === ATN.INVALID_ALT_NUMBER) {
                alt = c.alt; // found first alt
            } else if( c.alt!==alt) {
                return ATN.INVALID_ALT_NUMBER;
            }
        }
        return alt;
    }

    /**
     * Add an edge to the DFA, if possible. This method calls
     * {@link //addDFAState} to ensure the {@code to} state is present in the
     * DFA. If {@code from} is {@code null}, or if {@code t} is outside the
     * range of edges that can be represented in the DFA tables, this method
     * returns without adding the edge to the DFA.
     *
     * <p>If {@code to} is {@code null}, this method returns {@code null}.
     * Otherwise, this method returns the {@link DFAState} returned by calling
     * {@link //addDFAState} for the {@code to} state.</p>
     *
     * @param dfa The DFA
     * @param from_ The source state for the edge
     * @param t The input symbol
     * @param to The target state for the edge
     *
     * @return If {@code to} is {@code null}, this method returns {@code null};
     * otherwise this method returns the result of calling {@link //addDFAState}
     * on {@code to}
     */
    addDFAEdge(dfa, from_, t, to) {
        if( this.debug) {
            console.log("EDGE " + from_ + " -> " + to + " upon " + this.getTokenName(t));
        }
        if (to===null) {
            return null;
        }
        to = this.addDFAState(dfa, to); // used existing if possible not incoming
        if (from_===null || t < -1 || t > this.atn.maxTokenType) {
            return to;
        }
        if (from_.edges===null) {
            from_.edges = [];
        }
        from_.edges[t+1] = to; // connect

        if (this.debug) {
            const literalNames = this.parser===null ? null : this.parser.literalNames;
            const symbolicNames = this.parser===null ? null : this.parser.symbolicNames;
            console.log("DFA=\n" + dfa.toString(literalNames, symbolicNames));
        }
        return to;
    }

    /**
     * Add state {@code D} to the DFA if it is not already present, and return
     * the actual instance stored in the DFA. If a state equivalent to {@code D}
     * is already in the DFA, the existing state is returned. Otherwise this
     * method returns {@code D} after adding it to the DFA.
     *
     * <p>If {@code D} is {@link //ERROR}, this method returns {@link //ERROR} and
     * does not change the DFA.</p>
     *
     * @param dfa The dfa
     * @param D The DFA state to add
     * @return The state stored in the DFA. This will be either the existing
     * state if {@code D} is already in the DFA, or {@code D} itself if the
     * state was not already present
     */
    addDFAState(dfa, D) {
        if (D === ATNSimulator.ERROR) {
            return D;
        }
        const existing = dfa.states.get(D);
        if(existing!==null) {
            return existing;
        }
        D.stateNumber = dfa.states.length;
        if (! D.configs.readOnly) {
            D.configs.optimizeConfigs(this);
            D.configs.setReadonly(true);
        }
        dfa.states.add(D);
        if (this.debug) {
            console.log("adding new DFA state: " + D);
        }
        return D;
    }

    reportAttemptingFullContext(dfa, conflictingAlts, configs, startIndex, stopIndex) {
        if (this.debug || this.retry_debug) {
            const interval = new Interval$3(startIndex, stopIndex + 1);
            console.log("reportAttemptingFullContext decision=" + dfa.decision + ":" + configs +
                               ", input=" + this.parser.getTokenStream().getText(interval));
        }
        if (this.parser!==null) {
            this.parser.getErrorListenerDispatch().reportAttemptingFullContext(this.parser, dfa, startIndex, stopIndex, conflictingAlts, configs);
        }
    }

    reportContextSensitivity(dfa, prediction, configs, startIndex, stopIndex) {
        if (this.debug || this.retry_debug) {
            const interval = new Interval$3(startIndex, stopIndex + 1);
            console.log("reportContextSensitivity decision=" + dfa.decision + ":" + configs +
                               ", input=" + this.parser.getTokenStream().getText(interval));
        }
        if (this.parser!==null) {
            this.parser.getErrorListenerDispatch().reportContextSensitivity(this.parser, dfa, startIndex, stopIndex, prediction, configs);
        }
    }

    // If context sensitive parsing, we know it's ambiguity not conflict//
    reportAmbiguity(dfa, D, startIndex, stopIndex,
                                   exact, ambigAlts, configs ) {
        if (this.debug || this.retry_debug) {
            const interval = new Interval$3(startIndex, stopIndex + 1);
            console.log("reportAmbiguity " + ambigAlts + ":" + configs +
                               ", input=" + this.parser.getTokenStream().getText(interval));
        }
        if (this.parser!==null) {
            this.parser.getErrorListenerDispatch().reportAmbiguity(this.parser, dfa, startIndex, stopIndex, exact, ambigAlts, configs);
        }
    }
}

var ParserATNSimulator_1 = ParserATNSimulator;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

atn$2.ATN = ATN_1;
atn$2.ATNDeserializer = ATNDeserializer_1;
atn$2.LexerATNSimulator = LexerATNSimulator_1;
atn$2.ParserATNSimulator = ParserATNSimulator_1;
atn$2.PredictionMode = PredictionMode_1;

var codepointat = {};

/*! https://mths.be/codepointat v0.2.0 by @mathias */

if (!String.prototype.codePointAt) {
	(function() {
		var defineProperty = (function() {
			// IE 8 only supports `Object.defineProperty` on DOM elements
			let result;
			try {
				const object = {};
				const $defineProperty = Object.defineProperty;
				result = $defineProperty(object, object, object) && $defineProperty;
			} catch(error) {
			}
			return result;
		}());
		const codePointAt = function(position) {
			if (this == null) {
				throw TypeError();
			}
			const string = String(this);
			const size = string.length;
			// `ToInteger`
			let index = position ? Number(position) : 0;
			if (index !== index) { // better `isNaN`
				index = 0;
			}
			// Account for out-of-bounds indices:
			if (index < 0 || index >= size) {
				return undefined;
			}
			// Get the first code unit
			const first = string.charCodeAt(index);
			let second;
			if ( // check if its the start of a surrogate pair
				first >= 0xD800 && first <= 0xDBFF && // high surrogate
				size > index + 1 // there is a next code unit
			) {
				second = string.charCodeAt(index + 1);
				if (second >= 0xDC00 && second <= 0xDFFF) { // low surrogate
					// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae
					return (first - 0xD800) * 0x400 + second - 0xDC00 + 0x10000;
				}
			}
			return first;
		};
		if (defineProperty) {
			defineProperty(String.prototype, 'codePointAt', {
				'value': codePointAt,
				'configurable': true,
				'writable': true
			});
		} else {
			String.prototype.codePointAt = codePointAt;
		}
	}());
}

var dfa = {};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const Utils = Utils$4;

/**
 * A DFA walker that knows how to dump them to serialized strings.
 */
let DFASerializer$1 = class DFASerializer {
    constructor(dfa, literalNames, symbolicNames) {
        this.dfa = dfa;
        this.literalNames = literalNames || [];
        this.symbolicNames = symbolicNames || [];
    }

    toString() {
       if(this.dfa.s0 === null) {
           return null;
       }
       let buf = "";
       const states = this.dfa.sortedStates();
       for(let i=0; i<states.length; i++) {
           const s = states[i];
           if(s.edges!==null) {
                const n = s.edges.length;
                for(let j=0;j<n;j++) {
                    const t = s.edges[j] || null;
                    if(t!==null && t.stateNumber !== 0x7FFFFFFF) {
                        buf = buf.concat(this.getStateString(s));
                        buf = buf.concat("-");
                        buf = buf.concat(this.getEdgeLabel(j));
                        buf = buf.concat("->");
                        buf = buf.concat(this.getStateString(t));
                        buf = buf.concat('\n');
                    }
                }
           }
       }
       return buf.length===0 ? null : buf;
    }

    getEdgeLabel(i) {
        if (i===0) {
            return "EOF";
        } else if(this.literalNames !==null || this.symbolicNames!==null) {
            return this.literalNames[i-1] || this.symbolicNames[i-1];
        } else {
            return String.fromCharCode(i-1);
        }
    }

    getStateString(s) {
        const baseStateStr = ( s.isAcceptState ? ":" : "") + "s" + s.stateNumber + ( s.requiresFullContext ? "^" : "");
        if(s.isAcceptState) {
            if (s.predicates !== null) {
                return baseStateStr + "=>" + Utils.arrayToString(s.predicates);
            } else {
                return baseStateStr + "=>" + s.prediction.toString();
            }
        } else {
            return baseStateStr;
        }
    }
};

let LexerDFASerializer$1 = class LexerDFASerializer extends DFASerializer$1 {
    constructor(dfa) {
        super(dfa, null);
    }

    getEdgeLabel(i) {
        return "'" + String.fromCharCode(i) + "'";
    }
};

var DFASerializer_1 = { DFASerializer: DFASerializer$1 , LexerDFASerializer: LexerDFASerializer$1 };

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Set: Set$1} = Utils$4;
const {DFAState} = DFAState_1;
const {StarLoopEntryState} = ATNState_1;
const {ATNConfigSet} = ATNConfigSet_1;
const {DFASerializer} = DFASerializer_1;
const {LexerDFASerializer} = DFASerializer_1;

class DFA {
	constructor(atnStartState, decision) {
		if (decision === undefined) {
			decision = 0;
		}
		/**
		 * From which ATN state did we create this DFA?
		 */
		this.atnStartState = atnStartState;
		this.decision = decision;
		/**
		 * A set of all DFA states. Use {@link Map} so we can get old state back
		 * ({@link Set} only allows you to see if it's there).
		 */
		this._states = new Set$1();
		this.s0 = null;
		/**
		 * {@code true} if this DFA is for a precedence decision; otherwise,
		 * {@code false}. This is the backing field for {@link //isPrecedenceDfa},
		 * {@link //setPrecedenceDfa}
		 */
		this.precedenceDfa = false;
		if (atnStartState instanceof StarLoopEntryState)
		{
			if (atnStartState.isPrecedenceDecision) {
				this.precedenceDfa = true;
				const precedenceState = new DFAState(null, new ATNConfigSet());
				precedenceState.edges = [];
				precedenceState.isAcceptState = false;
				precedenceState.requiresFullContext = false;
				this.s0 = precedenceState;
			}
		}
	}

	/**
	 * Get the start state for a specific precedence value.
	 *
	 * @param precedence The current precedence.
	 * @return The start state corresponding to the specified precedence, or
	 * {@code null} if no start state exists for the specified precedence.
	 *
	 * @throws IllegalStateException if this is not a precedence DFA.
	 * @see //isPrecedenceDfa()
	 */
	getPrecedenceStartState(precedence) {
		if (!(this.precedenceDfa)) {
			throw ("Only precedence DFAs may contain a precedence start state.");
		}
		// s0.edges is never null for a precedence DFA
		if (precedence < 0 || precedence >= this.s0.edges.length) {
			return null;
		}
		return this.s0.edges[precedence] || null;
	}

	/**
	 * Set the start state for a specific precedence value.
	 *
	 * @param precedence The current precedence.
	 * @param startState The start state corresponding to the specified
	 * precedence.
	 *
	 * @throws IllegalStateException if this is not a precedence DFA.
	 * @see //isPrecedenceDfa()
	 */
	setPrecedenceStartState(precedence, startState) {
		if (!(this.precedenceDfa)) {
			throw ("Only precedence DFAs may contain a precedence start state.");
		}
		if (precedence < 0) {
			return;
		}

		/**
		 * synchronization on s0 here is ok. when the DFA is turned into a
		 * precedence DFA, s0 will be initialized once and not updated again
		 * s0.edges is never null for a precedence DFA
		 */
		this.s0.edges[precedence] = startState;
	}

	/**
	 * Sets whether this is a precedence DFA. If the specified value differs
	 * from the current DFA configuration, the following actions are taken;
	 * otherwise no changes are made to the current DFA.
	 *
	 * <ul>
	 * <li>The {@link //states} map is cleared</li>
	 * <li>If {@code precedenceDfa} is {@code false}, the initial state
	 * {@link //s0} is set to {@code null}; otherwise, it is initialized to a new
	 * {@link DFAState} with an empty outgoing {@link DFAState//edges} array to
	 * store the start states for individual precedence values.</li>
	 * <li>The {@link //precedenceDfa} field is updated</li>
	 * </ul>
	 *
	 * @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,
	 * {@code false}
	 */
	setPrecedenceDfa(precedenceDfa) {
		if (this.precedenceDfa!==precedenceDfa) {
			this._states = new Set$1();
			if (precedenceDfa) {
				const precedenceState = new DFAState(null, new ATNConfigSet());
				precedenceState.edges = [];
				precedenceState.isAcceptState = false;
				precedenceState.requiresFullContext = false;
				this.s0 = precedenceState;
			} else {
				this.s0 = null;
			}
			this.precedenceDfa = precedenceDfa;
		}
	}

	/**
	 * Return a list of all states in this DFA, ordered by state number.
	 */
	sortedStates() {
		const list = this._states.values();
		return list.sort(function(a, b) {
			return a.stateNumber - b.stateNumber;
		});
	}

	toString(literalNames, symbolicNames) {
		literalNames = literalNames || null;
		symbolicNames = symbolicNames || null;
		if (this.s0 === null) {
			return "";
		}
		const serializer = new DFASerializer(this, literalNames, symbolicNames);
		return serializer.toString();
	}

	toLexerString() {
		if (this.s0 === null) {
			return "";
		}
		const serializer = new LexerDFASerializer(this);
		return serializer.toString();
	}

	get states(){
		return this._states;
	}
}


var DFA_1 = DFA;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

dfa.DFA = DFA_1;
dfa.DFASerializer = DFASerializer_1.DFASerializer;
dfa.LexerDFASerializer = DFASerializer_1.LexerDFASerializer;
dfa.PredPrediction = DFAState_1.PredPrediction;

var fromcodepoint = {};

/*! https://mths.be/fromcodepoint v0.2.1 by @mathias */

if (!String.fromCodePoint) {
	(function() {
		const defineProperty = (function() {
			// IE 8 only supports `Object.defineProperty` on DOM elements
			let result;
			try {
				const object = {};
				const $defineProperty = Object.defineProperty;
				result = $defineProperty(object, object, object) && $defineProperty;
			} catch(error) {}
			return result;
		}());
		const stringFromCharCode = String.fromCharCode;
		const floor = Math.floor;
		const fromCodePoint = function(_) {
			const MAX_SIZE = 0x4000;
			const codeUnits = [];
			let highSurrogate;
			let lowSurrogate;
			let index = -1;
			const length = arguments.length;
			if (!length) {
				return '';
			}
			let result = '';
			while (++index < length) {
				let codePoint = Number(arguments[index]);
				if (
					!isFinite(codePoint) || // `NaN`, `+Infinity`, or `-Infinity`
					codePoint < 0 || // not a valid Unicode code point
					codePoint > 0x10FFFF || // not a valid Unicode code point
					floor(codePoint) !== codePoint // not an integer
				) {
					throw RangeError('Invalid code point: ' + codePoint);
				}
				if (codePoint <= 0xFFFF) { // BMP code point
					codeUnits.push(codePoint);
				} else { // Astral code point; split in surrogate halves
					// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae
					codePoint -= 0x10000;
					highSurrogate = (codePoint >> 10) + 0xD800;
					lowSurrogate = (codePoint % 0x400) + 0xDC00;
					codeUnits.push(highSurrogate, lowSurrogate);
				}
				if (index + 1 === length || codeUnits.length > MAX_SIZE) {
					result += stringFromCharCode.apply(null, codeUnits);
					codeUnits.length = 0;
				}
			}
			return result;
		};
		if (defineProperty) {
			defineProperty(String, 'fromCodePoint', {
				'value': fromCodePoint,
				'configurable': true,
				'writable': true
			});
		} else {
			String.fromCodePoint = fromCodePoint;
		}
	}());
}

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const Tree = Tree_1;
const Trees = Trees_1;
var tree = {...Tree, Trees};

var error = {};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {BitSet} = Utils$4;
const {ErrorListener: ErrorListener$1} = ErrorListener_1;
const {Interval: Interval$2} = IntervalSet_1;


/**
 * This implementation of {@link ANTLRErrorListener} can be used to identify
 *  certain potential correctness and performance problems in grammars. "Reports"
 *  are made by calling {@link Parser//notifyErrorListeners} with the appropriate
 *  message.
 *
 *  <ul>
 *  <li><b>Ambiguities</b>: These are cases where more than one path through the
 *  grammar can match the input.</li>
 *  <li><b>Weak context sensitivity</b>: These are cases where full-context
 *  prediction resolved an SLL conflict to a unique alternative which equaled the
 *  minimum alternative of the SLL conflict.</li>
 *  <li><b>Strong (forced) context sensitivity</b>: These are cases where the
 *  full-context prediction resolved an SLL conflict to a unique alternative,
 *  <em>and</em> the minimum alternative of the SLL conflict was found to not be
 *  a truly viable alternative. Two-stage parsing cannot be used for inputs where
 *  this situation occurs.</li>
 *  </ul>
 */
class DiagnosticErrorListener extends ErrorListener$1 {
	constructor(exactOnly) {
		super();
		exactOnly = exactOnly || true;
		// whether all ambiguities or only exact ambiguities are reported.
		this.exactOnly = exactOnly;
	}

	reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {
		if (this.exactOnly && !exact) {
			return;
		}
		const msg = "reportAmbiguity d=" +
			this.getDecisionDescription(recognizer, dfa) +
			": ambigAlts=" +
			this.getConflictingAlts(ambigAlts, configs) +
			", input='" +
			recognizer.getTokenStream().getText(new Interval$2(startIndex, stopIndex)) + "'";
		recognizer.notifyErrorListeners(msg);
	}

	reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {
		const msg = "reportAttemptingFullContext d=" +
			this.getDecisionDescription(recognizer, dfa) +
			", input='" +
			recognizer.getTokenStream().getText(new Interval$2(startIndex, stopIndex)) + "'";
		recognizer.notifyErrorListeners(msg);
	}

	reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {
		const msg = "reportContextSensitivity d=" +
			this.getDecisionDescription(recognizer, dfa) +
			", input='" +
			recognizer.getTokenStream().getText(new Interval$2(startIndex, stopIndex)) + "'";
		recognizer.notifyErrorListeners(msg);
	}

	getDecisionDescription(recognizer, dfa) {
		const decision = dfa.decision;
		const ruleIndex = dfa.atnStartState.ruleIndex;

		const ruleNames = recognizer.ruleNames;
		if (ruleIndex < 0 || ruleIndex >= ruleNames.length) {
			return "" + decision;
		}
		const ruleName = ruleNames[ruleIndex] || null;
		if (ruleName === null || ruleName.length === 0) {
			return "" + decision;
		}
		return `${decision} (${ruleName})`;
	}

	/**
	 * Computes the set of conflicting or ambiguous alternatives from a
	 * configuration set, if that information was not already provided by the
	 * parser.
	 *
	 * @param reportedAlts The set of conflicting or ambiguous alternatives, as
	 * reported by the parser.
	 * @param configs The conflicting or ambiguous configuration set.
	 * @return Returns {@code reportedAlts} if it is not {@code null}, otherwise
	 * returns the set of alternatives represented in {@code configs}.
     */
	getConflictingAlts(reportedAlts, configs) {
		if (reportedAlts !== null) {
			return reportedAlts;
		}
		const result = new BitSet();
		for (let i = 0; i < configs.items.length; i++) {
			result.add(configs.items[i].alt);
		}
		return `{${result.values().join(", ")}}`;
	}
}

var DiagnosticErrorListener_1 = DiagnosticErrorListener;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Token: Token$4} = Token_1;
const {NoViableAltException, InputMismatchException, FailedPredicateException, ParseCancellationException} = Errors;
const {ATNState} = ATNState_1;
const {Interval: Interval$1, IntervalSet} = IntervalSet_1;

class ErrorStrategy {

    reset(recognizer) {
    }

    recoverInline(recognizer) {
    }

    recover(recognizer, e) {
    }

    sync(recognizer) {
    }

    inErrorRecoveryMode(recognizer) {
    }

    reportError(recognizer) {
    }
}


/**
 * This is the default implementation of {@link ANTLRErrorStrategy} used for
 * error reporting and recovery in ANTLR parsers.
*/
let DefaultErrorStrategy$1 = class DefaultErrorStrategy extends ErrorStrategy {
    constructor() {
        super();
        /**
         * Indicates whether the error strategy is currently "recovering from an
         * error". This is used to suppress reporting multiple error messages while
         * attempting to recover from a detected syntax error.
         *
         * @see //inErrorRecoveryMode
         */
        this.errorRecoveryMode = false;

        /**
         * The index into the input stream where the last error occurred.
         * This is used to prevent infinite loops where an error is found
         * but no token is consumed during recovery...another error is found,
         * ad nauseum. This is a failsafe mechanism to guarantee that at least
         * one token/tree node is consumed for two errors.
         */
        this.lastErrorIndex = -1;
        this.lastErrorStates = null;
        this.nextTokensContext = null;
        this.nextTokenState = 0;
    }

    /**
     * <p>The default implementation simply calls {@link //endErrorCondition} to
     * ensure that the handler is not in error recovery mode.</p>
    */
    reset(recognizer) {
        this.endErrorCondition(recognizer);
    }

    /**
     * This method is called to enter error recovery mode when a recognition
     * exception is reported.
     *
     * @param recognizer the parser instance
    */
    beginErrorCondition(recognizer) {
        this.errorRecoveryMode = true;
    }

    inErrorRecoveryMode(recognizer) {
        return this.errorRecoveryMode;
    }

    /**
     * This method is called to leave error recovery mode after recovering from
     * a recognition exception.
     * @param recognizer
     */
    endErrorCondition(recognizer) {
        this.errorRecoveryMode = false;
        this.lastErrorStates = null;
        this.lastErrorIndex = -1;
    }

    /**
     * {@inheritDoc}
     * <p>The default implementation simply calls {@link //endErrorCondition}.</p>
     */
    reportMatch(recognizer) {
        this.endErrorCondition(recognizer);
    }

    /**
     * {@inheritDoc}
     *
     * <p>The default implementation returns immediately if the handler is already
     * in error recovery mode. Otherwise, it calls {@link //beginErrorCondition}
     * and dispatches the reporting task based on the runtime type of {@code e}
     * according to the following table.</p>
     *
     * <ul>
     * <li>{@link NoViableAltException}: Dispatches the call to
     * {@link //reportNoViableAlternative}</li>
     * <li>{@link InputMismatchException}: Dispatches the call to
     * {@link //reportInputMismatch}</li>
     * <li>{@link FailedPredicateException}: Dispatches the call to
     * {@link //reportFailedPredicate}</li>
     * <li>All other types: calls {@link Parser//notifyErrorListeners} to report
     * the exception</li>
     * </ul>
     */
    reportError(recognizer, e) {
       // if we've already reported an error and have not matched a token
       // yet successfully, don't report any errors.
        if(this.inErrorRecoveryMode(recognizer)) {
            return; // don't report spurious errors
        }
        this.beginErrorCondition(recognizer);
        if ( e instanceof NoViableAltException ) {
            this.reportNoViableAlternative(recognizer, e);
        } else if ( e instanceof InputMismatchException ) {
            this.reportInputMismatch(recognizer, e);
        } else if ( e instanceof FailedPredicateException ) {
            this.reportFailedPredicate(recognizer, e);
        } else {
            console.log("unknown recognition error type: " + e.constructor.name);
            console.log(e.stack);
            recognizer.notifyErrorListeners(e.getOffendingToken(), e.getMessage(), e);
        }
    }

    /**
     *
     * {@inheritDoc}
     *
     * <p>The default implementation resynchronizes the parser by consuming tokens
     * until we find one in the resynchronization set--loosely the set of tokens
     * that can follow the current rule.</p>
     *
     */
    recover(recognizer, e) {
        if (this.lastErrorIndex===recognizer.getInputStream().index &&
            this.lastErrorStates !== null && this.lastErrorStates.indexOf(recognizer.state)>=0) {
            // uh oh, another error at same token index and previously-visited
            // state in ATN; must be a case where LT(1) is in the recovery
            // token set so nothing got consumed. Consume a single token
            // at least to prevent an infinite loop; this is a failsafe.
            recognizer.consume();
        }
        this.lastErrorIndex = recognizer._input.index;
        if (this.lastErrorStates === null) {
            this.lastErrorStates = [];
        }
        this.lastErrorStates.push(recognizer.state);
        const followSet = this.getErrorRecoverySet(recognizer);
        this.consumeUntil(recognizer, followSet);
    }

    /**
     * The default implementation of {@link ANTLRErrorStrategy//sync} makes sure
     * that the current lookahead symbol is consistent with what were expecting
     * at this point in the ATN. You can call this anytime but ANTLR only
     * generates code to check before subrules/loops and each iteration.
     *
     * <p>Implements Jim Idle's magic sync mechanism in closures and optional
     * subrules. E.g.,</p>
     *
     * <pre>
     * a : sync ( stuff sync )* ;
     * sync : {consume to what can follow sync} ;
     * </pre>
     *
     * At the start of a sub rule upon error, {@link //sync} performs single
     * token deletion, if possible. If it can't do that, it bails on the current
     * rule and uses the default error recovery, which consumes until the
     * resynchronization set of the current rule.
     *
     * <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block
     * with an empty alternative), then the expected set includes what follows
     * the subrule.</p>
     *
     * <p>During loop iteration, it consumes until it sees a token that can start a
     * sub rule or what follows loop. Yes, that is pretty aggressive. We opt to
     * stay in the loop as long as possible.</p>
     *
     * <p><strong>ORIGINS</strong></p>
     *
     * <p>Previous versions of ANTLR did a poor job of their recovery within loops.
     * A single mismatch token or missing token would force the parser to bail
     * out of the entire rules surrounding the loop. So, for rule</p>
     *
     * <pre>
     * classDef : 'class' ID '{' member* '}'
     * </pre>
     *
     * input with an extra token between members would force the parser to
     * consume until it found the next class definition rather than the next
     * member definition of the current class.
     *
     * <p>This functionality cost a little bit of effort because the parser has to
     * compare token set at the start of the loop and at each iteration. If for
     * some reason speed is suffering for you, you can turn off this
     * functionality by simply overriding this method as a blank { }.</p>
     *
     */
    sync(recognizer) {
        // If already recovering, don't try to sync
        if (this.inErrorRecoveryMode(recognizer)) {
            return;
        }
        const s = recognizer._interp.atn.states[recognizer.state];
        const la = recognizer.getTokenStream().LA(1);
        // try cheaper subset first; might get lucky. seems to shave a wee bit off
        const nextTokens = recognizer.atn.nextTokens(s);
        if(nextTokens.contains(la)) {
            this.nextTokensContext = null;
            this.nextTokenState = ATNState.INVALID_STATE_NUMBER;
            return;
        } else if (nextTokens.contains(Token$4.EPSILON)) {
            if(this.nextTokensContext === null) {
                // It's possible the next token won't match information tracked
                // by sync is restricted for performance.
                this.nextTokensContext = recognizer._ctx;
                this.nextTokensState = recognizer._stateNumber;
            }
            return;
        }
        switch (s.stateType) {
        case ATNState.BLOCK_START:
        case ATNState.STAR_BLOCK_START:
        case ATNState.PLUS_BLOCK_START:
        case ATNState.STAR_LOOP_ENTRY:
           // report error and recover if possible
            if( this.singleTokenDeletion(recognizer) !== null) {
                return;
            } else {
                throw new InputMismatchException(recognizer);
            }
        case ATNState.PLUS_LOOP_BACK:
        case ATNState.STAR_LOOP_BACK:
            this.reportUnwantedToken(recognizer);
            const expecting = new IntervalSet();
            expecting.addSet(recognizer.getExpectedTokens());
            const whatFollowsLoopIterationOrRule = expecting.addSet(this.getErrorRecoverySet(recognizer));
            this.consumeUntil(recognizer, whatFollowsLoopIterationOrRule);
            break;
            // do nothing if we can't identify the exact kind of ATN state
        }
    }

    /**
     * This is called by {@link //reportError} when the exception is a
     * {@link NoViableAltException}.
     *
     * @see //reportError
     *
     * @param recognizer the parser instance
     * @param e the recognition exception
     */
    reportNoViableAlternative(recognizer, e) {
        const tokens = recognizer.getTokenStream();
        let input;
        if(tokens !== null) {
            if (e.startToken.type===Token$4.EOF) {
                input = "<EOF>";
            } else {
                input = tokens.getText(new Interval$1(e.startToken.tokenIndex, e.offendingToken.tokenIndex));
            }
        } else {
            input = "<unknown input>";
        }
        const msg = "no viable alternative at input " + this.escapeWSAndQuote(input);
        recognizer.notifyErrorListeners(msg, e.offendingToken, e);
    }

    /**
     * This is called by {@link //reportError} when the exception is an
     * {@link InputMismatchException}.
     *
     * @see //reportError
     *
     * @param recognizer the parser instance
     * @param e the recognition exception
     */
    reportInputMismatch(recognizer, e) {
        const msg = "mismatched input " + this.getTokenErrorDisplay(e.offendingToken) +
            " expecting " + e.getExpectedTokens().toString(recognizer.literalNames, recognizer.symbolicNames);
        recognizer.notifyErrorListeners(msg, e.offendingToken, e);
    }

    /**
     * This is called by {@link //reportError} when the exception is a
     * {@link FailedPredicateException}.
     *
     * @see //reportError
     *
     * @param recognizer the parser instance
     * @param e the recognition exception
     */
    reportFailedPredicate(recognizer, e) {
        const ruleName = recognizer.ruleNames[recognizer._ctx.ruleIndex];
        const msg = "rule " + ruleName + " " + e.message;
        recognizer.notifyErrorListeners(msg, e.offendingToken, e);
    }

    /**
     * This method is called to report a syntax error which requires the removal
     * of a token from the input stream. At the time this method is called, the
     * erroneous symbol is current {@code LT(1)} symbol and has not yet been
     * removed from the input stream. When this method returns,
     * {@code recognizer} is in error recovery mode.
     *
     * <p>This method is called when {@link //singleTokenDeletion} identifies
     * single-token deletion as a viable recovery strategy for a mismatched
     * input error.</p>
     *
     * <p>The default implementation simply returns if the handler is already in
     * error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to
     * enter error recovery mode, followed by calling
     * {@link Parser//notifyErrorListeners}.</p>
     *
     * @param recognizer the parser instance
     *
     */
    reportUnwantedToken(recognizer) {
        if (this.inErrorRecoveryMode(recognizer)) {
            return;
        }
        this.beginErrorCondition(recognizer);
        const t = recognizer.getCurrentToken();
        const tokenName = this.getTokenErrorDisplay(t);
        const expecting = this.getExpectedTokens(recognizer);
        const msg = "extraneous input " + tokenName + " expecting " +
            expecting.toString(recognizer.literalNames, recognizer.symbolicNames);
        recognizer.notifyErrorListeners(msg, t, null);
    }

    /**
     * This method is called to report a syntax error which requires the
     * insertion of a missing token into the input stream. At the time this
     * method is called, the missing token has not yet been inserted. When this
     * method returns, {@code recognizer} is in error recovery mode.
     *
     * <p>This method is called when {@link //singleTokenInsertion} identifies
     * single-token insertion as a viable recovery strategy for a mismatched
     * input error.</p>
     *
     * <p>The default implementation simply returns if the handler is already in
     * error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to
     * enter error recovery mode, followed by calling
     * {@link Parser//notifyErrorListeners}.</p>
     *
     * @param recognizer the parser instance
     */
    reportMissingToken(recognizer) {
        if ( this.inErrorRecoveryMode(recognizer)) {
            return;
        }
        this.beginErrorCondition(recognizer);
        const t = recognizer.getCurrentToken();
        const expecting = this.getExpectedTokens(recognizer);
        const msg = "missing " + expecting.toString(recognizer.literalNames, recognizer.symbolicNames) +
            " at " + this.getTokenErrorDisplay(t);
        recognizer.notifyErrorListeners(msg, t, null);
    }

    /**
     * <p>The default implementation attempts to recover from the mismatched input
     * by using single token insertion and deletion as described below. If the
     * recovery attempt fails, this method throws an
     * {@link InputMismatchException}.</p>
     *
     * <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>
     *
     * <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the
     * right token, however, then assume {@code LA(1)} is some extra spurious
     * token and delete it. Then consume and return the next token (which was
     * the {@code LA(2)} token) as the successful result of the match operation.</p>
     *
     * <p>This recovery strategy is implemented by {@link
     * //singleTokenDeletion}.</p>
     *
     * <p><strong>MISSING TOKEN</strong> (single token insertion)</p>
     *
     * <p>If current token (at {@code LA(1)}) is consistent with what could come
     * after the expected {@code LA(1)} token, then assume the token is missing
     * and use the parser's {@link TokenFactory} to create it on the fly. The
     * "insertion" is performed by returning the created token as the successful
     * result of the match operation.</p>
     *
     * <p>This recovery strategy is implemented by {@link
     * //singleTokenInsertion}.</p>
     *
     * <p><strong>EXAMPLE</strong></p>
     *
     * <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When
     * the parser returns from the nested call to {@code expr}, it will have
     * call chain:</p>
     *
     * <pre>
     * stat &rarr; expr &rarr; atom
     * </pre>
     *
     * and it will be trying to match the {@code ')'} at this point in the
     * derivation:
     *
     * <pre>
     * =&gt; ID '=' '(' INT ')' ('+' atom)* ';'
     * ^
     * </pre>
     *
     * The attempt to match {@code ')'} will fail when it sees {@code ';'} and
     * call {@link //recoverInline}. To recover, it sees that {@code LA(1)==';'}
     * is in the set of tokens that can follow the {@code ')'} token reference
     * in rule {@code atom}. It can assume that you forgot the {@code ')'}.
     */
    recoverInline(recognizer) {
        // SINGLE TOKEN DELETION
        const matchedSymbol = this.singleTokenDeletion(recognizer);
        if (matchedSymbol !== null) {
            // we have deleted the extra token.
            // now, move past ttype token as if all were ok
            recognizer.consume();
            return matchedSymbol;
        }
        // SINGLE TOKEN INSERTION
        if (this.singleTokenInsertion(recognizer)) {
            return this.getMissingSymbol(recognizer);
        }
        // even that didn't work; must throw the exception
        throw new InputMismatchException(recognizer);
    }

    /**
     * This method implements the single-token insertion inline error recovery
     * strategy. It is called by {@link //recoverInline} if the single-token
     * deletion strategy fails to recover from the mismatched input. If this
     * method returns {@code true}, {@code recognizer} will be in error recovery
     * mode.
     *
     * <p>This method determines whether or not single-token insertion is viable by
     * checking if the {@code LA(1)} input symbol could be successfully matched
     * if it were instead the {@code LA(2)} symbol. If this method returns
     * {@code true}, the caller is responsible for creating and inserting a
     * token with the correct type to produce this behavior.</p>
     *
     * @param recognizer the parser instance
     * @return {@code true} if single-token insertion is a viable recovery
     * strategy for the current mismatched input, otherwise {@code false}
     */
    singleTokenInsertion(recognizer) {
        const currentSymbolType = recognizer.getTokenStream().LA(1);
        // if current token is consistent with what could come after current
        // ATN state, then we know we're missing a token; error recovery
        // is free to conjure up and insert the missing token
        const atn = recognizer._interp.atn;
        const currentState = atn.states[recognizer.state];
        const next = currentState.transitions[0].target;
        const expectingAtLL2 = atn.nextTokens(next, recognizer._ctx);
        if (expectingAtLL2.contains(currentSymbolType) ){
            this.reportMissingToken(recognizer);
            return true;
        } else {
            return false;
        }
    }

    /**
     * This method implements the single-token deletion inline error recovery
     * strategy. It is called by {@link //recoverInline} to attempt to recover
     * from mismatched input. If this method returns null, the parser and error
     * handler state will not have changed. If this method returns non-null,
     * {@code recognizer} will <em>not</em> be in error recovery mode since the
     * returned token was a successful match.
     *
     * <p>If the single-token deletion is successful, this method calls
     * {@link //reportUnwantedToken} to report the error, followed by
     * {@link Parser//consume} to actually "delete" the extraneous token. Then,
     * before returning {@link //reportMatch} is called to signal a successful
     * match.</p>
     *
     * @param recognizer the parser instance
     * @return the successfully matched {@link Token} instance if single-token
     * deletion successfully recovers from the mismatched input, otherwise
     * {@code null}
     */
    singleTokenDeletion(recognizer) {
        const nextTokenType = recognizer.getTokenStream().LA(2);
        const expecting = this.getExpectedTokens(recognizer);
        if (expecting.contains(nextTokenType)) {
            this.reportUnwantedToken(recognizer);
            // print("recoverFromMismatchedToken deleting " \
            // + str(recognizer.getTokenStream().LT(1)) \
            // + " since " + str(recognizer.getTokenStream().LT(2)) \
            // + " is what we want", file=sys.stderr)
            recognizer.consume(); // simply delete extra token
            // we want to return the token we're actually matching
            const matchedSymbol = recognizer.getCurrentToken();
            this.reportMatch(recognizer); // we know current token is correct
            return matchedSymbol;
        } else {
            return null;
        }
    }

    /**
     * Conjure up a missing token during error recovery.
     *
     * The recognizer attempts to recover from single missing
     * symbols. But, actions might refer to that missing symbol.
     * For example, x=ID {f($x);}. The action clearly assumes
     * that there has been an identifier matched previously and that
     * $x points at that token. If that token is missing, but
     * the next token in the stream is what we want we assume that
     * this token is missing and we keep going. Because we
     * have to return some token to replace the missing token,
     * we have to conjure one up. This method gives the user control
     * over the tokens returned for missing tokens. Mostly,
     * you will want to create something special for identifier
     * tokens. For literals such as '{' and ',', the default
     * action in the parser or tree parser works. It simply creates
     * a CommonToken of the appropriate type. The text will be the token.
     * If you change what tokens must be created by the lexer,
     * override this method to create the appropriate tokens.
     *
     */
    getMissingSymbol(recognizer) {
        const currentSymbol = recognizer.getCurrentToken();
        const expecting = this.getExpectedTokens(recognizer);
        const expectedTokenType = expecting.first(); // get any element
        let tokenText;
        if (expectedTokenType===Token$4.EOF) {
            tokenText = "<missing EOF>";
        } else {
            tokenText = "<missing " + recognizer.literalNames[expectedTokenType] + ">";
        }
        let current = currentSymbol;
        const lookback = recognizer.getTokenStream().LT(-1);
        if (current.type===Token$4.EOF && lookback !== null) {
            current = lookback;
        }
        return recognizer.getTokenFactory().create(current.source,
            expectedTokenType, tokenText, Token$4.DEFAULT_CHANNEL,
            -1, -1, current.line, current.column);
    }

    getExpectedTokens(recognizer) {
        return recognizer.getExpectedTokens();
    }

    /**
     * How should a token be displayed in an error message? The default
     * is to display just the text, but during development you might
     * want to have a lot of information spit out. Override in that case
     * to use t.toString() (which, for CommonToken, dumps everything about
     * the token). This is better than forcing you to override a method in
     * your token objects because you don't have to go modify your lexer
     * so that it creates a new Java type.
     */
    getTokenErrorDisplay(t) {
        if (t === null) {
            return "<no token>";
        }
        let s = t.text;
        if (s === null) {
            if (t.type===Token$4.EOF) {
                s = "<EOF>";
            } else {
                s = "<" + t.type + ">";
            }
        }
        return this.escapeWSAndQuote(s);
    }

    escapeWSAndQuote(s) {
        s = s.replace(/\n/g,"\\n");
        s = s.replace(/\r/g,"\\r");
        s = s.replace(/\t/g,"\\t");
        return "'" + s + "'";
    }

    /**
     * Compute the error recovery set for the current rule. During
     * rule invocation, the parser pushes the set of tokens that can
     * follow that rule reference on the stack; this amounts to
     * computing FIRST of what follows the rule reference in the
     * enclosing rule. See LinearApproximator.FIRST().
     * This local follow set only includes tokens
     * from within the rule; i.e., the FIRST computation done by
     * ANTLR stops at the end of a rule.
     *
     * EXAMPLE
     *
     * When you find a "no viable alt exception", the input is not
     * consistent with any of the alternatives for rule r. The best
     * thing to do is to consume tokens until you see something that
     * can legally follow a call to r//or* any rule that called r.
     * You don't want the exact set of viable next tokens because the
     * input might just be missing a token--you might consume the
     * rest of the input looking for one of the missing tokens.
     *
     * Consider grammar:
     *
     * a : '[' b ']'
     * | '(' b ')'
     * ;
     * b : c '^' INT ;
     * c : ID
     * | INT
     * ;
     *
     * At each rule invocation, the set of tokens that could follow
     * that rule is pushed on a stack. Here are the various
     * context-sensitive follow sets:
     *
     * FOLLOW(b1_in_a) = FIRST(']') = ']'
     * FOLLOW(b2_in_a) = FIRST(')') = ')'
     * FOLLOW(c_in_b) = FIRST('^') = '^'
     *
     * Upon erroneous input "[]", the call chain is
     *
     * a -> b -> c
     *
     * and, hence, the follow context stack is:
     *
     * depth follow set start of rule execution
     * 0 <EOF> a (from main())
     * 1 ']' b
     * 2 '^' c
     *
     * Notice that ')' is not included, because b would have to have
     * been called from a different context in rule a for ')' to be
     * included.
     *
     * For error recovery, we cannot consider FOLLOW(c)
     * (context-sensitive or otherwise). We need the combined set of
     * all context-sensitive FOLLOW sets--the set of all tokens that
     * could follow any reference in the call chain. We need to
     * resync to one of those tokens. Note that FOLLOW(c)='^' and if
     * we resync'd to that token, we'd consume until EOF. We need to
     * sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.
     * In this case, for input "[]", LA(1) is ']' and in the set, so we would
     * not consume anything. After printing an error, rule c would
     * return normally. Rule b would not find the required '^' though.
     * At this point, it gets a mismatched token error and throws an
     * exception (since LA(1) is not in the viable following token
     * set). The rule exception handler tries to recover, but finds
     * the same recovery set and doesn't consume anything. Rule b
     * exits normally returning to rule a. Now it finds the ']' (and
     * with the successful match exits errorRecovery mode).
     *
     * So, you can see that the parser walks up the call chain looking
     * for the token that was a member of the recovery set.
     *
     * Errors are not generated in errorRecovery mode.
     *
     * ANTLR's error recovery mechanism is based upon original ideas:
     *
     * "Algorithms + Data Structures = Programs" by Niklaus Wirth
     *
     * and
     *
     * "A note on error recovery in recursive descent parsers":
     * http://portal.acm.org/citation.cfm?id=947902.947905
     *
     * Later, Josef Grosch had some good ideas:
     *
     * "Efficient and Comfortable Error Recovery in Recursive Descent
     * Parsers":
     * ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip
     *
     * Like Grosch I implement context-sensitive FOLLOW sets that are combined
     * at run-time upon error to avoid overhead during parsing.
     */
    getErrorRecoverySet(recognizer) {
        const atn = recognizer._interp.atn;
        let ctx = recognizer._ctx;
        const recoverSet = new IntervalSet();
        while (ctx !== null && ctx.invokingState>=0) {
            // compute what follows who invoked us
            const invokingState = atn.states[ctx.invokingState];
            const rt = invokingState.transitions[0];
            const follow = atn.nextTokens(rt.followState);
            recoverSet.addSet(follow);
            ctx = ctx.parentCtx;
        }
        recoverSet.removeOne(Token$4.EPSILON);
        return recoverSet;
    }

// Consume tokens until one matches the given token set.//
    consumeUntil(recognizer, set) {
        let ttype = recognizer.getTokenStream().LA(1);
        while( ttype !== Token$4.EOF && !set.contains(ttype)) {
            recognizer.consume();
            ttype = recognizer.getTokenStream().LA(1);
        }
    }
};


/**
 * This implementation of {@link ANTLRErrorStrategy} responds to syntax errors
 * by immediately canceling the parse operation with a
 * {@link ParseCancellationException}. The implementation ensures that the
 * {@link ParserRuleContext//exception} field is set for all parse tree nodes
 * that were not completed prior to encountering the error.
 *
 * <p>
 * This error strategy is useful in the following scenarios.</p>
 *
 * <ul>
 * <li><strong>Two-stage parsing:</strong> This error strategy allows the first
 * stage of two-stage parsing to immediately terminate if an error is
 * encountered, and immediately fall back to the second stage. In addition to
 * avoiding wasted work by attempting to recover from errors here, the empty
 * implementation of {@link BailErrorStrategy//sync} improves the performance of
 * the first stage.</li>
 * <li><strong>Silent validation:</strong> When syntax errors are not being
 * reported or logged, and the parse result is simply ignored if errors occur,
 * the {@link BailErrorStrategy} avoids wasting work on recovering from errors
 * when the result will be ignored either way.</li>
 * </ul>
 *
 * <p>
 * {@code myparser.setErrorHandler(new BailErrorStrategy());}</p>
 *
 * @see Parser//setErrorHandler(ANTLRErrorStrategy)
 * */
class BailErrorStrategy extends DefaultErrorStrategy$1 {
    constructor() {
        super();
    }

    /**
     * Instead of recovering from exception {@code e}, re-throw it wrapped
     * in a {@link ParseCancellationException} so it is not caught by the
     * rule function catches. Use {@link Exception//getCause()} to get the
     * original {@link RecognitionException}.
     */
    recover(recognizer, e) {
        let context = recognizer._ctx;
        while (context !== null) {
            context.exception = e;
            context = context.parentCtx;
        }
        throw new ParseCancellationException(e);
    }

    /**
     * Make sure we don't attempt to recover inline; if the parser
     * successfully recovers, it won't throw an exception.
     */
    recoverInline(recognizer) {
        this.recover(recognizer, new InputMismatchException(recognizer));
    }

// Make sure we don't attempt to recover from problems in subrules.//
    sync(recognizer) {
        // pass
    }
}


var ErrorStrategy_1 = {BailErrorStrategy, DefaultErrorStrategy: DefaultErrorStrategy$1};

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

error.RecognitionException = Errors.RecognitionException;
error.NoViableAltException = Errors.NoViableAltException;
error.LexerNoViableAltException = Errors.LexerNoViableAltException;
error.InputMismatchException = Errors.InputMismatchException;
error.FailedPredicateException = Errors.FailedPredicateException;
error.DiagnosticErrorListener = DiagnosticErrorListener_1;
error.BailErrorStrategy = ErrorStrategy_1.BailErrorStrategy;
error.DefaultErrorStrategy = ErrorStrategy_1.DefaultErrorStrategy;
error.ErrorListener = ErrorListener_1.ErrorListener;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Token: Token$3} = Token_1;



/**
 * If decodeToUnicodeCodePoints is true, the input is treated
 * as a series of Unicode code points.
 *
 * Otherwise, the input is treated as a series of 16-bit UTF-16 code
 * units.
 */
class InputStream {
	constructor(data, decodeToUnicodeCodePoints) {
		this.name = "<empty>";
		this.strdata = data;
		this.decodeToUnicodeCodePoints = decodeToUnicodeCodePoints || false;
		// _loadString - Vacuum all input from a string and then treat it like a buffer.
		this._index = 0;
		this.data = [];
		if (this.decodeToUnicodeCodePoints) {
			for (let i = 0; i < this.strdata.length; ) {
				const codePoint = this.strdata.codePointAt(i);
				this.data.push(codePoint);
				i += codePoint <= 0xFFFF ? 1 : 2;
			}
		} else {
			this.data = new Array(this.strdata.length);
			for (let i = 0; i < this.strdata.length; i++) {
				const codeUnit = this.strdata.charCodeAt(i);
				this.data[i] = codeUnit;
			}
		}
		this._size = this.data.length;
	}

	/**
	 * Reset the stream so that it's in the same state it was
	 * when the object was created *except* the data array is not
	 * touched.
	 */
	reset() {
		this._index = 0;
	}

	consume() {
		if (this._index >= this._size) {
			// assert this.LA(1) == Token.EOF
			throw ("cannot consume EOF");
		}
		this._index += 1;
	}

	LA(offset) {
		if (offset === 0) {
			return 0; // undefined
		}
		if (offset < 0) {
			offset += 1; // e.g., translate LA(-1) to use offset=0
		}
		const pos = this._index + offset - 1;
		if (pos < 0 || pos >= this._size) { // invalid
			return Token$3.EOF;
		}
		return this.data[pos];
	}

	LT(offset) {
		return this.LA(offset);
	}

// mark/release do nothing; we have entire buffer
	mark() {
		return -1;
	}

	release(marker) {
	}

	/**
	 * consume() ahead until p==_index; can't just set p=_index as we must
	 * update line and column. If we seek backwards, just set p
	 */
	seek(_index) {
		if (_index <= this._index) {
			this._index = _index; // just jump; don't update stream state (line,
									// ...)
			return;
		}
		// seek forward
		this._index = Math.min(_index, this._size);
	}

	getText(start, stop) {
		if (stop >= this._size) {
			stop = this._size - 1;
		}
		if (start >= this._size) {
			return "";
		} else {
			if (this.decodeToUnicodeCodePoints) {
				let result = "";
				for (let i = start; i <= stop; i++) {
					result += String.fromCodePoint(this.data[i]);
				}
				return result;
			} else {
				return this.strdata.slice(start, stop + 1);
			}
		}
	}

	toString() {
		return this.strdata;
	}

	get index(){
		return this._index;
	}

	get size(){
		return this._size;
	}
}


var InputStream_1 = InputStream;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Token: Token$2} = Token_1;
const Lexer$2 = Lexer_1;
const {Interval} = IntervalSet_1;

// this is just to keep meaningful parameter types to Parser
class TokenStream {}

/**
 * This implementation of {@link TokenStream} loads tokens from a
 * {@link TokenSource} on-demand, and places the tokens in a buffer to provide
 * access to any previous token by index.
 *
 * <p>
 * This token stream ignores the value of {@link Token//getChannel}. If your
 * parser requires the token stream filter tokens to only those on a particular
 * channel, such as {@link Token//DEFAULT_CHANNEL} or
 * {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a
 * {@link CommonTokenStream}.</p>
 */
let BufferedTokenStream$1 = class BufferedTokenStream extends TokenStream {
	constructor(tokenSource) {

		super();
		// The {@link TokenSource} from which tokens for this stream are fetched.
		this.tokenSource = tokenSource;
		/**
		 * A collection of all tokens fetched from the token source. The list is
		 * considered a complete view of the input once {@link //fetchedEOF} is set
		 * to {@code true}.
		 */
		this.tokens = [];

		/**
		 * The index into {@link //tokens} of the current token (next token to
		 * {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should
		 * be
		 * {@link //LT LT(1)}.
		 *
		 * <p>This field is set to -1 when the stream is first constructed or when
		 * {@link //setTokenSource} is called, indicating that the first token has
		 * not yet been fetched from the token source. For additional information,
		 * see the documentation of {@link IntStream} for a description of
		 * Initializing Methods.</p>
		 */
		this.index = -1;

		/**
		 * Indicates whether the {@link Token//EOF} token has been fetched from
		 * {@link //tokenSource} and added to {@link //tokens}. This field improves
		 * performance for the following cases:
		 *
		 * <ul>
		 * <li>{@link //consume}: The lookahead check in {@link //consume} to
		 * prevent
		 * consuming the EOF symbol is optimized by checking the values of
		 * {@link //fetchedEOF} and {@link //p} instead of calling {@link
		 * //LA}.</li>
		 * <li>{@link //fetch}: The check to prevent adding multiple EOF symbols
		 * into
		 * {@link //tokens} is trivial with this field.</li>
		 * <ul>
		 */
		this.fetchedEOF = false;
	}

	mark() {
		return 0;
	}

	release(marker) {
		// no resources to release
	}

	reset() {
		this.seek(0);
	}

	seek(index) {
		this.lazyInit();
		this.index = this.adjustSeekIndex(index);
	}

	get(index) {
		this.lazyInit();
		return this.tokens[index];
	}

	consume() {
		let skipEofCheck = false;
		if (this.index >= 0) {
			if (this.fetchedEOF) {
				// the last token in tokens is EOF. skip check if p indexes any
				// fetched token except the last.
				skipEofCheck = this.index < this.tokens.length - 1;
			} else {
				// no EOF token in tokens. skip check if p indexes a fetched token.
				skipEofCheck = this.index < this.tokens.length;
			}
		} else {
			// not yet initialized
			skipEofCheck = false;
		}
		if (!skipEofCheck && this.LA(1) === Token$2.EOF) {
			throw "cannot consume EOF";
		}
		if (this.sync(this.index + 1)) {
			this.index = this.adjustSeekIndex(this.index + 1);
		}
	}

	/**
	 * Make sure index {@code i} in tokens has a token.
	 *
	 * @return {Boolean} {@code true} if a token is located at index {@code i}, otherwise
	 * {@code false}.
	 * @see //get(int i)
	 */
	sync(i) {
		const n = i - this.tokens.length + 1; // how many more elements we need?
		if (n > 0) {
			const fetched = this.fetch(n);
			return fetched >= n;
		}
		return true;
	}

	/**
	 * Add {@code n} elements to buffer.
	 *
	 * @return {Number} The actual number of elements added to the buffer.
	 */
	fetch(n) {
		if (this.fetchedEOF) {
			return 0;
		}
		for (let i = 0; i < n; i++) {
			const t = this.tokenSource.nextToken();
			t.tokenIndex = this.tokens.length;
			this.tokens.push(t);
			if (t.type === Token$2.EOF) {
				this.fetchedEOF = true;
				return i + 1;
			}
		}
		return n;
	}

// Get all tokens from start..stop inclusively///
	getTokens(start, stop, types) {
		if (types === undefined) {
			types = null;
		}
		if (start < 0 || stop < 0) {
			return null;
		}
		this.lazyInit();
		const subset = [];
		if (stop >= this.tokens.length) {
			stop = this.tokens.length - 1;
		}
		for (let i = start; i < stop; i++) {
			const t = this.tokens[i];
			if (t.type === Token$2.EOF) {
				break;
			}
			if (types === null || types.contains(t.type)) {
				subset.push(t);
			}
		}
		return subset;
	}

	LA(i) {
		return this.LT(i).type;
	}

	LB(k) {
		if (this.index - k < 0) {
			return null;
		}
		return this.tokens[this.index - k];
	}

	LT(k) {
		this.lazyInit();
		if (k === 0) {
			return null;
		}
		if (k < 0) {
			return this.LB(-k);
		}
		const i = this.index + k - 1;
		this.sync(i);
		if (i >= this.tokens.length) { // return EOF token
			// EOF must be last token
			return this.tokens[this.tokens.length - 1];
		}
		return this.tokens[i];
	}

	/**
	 * Allowed derived classes to modify the behavior of operations which change
	 * the current stream position by adjusting the target token index of a seek
	 * operation. The default implementation simply returns {@code i}. If an
	 * exception is thrown in this method, the current stream index should not be
	 * changed.
	 *
	 * <p>For example, {@link CommonTokenStream} overrides this method to ensure
	 * that
	 * the seek target is always an on-channel token.</p>
	 *
	 * @param {Number} i The target token index.
	 * @return {Number} The adjusted target token index.
	 */
	adjustSeekIndex(i) {
		return i;
	}

	lazyInit() {
		if (this.index === -1) {
			this.setup();
		}
	}

	setup() {
		this.sync(0);
		this.index = this.adjustSeekIndex(0);
	}

// Reset this token stream by setting its token source.///
	setTokenSource(tokenSource) {
		this.tokenSource = tokenSource;
		this.tokens = [];
		this.index = -1;
		this.fetchedEOF = false;
	}

	/**
	 * Given a starting index, return the index of the next token on channel.
	 * Return i if tokens[i] is on channel. Return -1 if there are no tokens
	 * on channel between i and EOF.
	 */
	nextTokenOnChannel(i, channel) {
		this.sync(i);
		if (i >= this.tokens.length) {
			return -1;
		}
		let token = this.tokens[i];
		while (token.channel !== this.channel) {
			if (token.type === Token$2.EOF) {
				return -1;
			}
			i += 1;
			this.sync(i);
			token = this.tokens[i];
		}
		return i;
	}

	/**
	 * Given a starting index, return the index of the previous token on channel.
	 * Return i if tokens[i] is on channel. Return -1 if there are no tokens
	 * on channel between i and 0.
	 */
	previousTokenOnChannel(i, channel) {
		while (i >= 0 && this.tokens[i].channel !== channel) {
			i -= 1;
		}
		return i;
	}

	/**
	 * Collect all tokens on specified channel to the right of
	 * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or
	 * EOF. If channel is -1, find any non default channel token.
	 */
	getHiddenTokensToRight(tokenIndex,
			channel) {
		if (channel === undefined) {
			channel = -1;
		}
		this.lazyInit();
		if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {
			throw "" + tokenIndex + " not in 0.." + this.tokens.length - 1;
		}
		const nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer$2.DEFAULT_TOKEN_CHANNEL);
		const from_ = tokenIndex + 1;
		// if none onchannel to right, nextOnChannel=-1 so set to = last token
		const to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;
		return this.filterForChannel(from_, to, channel);
	}

	/**
	 * Collect all tokens on specified channel to the left of
	 * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.
	 * If channel is -1, find any non default channel token.
	 */
	getHiddenTokensToLeft(tokenIndex,
			channel) {
		if (channel === undefined) {
			channel = -1;
		}
		this.lazyInit();
		if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {
			throw "" + tokenIndex + " not in 0.." + this.tokens.length - 1;
		}
		const prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer$2.DEFAULT_TOKEN_CHANNEL);
		if (prevOnChannel === tokenIndex - 1) {
			return null;
		}
		// if none on channel to left, prevOnChannel=-1 then from=0
		const from_ = prevOnChannel + 1;
		const to = tokenIndex - 1;
		return this.filterForChannel(from_, to, channel);
	}

	filterForChannel(left, right, channel) {
		const hidden = [];
		for (let i = left; i < right + 1; i++) {
			const t = this.tokens[i];
			if (channel === -1) {
				if (t.channel !== Lexer$2.DEFAULT_TOKEN_CHANNEL) {
					hidden.push(t);
				}
			} else if (t.channel === channel) {
				hidden.push(t);
			}
		}
		if (hidden.length === 0) {
			return null;
		}
		return hidden;
	}

	getSourceName() {
		return this.tokenSource.getSourceName();
	}

// Get the text of all tokens in this buffer.///
	getText(interval) {
		this.lazyInit();
		this.fill();
		if (interval === undefined || interval === null) {
			interval = new Interval(0, this.tokens.length - 1);
		}
		let start = interval.start;
		if (start instanceof Token$2) {
			start = start.tokenIndex;
		}
		let stop = interval.stop;
		if (stop instanceof Token$2) {
			stop = stop.tokenIndex;
		}
		if (start === null || stop === null || start < 0 || stop < 0) {
			return "";
		}
		if (stop >= this.tokens.length) {
			stop = this.tokens.length - 1;
		}
		let s = "";
		for (let i = start; i < stop + 1; i++) {
			const t = this.tokens[i];
			if (t.type === Token$2.EOF) {
				break;
			}
			s = s + t.text;
		}
		return s;
	}

// Get all tokens from lexer until EOF///
	fill() {
		this.lazyInit();
		while (this.fetch(1000) === 1000) {
			continue;
		}
	}
};


var BufferedTokenStream_1 = BufferedTokenStream$1;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const Token$1 = Token_1.Token;
const BufferedTokenStream = BufferedTokenStream_1;

/**
 * This class extends {@link BufferedTokenStream} with functionality to filter
 * token streams to tokens on a particular channel (tokens where
 * {@link Token//getChannel} returns a particular value).
 *
 * <p>
 * This token stream provides access to all tokens by index or when calling
 * methods like {@link //getText}. The channel filtering is only used for code
 * accessing tokens via the lookahead methods {@link //LA}, {@link //LT}, and
 * {@link //LB}.</p>
 *
 * <p>
 * By default, tokens are placed on the default channel
 * ({@link Token//DEFAULT_CHANNEL}), but may be reassigned by using the
 * {@code ->channel(HIDDEN)} lexer command, or by using an embedded action to
 * call {@link Lexer//setChannel}.
 * </p>
 *
 * <p>
 * Note: lexer rules which use the {@code ->skip} lexer command or call
 * {@link Lexer//skip} do not produce tokens at all, so input text matched by
 * such a rule will not be available as part of the token stream, regardless of
 * channel.</p>
 */
class CommonTokenStream extends BufferedTokenStream {
    constructor(lexer, channel) {
        super(lexer);
        this.channel = channel===undefined ? Token$1.DEFAULT_CHANNEL : channel;
    }

    adjustSeekIndex(i) {
        return this.nextTokenOnChannel(i, this.channel);
    }

    LB(k) {
        if (k===0 || this.index-k<0) {
            return null;
        }
        let i = this.index;
        let n = 1;
        // find k good tokens looking backwards
        while (n <= k) {
            // skip off-channel tokens
            i = this.previousTokenOnChannel(i - 1, this.channel);
            n += 1;
        }
        if (i < 0) {
            return null;
        }
        return this.tokens[i];
    }

    LT(k) {
        this.lazyInit();
        if (k === 0) {
            return null;
        }
        if (k < 0) {
            return this.LB(-k);
        }
        let i = this.index;
        let n = 1; // we know tokens[pos] is a good one
        // find k good tokens
        while (n < k) {
            // skip off-channel tokens, but make sure to not look past EOF
            if (this.sync(i + 1)) {
                i = this.nextTokenOnChannel(i + 1, this.channel);
            }
            n += 1;
        }
        return this.tokens[i];
    }

    // Count EOF just once.
    getNumberOfOnChannelTokens() {
        let n = 0;
        this.fill();
        for (let i =0; i< this.tokens.length;i++) {
            const t = this.tokens[i];
            if( t.channel===this.channel) {
                n += 1;
            }
            if( t.type===Token$1.EOF) {
                break;
            }
        }
        return n;
    }
}

var CommonTokenStream_1 = CommonTokenStream;

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */

const {Token} = Token_1;
const {ParseTreeListener, TerminalNode, ErrorNode} = Tree_1;
const Recognizer = Recognizer_1;
const {DefaultErrorStrategy} = ErrorStrategy_1;
const ATNDeserializer = ATNDeserializer_1;
const ATNDeserializationOptions = ATNDeserializationOptions_1;
const Lexer$1 = Lexer_1;

class TraceListener extends ParseTreeListener {
	constructor(parser) {
		super();
		this.parser = parser;
	}

	enterEveryRule(ctx) {
		console.log("enter   " + this.parser.ruleNames[ctx.ruleIndex] + ", LT(1)=" + this.parser._input.LT(1).text);
	}

	visitTerminal(node) {
		console.log("consume " + node.symbol + " rule " + this.parser.ruleNames[this.parser._ctx.ruleIndex]);
	}

	exitEveryRule(ctx) {
		console.log("exit    " + this.parser.ruleNames[ctx.ruleIndex] + ", LT(1)=" + this.parser._input.LT(1).text);
	}
}

let Parser$1 = class Parser extends Recognizer {
	/**
	 * this is all the parsing support code essentially; most of it is error
	 * recovery stuff.
	 */
	constructor(input) {
		super();
		// The input stream.
		this._input = null;
		/**
		 * The error handling strategy for the parser. The default value is a new
		 * instance of {@link DefaultErrorStrategy}.
		 */
		this._errHandler = new DefaultErrorStrategy();
		this._precedenceStack = [];
		this._precedenceStack.push(0);
		/**
		 * The {@link ParserRuleContext} object for the currently executing rule.
		 * this is always non-null during the parsing process.
		 */
		this._ctx = null;
		/**
		 * Specifies whether or not the parser should construct a parse tree during
		 * the parsing process. The default value is {@code true}.
		 */
		this.buildParseTrees = true;
		/**
		 * When {@link //setTrace}{@code (true)} is called, a reference to the
		 * {@link TraceListener} is stored here so it can be easily removed in a
		 * later call to {@link //setTrace}{@code (false)}. The listener itself is
		 * implemented as a parser listener so this field is not directly used by
		 * other parser methods.
		 */
		this._tracer = null;
		/**
		 * The list of {@link ParseTreeListener} listeners registered to receive
		 * events during the parse.
		 */
		this._parseListeners = null;
		/**
		 * The number of syntax errors reported during parsing. this value is
		 * incremented each time {@link //notifyErrorListeners} is called.
		 */
		this._syntaxErrors = 0;
		this.setInputStream(input);
	}

	// reset the parser's state
	reset() {
		if (this._input !== null) {
			this._input.seek(0);
		}
		this._errHandler.reset(this);
		this._ctx = null;
		this._syntaxErrors = 0;
		this.setTrace(false);
		this._precedenceStack = [];
		this._precedenceStack.push(0);
		if (this._interp !== null) {
			this._interp.reset();
		}
	}

	/**
	 * Match current input symbol against {@code ttype}. If the symbol type
	 * matches, {@link ANTLRErrorStrategy//reportMatch} and {@link //consume} are
	 * called to complete the match process.
	 *
	 * <p>If the symbol type does not match,
	 * {@link ANTLRErrorStrategy//recoverInline} is called on the current error
	 * strategy to attempt recovery. If {@link //getBuildParseTree} is
	 * {@code true} and the token index of the symbol returned by
	 * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to
	 * the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>
	 *
	 * @param ttype the token type to match
	 * @return the matched symbol
	 * @throws RecognitionException if the current input symbol did not match
	 * {@code ttype} and the error strategy could not recover from the
	 * mismatched symbol
	 */
	match(ttype) {
		let t = this.getCurrentToken();
		if (t.type === ttype) {
			this._errHandler.reportMatch(this);
			this.consume();
		} else {
			t = this._errHandler.recoverInline(this);
			if (this.buildParseTrees && t.tokenIndex === -1) {
				// we must have conjured up a new token during single token
				// insertion
				// if it's not the current symbol
				this._ctx.addErrorNode(t);
			}
		}
		return t;
	}

	/**
	 * Match current input symbol as a wildcard. If the symbol type matches
	 * (i.e. has a value greater than 0), {@link ANTLRErrorStrategy//reportMatch}
	 * and {@link //consume} are called to complete the match process.
	 *
	 * <p>If the symbol type does not match,
	 * {@link ANTLRErrorStrategy//recoverInline} is called on the current error
	 * strategy to attempt recovery. If {@link //getBuildParseTree} is
	 * {@code true} and the token index of the symbol returned by
	 * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to
	 * the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>
	 *
	 * @return the matched symbol
	 * @throws RecognitionException if the current input symbol did not match
	 * a wildcard and the error strategy could not recover from the mismatched
	 * symbol
	 */
	matchWildcard() {
		let t = this.getCurrentToken();
		if (t.type > 0) {
			this._errHandler.reportMatch(this);
			this.consume();
		} else {
			t = this._errHandler.recoverInline(this);
			if (this._buildParseTrees && t.tokenIndex === -1) {
				// we must have conjured up a new token during single token
				// insertion
				// if it's not the current symbol
				this._ctx.addErrorNode(t);
			}
		}
		return t;
	}

	getParseListeners() {
		return this._parseListeners || [];
	}

	/**
	 * Registers {@code listener} to receive events during the parsing process.
	 *
	 * <p>To support output-preserving grammar transformations (including but not
	 * limited to left-recursion removal, automated left-factoring, and
	 * optimized code generation), calls to listener methods during the parse
	 * may differ substantially from calls made by
	 * {@link ParseTreeWalker//DEFAULT} used after the parse is complete. In
	 * particular, rule entry and exit events may occur in a different order
	 * during the parse than after the parser. In addition, calls to certain
	 * rule entry methods may be omitted.</p>
	 *
	 * <p>With the following specific exceptions, calls to listener events are
	 * <em>deterministic</em>, i.e. for identical input the calls to listener
	 * methods will be the same.</p>
	 *
	 * <ul>
	 * <li>Alterations to the grammar used to generate code may change the
	 * behavior of the listener calls.</li>
	 * <li>Alterations to the command line options passed to ANTLR 4 when
	 * generating the parser may change the behavior of the listener calls.</li>
	 * <li>Changing the version of the ANTLR Tool used to generate the parser
	 * may change the behavior of the listener calls.</li>
	 * </ul>
	 *
	 * @param listener the listener to add
	 *
	 * @throws NullPointerException if {@code} listener is {@code null}
	 */
	addParseListener(listener) {
		if (listener === null) {
			throw "listener";
		}
		if (this._parseListeners === null) {
			this._parseListeners = [];
		}
		this._parseListeners.push(listener);
	}

	/**
	 * Remove {@code listener} from the list of parse listeners.
	 *
	 * <p>If {@code listener} is {@code null} or has not been added as a parse
	 * listener, this method does nothing.</p>
	 * @param listener the listener to remove
	 */
	removeParseListener(listener) {
		if (this._parseListeners !== null) {
			const idx = this._parseListeners.indexOf(listener);
			if (idx >= 0) {
				this._parseListeners.splice(idx, 1);
			}
			if (this._parseListeners.length === 0) {
				this._parseListeners = null;
			}
		}
	}

	// Remove all parse listeners.
	removeParseListeners() {
		this._parseListeners = null;
	}

	// Notify any parse listeners of an enter rule event.
	triggerEnterRuleEvent() {
		if (this._parseListeners !== null) {
			const ctx = this._ctx;
			this._parseListeners.forEach(function(listener) {
				listener.enterEveryRule(ctx);
				ctx.enterRule(listener);
			});
		}
	}

	/**
	 * Notify any parse listeners of an exit rule event.
	 * @see //addParseListener
	 */
	triggerExitRuleEvent() {
		if (this._parseListeners !== null) {
			// reverse order walk of listeners
			const ctx = this._ctx;
			this._parseListeners.slice(0).reverse().forEach(function(listener) {
				ctx.exitRule(listener);
				listener.exitEveryRule(ctx);
			});
		}
	}

	getTokenFactory() {
		return this._input.tokenSource._factory;
	}

	// Tell our token source and error strategy about a new way to create tokens.
	setTokenFactory(factory) {
		this._input.tokenSource._factory = factory;
	}

	/**
	 * The ATN with bypass alternatives is expensive to create so we create it
	 * lazily.
	 *
	 * @throws UnsupportedOperationException if the current parser does not
	 * implement the {@link //getSerializedATN()} method.
	 */
	getATNWithBypassAlts() {
		const serializedAtn = this.getSerializedATN();
		if (serializedAtn === null) {
			throw "The current parser does not support an ATN with bypass alternatives.";
		}
		let result = this.bypassAltsAtnCache[serializedAtn];
		if (result === null) {
			const deserializationOptions = new ATNDeserializationOptions();
			deserializationOptions.generateRuleBypassTransitions = true;
			result = new ATNDeserializer(deserializationOptions)
					.deserialize(serializedAtn);
			this.bypassAltsAtnCache[serializedAtn] = result;
		}
		return result;
	}

	/**
	 * The preferred method of getting a tree pattern. For example, here's a
	 * sample use:
	 *
	 * <pre>
	 * ParseTree t = parser.expr();
	 * ParseTreePattern p = parser.compileParseTreePattern("&lt;ID&gt;+0",
	 * MyParser.RULE_expr);
	 * ParseTreeMatch m = p.match(t);
	 * String id = m.get("ID");
	 * </pre>
	 */
	compileParseTreePattern(pattern, patternRuleIndex, lexer) {
		lexer = lexer || null;
		if (lexer === null) {
			if (this.getTokenStream() !== null) {
				const tokenSource = this.getTokenStream().tokenSource;
				if (tokenSource instanceof Lexer$1) {
					lexer = tokenSource;
				}
			}
		}
		if (lexer === null) {
			throw "Parser can't discover a lexer to use";
		}
		const m = new ParseTreePatternMatcher(lexer, this);
		return m.compile(pattern, patternRuleIndex);
	}

	getInputStream() {
		return this.getTokenStream();
	}

	setInputStream(input) {
		this.setTokenStream(input);
	}

	getTokenStream() {
		return this._input;
	}

	// Set the token stream and reset the parser.
	setTokenStream(input) {
		this._input = null;
		this.reset();
		this._input = input;
	}

	/**
	 * Match needs to return the current input symbol, which gets put
	 * into the label for the associated token ref; e.g., x=ID.
	 */
	getCurrentToken() {
		return this._input.LT(1);
	}

	notifyErrorListeners(msg, offendingToken, err) {
		offendingToken = offendingToken || null;
		err = err || null;
		if (offendingToken === null) {
			offendingToken = this.getCurrentToken();
		}
		this._syntaxErrors += 1;
		const line = offendingToken.line;
		const column = offendingToken.column;
		const listener = this.getErrorListenerDispatch();
		listener.syntaxError(this, offendingToken, line, column, msg, err);
	}

	/**
	 * Consume and return the {@linkplain //getCurrentToken current symbol}.
	 *
	 * <p>E.g., given the following input with {@code A} being the current
	 * lookahead symbol, this function moves the cursor to {@code B} and returns
	 * {@code A}.</p>
	 *
	 * <pre>
	 * A B
	 * ^
	 * </pre>
	 *
	 * If the parser is not in error recovery mode, the consumed symbol is added
	 * to the parse tree using {@link ParserRuleContext//addChild(Token)}, and
	 * {@link ParseTreeListener//visitTerminal} is called on any parse listeners.
	 * If the parser <em>is</em> in error recovery mode, the consumed symbol is
	 * added to the parse tree using
	 * {@link ParserRuleContext//addErrorNode(Token)}, and
	 * {@link ParseTreeListener//visitErrorNode} is called on any parse
	 * listeners.
	 */
	consume() {
		const o = this.getCurrentToken();
		if (o.type !== Token.EOF) {
			this.getInputStream().consume();
		}
		const hasListener = this._parseListeners !== null && this._parseListeners.length > 0;
		if (this.buildParseTrees || hasListener) {
			let node;
			if (this._errHandler.inErrorRecoveryMode(this)) {
				node = this._ctx.addErrorNode(o);
			} else {
				node = this._ctx.addTokenNode(o);
			}
			node.invokingState = this.state;
			if (hasListener) {
				this._parseListeners.forEach(function(listener) {
					if (node instanceof ErrorNode || (node.isErrorNode !== undefined && node.isErrorNode())) {
						listener.visitErrorNode(node);
					} else if (node instanceof TerminalNode) {
						listener.visitTerminal(node);
					}
				});
			}
		}
		return o;
	}

	addContextToParseTree() {
		// add current context to parent if we have a parent
		if (this._ctx.parentCtx !== null) {
			this._ctx.parentCtx.addChild(this._ctx);
		}
	}

	/**
	 * Always called by generated parsers upon entry to a rule. Access field
	 * {@link //_ctx} get the current context.
	 */
	enterRule(localctx, state, ruleIndex) {
		this.state = state;
		this._ctx = localctx;
		this._ctx.start = this._input.LT(1);
		if (this.buildParseTrees) {
			this.addContextToParseTree();
		}
		this.triggerEnterRuleEvent();
	}

	exitRule() {
		this._ctx.stop = this._input.LT(-1);
		// trigger event on _ctx, before it reverts to parent
		this.triggerExitRuleEvent();
		this.state = this._ctx.invokingState;
		this._ctx = this._ctx.parentCtx;
	}

	enterOuterAlt(localctx, altNum) {
		localctx.setAltNumber(altNum);
		// if we have new localctx, make sure we replace existing ctx
		// that is previous child of parse tree
		if (this.buildParseTrees && this._ctx !== localctx) {
			if (this._ctx.parentCtx !== null) {
				this._ctx.parentCtx.removeLastChild();
				this._ctx.parentCtx.addChild(localctx);
			}
		}
		this._ctx = localctx;
	}

	/**
	 * Get the precedence level for the top-most precedence rule.
	 *
	 * @return The precedence level for the top-most precedence rule, or -1 if
	 * the parser context is not nested within a precedence rule.
	 */
	getPrecedence() {
		if (this._precedenceStack.length === 0) {
			return -1;
		} else {
			return this._precedenceStack[this._precedenceStack.length-1];
		}
	}

	enterRecursionRule(localctx, state, ruleIndex, precedence) {
	   this.state = state;
	   this._precedenceStack.push(precedence);
	   this._ctx = localctx;
	   this._ctx.start = this._input.LT(1);
	   this.triggerEnterRuleEvent(); // simulates rule entry for left-recursive rules
   }

	// Like {@link //enterRule} but for recursive rules.
	pushNewRecursionContext(localctx, state, ruleIndex) {
		const previous = this._ctx;
		previous.parentCtx = localctx;
		previous.invokingState = state;
		previous.stop = this._input.LT(-1);

		this._ctx = localctx;
		this._ctx.start = previous.start;
		if (this.buildParseTrees) {
			this._ctx.addChild(previous);
		}
		this.triggerEnterRuleEvent(); // simulates rule entry for left-recursive rules
	}

	unrollRecursionContexts(parentCtx) {
		this._precedenceStack.pop();
		this._ctx.stop = this._input.LT(-1);
		const retCtx = this._ctx; // save current ctx (return value)
		// unroll so _ctx is as it was before call to recursive method
		const parseListeners = this.getParseListeners();
		if (parseListeners !== null && parseListeners.length > 0) {
			while (this._ctx !== parentCtx) {
				this.triggerExitRuleEvent();
				this._ctx = this._ctx.parentCtx;
			}
		} else {
			this._ctx = parentCtx;
		}
		// hook into tree
		retCtx.parentCtx = parentCtx;
		if (this.buildParseTrees && parentCtx !== null) {
			// add return ctx into invoking rule's tree
			parentCtx.addChild(retCtx);
		}
	}

	getInvokingContext(ruleIndex) {
		let ctx = this._ctx;
		while (ctx !== null) {
			if (ctx.ruleIndex === ruleIndex) {
				return ctx;
			}
			ctx = ctx.parentCtx;
		}
		return null;
	}

	precpred(localctx, precedence) {
		return precedence >= this._precedenceStack[this._precedenceStack.length-1];
	}

	inContext(context) {
		// TODO: useful in parser?
		return false;
	}

	/**
	 * Checks whether or not {@code symbol} can follow the current state in the
	 * ATN. The behavior of this method is equivalent to the following, but is
	 * implemented such that the complete context-sensitive follow set does not
	 * need to be explicitly constructed.
	 *
	 * <pre>
	 * return getExpectedTokens().contains(symbol);
	 * </pre>
	 *
	 * @param symbol the symbol type to check
	 * @return {@code true} if {@code symbol} can follow the current state in
	 * the ATN, otherwise {@code false}.
	 */
	isExpectedToken(symbol) {
		const atn = this._interp.atn;
		let ctx = this._ctx;
		const s = atn.states[this.state];
		let following = atn.nextTokens(s);
		if (following.contains(symbol)) {
			return true;
		}
		if (!following.contains(Token.EPSILON)) {
			return false;
		}
		while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {
			const invokingState = atn.states[ctx.invokingState];
			const rt = invokingState.transitions[0];
			following = atn.nextTokens(rt.followState);
			if (following.contains(symbol)) {
				return true;
			}
			ctx = ctx.parentCtx;
		}
		if (following.contains(Token.EPSILON) && symbol === Token.EOF) {
			return true;
		} else {
			return false;
		}
	}

	/**
	 * Computes the set of input symbols which could follow the current parser
	 * state and context, as given by {@link //getState} and {@link //getContext},
	 * respectively.
	 *
	 * @see ATN//getExpectedTokens(int, RuleContext)
	 */
	getExpectedTokens() {
		return this._interp.atn.getExpectedTokens(this.state, this._ctx);
	}

	getExpectedTokensWithinCurrentRule() {
		const atn = this._interp.atn;
		const s = atn.states[this.state];
		return atn.nextTokens(s);
	}

	// Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found.
	getRuleIndex(ruleName) {
		const ruleIndex = this.getRuleIndexMap()[ruleName];
		if (ruleIndex !== null) {
			return ruleIndex;
		} else {
			return -1;
		}
	}

	/**
	 * Return List&lt;String&gt; of the rule names in your parser instance
	 * leading up to a call to the current rule. You could override if
	 * you want more details such as the file/line info of where
	 * in the ATN a rule is invoked.
	 *
	 * this is very useful for error messages.
	 */
	getRuleInvocationStack(p) {
		p = p || null;
		if (p === null) {
			p = this._ctx;
		}
		const stack = [];
		while (p !== null) {
			// compute what follows who invoked us
			const ruleIndex = p.ruleIndex;
			if (ruleIndex < 0) {
				stack.push("n/a");
			} else {
				stack.push(this.ruleNames[ruleIndex]);
			}
			p = p.parentCtx;
		}
		return stack;
	}

	// For debugging and other purposes.
	getDFAStrings() {
		return this._interp.decisionToDFA.toString();
	}

	// For debugging and other purposes.
	dumpDFA() {
		let seenOne = false;
		for (let i = 0; i < this._interp.decisionToDFA.length; i++) {
			const dfa = this._interp.decisionToDFA[i];
			if (dfa.states.length > 0) {
				if (seenOne) {
					console.log();
				}
				this.printer.println("Decision " + dfa.decision + ":");
				this.printer.print(dfa.toString(this.literalNames, this.symbolicNames));
				seenOne = true;
			}
		}
	}

	/*
		"			printer = function() {\r\n" +
		"				this.println = function(s) { document.getElementById('output') += s + '\\n'; }\r\n" +
		"				this.print = function(s) { document.getElementById('output') += s; }\r\n" +
		"			};\r\n" +
		*/
	getSourceName() {
		return this._input.sourceName;
	}

	/**
	 * During a parse is sometimes useful to listen in on the rule entry and exit
	 * events as well as token matches. this is for quick and dirty debugging.
	 */
	setTrace(trace) {
		if (!trace) {
			this.removeParseListener(this._tracer);
			this._tracer = null;
		} else {
			if (this._tracer !== null) {
				this.removeParseListener(this._tracer);
			}
			this._tracer = new TraceListener(this);
			this.addParseListener(this._tracer);
		}
	}
};

/**
 * this field maps from the serialized ATN string to the deserialized {@link
 * ATN} with
 * bypass alternatives.
 *
 * @see ATNDeserializationOptions//isGenerateRuleBypassTransitions()
 */
Parser$1.bypassAltsAtnCache = {};

var Parser_1 = Parser$1;

// This is a modified version of antr4's index.js, in which
// the "require" statements of two unused classes are commented out
// to avoid introducing a dependency on Node.js' "fs" package.

/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.
 * Use of this file is governed by the BSD 3-clause license that
 * can be found in the LICENSE.txt file in the project root.
 */
antlr4Index.atn = atn$2;
antlr4Index.codepointat = codepointat;
antlr4Index.dfa = dfa;
antlr4Index.fromcodepoint = fromcodepoint;
antlr4Index.tree = tree;
antlr4Index.error = error;
antlr4Index.Token = Token_1.Token;
// Commented out to avoid the problem with 'fs' during the webpack build
// exports.CharStreams = require('antlr4/src/antlr4/CharStreams');
antlr4Index.CommonToken = Token_1.CommonToken;
antlr4Index.InputStream = InputStream_1;
// Commented out to avoid the problem with 'fs' during the webpack build
// exports.FileStream = require('antlr4/src/antlr4/FileStream');
antlr4Index.CommonTokenStream = CommonTokenStream_1;
antlr4Index.Lexer = Lexer_1;
antlr4Index.Parser = Parser_1;
var pc = PredictionContext_1;
antlr4Index.PredictionContextCache = pc.PredictionContextCache;
antlr4Index.ParserRuleContext = ParserRuleContext_1;
antlr4Index.Interval = IntervalSet_1.Interval;
antlr4Index.IntervalSet = IntervalSet_1.IntervalSet;
antlr4Index.Utils = Utils$4;
antlr4Index.LL1Analyzer = LL1Analyzer_1.LL1Analyzer;

// Generated from FHIRPath.g4 by ANTLR 4.9.3
// jshint ignore: start
const antlr4$3 = antlr4Index;



const serializedATN$1 = ["\u0003\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786",
    "\u5964\u0002A\u0203\b\u0001\u0004\u0002\t\u0002\u0004\u0003\t\u0003",
    "\u0004\u0004\t\u0004\u0004\u0005\t\u0005\u0004\u0006\t\u0006\u0004\u0007",
    "\t\u0007\u0004\b\t\b\u0004\t\t\t\u0004\n\t\n\u0004\u000b\t\u000b\u0004",
    "\f\t\f\u0004\r\t\r\u0004\u000e\t\u000e\u0004\u000f\t\u000f\u0004\u0010",
    "\t\u0010\u0004\u0011\t\u0011\u0004\u0012\t\u0012\u0004\u0013\t\u0013",
    "\u0004\u0014\t\u0014\u0004\u0015\t\u0015\u0004\u0016\t\u0016\u0004\u0017",
    "\t\u0017\u0004\u0018\t\u0018\u0004\u0019\t\u0019\u0004\u001a\t\u001a",
    "\u0004\u001b\t\u001b\u0004\u001c\t\u001c\u0004\u001d\t\u001d\u0004\u001e",
    "\t\u001e\u0004\u001f\t\u001f\u0004 \t \u0004!\t!\u0004\"\t\"\u0004#",
    "\t#\u0004$\t$\u0004%\t%\u0004&\t&\u0004\'\t\'\u0004(\t(\u0004)\t)\u0004",
    "*\t*\u0004+\t+\u0004,\t,\u0004-\t-\u0004.\t.\u0004/\t/\u00040\t0\u0004",
    "1\t1\u00042\t2\u00043\t3\u00044\t4\u00045\t5\u00046\t6\u00047\t7\u0004",
    "8\t8\u00049\t9\u0004:\t:\u0004;\t;\u0004<\t<\u0004=\t=\u0004>\t>\u0004",
    "?\t?\u0004@\t@\u0004A\tA\u0004B\tB\u0004C\tC\u0004D\tD\u0003\u0002\u0003",
    "\u0002\u0003\u0003\u0003\u0003\u0003\u0004\u0003\u0004\u0003\u0005\u0003",
    "\u0005\u0003\u0006\u0003\u0006\u0003\u0007\u0003\u0007\u0003\b\u0003",
    "\b\u0003\t\u0003\t\u0003\t\u0003\t\u0003\n\u0003\n\u0003\n\u0003\n\u0003",
    "\u000b\u0003\u000b\u0003\f\u0003\f\u0003\r\u0003\r\u0003\r\u0003\u000e",
    "\u0003\u000e\u0003\u000f\u0003\u000f\u0003\u0010\u0003\u0010\u0003\u0010",
    "\u0003\u0011\u0003\u0011\u0003\u0011\u0003\u0012\u0003\u0012\u0003\u0012",
    "\u0003\u0013\u0003\u0013\u0003\u0014\u0003\u0014\u0003\u0015\u0003\u0015",
    "\u0003\u0015\u0003\u0016\u0003\u0016\u0003\u0016\u0003\u0017\u0003\u0017",
    "\u0003\u0017\u0003\u0018\u0003\u0018\u0003\u0018\u0003\u0018\u0003\u0018",
    "\u0003\u0018\u0003\u0018\u0003\u0018\u0003\u0018\u0003\u0019\u0003\u0019",
    "\u0003\u0019\u0003\u0019\u0003\u001a\u0003\u001a\u0003\u001a\u0003\u001b",
    "\u0003\u001b\u0003\u001b\u0003\u001b\u0003\u001c\u0003\u001c\u0003\u001c",
    "\u0003\u001c\u0003\u001c\u0003\u001c\u0003\u001c\u0003\u001c\u0003\u001d",
    "\u0003\u001d\u0003\u001e\u0003\u001e\u0003\u001f\u0003\u001f\u0003 ",
    "\u0003 \u0003!\u0003!\u0003!\u0003!\u0003!\u0003\"\u0003\"\u0003\"\u0003",
    "\"\u0003\"\u0003\"\u0003#\u0003#\u0003$\u0003$\u0003$\u0003$\u0003$",
    "\u0003$\u0003%\u0003%\u0003%\u0003%\u0003%\u0003%\u0003%\u0003&\u0003",
    "&\u0003&\u0003&\u0003&\u0003&\u0003&\u0003\'\u0003\'\u0003(\u0003(\u0003",
    "(\u0003(\u0003(\u0003)\u0003)\u0003)\u0003)\u0003)\u0003)\u0003*\u0003",
    "*\u0003*\u0003*\u0003*\u0003+\u0003+\u0003+\u0003+\u0003,\u0003,\u0003",
    ",\u0003,\u0003,\u0003-\u0003-\u0003-\u0003-\u0003-\u0003-\u0003-\u0003",
    ".\u0003.\u0003.\u0003.\u0003.\u0003.\u0003.\u0003/\u0003/\u0003/\u0003",
    "/\u0003/\u0003/\u0003/\u0003/\u0003/\u0003/\u0003/\u0003/\u00030\u0003",
    "0\u00030\u00030\u00030\u00030\u00031\u00031\u00031\u00031\u00031\u0003",
    "1\u00031\u00032\u00032\u00032\u00032\u00032\u00032\u00033\u00033\u0003",
    "3\u00033\u00033\u00034\u00034\u00034\u00034\u00034\u00034\u00035\u0003",
    "5\u00035\u00035\u00035\u00035\u00035\u00035\u00036\u00036\u00036\u0003",
    "6\u00036\u00036\u00036\u00036\u00037\u00037\u00037\u00037\u00037\u0003",
    "7\u00037\u00037\u00037\u00037\u00037\u00037\u00037\u00038\u00038\u0003",
    "8\u00038\u00038\u00038\u00038\u00038\u00038\u00038\u00038\u00038\u0003",
    "8\u00058\u0183\n8\u00058\u0185\n8\u00058\u0187\n8\u00038\u00058\u018a",
    "\n8\u00039\u00039\u00039\u00039\u0003:\u0003:\u0003:\u0003:\u0003:\u0003",
    ":\u0003:\u0003:\u0003:\u0003:\u0006:\u019a\n:\r:\u000e:\u019b\u0005",
    ":\u019e\n:\u0005:\u01a0\n:\u0005:\u01a2\n:\u0003:\u0003:\u0003:\u0003",
    ":\u0003:\u0003:\u0003:\u0005:\u01ab\n:\u0003;\u0005;\u01ae\n;\u0003",
    ";\u0007;\u01b1\n;\f;\u000e;\u01b4\u000b;\u0003<\u0003<\u0003<\u0007",
    "<\u01b9\n<\f<\u000e<\u01bc\u000b<\u0003<\u0003<\u0003=\u0003=\u0003",
    "=\u0007=\u01c3\n=\f=\u000e=\u01c6\u000b=\u0003=\u0003=\u0003>\u0006",
    ">\u01cb\n>\r>\u000e>\u01cc\u0003>\u0003>\u0006>\u01d1\n>\r>\u000e>\u01d2",
    "\u0005>\u01d5\n>\u0003?\u0006?\u01d8\n?\r?\u000e?\u01d9\u0003?\u0003",
    "?\u0003@\u0003@\u0003@\u0003@\u0007@\u01e2\n@\f@\u000e@\u01e5\u000b",
    "@\u0003@\u0003@\u0003@\u0003@\u0003@\u0003A\u0003A\u0003A\u0003A\u0007",
    "A\u01f0\nA\fA\u000eA\u01f3\u000bA\u0003A\u0003A\u0003B\u0003B\u0003",
    "B\u0005B\u01fa\nB\u0003C\u0003C\u0003C\u0003C\u0003C\u0003C\u0003D\u0003",
    "D\u0003\u01e3\u0002E\u0003\u0003\u0005\u0004\u0007\u0005\t\u0006\u000b",
    "\u0007\r\b\u000f\t\u0011\n\u0013\u000b\u0015\f\u0017\r\u0019\u000e\u001b",
    "\u000f\u001d\u0010\u001f\u0011!\u0012#\u0013%\u0014\'\u0015)\u0016+",
    "\u0017-\u0018/\u00191\u001a3\u001b5\u001c7\u001d9\u001e;\u001f= ?!A",
    "\"C#E$G%I&K\'M(O)Q*S+U,W-Y.[/]0_1a2c3e4g5i6k7m8o9q:s\u0002u;w<y={>}",
    "?\u007f@\u0081A\u0083\u0002\u0085\u0002\u0087\u0002\u0003\u0002\f\u0003",
    "\u00022;\u0004\u0002--//\u0005\u0002C\\aac|\u0006\u00022;C\\aac|\u0004",
    "\u0002^^bb\u0003\u0002))\u0005\u0002\u000b\f\u000f\u000f\"\"\u0004\u0002",
    "\f\f\u000f\u000f\n\u0002))11^^bbhhppttvv\u0005\u00022;CHch\u0002\u0214",
    "\u0002\u0003\u0003\u0002\u0002\u0002\u0002\u0005\u0003\u0002\u0002\u0002",
    "\u0002\u0007\u0003\u0002\u0002\u0002\u0002\t\u0003\u0002\u0002\u0002",
    "\u0002\u000b\u0003\u0002\u0002\u0002\u0002\r\u0003\u0002\u0002\u0002",
    "\u0002\u000f\u0003\u0002\u0002\u0002\u0002\u0011\u0003\u0002\u0002\u0002",
    "\u0002\u0013\u0003\u0002\u0002\u0002\u0002\u0015\u0003\u0002\u0002\u0002",
    "\u0002\u0017\u0003\u0002\u0002\u0002\u0002\u0019\u0003\u0002\u0002\u0002",
    "\u0002\u001b\u0003\u0002\u0002\u0002\u0002\u001d\u0003\u0002\u0002\u0002",
    "\u0002\u001f\u0003\u0002\u0002\u0002\u0002!\u0003\u0002\u0002\u0002",
    "\u0002#\u0003\u0002\u0002\u0002\u0002%\u0003\u0002\u0002\u0002\u0002",
    "\'\u0003\u0002\u0002\u0002\u0002)\u0003\u0002\u0002\u0002\u0002+\u0003",
    "\u0002\u0002\u0002\u0002-\u0003\u0002\u0002\u0002\u0002/\u0003\u0002",
    "\u0002\u0002\u00021\u0003\u0002\u0002\u0002\u00023\u0003\u0002\u0002",
    "\u0002\u00025\u0003\u0002\u0002\u0002\u00027\u0003\u0002\u0002\u0002",
    "\u00029\u0003\u0002\u0002\u0002\u0002;\u0003\u0002\u0002\u0002\u0002",
    "=\u0003\u0002\u0002\u0002\u0002?\u0003\u0002\u0002\u0002\u0002A\u0003",
    "\u0002\u0002\u0002\u0002C\u0003\u0002\u0002\u0002\u0002E\u0003\u0002",
    "\u0002\u0002\u0002G\u0003\u0002\u0002\u0002\u0002I\u0003\u0002\u0002",
    "\u0002\u0002K\u0003\u0002\u0002\u0002\u0002M\u0003\u0002\u0002\u0002",
    "\u0002O\u0003\u0002\u0002\u0002\u0002Q\u0003\u0002\u0002\u0002\u0002",
    "S\u0003\u0002\u0002\u0002\u0002U\u0003\u0002\u0002\u0002\u0002W\u0003",
    "\u0002\u0002\u0002\u0002Y\u0003\u0002\u0002\u0002\u0002[\u0003\u0002",
    "\u0002\u0002\u0002]\u0003\u0002\u0002\u0002\u0002_\u0003\u0002\u0002",
    "\u0002\u0002a\u0003\u0002\u0002\u0002\u0002c\u0003\u0002\u0002\u0002",
    "\u0002e\u0003\u0002\u0002\u0002\u0002g\u0003\u0002\u0002\u0002\u0002",
    "i\u0003\u0002\u0002\u0002\u0002k\u0003\u0002\u0002\u0002\u0002m\u0003",
    "\u0002\u0002\u0002\u0002o\u0003\u0002\u0002\u0002\u0002q\u0003\u0002",
    "\u0002\u0002\u0002u\u0003\u0002\u0002\u0002\u0002w\u0003\u0002\u0002",
    "\u0002\u0002y\u0003\u0002\u0002\u0002\u0002{\u0003\u0002\u0002\u0002",
    "\u0002}\u0003\u0002\u0002\u0002\u0002\u007f\u0003\u0002\u0002\u0002",
    "\u0002\u0081\u0003\u0002\u0002\u0002\u0003\u0089\u0003\u0002\u0002\u0002",
    "\u0005\u008b\u0003\u0002\u0002\u0002\u0007\u008d\u0003\u0002\u0002\u0002",
    "\t\u008f\u0003\u0002\u0002\u0002\u000b\u0091\u0003\u0002\u0002\u0002",
    "\r\u0093\u0003\u0002\u0002\u0002\u000f\u0095\u0003\u0002\u0002\u0002",
    "\u0011\u0097\u0003\u0002\u0002\u0002\u0013\u009b\u0003\u0002\u0002\u0002",
    "\u0015\u009f\u0003\u0002\u0002\u0002\u0017\u00a1\u0003\u0002\u0002\u0002",
    "\u0019\u00a3\u0003\u0002\u0002\u0002\u001b\u00a6\u0003\u0002\u0002\u0002",
    "\u001d\u00a8\u0003\u0002\u0002\u0002\u001f\u00aa\u0003\u0002\u0002\u0002",
    "!\u00ad\u0003\u0002\u0002\u0002#\u00b0\u0003\u0002\u0002\u0002%\u00b3",
    "\u0003\u0002\u0002\u0002\'\u00b5\u0003\u0002\u0002\u0002)\u00b7\u0003",
    "\u0002\u0002\u0002+\u00ba\u0003\u0002\u0002\u0002-\u00bd\u0003\u0002",
    "\u0002\u0002/\u00c0\u0003\u0002\u0002\u00021\u00c9\u0003\u0002\u0002",
    "\u00023\u00cd\u0003\u0002\u0002\u00025\u00d0\u0003\u0002\u0002\u0002",
    "7\u00d4\u0003\u0002\u0002\u00029\u00dc\u0003\u0002\u0002\u0002;\u00de",
    "\u0003\u0002\u0002\u0002=\u00e0\u0003\u0002\u0002\u0002?\u00e2\u0003",
    "\u0002\u0002\u0002A\u00e4\u0003\u0002\u0002\u0002C\u00e9\u0003\u0002",
    "\u0002\u0002E\u00ef\u0003\u0002\u0002\u0002G\u00f1\u0003\u0002\u0002",
    "\u0002I\u00f7\u0003\u0002\u0002\u0002K\u00fe\u0003\u0002\u0002\u0002",
    "M\u0105\u0003\u0002\u0002\u0002O\u0107\u0003\u0002\u0002\u0002Q\u010c",
    "\u0003\u0002\u0002\u0002S\u0112\u0003\u0002\u0002\u0002U\u0117\u0003",
    "\u0002\u0002\u0002W\u011b\u0003\u0002\u0002\u0002Y\u0120\u0003\u0002",
    "\u0002\u0002[\u0127\u0003\u0002\u0002\u0002]\u012e\u0003\u0002\u0002",
    "\u0002_\u013a\u0003\u0002\u0002\u0002a\u0140\u0003\u0002\u0002\u0002",
    "c\u0147\u0003\u0002\u0002\u0002e\u014d\u0003\u0002\u0002\u0002g\u0152",
    "\u0003\u0002\u0002\u0002i\u0158\u0003\u0002\u0002\u0002k\u0160\u0003",
    "\u0002\u0002\u0002m\u0168\u0003\u0002\u0002\u0002o\u0175\u0003\u0002",
    "\u0002\u0002q\u018b\u0003\u0002\u0002\u0002s\u018f\u0003\u0002\u0002",
    "\u0002u\u01ad\u0003\u0002\u0002\u0002w\u01b5\u0003\u0002\u0002\u0002",
    "y\u01bf\u0003\u0002\u0002\u0002{\u01ca\u0003\u0002\u0002\u0002}\u01d7",
    "\u0003\u0002\u0002\u0002\u007f\u01dd\u0003\u0002\u0002\u0002\u0081\u01eb",
    "\u0003\u0002\u0002\u0002\u0083\u01f6\u0003\u0002\u0002\u0002\u0085\u01fb",
    "\u0003\u0002\u0002\u0002\u0087\u0201\u0003\u0002\u0002\u0002\u0089\u008a",
    "\u00070\u0002\u0002\u008a\u0004\u0003\u0002\u0002\u0002\u008b\u008c",
    "\u0007]\u0002\u0002\u008c\u0006\u0003\u0002\u0002\u0002\u008d\u008e",
    "\u0007_\u0002\u0002\u008e\b\u0003\u0002\u0002\u0002\u008f\u0090\u0007",
    "-\u0002\u0002\u0090\n\u0003\u0002\u0002\u0002\u0091\u0092\u0007/\u0002",
    "\u0002\u0092\f\u0003\u0002\u0002\u0002\u0093\u0094\u0007,\u0002\u0002",
    "\u0094\u000e\u0003\u0002\u0002\u0002\u0095\u0096\u00071\u0002\u0002",
    "\u0096\u0010\u0003\u0002\u0002\u0002\u0097\u0098\u0007f\u0002\u0002",
    "\u0098\u0099\u0007k\u0002\u0002\u0099\u009a\u0007x\u0002\u0002\u009a",
    "\u0012\u0003\u0002\u0002\u0002\u009b\u009c\u0007o\u0002\u0002\u009c",
    "\u009d\u0007q\u0002\u0002\u009d\u009e\u0007f\u0002\u0002\u009e\u0014",
    "\u0003\u0002\u0002\u0002\u009f\u00a0\u0007(\u0002\u0002\u00a0\u0016",
    "\u0003\u0002\u0002\u0002\u00a1\u00a2\u0007~\u0002\u0002\u00a2\u0018",
    "\u0003\u0002\u0002\u0002\u00a3\u00a4\u0007>\u0002\u0002\u00a4\u00a5",
    "\u0007?\u0002\u0002\u00a5\u001a\u0003\u0002\u0002\u0002\u00a6\u00a7",
    "\u0007>\u0002\u0002\u00a7\u001c\u0003\u0002\u0002\u0002\u00a8\u00a9",
    "\u0007@\u0002\u0002\u00a9\u001e\u0003\u0002\u0002\u0002\u00aa\u00ab",
    "\u0007@\u0002\u0002\u00ab\u00ac\u0007?\u0002\u0002\u00ac \u0003\u0002",
    "\u0002\u0002\u00ad\u00ae\u0007k\u0002\u0002\u00ae\u00af\u0007u\u0002",
    "\u0002\u00af\"\u0003\u0002\u0002\u0002\u00b0\u00b1\u0007c\u0002\u0002",
    "\u00b1\u00b2\u0007u\u0002\u0002\u00b2$\u0003\u0002\u0002\u0002\u00b3",
    "\u00b4\u0007?\u0002\u0002\u00b4&\u0003\u0002\u0002\u0002\u00b5\u00b6",
    "\u0007\u0080\u0002\u0002\u00b6(\u0003\u0002\u0002\u0002\u00b7\u00b8",
    "\u0007#\u0002\u0002\u00b8\u00b9\u0007?\u0002\u0002\u00b9*\u0003\u0002",
    "\u0002\u0002\u00ba\u00bb\u0007#\u0002\u0002\u00bb\u00bc\u0007\u0080",
    "\u0002\u0002\u00bc,\u0003\u0002\u0002\u0002\u00bd\u00be\u0007k\u0002",
    "\u0002\u00be\u00bf\u0007p\u0002\u0002\u00bf.\u0003\u0002\u0002\u0002",
    "\u00c0\u00c1\u0007e\u0002\u0002\u00c1\u00c2\u0007q\u0002\u0002\u00c2",
    "\u00c3\u0007p\u0002\u0002\u00c3\u00c4\u0007v\u0002\u0002\u00c4\u00c5",
    "\u0007c\u0002\u0002\u00c5\u00c6\u0007k\u0002\u0002\u00c6\u00c7\u0007",
    "p\u0002\u0002\u00c7\u00c8\u0007u\u0002\u0002\u00c80\u0003\u0002\u0002",
    "\u0002\u00c9\u00ca\u0007c\u0002\u0002\u00ca\u00cb\u0007p\u0002\u0002",
    "\u00cb\u00cc\u0007f\u0002\u0002\u00cc2\u0003\u0002\u0002\u0002\u00cd",
    "\u00ce\u0007q\u0002\u0002\u00ce\u00cf\u0007t\u0002\u0002\u00cf4\u0003",
    "\u0002\u0002\u0002\u00d0\u00d1\u0007z\u0002\u0002\u00d1\u00d2\u0007",
    "q\u0002\u0002\u00d2\u00d3\u0007t\u0002\u0002\u00d36\u0003\u0002\u0002",
    "\u0002\u00d4\u00d5\u0007k\u0002\u0002\u00d5\u00d6\u0007o\u0002\u0002",
    "\u00d6\u00d7\u0007r\u0002\u0002\u00d7\u00d8\u0007n\u0002\u0002\u00d8",
    "\u00d9\u0007k\u0002\u0002\u00d9\u00da\u0007g\u0002\u0002\u00da\u00db",
    "\u0007u\u0002\u0002\u00db8\u0003\u0002\u0002\u0002\u00dc\u00dd\u0007",
    "*\u0002\u0002\u00dd:\u0003\u0002\u0002\u0002\u00de\u00df\u0007+\u0002",
    "\u0002\u00df<\u0003\u0002\u0002\u0002\u00e0\u00e1\u0007}\u0002\u0002",
    "\u00e1>\u0003\u0002\u0002\u0002\u00e2\u00e3\u0007\u007f\u0002\u0002",
    "\u00e3@\u0003\u0002\u0002\u0002\u00e4\u00e5\u0007v\u0002\u0002\u00e5",
    "\u00e6\u0007t\u0002\u0002\u00e6\u00e7\u0007w\u0002\u0002\u00e7\u00e8",
    "\u0007g\u0002\u0002\u00e8B\u0003\u0002\u0002\u0002\u00e9\u00ea\u0007",
    "h\u0002\u0002\u00ea\u00eb\u0007c\u0002\u0002\u00eb\u00ec\u0007n\u0002",
    "\u0002\u00ec\u00ed\u0007u\u0002\u0002\u00ed\u00ee\u0007g\u0002\u0002",
    "\u00eeD\u0003\u0002\u0002\u0002\u00ef\u00f0\u0007\'\u0002\u0002\u00f0",
    "F\u0003\u0002\u0002\u0002\u00f1\u00f2\u0007&\u0002\u0002\u00f2\u00f3",
    "\u0007v\u0002\u0002\u00f3\u00f4\u0007j\u0002\u0002\u00f4\u00f5\u0007",
    "k\u0002\u0002\u00f5\u00f6\u0007u\u0002\u0002\u00f6H\u0003\u0002\u0002",
    "\u0002\u00f7\u00f8\u0007&\u0002\u0002\u00f8\u00f9\u0007k\u0002\u0002",
    "\u00f9\u00fa\u0007p\u0002\u0002\u00fa\u00fb\u0007f\u0002\u0002\u00fb",
    "\u00fc\u0007g\u0002\u0002\u00fc\u00fd\u0007z\u0002\u0002\u00fdJ\u0003",
    "\u0002\u0002\u0002\u00fe\u00ff\u0007&\u0002\u0002\u00ff\u0100\u0007",
    "v\u0002\u0002\u0100\u0101\u0007q\u0002\u0002\u0101\u0102\u0007v\u0002",
    "\u0002\u0102\u0103\u0007c\u0002\u0002\u0103\u0104\u0007n\u0002\u0002",
    "\u0104L\u0003\u0002\u0002\u0002\u0105\u0106\u0007.\u0002\u0002\u0106",
    "N\u0003\u0002\u0002\u0002\u0107\u0108\u0007{\u0002\u0002\u0108\u0109",
    "\u0007g\u0002\u0002\u0109\u010a\u0007c\u0002\u0002\u010a\u010b\u0007",
    "t\u0002\u0002\u010bP\u0003\u0002\u0002\u0002\u010c\u010d\u0007o\u0002",
    "\u0002\u010d\u010e\u0007q\u0002\u0002\u010e\u010f\u0007p\u0002\u0002",
    "\u010f\u0110\u0007v\u0002\u0002\u0110\u0111\u0007j\u0002\u0002\u0111",
    "R\u0003\u0002\u0002\u0002\u0112\u0113\u0007y\u0002\u0002\u0113\u0114",
    "\u0007g\u0002\u0002\u0114\u0115\u0007g\u0002\u0002\u0115\u0116\u0007",
    "m\u0002\u0002\u0116T\u0003\u0002\u0002\u0002\u0117\u0118\u0007f\u0002",
    "\u0002\u0118\u0119\u0007c\u0002\u0002\u0119\u011a\u0007{\u0002\u0002",
    "\u011aV\u0003\u0002\u0002\u0002\u011b\u011c\u0007j\u0002\u0002\u011c",
    "\u011d\u0007q\u0002\u0002\u011d\u011e\u0007w\u0002\u0002\u011e\u011f",
    "\u0007t\u0002\u0002\u011fX\u0003\u0002\u0002\u0002\u0120\u0121\u0007",
    "o\u0002\u0002\u0121\u0122\u0007k\u0002\u0002\u0122\u0123\u0007p\u0002",
    "\u0002\u0123\u0124\u0007w\u0002\u0002\u0124\u0125\u0007v\u0002\u0002",
    "\u0125\u0126\u0007g\u0002\u0002\u0126Z\u0003\u0002\u0002\u0002\u0127",
    "\u0128\u0007u\u0002\u0002\u0128\u0129\u0007g\u0002\u0002\u0129\u012a",
    "\u0007e\u0002\u0002\u012a\u012b\u0007q\u0002\u0002\u012b\u012c\u0007",
    "p\u0002\u0002\u012c\u012d\u0007f\u0002\u0002\u012d\\\u0003\u0002\u0002",
    "\u0002\u012e\u012f\u0007o\u0002\u0002\u012f\u0130\u0007k\u0002\u0002",
    "\u0130\u0131\u0007n\u0002\u0002\u0131\u0132\u0007n\u0002\u0002\u0132",
    "\u0133\u0007k\u0002\u0002\u0133\u0134\u0007u\u0002\u0002\u0134\u0135",
    "\u0007g\u0002\u0002\u0135\u0136\u0007e\u0002\u0002\u0136\u0137\u0007",
    "q\u0002\u0002\u0137\u0138\u0007p\u0002\u0002\u0138\u0139\u0007f\u0002",
    "\u0002\u0139^\u0003\u0002\u0002\u0002\u013a\u013b\u0007{\u0002\u0002",
    "\u013b\u013c\u0007g\u0002\u0002\u013c\u013d\u0007c\u0002\u0002\u013d",
    "\u013e\u0007t\u0002\u0002\u013e\u013f\u0007u\u0002\u0002\u013f`\u0003",
    "\u0002\u0002\u0002\u0140\u0141\u0007o\u0002\u0002\u0141\u0142\u0007",
    "q\u0002\u0002\u0142\u0143\u0007p\u0002\u0002\u0143\u0144\u0007v\u0002",
    "\u0002\u0144\u0145\u0007j\u0002\u0002\u0145\u0146\u0007u\u0002\u0002",
    "\u0146b\u0003\u0002\u0002\u0002\u0147\u0148\u0007y\u0002\u0002\u0148",
    "\u0149\u0007g\u0002\u0002\u0149\u014a\u0007g\u0002\u0002\u014a\u014b",
    "\u0007m\u0002\u0002\u014b\u014c\u0007u\u0002\u0002\u014cd\u0003\u0002",
    "\u0002\u0002\u014d\u014e\u0007f\u0002\u0002\u014e\u014f\u0007c\u0002",
    "\u0002\u014f\u0150\u0007{\u0002\u0002\u0150\u0151\u0007u\u0002\u0002",
    "\u0151f\u0003\u0002\u0002\u0002\u0152\u0153\u0007j\u0002\u0002\u0153",
    "\u0154\u0007q\u0002\u0002\u0154\u0155\u0007w\u0002\u0002\u0155\u0156",
    "\u0007t\u0002\u0002\u0156\u0157\u0007u\u0002\u0002\u0157h\u0003\u0002",
    "\u0002\u0002\u0158\u0159\u0007o\u0002\u0002\u0159\u015a\u0007k\u0002",
    "\u0002\u015a\u015b\u0007p\u0002\u0002\u015b\u015c\u0007w\u0002\u0002",
    "\u015c\u015d\u0007v\u0002\u0002\u015d\u015e\u0007g\u0002\u0002\u015e",
    "\u015f\u0007u\u0002\u0002\u015fj\u0003\u0002\u0002\u0002\u0160\u0161",
    "\u0007u\u0002\u0002\u0161\u0162\u0007g\u0002\u0002\u0162\u0163\u0007",
    "e\u0002\u0002\u0163\u0164\u0007q\u0002\u0002\u0164\u0165\u0007p\u0002",
    "\u0002\u0165\u0166\u0007f\u0002\u0002\u0166\u0167\u0007u\u0002\u0002",
    "\u0167l\u0003\u0002\u0002\u0002\u0168\u0169\u0007o\u0002\u0002\u0169",
    "\u016a\u0007k\u0002\u0002\u016a\u016b\u0007n\u0002\u0002\u016b\u016c",
    "\u0007n\u0002\u0002\u016c\u016d\u0007k\u0002\u0002\u016d\u016e\u0007",
    "u\u0002\u0002\u016e\u016f\u0007g\u0002\u0002\u016f\u0170\u0007e\u0002",
    "\u0002\u0170\u0171\u0007q\u0002\u0002\u0171\u0172\u0007p\u0002\u0002",
    "\u0172\u0173\u0007f\u0002\u0002\u0173\u0174\u0007u\u0002\u0002\u0174",
    "n\u0003\u0002\u0002\u0002\u0175\u0176\u0007B\u0002\u0002\u0176\u0177",
    "\t\u0002\u0002\u0002\u0177\u0178\t\u0002\u0002\u0002\u0178\u0179\t\u0002",
    "\u0002\u0002\u0179\u0186\t\u0002\u0002\u0002\u017a\u017b\u0007/\u0002",
    "\u0002\u017b\u017c\t\u0002\u0002\u0002\u017c\u0184\t\u0002\u0002\u0002",
    "\u017d\u017e\u0007/\u0002\u0002\u017e\u017f\t\u0002\u0002\u0002\u017f",
    "\u0182\t\u0002\u0002\u0002\u0180\u0181\u0007V\u0002\u0002\u0181\u0183",
    "\u0005s:\u0002\u0182\u0180\u0003\u0002\u0002\u0002\u0182\u0183\u0003",
    "\u0002\u0002\u0002\u0183\u0185\u0003\u0002\u0002\u0002\u0184\u017d\u0003",
    "\u0002\u0002\u0002\u0184\u0185\u0003\u0002\u0002\u0002\u0185\u0187\u0003",
    "\u0002\u0002\u0002\u0186\u017a\u0003\u0002\u0002\u0002\u0186\u0187\u0003",
    "\u0002\u0002\u0002\u0187\u0189\u0003\u0002\u0002\u0002\u0188\u018a\u0007",
    "\\\u0002\u0002\u0189\u0188\u0003\u0002\u0002\u0002\u0189\u018a\u0003",
    "\u0002\u0002\u0002\u018ap\u0003\u0002\u0002\u0002\u018b\u018c\u0007",
    "B\u0002\u0002\u018c\u018d\u0007V\u0002\u0002\u018d\u018e\u0005s:\u0002",
    "\u018er\u0003\u0002\u0002\u0002\u018f\u0190\t\u0002\u0002\u0002\u0190",
    "\u01a1\t\u0002\u0002\u0002\u0191\u0192\u0007<\u0002\u0002\u0192\u0193",
    "\t\u0002\u0002\u0002\u0193\u019f\t\u0002\u0002\u0002\u0194\u0195\u0007",
    "<\u0002\u0002\u0195\u0196\t\u0002\u0002\u0002\u0196\u019d\t\u0002\u0002",
    "\u0002\u0197\u0199\u00070\u0002\u0002\u0198\u019a\t\u0002\u0002\u0002",
    "\u0199\u0198\u0003\u0002\u0002\u0002\u019a\u019b\u0003\u0002\u0002\u0002",
    "\u019b\u0199\u0003\u0002\u0002\u0002\u019b\u019c\u0003\u0002\u0002\u0002",
    "\u019c\u019e\u0003\u0002\u0002\u0002\u019d\u0197\u0003\u0002\u0002\u0002",
    "\u019d\u019e\u0003\u0002\u0002\u0002\u019e\u01a0\u0003\u0002\u0002\u0002",
    "\u019f\u0194\u0003\u0002\u0002\u0002\u019f\u01a0\u0003\u0002\u0002\u0002",
    "\u01a0\u01a2\u0003\u0002\u0002\u0002\u01a1\u0191\u0003\u0002\u0002\u0002",
    "\u01a1\u01a2\u0003\u0002\u0002\u0002\u01a2\u01aa\u0003\u0002\u0002\u0002",
    "\u01a3\u01ab\u0007\\\u0002\u0002\u01a4\u01a5\t\u0003\u0002\u0002\u01a5",
    "\u01a6\t\u0002\u0002\u0002\u01a6\u01a7\t\u0002\u0002\u0002\u01a7\u01a8",
    "\u0007<\u0002\u0002\u01a8\u01a9\t\u0002\u0002\u0002\u01a9\u01ab\t\u0002",
    "\u0002\u0002\u01aa\u01a3\u0003\u0002\u0002\u0002\u01aa\u01a4\u0003\u0002",
    "\u0002\u0002\u01aa\u01ab\u0003\u0002\u0002\u0002\u01abt\u0003\u0002",
    "\u0002\u0002\u01ac\u01ae\t\u0004\u0002\u0002\u01ad\u01ac\u0003\u0002",
    "\u0002\u0002\u01ae\u01b2\u0003\u0002\u0002\u0002\u01af\u01b1\t\u0005",
    "\u0002\u0002\u01b0\u01af\u0003\u0002\u0002\u0002\u01b1\u01b4\u0003\u0002",
    "\u0002\u0002\u01b2\u01b0\u0003\u0002\u0002\u0002\u01b2\u01b3\u0003\u0002",
    "\u0002\u0002\u01b3v\u0003\u0002\u0002\u0002\u01b4\u01b2\u0003\u0002",
    "\u0002\u0002\u01b5\u01ba\u0007b\u0002\u0002\u01b6\u01b9\u0005\u0083",
    "B\u0002\u01b7\u01b9\n\u0006\u0002\u0002\u01b8\u01b6\u0003\u0002\u0002",
    "\u0002\u01b8\u01b7\u0003\u0002\u0002\u0002\u01b9\u01bc\u0003\u0002\u0002",
    "\u0002\u01ba\u01b8\u0003\u0002\u0002\u0002\u01ba\u01bb\u0003\u0002\u0002",
    "\u0002\u01bb\u01bd\u0003\u0002\u0002\u0002\u01bc\u01ba\u0003\u0002\u0002",
    "\u0002\u01bd\u01be\u0007b\u0002\u0002\u01bex\u0003\u0002\u0002\u0002",
    "\u01bf\u01c4\u0007)\u0002\u0002\u01c0\u01c3\u0005\u0083B\u0002\u01c1",
    "\u01c3\n\u0007\u0002\u0002\u01c2\u01c0\u0003\u0002\u0002\u0002\u01c2",
    "\u01c1\u0003\u0002\u0002\u0002\u01c3\u01c6\u0003\u0002\u0002\u0002\u01c4",
    "\u01c2\u0003\u0002\u0002\u0002\u01c4\u01c5\u0003\u0002\u0002\u0002\u01c5",
    "\u01c7\u0003\u0002\u0002\u0002\u01c6\u01c4\u0003\u0002\u0002\u0002\u01c7",
    "\u01c8\u0007)\u0002\u0002\u01c8z\u0003\u0002\u0002\u0002\u01c9\u01cb",
    "\t\u0002\u0002\u0002\u01ca\u01c9\u0003\u0002\u0002\u0002\u01cb\u01cc",
    "\u0003\u0002\u0002\u0002\u01cc\u01ca\u0003\u0002\u0002\u0002\u01cc\u01cd",
    "\u0003\u0002\u0002\u0002\u01cd\u01d4\u0003\u0002\u0002\u0002\u01ce\u01d0",
    "\u00070\u0002\u0002\u01cf\u01d1\t\u0002\u0002\u0002\u01d0\u01cf\u0003",
    "\u0002\u0002\u0002\u01d1\u01d2\u0003\u0002\u0002\u0002\u01d2\u01d0\u0003",
    "\u0002\u0002\u0002\u01d2\u01d3\u0003\u0002\u0002\u0002\u01d3\u01d5\u0003",
    "\u0002\u0002\u0002\u01d4\u01ce\u0003\u0002\u0002\u0002\u01d4\u01d5\u0003",
    "\u0002\u0002\u0002\u01d5|\u0003\u0002\u0002\u0002\u01d6\u01d8\t\b\u0002",
    "\u0002\u01d7\u01d6\u0003\u0002\u0002\u0002\u01d8\u01d9\u0003\u0002\u0002",
    "\u0002\u01d9\u01d7\u0003\u0002\u0002\u0002\u01d9\u01da\u0003\u0002\u0002",
    "\u0002\u01da\u01db\u0003\u0002\u0002\u0002\u01db\u01dc\b?\u0002\u0002",
    "\u01dc~\u0003\u0002\u0002\u0002\u01dd\u01de\u00071\u0002\u0002\u01de",
    "\u01df\u0007,\u0002\u0002\u01df\u01e3\u0003\u0002\u0002\u0002\u01e0",
    "\u01e2\u000b\u0002\u0002\u0002\u01e1\u01e0\u0003\u0002\u0002\u0002\u01e2",
    "\u01e5\u0003\u0002\u0002\u0002\u01e3\u01e4\u0003\u0002\u0002\u0002\u01e3",
    "\u01e1\u0003\u0002\u0002\u0002\u01e4\u01e6\u0003\u0002\u0002\u0002\u01e5",
    "\u01e3\u0003\u0002\u0002\u0002\u01e6\u01e7\u0007,\u0002\u0002\u01e7",
    "\u01e8\u00071\u0002\u0002\u01e8\u01e9\u0003\u0002\u0002\u0002\u01e9",
    "\u01ea\b@\u0002\u0002\u01ea\u0080\u0003\u0002\u0002\u0002\u01eb\u01ec",
    "\u00071\u0002\u0002\u01ec\u01ed\u00071\u0002\u0002\u01ed\u01f1\u0003",
    "\u0002\u0002\u0002\u01ee\u01f0\n\t\u0002\u0002\u01ef\u01ee\u0003\u0002",
    "\u0002\u0002\u01f0\u01f3\u0003\u0002\u0002\u0002\u01f1\u01ef\u0003\u0002",
    "\u0002\u0002\u01f1\u01f2\u0003\u0002\u0002\u0002\u01f2\u01f4\u0003\u0002",
    "\u0002\u0002\u01f3\u01f1\u0003\u0002\u0002\u0002\u01f4\u01f5\bA\u0002",
    "\u0002\u01f5\u0082\u0003\u0002\u0002\u0002\u01f6\u01f9\u0007^\u0002",
    "\u0002\u01f7\u01fa\t\n\u0002\u0002\u01f8\u01fa\u0005\u0085C\u0002\u01f9",
    "\u01f7\u0003\u0002\u0002\u0002\u01f9\u01f8\u0003\u0002\u0002\u0002\u01fa",
    "\u0084\u0003\u0002\u0002\u0002\u01fb\u01fc\u0007w\u0002\u0002\u01fc",
    "\u01fd\u0005\u0087D\u0002\u01fd\u01fe\u0005\u0087D\u0002\u01fe\u01ff",
    "\u0005\u0087D\u0002\u01ff\u0200\u0005\u0087D\u0002\u0200\u0086\u0003",
    "\u0002\u0002\u0002\u0201\u0202\t\u000b\u0002\u0002\u0202\u0088\u0003",
    "\u0002\u0002\u0002\u001a\u0002\u0182\u0184\u0186\u0189\u019b\u019d\u019f",
    "\u01a1\u01aa\u01ad\u01b0\u01b2\u01b8\u01ba\u01c2\u01c4\u01cc\u01d2\u01d4",
    "\u01d9\u01e3\u01f1\u01f9\u0003\u0002\u0003\u0002"].join("");


const atn$1 = new antlr4$3.atn.ATNDeserializer().deserialize(serializedATN$1);

const decisionsToDFA$1 = atn$1.decisionToState.map( (ds, index) => new antlr4$3.dfa.DFA(ds, index) );

class FHIRPathLexer extends antlr4$3.Lexer {

    static grammarFileName = "FHIRPath.g4";
    static channelNames = [ "DEFAULT_TOKEN_CHANNEL", "HIDDEN" ];
	static modeNames = [ "DEFAULT_MODE" ];
	static literalNames = [ null, "'.'", "'['", "']'", "'+'", "'-'", "'*'", 
                         "'/'", "'div'", "'mod'", "'&'", "'|'", "'<='", 
                         "'<'", "'>'", "'>='", "'is'", "'as'", "'='", "'~'", 
                         "'!='", "'!~'", "'in'", "'contains'", "'and'", 
                         "'or'", "'xor'", "'implies'", "'('", "')'", "'{'", 
                         "'}'", "'true'", "'false'", "'%'", "'$this'", "'$index'", 
                         "'$total'", "','", "'year'", "'month'", "'week'", 
                         "'day'", "'hour'", "'minute'", "'second'", "'millisecond'", 
                         "'years'", "'months'", "'weeks'", "'days'", "'hours'", 
                         "'minutes'", "'seconds'", "'milliseconds'" ];
	static symbolicNames = [ null, null, null, null, null, null, null, null, 
                          null, null, null, null, null, null, null, null, 
                          null, null, null, null, null, null, null, null, 
                          null, null, null, null, null, null, null, null, 
                          null, null, null, null, null, null, null, null, 
                          null, null, null, null, null, null, null, null, 
                          null, null, null, null, null, null, null, "DATETIME", 
                          "TIME", "IDENTIFIER", "DELIMITEDIDENTIFIER", "STRING", 
                          "NUMBER", "WS", "COMMENT", "LINE_COMMENT" ];
	static ruleNames = [ "T__0", "T__1", "T__2", "T__3", "T__4", "T__5", "T__6", 
                      "T__7", "T__8", "T__9", "T__10", "T__11", "T__12", 
                      "T__13", "T__14", "T__15", "T__16", "T__17", "T__18", 
                      "T__19", "T__20", "T__21", "T__22", "T__23", "T__24", 
                      "T__25", "T__26", "T__27", "T__28", "T__29", "T__30", 
                      "T__31", "T__32", "T__33", "T__34", "T__35", "T__36", 
                      "T__37", "T__38", "T__39", "T__40", "T__41", "T__42", 
                      "T__43", "T__44", "T__45", "T__46", "T__47", "T__48", 
                      "T__49", "T__50", "T__51", "T__52", "T__53", "DATETIME", 
                      "TIME", "TIMEFORMAT", "IDENTIFIER", "DELIMITEDIDENTIFIER", 
                      "STRING", "NUMBER", "WS", "COMMENT", "LINE_COMMENT", 
                      "ESC", "UNICODE", "HEX" ];

    constructor(input) {
        super(input);
        this._interp = new antlr4$3.atn.LexerATNSimulator(this, atn$1, decisionsToDFA$1, new antlr4$3.PredictionContextCache());
    }

    get atn() {
        return atn$1;
    }
}

FHIRPathLexer.EOF = antlr4$3.Token.EOF;
FHIRPathLexer.T__0 = 1;
FHIRPathLexer.T__1 = 2;
FHIRPathLexer.T__2 = 3;
FHIRPathLexer.T__3 = 4;
FHIRPathLexer.T__4 = 5;
FHIRPathLexer.T__5 = 6;
FHIRPathLexer.T__6 = 7;
FHIRPathLexer.T__7 = 8;
FHIRPathLexer.T__8 = 9;
FHIRPathLexer.T__9 = 10;
FHIRPathLexer.T__10 = 11;
FHIRPathLexer.T__11 = 12;
FHIRPathLexer.T__12 = 13;
FHIRPathLexer.T__13 = 14;
FHIRPathLexer.T__14 = 15;
FHIRPathLexer.T__15 = 16;
FHIRPathLexer.T__16 = 17;
FHIRPathLexer.T__17 = 18;
FHIRPathLexer.T__18 = 19;
FHIRPathLexer.T__19 = 20;
FHIRPathLexer.T__20 = 21;
FHIRPathLexer.T__21 = 22;
FHIRPathLexer.T__22 = 23;
FHIRPathLexer.T__23 = 24;
FHIRPathLexer.T__24 = 25;
FHIRPathLexer.T__25 = 26;
FHIRPathLexer.T__26 = 27;
FHIRPathLexer.T__27 = 28;
FHIRPathLexer.T__28 = 29;
FHIRPathLexer.T__29 = 30;
FHIRPathLexer.T__30 = 31;
FHIRPathLexer.T__31 = 32;
FHIRPathLexer.T__32 = 33;
FHIRPathLexer.T__33 = 34;
FHIRPathLexer.T__34 = 35;
FHIRPathLexer.T__35 = 36;
FHIRPathLexer.T__36 = 37;
FHIRPathLexer.T__37 = 38;
FHIRPathLexer.T__38 = 39;
FHIRPathLexer.T__39 = 40;
FHIRPathLexer.T__40 = 41;
FHIRPathLexer.T__41 = 42;
FHIRPathLexer.T__42 = 43;
FHIRPathLexer.T__43 = 44;
FHIRPathLexer.T__44 = 45;
FHIRPathLexer.T__45 = 46;
FHIRPathLexer.T__46 = 47;
FHIRPathLexer.T__47 = 48;
FHIRPathLexer.T__48 = 49;
FHIRPathLexer.T__49 = 50;
FHIRPathLexer.T__50 = 51;
FHIRPathLexer.T__51 = 52;
FHIRPathLexer.T__52 = 53;
FHIRPathLexer.T__53 = 54;
FHIRPathLexer.DATETIME = 55;
FHIRPathLexer.TIME = 56;
FHIRPathLexer.IDENTIFIER = 57;
FHIRPathLexer.DELIMITEDIDENTIFIER = 58;
FHIRPathLexer.STRING = 59;
FHIRPathLexer.NUMBER = 60;
FHIRPathLexer.WS = 61;
FHIRPathLexer.COMMENT = 62;
FHIRPathLexer.LINE_COMMENT = 63;




var FHIRPathLexer_1 = FHIRPathLexer;

// Generated from FHIRPath.g4 by ANTLR 4.9.3
// jshint ignore: start
const antlr4$2 = antlr4Index;

// This class defines a complete listener for a parse tree produced by FHIRPathParser.
let FHIRPathListener$1 = class FHIRPathListener extends antlr4$2.tree.ParseTreeListener {

	// Enter a parse tree produced by FHIRPathParser#entireExpression.
	enterEntireExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#entireExpression.
	exitEntireExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#indexerExpression.
	enterIndexerExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#indexerExpression.
	exitIndexerExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#polarityExpression.
	enterPolarityExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#polarityExpression.
	exitPolarityExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#additiveExpression.
	enterAdditiveExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#additiveExpression.
	exitAdditiveExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#multiplicativeExpression.
	enterMultiplicativeExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#multiplicativeExpression.
	exitMultiplicativeExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#unionExpression.
	enterUnionExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#unionExpression.
	exitUnionExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#orExpression.
	enterOrExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#orExpression.
	exitOrExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#andExpression.
	enterAndExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#andExpression.
	exitAndExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#membershipExpression.
	enterMembershipExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#membershipExpression.
	exitMembershipExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#inequalityExpression.
	enterInequalityExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#inequalityExpression.
	exitInequalityExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#invocationExpression.
	enterInvocationExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#invocationExpression.
	exitInvocationExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#equalityExpression.
	enterEqualityExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#equalityExpression.
	exitEqualityExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#impliesExpression.
	enterImpliesExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#impliesExpression.
	exitImpliesExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#termExpression.
	enterTermExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#termExpression.
	exitTermExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#typeExpression.
	enterTypeExpression(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#typeExpression.
	exitTypeExpression(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#invocationTerm.
	enterInvocationTerm(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#invocationTerm.
	exitInvocationTerm(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#literalTerm.
	enterLiteralTerm(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#literalTerm.
	exitLiteralTerm(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#externalConstantTerm.
	enterExternalConstantTerm(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#externalConstantTerm.
	exitExternalConstantTerm(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#parenthesizedTerm.
	enterParenthesizedTerm(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#parenthesizedTerm.
	exitParenthesizedTerm(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#nullLiteral.
	enterNullLiteral(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#nullLiteral.
	exitNullLiteral(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#booleanLiteral.
	enterBooleanLiteral(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#booleanLiteral.
	exitBooleanLiteral(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#stringLiteral.
	enterStringLiteral(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#stringLiteral.
	exitStringLiteral(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#numberLiteral.
	enterNumberLiteral(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#numberLiteral.
	exitNumberLiteral(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#dateTimeLiteral.
	enterDateTimeLiteral(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#dateTimeLiteral.
	exitDateTimeLiteral(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#timeLiteral.
	enterTimeLiteral(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#timeLiteral.
	exitTimeLiteral(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#quantityLiteral.
	enterQuantityLiteral(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#quantityLiteral.
	exitQuantityLiteral(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#externalConstant.
	enterExternalConstant(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#externalConstant.
	exitExternalConstant(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#memberInvocation.
	enterMemberInvocation(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#memberInvocation.
	exitMemberInvocation(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#functionInvocation.
	enterFunctionInvocation(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#functionInvocation.
	exitFunctionInvocation(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#thisInvocation.
	enterThisInvocation(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#thisInvocation.
	exitThisInvocation(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#indexInvocation.
	enterIndexInvocation(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#indexInvocation.
	exitIndexInvocation(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#totalInvocation.
	enterTotalInvocation(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#totalInvocation.
	exitTotalInvocation(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#functn.
	enterFunctn(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#functn.
	exitFunctn(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#paramList.
	enterParamList(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#paramList.
	exitParamList(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#quantity.
	enterQuantity(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#quantity.
	exitQuantity(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#unit.
	enterUnit(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#unit.
	exitUnit(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#dateTimePrecision.
	enterDateTimePrecision(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#dateTimePrecision.
	exitDateTimePrecision(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#pluralDateTimePrecision.
	enterPluralDateTimePrecision(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#pluralDateTimePrecision.
	exitPluralDateTimePrecision(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#typeSpecifier.
	enterTypeSpecifier(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#typeSpecifier.
	exitTypeSpecifier(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#qualifiedIdentifier.
	enterQualifiedIdentifier(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#qualifiedIdentifier.
	exitQualifiedIdentifier(ctx) {
	}


	// Enter a parse tree produced by FHIRPathParser#identifier.
	enterIdentifier(ctx) {
	}

	// Exit a parse tree produced by FHIRPathParser#identifier.
	exitIdentifier(ctx) {
	}



};
var FHIRPathListener_1 = FHIRPathListener$1;

// Generated from FHIRPath.g4 by ANTLR 4.9.3
// jshint ignore: start
const antlr4$1 = antlr4Index;
const FHIRPathListener = FHIRPathListener_1;

const serializedATN = ["\u0003\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786",
    "\u5964\u0003A\u009c\u0004\u0002\t\u0002\u0004\u0003\t\u0003\u0004\u0004",
    "\t\u0004\u0004\u0005\t\u0005\u0004\u0006\t\u0006\u0004\u0007\t\u0007",
    "\u0004\b\t\b\u0004\t\t\t\u0004\n\t\n\u0004\u000b\t\u000b\u0004\f\t\f",
    "\u0004\r\t\r\u0004\u000e\t\u000e\u0004\u000f\t\u000f\u0004\u0010\t\u0010",
    "\u0003\u0002\u0003\u0002\u0003\u0002\u0003\u0003\u0003\u0003\u0003\u0003",
    "\u0003\u0003\u0005\u0003(\n\u0003\u0003\u0003\u0003\u0003\u0003\u0003",
    "\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003",
    "\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003",
    "\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003",
    "\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003",
    "\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003",
    "\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0003\u0007\u0003",
    "P\n\u0003\f\u0003\u000e\u0003S\u000b\u0003\u0003\u0004\u0003\u0004\u0003",
    "\u0004\u0003\u0004\u0003\u0004\u0003\u0004\u0003\u0004\u0005\u0004\\",
    "\n\u0004\u0003\u0005\u0003\u0005\u0003\u0005\u0003\u0005\u0003\u0005",
    "\u0003\u0005\u0003\u0005\u0003\u0005\u0005\u0005f\n\u0005\u0003\u0006",
    "\u0003\u0006\u0003\u0006\u0005\u0006k\n\u0006\u0003\u0007\u0003\u0007",
    "\u0003\u0007\u0003\u0007\u0003\u0007\u0005\u0007r\n\u0007\u0003\b\u0003",
    "\b\u0003\b\u0005\bw\n\b\u0003\b\u0003\b\u0003\t\u0003\t\u0003\t\u0007",
    "\t~\n\t\f\t\u000e\t\u0081\u000b\t\u0003\n\u0003\n\u0005\n\u0085\n\n",
    "\u0003\u000b\u0003\u000b\u0003\u000b\u0005\u000b\u008a\n\u000b\u0003",
    "\f\u0003\f\u0003\r\u0003\r\u0003\u000e\u0003\u000e\u0003\u000f\u0003",
    "\u000f\u0003\u000f\u0007\u000f\u0095\n\u000f\f\u000f\u000e\u000f\u0098",
    "\u000b\u000f\u0003\u0010\u0003\u0010\u0003\u0010\u0002\u0003\u0004\u0011",
    "\u0002\u0004\u0006\b\n\f\u000e\u0010\u0012\u0014\u0016\u0018\u001a\u001c",
    "\u001e\u0002\u000e\u0003\u0002\u0006\u0007\u0003\u0002\b\u000b\u0004",
    "\u0002\u0006\u0007\f\f\u0003\u0002\u000e\u0011\u0003\u0002\u0014\u0017",
    "\u0003\u0002\u0018\u0019\u0003\u0002\u001b\u001c\u0003\u0002\u0012\u0013",
    "\u0003\u0002\"#\u0003\u0002)0\u0003\u000218\u0005\u0002\u0012\u0013",
    "\u0018\u0019;<\u0002\u00ad\u0002 \u0003\u0002\u0002\u0002\u0004\'\u0003",
    "\u0002\u0002\u0002\u0006[\u0003\u0002\u0002\u0002\be\u0003\u0002\u0002",
    "\u0002\ng\u0003\u0002\u0002\u0002\fq\u0003\u0002\u0002\u0002\u000es",
    "\u0003\u0002\u0002\u0002\u0010z\u0003\u0002\u0002\u0002\u0012\u0082",
    "\u0003\u0002\u0002\u0002\u0014\u0089\u0003\u0002\u0002\u0002\u0016\u008b",
    "\u0003\u0002\u0002\u0002\u0018\u008d\u0003\u0002\u0002\u0002\u001a\u008f",
    "\u0003\u0002\u0002\u0002\u001c\u0091\u0003\u0002\u0002\u0002\u001e\u0099",
    "\u0003\u0002\u0002\u0002 !\u0005\u0004\u0003\u0002!\"\u0007\u0002\u0002",
    "\u0003\"\u0003\u0003\u0002\u0002\u0002#$\b\u0003\u0001\u0002$(\u0005",
    "\u0006\u0004\u0002%&\t\u0002\u0002\u0002&(\u0005\u0004\u0003\r\'#\u0003",
    "\u0002\u0002\u0002\'%\u0003\u0002\u0002\u0002(Q\u0003\u0002\u0002\u0002",
    ")*\f\f\u0002\u0002*+\t\u0003\u0002\u0002+P\u0005\u0004\u0003\r,-\f\u000b",
    "\u0002\u0002-.\t\u0004\u0002\u0002.P\u0005\u0004\u0003\f/0\f\n\u0002",
    "\u000201\u0007\r\u0002\u00021P\u0005\u0004\u0003\u000b23\f\t\u0002\u0002",
    "34\t\u0005\u0002\u00024P\u0005\u0004\u0003\n56\f\u0007\u0002\u00026",
    "7\t\u0006\u0002\u00027P\u0005\u0004\u0003\b89\f\u0006\u0002\u00029:",
    "\t\u0007\u0002\u0002:P\u0005\u0004\u0003\u0007;<\f\u0005\u0002\u0002",
    "<=\u0007\u001a\u0002\u0002=P\u0005\u0004\u0003\u0006>?\f\u0004\u0002",
    "\u0002?@\t\b\u0002\u0002@P\u0005\u0004\u0003\u0005AB\f\u0003\u0002\u0002",
    "BC\u0007\u001d\u0002\u0002CP\u0005\u0004\u0003\u0004DE\f\u000f\u0002",
    "\u0002EF\u0007\u0003\u0002\u0002FP\u0005\f\u0007\u0002GH\f\u000e\u0002",
    "\u0002HI\u0007\u0004\u0002\u0002IJ\u0005\u0004\u0003\u0002JK\u0007\u0005",
    "\u0002\u0002KP\u0003\u0002\u0002\u0002LM\f\b\u0002\u0002MN\t\t\u0002",
    "\u0002NP\u0005\u001a\u000e\u0002O)\u0003\u0002\u0002\u0002O,\u0003\u0002",
    "\u0002\u0002O/\u0003\u0002\u0002\u0002O2\u0003\u0002\u0002\u0002O5\u0003",
    "\u0002\u0002\u0002O8\u0003\u0002\u0002\u0002O;\u0003\u0002\u0002\u0002",
    "O>\u0003\u0002\u0002\u0002OA\u0003\u0002\u0002\u0002OD\u0003\u0002\u0002",
    "\u0002OG\u0003\u0002\u0002\u0002OL\u0003\u0002\u0002\u0002PS\u0003\u0002",
    "\u0002\u0002QO\u0003\u0002\u0002\u0002QR\u0003\u0002\u0002\u0002R\u0005",
    "\u0003\u0002\u0002\u0002SQ\u0003\u0002\u0002\u0002T\\\u0005\f\u0007",
    "\u0002U\\\u0005\b\u0005\u0002V\\\u0005\n\u0006\u0002WX\u0007\u001e\u0002",
    "\u0002XY\u0005\u0004\u0003\u0002YZ\u0007\u001f\u0002\u0002Z\\\u0003",
    "\u0002\u0002\u0002[T\u0003\u0002\u0002\u0002[U\u0003\u0002\u0002\u0002",
    "[V\u0003\u0002\u0002\u0002[W\u0003\u0002\u0002\u0002\\\u0007\u0003\u0002",
    "\u0002\u0002]^\u0007 \u0002\u0002^f\u0007!\u0002\u0002_f\t\n\u0002\u0002",
    "`f\u0007=\u0002\u0002af\u0007>\u0002\u0002bf\u00079\u0002\u0002cf\u0007",
    ":\u0002\u0002df\u0005\u0012\n\u0002e]\u0003\u0002\u0002\u0002e_\u0003",
    "\u0002\u0002\u0002e`\u0003\u0002\u0002\u0002ea\u0003\u0002\u0002\u0002",
    "eb\u0003\u0002\u0002\u0002ec\u0003\u0002\u0002\u0002ed\u0003\u0002\u0002",
    "\u0002f\t\u0003\u0002\u0002\u0002gj\u0007$\u0002\u0002hk\u0005\u001e",
    "\u0010\u0002ik\u0007=\u0002\u0002jh\u0003\u0002\u0002\u0002ji\u0003",
    "\u0002\u0002\u0002k\u000b\u0003\u0002\u0002\u0002lr\u0005\u001e\u0010",
    "\u0002mr\u0005\u000e\b\u0002nr\u0007%\u0002\u0002or\u0007&\u0002\u0002",
    "pr\u0007\'\u0002\u0002ql\u0003\u0002\u0002\u0002qm\u0003\u0002\u0002",
    "\u0002qn\u0003\u0002\u0002\u0002qo\u0003\u0002\u0002\u0002qp\u0003\u0002",
    "\u0002\u0002r\r\u0003\u0002\u0002\u0002st\u0005\u001e\u0010\u0002tv",
    "\u0007\u001e\u0002\u0002uw\u0005\u0010\t\u0002vu\u0003\u0002\u0002\u0002",
    "vw\u0003\u0002\u0002\u0002wx\u0003\u0002\u0002\u0002xy\u0007\u001f\u0002",
    "\u0002y\u000f\u0003\u0002\u0002\u0002z\u007f\u0005\u0004\u0003\u0002",
    "{|\u0007(\u0002\u0002|~\u0005\u0004\u0003\u0002}{\u0003\u0002\u0002",
    "\u0002~\u0081\u0003\u0002\u0002\u0002\u007f}\u0003\u0002\u0002\u0002",
    "\u007f\u0080\u0003\u0002\u0002\u0002\u0080\u0011\u0003\u0002\u0002\u0002",
    "\u0081\u007f\u0003\u0002\u0002\u0002\u0082\u0084\u0007>\u0002\u0002",
    "\u0083\u0085\u0005\u0014\u000b\u0002\u0084\u0083\u0003\u0002\u0002\u0002",
    "\u0084\u0085\u0003\u0002\u0002\u0002\u0085\u0013\u0003\u0002\u0002\u0002",
    "\u0086\u008a\u0005\u0016\f\u0002\u0087\u008a\u0005\u0018\r\u0002\u0088",
    "\u008a\u0007=\u0002\u0002\u0089\u0086\u0003\u0002\u0002\u0002\u0089",
    "\u0087\u0003\u0002\u0002\u0002\u0089\u0088\u0003\u0002\u0002\u0002\u008a",
    "\u0015\u0003\u0002\u0002\u0002\u008b\u008c\t\u000b\u0002\u0002\u008c",
    "\u0017\u0003\u0002\u0002\u0002\u008d\u008e\t\f\u0002\u0002\u008e\u0019",
    "\u0003\u0002\u0002\u0002\u008f\u0090\u0005\u001c\u000f\u0002\u0090\u001b",
    "\u0003\u0002\u0002\u0002\u0091\u0096\u0005\u001e\u0010\u0002\u0092\u0093",
    "\u0007\u0003\u0002\u0002\u0093\u0095\u0005\u001e\u0010\u0002\u0094\u0092",
    "\u0003\u0002\u0002\u0002\u0095\u0098\u0003\u0002\u0002\u0002\u0096\u0094",
    "\u0003\u0002\u0002\u0002\u0096\u0097\u0003\u0002\u0002\u0002\u0097\u001d",
    "\u0003\u0002\u0002\u0002\u0098\u0096\u0003\u0002\u0002\u0002\u0099\u009a",
    "\t\r\u0002\u0002\u009a\u001f\u0003\u0002\u0002\u0002\u000e\'OQ[ejqv",
    "\u007f\u0084\u0089\u0096"].join("");


const atn = new antlr4$1.atn.ATNDeserializer().deserialize(serializedATN);

const decisionsToDFA = atn.decisionToState.map( (ds, index) => new antlr4$1.dfa.DFA(ds, index) );

const sharedContextCache = new antlr4$1.PredictionContextCache();

class FHIRPathParser extends antlr4$1.Parser {

    static grammarFileName = "FHIRPath.g4";
    static literalNames = [ null, "'.'", "'['", "']'", "'+'", "'-'", "'*'", 
                            "'/'", "'div'", "'mod'", "'&'", "'|'", "'<='", 
                            "'<'", "'>'", "'>='", "'is'", "'as'", "'='", 
                            "'~'", "'!='", "'!~'", "'in'", "'contains'", 
                            "'and'", "'or'", "'xor'", "'implies'", "'('", 
                            "')'", "'{'", "'}'", "'true'", "'false'", "'%'", 
                            "'$this'", "'$index'", "'$total'", "','", "'year'", 
                            "'month'", "'week'", "'day'", "'hour'", "'minute'", 
                            "'second'", "'millisecond'", "'years'", "'months'", 
                            "'weeks'", "'days'", "'hours'", "'minutes'", 
                            "'seconds'", "'milliseconds'" ];
    static symbolicNames = [ null, null, null, null, null, null, null, null, 
                             null, null, null, null, null, null, null, null, 
                             null, null, null, null, null, null, null, null, 
                             null, null, null, null, null, null, null, null, 
                             null, null, null, null, null, null, null, null, 
                             null, null, null, null, null, null, null, null, 
                             null, null, null, null, null, null, null, "DATETIME", 
                             "TIME", "IDENTIFIER", "DELIMITEDIDENTIFIER", 
                             "STRING", "NUMBER", "WS", "COMMENT", "LINE_COMMENT" ];
    static ruleNames = [ "entireExpression", "expression", "term", "literal", 
                         "externalConstant", "invocation", "functn", "paramList", 
                         "quantity", "unit", "dateTimePrecision", "pluralDateTimePrecision", 
                         "typeSpecifier", "qualifiedIdentifier", "identifier" ];

    constructor(input) {
        super(input);
        this._interp = new antlr4$1.atn.ParserATNSimulator(this, atn, decisionsToDFA, sharedContextCache);
        this.ruleNames = FHIRPathParser.ruleNames;
        this.literalNames = FHIRPathParser.literalNames;
        this.symbolicNames = FHIRPathParser.symbolicNames;
    }

    get atn() {
        return atn;
    }

    sempred(localctx, ruleIndex, predIndex) {
    	switch(ruleIndex) {
    	case 1:
    	    		return this.expression_sempred(localctx, predIndex);
        default:
            throw "No predicate with index:" + ruleIndex;
       }
    }

    expression_sempred(localctx, predIndex) {
    	switch(predIndex) {
    		case 0:
    			return this.precpred(this._ctx, 10);
    		case 1:
    			return this.precpred(this._ctx, 9);
    		case 2:
    			return this.precpred(this._ctx, 8);
    		case 3:
    			return this.precpred(this._ctx, 7);
    		case 4:
    			return this.precpred(this._ctx, 5);
    		case 5:
    			return this.precpred(this._ctx, 4);
    		case 6:
    			return this.precpred(this._ctx, 3);
    		case 7:
    			return this.precpred(this._ctx, 2);
    		case 8:
    			return this.precpred(this._ctx, 1);
    		case 9:
    			return this.precpred(this._ctx, 13);
    		case 10:
    			return this.precpred(this._ctx, 12);
    		case 11:
    			return this.precpred(this._ctx, 6);
    		default:
    			throw "No predicate with index:" + predIndex;
    	}
    };




	entireExpression() {
	    let localctx = new EntireExpressionContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 0, FHIRPathParser.RULE_entireExpression);
	    try {
	        this.enterOuterAlt(localctx, 1);
	        this.state = 30;
	        this.expression(0);
	        this.state = 31;
	        this.match(FHIRPathParser.EOF);
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}


	expression(_p) {
		if(_p===undefined) {
		    _p = 0;
		}
	    const _parentctx = this._ctx;
	    const _parentState = this.state;
	    let localctx = new ExpressionContext(this, this._ctx, _parentState);
	    let _prevctx = localctx;
	    const _startState = 2;
	    this.enterRecursionRule(localctx, 2, FHIRPathParser.RULE_expression, _p);
	    var _la = 0; // Token type
	    try {
	        this.enterOuterAlt(localctx, 1);
	        this.state = 37;
	        this._errHandler.sync(this);
	        switch(this._input.LA(1)) {
	        case FHIRPathParser.T__15:
	        case FHIRPathParser.T__16:
	        case FHIRPathParser.T__21:
	        case FHIRPathParser.T__22:
	        case FHIRPathParser.T__27:
	        case FHIRPathParser.T__29:
	        case FHIRPathParser.T__31:
	        case FHIRPathParser.T__32:
	        case FHIRPathParser.T__33:
	        case FHIRPathParser.T__34:
	        case FHIRPathParser.T__35:
	        case FHIRPathParser.T__36:
	        case FHIRPathParser.DATETIME:
	        case FHIRPathParser.TIME:
	        case FHIRPathParser.IDENTIFIER:
	        case FHIRPathParser.DELIMITEDIDENTIFIER:
	        case FHIRPathParser.STRING:
	        case FHIRPathParser.NUMBER:
	            localctx = new TermExpressionContext(this, localctx);
	            this._ctx = localctx;
	            _prevctx = localctx;

	            this.state = 34;
	            this.term();
	            break;
	        case FHIRPathParser.T__3:
	        case FHIRPathParser.T__4:
	            localctx = new PolarityExpressionContext(this, localctx);
	            this._ctx = localctx;
	            _prevctx = localctx;
	            this.state = 35;
	            _la = this._input.LA(1);
	            if(!(_la===FHIRPathParser.T__3 || _la===FHIRPathParser.T__4)) {
	            this._errHandler.recoverInline(this);
	            }
	            else {
	            	this._errHandler.reportMatch(this);
	                this.consume();
	            }
	            this.state = 36;
	            this.expression(11);
	            break;
	        default:
	            throw new antlr4$1.error.NoViableAltException(this);
	        }
	        this._ctx.stop = this._input.LT(-1);
	        this.state = 79;
	        this._errHandler.sync(this);
	        var _alt = this._interp.adaptivePredict(this._input,2,this._ctx);
	        while(_alt!=2 && _alt!=antlr4$1.atn.ATN.INVALID_ALT_NUMBER) {
	            if(_alt===1) {
	                if(this._parseListeners!==null) {
	                    this.triggerExitRuleEvent();
	                }
	                _prevctx = localctx;
	                this.state = 77;
	                this._errHandler.sync(this);
	                var la_ = this._interp.adaptivePredict(this._input,1,this._ctx);
	                switch(la_) {
	                case 1:
	                    localctx = new MultiplicativeExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));
	                    this.pushNewRecursionContext(localctx, _startState, FHIRPathParser.RULE_expression);
	                    this.state = 39;
	                    if (!( this.precpred(this._ctx, 10))) {
	                        throw new antlr4$1.error.FailedPredicateException(this, "this.precpred(this._ctx, 10)");
	                    }
	                    this.state = 40;
	                    _la = this._input.LA(1);
	                    if(!((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << FHIRPathParser.T__5) | (1 << FHIRPathParser.T__6) | (1 << FHIRPathParser.T__7) | (1 << FHIRPathParser.T__8))) !== 0))) {
	                    this._errHandler.recoverInline(this);
	                    }
	                    else {
	                    	this._errHandler.reportMatch(this);
	                        this.consume();
	                    }
	                    this.state = 41;
	                    this.expression(11);
	                    break;

	                case 2:
	                    localctx = new AdditiveExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));
	                    this.pushNewRecursionContext(localctx, _startState, FHIRPathParser.RULE_expression);
	                    this.state = 42;
	                    if (!( this.precpred(this._ctx, 9))) {
	                        throw new antlr4$1.error.FailedPredicateException(this, "this.precpred(this._ctx, 9)");
	                    }
	                    this.state = 43;
	                    _la = this._input.LA(1);
	                    if(!((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << FHIRPathParser.T__3) | (1 << FHIRPathParser.T__4) | (1 << FHIRPathParser.T__9))) !== 0))) {
	                    this._errHandler.recoverInline(this);
	                    }
	                    else {
	                    	this._errHandler.reportMatch(this);
	                        this.consume();
	                    }
	                    this.state = 44;
	                    this.expression(10);
	                    break;

	                case 3:
	                    localctx = new UnionExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));
	                    this.pushNewRecursionContext(localctx, _startState, FHIRPathParser.RULE_expression);
	                    this.state = 45;
	                    if (!( this.precpred(this._ctx, 8))) {
	                        throw new antlr4$1.error.FailedPredicateException(this, "this.precpred(this._ctx, 8)");
	                    }
	                    this.state = 46;
	                    this.match(FHIRPathParser.T__10);
	                    this.state = 47;
	                    this.expression(9);
	                    break;

	                case 4:
	                    localctx = new InequalityExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));
	                    this.pushNewRecursionContext(localctx, _startState, FHIRPathParser.RULE_expression);
	                    this.state = 48;
	                    if (!( this.precpred(this._ctx, 7))) {
	                        throw new antlr4$1.error.FailedPredicateException(this, "this.precpred(this._ctx, 7)");
	                    }
	                    this.state = 49;
	                    _la = this._input.LA(1);
	                    if(!((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << FHIRPathParser.T__11) | (1 << FHIRPathParser.T__12) | (1 << FHIRPathParser.T__13) | (1 << FHIRPathParser.T__14))) !== 0))) {
	                    this._errHandler.recoverInline(this);
	                    }
	                    else {
	                    	this._errHandler.reportMatch(this);
	                        this.consume();
	                    }
	                    this.state = 50;
	                    this.expression(8);
	                    break;

	                case 5:
	                    localctx = new EqualityExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));
	                    this.pushNewRecursionContext(localctx, _startState, FHIRPathParser.RULE_expression);
	                    this.state = 51;
	                    if (!( this.precpred(this._ctx, 5))) {
	                        throw new antlr4$1.error.FailedPredicateException(this, "this.precpred(this._ctx, 5)");
	                    }
	                    this.state = 52;
	                    _la = this._input.LA(1);
	                    if(!((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << FHIRPathParser.T__17) | (1 << FHIRPathParser.T__18) | (1 << FHIRPathParser.T__19) | (1 << FHIRPathParser.T__20))) !== 0))) {
	                    this._errHandler.recoverInline(this);
	                    }
	                    else {
	                    	this._errHandler.reportMatch(this);
	                        this.consume();
	                    }
	                    this.state = 53;
	                    this.expression(6);
	                    break;

	                case 6:
	                    localctx = new MembershipExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));
	                    this.pushNewRecursionContext(localctx, _startState, FHIRPathParser.RULE_expression);
	                    this.state = 54;
	                    if (!( this.precpred(this._ctx, 4))) {
	                        throw new antlr4$1.error.FailedPredicateException(this, "this.precpred(this._ctx, 4)");
	                    }
	                    this.state = 55;
	                    _la = this._input.LA(1);
	                    if(!(_la===FHIRPathParser.T__21 || _la===FHIRPathParser.T__22)) {
	                    this._errHandler.recoverInline(this);
	                    }
	                    else {
	                    	this._errHandler.reportMatch(this);
	                        this.consume();
	                    }
	                    this.state = 56;
	                    this.expression(5);
	                    break;

	                case 7:
	                    localctx = new AndExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));
	                    this.pushNewRecursionContext(localctx, _startState, FHIRPathParser.RULE_expression);
	                    this.state = 57;
	                    if (!( this.precpred(this._ctx, 3))) {
	                        throw new antlr4$1.error.FailedPredicateException(this, "this.precpred(this._ctx, 3)");
	                    }
	                    this.state = 58;
	                    this.match(FHIRPathParser.T__23);
	                    this.state = 59;
	                    this.expression(4);
	                    break;

	                case 8:
	                    localctx = new OrExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));
	                    this.pushNewRecursionContext(localctx, _startState, FHIRPathParser.RULE_expression);
	                    this.state = 60;
	                    if (!( this.precpred(this._ctx, 2))) {
	                        throw new antlr4$1.error.FailedPredicateException(this, "this.precpred(this._ctx, 2)");
	                    }
	                    this.state = 61;
	                    _la = this._input.LA(1);
	                    if(!(_la===FHIRPathParser.T__24 || _la===FHIRPathParser.T__25)) {
	                    this._errHandler.recoverInline(this);
	                    }
	                    else {
	                    	this._errHandler.reportMatch(this);
	                        this.consume();
	                    }
	                    this.state = 62;
	                    this.expression(3);
	                    break;

	                case 9:
	                    localctx = new ImpliesExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));
	                    this.pushNewRecursionContext(localctx, _startState, FHIRPathParser.RULE_expression);
	                    this.state = 63;
	                    if (!( this.precpred(this._ctx, 1))) {
	                        throw new antlr4$1.error.FailedPredicateException(this, "this.precpred(this._ctx, 1)");
	                    }
	                    this.state = 64;
	                    this.match(FHIRPathParser.T__26);
	                    this.state = 65;
	                    this.expression(2);
	                    break;

	                case 10:
	                    localctx = new InvocationExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));
	                    this.pushNewRecursionContext(localctx, _startState, FHIRPathParser.RULE_expression);
	                    this.state = 66;
	                    if (!( this.precpred(this._ctx, 13))) {
	                        throw new antlr4$1.error.FailedPredicateException(this, "this.precpred(this._ctx, 13)");
	                    }
	                    this.state = 67;
	                    this.match(FHIRPathParser.T__0);
	                    this.state = 68;
	                    this.invocation();
	                    break;

	                case 11:
	                    localctx = new IndexerExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));
	                    this.pushNewRecursionContext(localctx, _startState, FHIRPathParser.RULE_expression);
	                    this.state = 69;
	                    if (!( this.precpred(this._ctx, 12))) {
	                        throw new antlr4$1.error.FailedPredicateException(this, "this.precpred(this._ctx, 12)");
	                    }
	                    this.state = 70;
	                    this.match(FHIRPathParser.T__1);
	                    this.state = 71;
	                    this.expression(0);
	                    this.state = 72;
	                    this.match(FHIRPathParser.T__2);
	                    break;

	                case 12:
	                    localctx = new TypeExpressionContext(this, new ExpressionContext(this, _parentctx, _parentState));
	                    this.pushNewRecursionContext(localctx, _startState, FHIRPathParser.RULE_expression);
	                    this.state = 74;
	                    if (!( this.precpred(this._ctx, 6))) {
	                        throw new antlr4$1.error.FailedPredicateException(this, "this.precpred(this._ctx, 6)");
	                    }
	                    this.state = 75;
	                    _la = this._input.LA(1);
	                    if(!(_la===FHIRPathParser.T__15 || _la===FHIRPathParser.T__16)) {
	                    this._errHandler.recoverInline(this);
	                    }
	                    else {
	                    	this._errHandler.reportMatch(this);
	                        this.consume();
	                    }
	                    this.state = 76;
	                    this.typeSpecifier();
	                    break;

	                } 
	            }
	            this.state = 81;
	            this._errHandler.sync(this);
	            _alt = this._interp.adaptivePredict(this._input,2,this._ctx);
	        }

	    } catch( error) {
	        if(error instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = error;
		        this._errHandler.reportError(this, error);
		        this._errHandler.recover(this, error);
		    } else {
		    	throw error;
		    }
	    } finally {
	        this.unrollRecursionContexts(_parentctx);
	    }
	    return localctx;
	}



	term() {
	    let localctx = new TermContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 4, FHIRPathParser.RULE_term);
	    try {
	        this.state = 89;
	        this._errHandler.sync(this);
	        switch(this._input.LA(1)) {
	        case FHIRPathParser.T__15:
	        case FHIRPathParser.T__16:
	        case FHIRPathParser.T__21:
	        case FHIRPathParser.T__22:
	        case FHIRPathParser.T__34:
	        case FHIRPathParser.T__35:
	        case FHIRPathParser.T__36:
	        case FHIRPathParser.IDENTIFIER:
	        case FHIRPathParser.DELIMITEDIDENTIFIER:
	            localctx = new InvocationTermContext(this, localctx);
	            this.enterOuterAlt(localctx, 1);
	            this.state = 82;
	            this.invocation();
	            break;
	        case FHIRPathParser.T__29:
	        case FHIRPathParser.T__31:
	        case FHIRPathParser.T__32:
	        case FHIRPathParser.DATETIME:
	        case FHIRPathParser.TIME:
	        case FHIRPathParser.STRING:
	        case FHIRPathParser.NUMBER:
	            localctx = new LiteralTermContext(this, localctx);
	            this.enterOuterAlt(localctx, 2);
	            this.state = 83;
	            this.literal();
	            break;
	        case FHIRPathParser.T__33:
	            localctx = new ExternalConstantTermContext(this, localctx);
	            this.enterOuterAlt(localctx, 3);
	            this.state = 84;
	            this.externalConstant();
	            break;
	        case FHIRPathParser.T__27:
	            localctx = new ParenthesizedTermContext(this, localctx);
	            this.enterOuterAlt(localctx, 4);
	            this.state = 85;
	            this.match(FHIRPathParser.T__27);
	            this.state = 86;
	            this.expression(0);
	            this.state = 87;
	            this.match(FHIRPathParser.T__28);
	            break;
	        default:
	            throw new antlr4$1.error.NoViableAltException(this);
	        }
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}



	literal() {
	    let localctx = new LiteralContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 6, FHIRPathParser.RULE_literal);
	    var _la = 0; // Token type
	    try {
	        this.state = 99;
	        this._errHandler.sync(this);
	        var la_ = this._interp.adaptivePredict(this._input,4,this._ctx);
	        switch(la_) {
	        case 1:
	            localctx = new NullLiteralContext(this, localctx);
	            this.enterOuterAlt(localctx, 1);
	            this.state = 91;
	            this.match(FHIRPathParser.T__29);
	            this.state = 92;
	            this.match(FHIRPathParser.T__30);
	            break;

	        case 2:
	            localctx = new BooleanLiteralContext(this, localctx);
	            this.enterOuterAlt(localctx, 2);
	            this.state = 93;
	            _la = this._input.LA(1);
	            if(!(_la===FHIRPathParser.T__31 || _la===FHIRPathParser.T__32)) {
	            this._errHandler.recoverInline(this);
	            }
	            else {
	            	this._errHandler.reportMatch(this);
	                this.consume();
	            }
	            break;

	        case 3:
	            localctx = new StringLiteralContext(this, localctx);
	            this.enterOuterAlt(localctx, 3);
	            this.state = 94;
	            this.match(FHIRPathParser.STRING);
	            break;

	        case 4:
	            localctx = new NumberLiteralContext(this, localctx);
	            this.enterOuterAlt(localctx, 4);
	            this.state = 95;
	            this.match(FHIRPathParser.NUMBER);
	            break;

	        case 5:
	            localctx = new DateTimeLiteralContext(this, localctx);
	            this.enterOuterAlt(localctx, 5);
	            this.state = 96;
	            this.match(FHIRPathParser.DATETIME);
	            break;

	        case 6:
	            localctx = new TimeLiteralContext(this, localctx);
	            this.enterOuterAlt(localctx, 6);
	            this.state = 97;
	            this.match(FHIRPathParser.TIME);
	            break;

	        case 7:
	            localctx = new QuantityLiteralContext(this, localctx);
	            this.enterOuterAlt(localctx, 7);
	            this.state = 98;
	            this.quantity();
	            break;

	        }
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}



	externalConstant() {
	    let localctx = new ExternalConstantContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 8, FHIRPathParser.RULE_externalConstant);
	    try {
	        this.enterOuterAlt(localctx, 1);
	        this.state = 101;
	        this.match(FHIRPathParser.T__33);
	        this.state = 104;
	        this._errHandler.sync(this);
	        switch(this._input.LA(1)) {
	        case FHIRPathParser.T__15:
	        case FHIRPathParser.T__16:
	        case FHIRPathParser.T__21:
	        case FHIRPathParser.T__22:
	        case FHIRPathParser.IDENTIFIER:
	        case FHIRPathParser.DELIMITEDIDENTIFIER:
	            this.state = 102;
	            this.identifier();
	            break;
	        case FHIRPathParser.STRING:
	            this.state = 103;
	            this.match(FHIRPathParser.STRING);
	            break;
	        default:
	            throw new antlr4$1.error.NoViableAltException(this);
	        }
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}



	invocation() {
	    let localctx = new InvocationContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 10, FHIRPathParser.RULE_invocation);
	    try {
	        this.state = 111;
	        this._errHandler.sync(this);
	        var la_ = this._interp.adaptivePredict(this._input,6,this._ctx);
	        switch(la_) {
	        case 1:
	            localctx = new MemberInvocationContext(this, localctx);
	            this.enterOuterAlt(localctx, 1);
	            this.state = 106;
	            this.identifier();
	            break;

	        case 2:
	            localctx = new FunctionInvocationContext(this, localctx);
	            this.enterOuterAlt(localctx, 2);
	            this.state = 107;
	            this.functn();
	            break;

	        case 3:
	            localctx = new ThisInvocationContext(this, localctx);
	            this.enterOuterAlt(localctx, 3);
	            this.state = 108;
	            this.match(FHIRPathParser.T__34);
	            break;

	        case 4:
	            localctx = new IndexInvocationContext(this, localctx);
	            this.enterOuterAlt(localctx, 4);
	            this.state = 109;
	            this.match(FHIRPathParser.T__35);
	            break;

	        case 5:
	            localctx = new TotalInvocationContext(this, localctx);
	            this.enterOuterAlt(localctx, 5);
	            this.state = 110;
	            this.match(FHIRPathParser.T__36);
	            break;

	        }
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}



	functn() {
	    let localctx = new FunctnContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 12, FHIRPathParser.RULE_functn);
	    var _la = 0; // Token type
	    try {
	        this.enterOuterAlt(localctx, 1);
	        this.state = 113;
	        this.identifier();
	        this.state = 114;
	        this.match(FHIRPathParser.T__27);
	        this.state = 116;
	        this._errHandler.sync(this);
	        _la = this._input.LA(1);
	        if((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << FHIRPathParser.T__3) | (1 << FHIRPathParser.T__4) | (1 << FHIRPathParser.T__15) | (1 << FHIRPathParser.T__16) | (1 << FHIRPathParser.T__21) | (1 << FHIRPathParser.T__22) | (1 << FHIRPathParser.T__27) | (1 << FHIRPathParser.T__29))) !== 0) || ((((_la - 32)) & ~0x1f) == 0 && ((1 << (_la - 32)) & ((1 << (FHIRPathParser.T__31 - 32)) | (1 << (FHIRPathParser.T__32 - 32)) | (1 << (FHIRPathParser.T__33 - 32)) | (1 << (FHIRPathParser.T__34 - 32)) | (1 << (FHIRPathParser.T__35 - 32)) | (1 << (FHIRPathParser.T__36 - 32)) | (1 << (FHIRPathParser.DATETIME - 32)) | (1 << (FHIRPathParser.TIME - 32)) | (1 << (FHIRPathParser.IDENTIFIER - 32)) | (1 << (FHIRPathParser.DELIMITEDIDENTIFIER - 32)) | (1 << (FHIRPathParser.STRING - 32)) | (1 << (FHIRPathParser.NUMBER - 32)))) !== 0)) {
	            this.state = 115;
	            this.paramList();
	        }

	        this.state = 118;
	        this.match(FHIRPathParser.T__28);
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}



	paramList() {
	    let localctx = new ParamListContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 14, FHIRPathParser.RULE_paramList);
	    var _la = 0; // Token type
	    try {
	        this.enterOuterAlt(localctx, 1);
	        this.state = 120;
	        this.expression(0);
	        this.state = 125;
	        this._errHandler.sync(this);
	        _la = this._input.LA(1);
	        while(_la===FHIRPathParser.T__37) {
	            this.state = 121;
	            this.match(FHIRPathParser.T__37);
	            this.state = 122;
	            this.expression(0);
	            this.state = 127;
	            this._errHandler.sync(this);
	            _la = this._input.LA(1);
	        }
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}



	quantity() {
	    let localctx = new QuantityContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 16, FHIRPathParser.RULE_quantity);
	    try {
	        this.enterOuterAlt(localctx, 1);
	        this.state = 128;
	        this.match(FHIRPathParser.NUMBER);
	        this.state = 130;
	        this._errHandler.sync(this);
	        var la_ = this._interp.adaptivePredict(this._input,9,this._ctx);
	        if(la_===1) {
	            this.state = 129;
	            this.unit();

	        }
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}



	unit() {
	    let localctx = new UnitContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 18, FHIRPathParser.RULE_unit);
	    try {
	        this.state = 135;
	        this._errHandler.sync(this);
	        switch(this._input.LA(1)) {
	        case FHIRPathParser.T__38:
	        case FHIRPathParser.T__39:
	        case FHIRPathParser.T__40:
	        case FHIRPathParser.T__41:
	        case FHIRPathParser.T__42:
	        case FHIRPathParser.T__43:
	        case FHIRPathParser.T__44:
	        case FHIRPathParser.T__45:
	            this.enterOuterAlt(localctx, 1);
	            this.state = 132;
	            this.dateTimePrecision();
	            break;
	        case FHIRPathParser.T__46:
	        case FHIRPathParser.T__47:
	        case FHIRPathParser.T__48:
	        case FHIRPathParser.T__49:
	        case FHIRPathParser.T__50:
	        case FHIRPathParser.T__51:
	        case FHIRPathParser.T__52:
	        case FHIRPathParser.T__53:
	            this.enterOuterAlt(localctx, 2);
	            this.state = 133;
	            this.pluralDateTimePrecision();
	            break;
	        case FHIRPathParser.STRING:
	            this.enterOuterAlt(localctx, 3);
	            this.state = 134;
	            this.match(FHIRPathParser.STRING);
	            break;
	        default:
	            throw new antlr4$1.error.NoViableAltException(this);
	        }
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}



	dateTimePrecision() {
	    let localctx = new DateTimePrecisionContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 20, FHIRPathParser.RULE_dateTimePrecision);
	    var _la = 0; // Token type
	    try {
	        this.enterOuterAlt(localctx, 1);
	        this.state = 137;
	        _la = this._input.LA(1);
	        if(!(((((_la - 39)) & ~0x1f) == 0 && ((1 << (_la - 39)) & ((1 << (FHIRPathParser.T__38 - 39)) | (1 << (FHIRPathParser.T__39 - 39)) | (1 << (FHIRPathParser.T__40 - 39)) | (1 << (FHIRPathParser.T__41 - 39)) | (1 << (FHIRPathParser.T__42 - 39)) | (1 << (FHIRPathParser.T__43 - 39)) | (1 << (FHIRPathParser.T__44 - 39)) | (1 << (FHIRPathParser.T__45 - 39)))) !== 0))) {
	        this._errHandler.recoverInline(this);
	        }
	        else {
	        	this._errHandler.reportMatch(this);
	            this.consume();
	        }
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}



	pluralDateTimePrecision() {
	    let localctx = new PluralDateTimePrecisionContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 22, FHIRPathParser.RULE_pluralDateTimePrecision);
	    var _la = 0; // Token type
	    try {
	        this.enterOuterAlt(localctx, 1);
	        this.state = 139;
	        _la = this._input.LA(1);
	        if(!(((((_la - 47)) & ~0x1f) == 0 && ((1 << (_la - 47)) & ((1 << (FHIRPathParser.T__46 - 47)) | (1 << (FHIRPathParser.T__47 - 47)) | (1 << (FHIRPathParser.T__48 - 47)) | (1 << (FHIRPathParser.T__49 - 47)) | (1 << (FHIRPathParser.T__50 - 47)) | (1 << (FHIRPathParser.T__51 - 47)) | (1 << (FHIRPathParser.T__52 - 47)) | (1 << (FHIRPathParser.T__53 - 47)))) !== 0))) {
	        this._errHandler.recoverInline(this);
	        }
	        else {
	        	this._errHandler.reportMatch(this);
	            this.consume();
	        }
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}



	typeSpecifier() {
	    let localctx = new TypeSpecifierContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 24, FHIRPathParser.RULE_typeSpecifier);
	    try {
	        this.enterOuterAlt(localctx, 1);
	        this.state = 141;
	        this.qualifiedIdentifier();
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}



	qualifiedIdentifier() {
	    let localctx = new QualifiedIdentifierContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 26, FHIRPathParser.RULE_qualifiedIdentifier);
	    try {
	        this.enterOuterAlt(localctx, 1);
	        this.state = 143;
	        this.identifier();
	        this.state = 148;
	        this._errHandler.sync(this);
	        var _alt = this._interp.adaptivePredict(this._input,11,this._ctx);
	        while(_alt!=2 && _alt!=antlr4$1.atn.ATN.INVALID_ALT_NUMBER) {
	            if(_alt===1) {
	                this.state = 144;
	                this.match(FHIRPathParser.T__0);
	                this.state = 145;
	                this.identifier(); 
	            }
	            this.state = 150;
	            this._errHandler.sync(this);
	            _alt = this._interp.adaptivePredict(this._input,11,this._ctx);
	        }

	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}



	identifier() {
	    let localctx = new IdentifierContext(this, this._ctx, this.state);
	    this.enterRule(localctx, 28, FHIRPathParser.RULE_identifier);
	    var _la = 0; // Token type
	    try {
	        this.enterOuterAlt(localctx, 1);
	        this.state = 151;
	        _la = this._input.LA(1);
	        if(!((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << FHIRPathParser.T__15) | (1 << FHIRPathParser.T__16) | (1 << FHIRPathParser.T__21) | (1 << FHIRPathParser.T__22))) !== 0) || _la===FHIRPathParser.IDENTIFIER || _la===FHIRPathParser.DELIMITEDIDENTIFIER)) {
	        this._errHandler.recoverInline(this);
	        }
	        else {
	        	this._errHandler.reportMatch(this);
	            this.consume();
	        }
	    } catch (re) {
	    	if(re instanceof antlr4$1.error.RecognitionException) {
		        localctx.exception = re;
		        this._errHandler.reportError(this, re);
		        this._errHandler.recover(this, re);
		    } else {
		    	throw re;
		    }
	    } finally {
	        this.exitRule();
	    }
	    return localctx;
	}


}

FHIRPathParser.EOF = antlr4$1.Token.EOF;
FHIRPathParser.T__0 = 1;
FHIRPathParser.T__1 = 2;
FHIRPathParser.T__2 = 3;
FHIRPathParser.T__3 = 4;
FHIRPathParser.T__4 = 5;
FHIRPathParser.T__5 = 6;
FHIRPathParser.T__6 = 7;
FHIRPathParser.T__7 = 8;
FHIRPathParser.T__8 = 9;
FHIRPathParser.T__9 = 10;
FHIRPathParser.T__10 = 11;
FHIRPathParser.T__11 = 12;
FHIRPathParser.T__12 = 13;
FHIRPathParser.T__13 = 14;
FHIRPathParser.T__14 = 15;
FHIRPathParser.T__15 = 16;
FHIRPathParser.T__16 = 17;
FHIRPathParser.T__17 = 18;
FHIRPathParser.T__18 = 19;
FHIRPathParser.T__19 = 20;
FHIRPathParser.T__20 = 21;
FHIRPathParser.T__21 = 22;
FHIRPathParser.T__22 = 23;
FHIRPathParser.T__23 = 24;
FHIRPathParser.T__24 = 25;
FHIRPathParser.T__25 = 26;
FHIRPathParser.T__26 = 27;
FHIRPathParser.T__27 = 28;
FHIRPathParser.T__28 = 29;
FHIRPathParser.T__29 = 30;
FHIRPathParser.T__30 = 31;
FHIRPathParser.T__31 = 32;
FHIRPathParser.T__32 = 33;
FHIRPathParser.T__33 = 34;
FHIRPathParser.T__34 = 35;
FHIRPathParser.T__35 = 36;
FHIRPathParser.T__36 = 37;
FHIRPathParser.T__37 = 38;
FHIRPathParser.T__38 = 39;
FHIRPathParser.T__39 = 40;
FHIRPathParser.T__40 = 41;
FHIRPathParser.T__41 = 42;
FHIRPathParser.T__42 = 43;
FHIRPathParser.T__43 = 44;
FHIRPathParser.T__44 = 45;
FHIRPathParser.T__45 = 46;
FHIRPathParser.T__46 = 47;
FHIRPathParser.T__47 = 48;
FHIRPathParser.T__48 = 49;
FHIRPathParser.T__49 = 50;
FHIRPathParser.T__50 = 51;
FHIRPathParser.T__51 = 52;
FHIRPathParser.T__52 = 53;
FHIRPathParser.T__53 = 54;
FHIRPathParser.DATETIME = 55;
FHIRPathParser.TIME = 56;
FHIRPathParser.IDENTIFIER = 57;
FHIRPathParser.DELIMITEDIDENTIFIER = 58;
FHIRPathParser.STRING = 59;
FHIRPathParser.NUMBER = 60;
FHIRPathParser.WS = 61;
FHIRPathParser.COMMENT = 62;
FHIRPathParser.LINE_COMMENT = 63;

FHIRPathParser.RULE_entireExpression = 0;
FHIRPathParser.RULE_expression = 1;
FHIRPathParser.RULE_term = 2;
FHIRPathParser.RULE_literal = 3;
FHIRPathParser.RULE_externalConstant = 4;
FHIRPathParser.RULE_invocation = 5;
FHIRPathParser.RULE_functn = 6;
FHIRPathParser.RULE_paramList = 7;
FHIRPathParser.RULE_quantity = 8;
FHIRPathParser.RULE_unit = 9;
FHIRPathParser.RULE_dateTimePrecision = 10;
FHIRPathParser.RULE_pluralDateTimePrecision = 11;
FHIRPathParser.RULE_typeSpecifier = 12;
FHIRPathParser.RULE_qualifiedIdentifier = 13;
FHIRPathParser.RULE_identifier = 14;

class EntireExpressionContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_entireExpression;
    }

	expression() {
	    return this.getTypedRuleContext(ExpressionContext,0);
	};

	EOF() {
	    return this.getToken(FHIRPathParser.EOF, 0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterEntireExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitEntireExpression(this);
		}
	}


}



class ExpressionContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_expression;
    }


	 
		copyFrom(ctx) {
			super.copyFrom(ctx);
		}

}


class IndexerExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression = function(i) {
	    if(i===undefined) {
	        i = null;
	    }
	    if(i===null) {
	        return this.getTypedRuleContexts(ExpressionContext);
	    } else {
	        return this.getTypedRuleContext(ExpressionContext,i);
	    }
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterIndexerExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitIndexerExpression(this);
		}
	}


}

FHIRPathParser.IndexerExpressionContext = IndexerExpressionContext;

class PolarityExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression() {
	    return this.getTypedRuleContext(ExpressionContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterPolarityExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitPolarityExpression(this);
		}
	}


}

FHIRPathParser.PolarityExpressionContext = PolarityExpressionContext;

class AdditiveExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression = function(i) {
	    if(i===undefined) {
	        i = null;
	    }
	    if(i===null) {
	        return this.getTypedRuleContexts(ExpressionContext);
	    } else {
	        return this.getTypedRuleContext(ExpressionContext,i);
	    }
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterAdditiveExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitAdditiveExpression(this);
		}
	}


}

FHIRPathParser.AdditiveExpressionContext = AdditiveExpressionContext;

class MultiplicativeExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression = function(i) {
	    if(i===undefined) {
	        i = null;
	    }
	    if(i===null) {
	        return this.getTypedRuleContexts(ExpressionContext);
	    } else {
	        return this.getTypedRuleContext(ExpressionContext,i);
	    }
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterMultiplicativeExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitMultiplicativeExpression(this);
		}
	}


}

FHIRPathParser.MultiplicativeExpressionContext = MultiplicativeExpressionContext;

class UnionExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression = function(i) {
	    if(i===undefined) {
	        i = null;
	    }
	    if(i===null) {
	        return this.getTypedRuleContexts(ExpressionContext);
	    } else {
	        return this.getTypedRuleContext(ExpressionContext,i);
	    }
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterUnionExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitUnionExpression(this);
		}
	}


}

FHIRPathParser.UnionExpressionContext = UnionExpressionContext;

class OrExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression = function(i) {
	    if(i===undefined) {
	        i = null;
	    }
	    if(i===null) {
	        return this.getTypedRuleContexts(ExpressionContext);
	    } else {
	        return this.getTypedRuleContext(ExpressionContext,i);
	    }
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterOrExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitOrExpression(this);
		}
	}


}

FHIRPathParser.OrExpressionContext = OrExpressionContext;

class AndExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression = function(i) {
	    if(i===undefined) {
	        i = null;
	    }
	    if(i===null) {
	        return this.getTypedRuleContexts(ExpressionContext);
	    } else {
	        return this.getTypedRuleContext(ExpressionContext,i);
	    }
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterAndExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitAndExpression(this);
		}
	}


}

FHIRPathParser.AndExpressionContext = AndExpressionContext;

class MembershipExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression = function(i) {
	    if(i===undefined) {
	        i = null;
	    }
	    if(i===null) {
	        return this.getTypedRuleContexts(ExpressionContext);
	    } else {
	        return this.getTypedRuleContext(ExpressionContext,i);
	    }
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterMembershipExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitMembershipExpression(this);
		}
	}


}

FHIRPathParser.MembershipExpressionContext = MembershipExpressionContext;

class InequalityExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression = function(i) {
	    if(i===undefined) {
	        i = null;
	    }
	    if(i===null) {
	        return this.getTypedRuleContexts(ExpressionContext);
	    } else {
	        return this.getTypedRuleContext(ExpressionContext,i);
	    }
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterInequalityExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitInequalityExpression(this);
		}
	}


}

FHIRPathParser.InequalityExpressionContext = InequalityExpressionContext;

class InvocationExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression() {
	    return this.getTypedRuleContext(ExpressionContext,0);
	};

	invocation() {
	    return this.getTypedRuleContext(InvocationContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterInvocationExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitInvocationExpression(this);
		}
	}


}

FHIRPathParser.InvocationExpressionContext = InvocationExpressionContext;

class EqualityExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression = function(i) {
	    if(i===undefined) {
	        i = null;
	    }
	    if(i===null) {
	        return this.getTypedRuleContexts(ExpressionContext);
	    } else {
	        return this.getTypedRuleContext(ExpressionContext,i);
	    }
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterEqualityExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitEqualityExpression(this);
		}
	}


}

FHIRPathParser.EqualityExpressionContext = EqualityExpressionContext;

class ImpliesExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression = function(i) {
	    if(i===undefined) {
	        i = null;
	    }
	    if(i===null) {
	        return this.getTypedRuleContexts(ExpressionContext);
	    } else {
	        return this.getTypedRuleContext(ExpressionContext,i);
	    }
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterImpliesExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitImpliesExpression(this);
		}
	}


}

FHIRPathParser.ImpliesExpressionContext = ImpliesExpressionContext;

class TermExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	term() {
	    return this.getTypedRuleContext(TermContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterTermExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitTermExpression(this);
		}
	}


}

FHIRPathParser.TermExpressionContext = TermExpressionContext;

class TypeExpressionContext extends ExpressionContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression() {
	    return this.getTypedRuleContext(ExpressionContext,0);
	};

	typeSpecifier() {
	    return this.getTypedRuleContext(TypeSpecifierContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterTypeExpression(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitTypeExpression(this);
		}
	}


}

FHIRPathParser.TypeExpressionContext = TypeExpressionContext;

class TermContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_term;
    }


	 
		copyFrom(ctx) {
			super.copyFrom(ctx);
		}

}


class ExternalConstantTermContext extends TermContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	externalConstant() {
	    return this.getTypedRuleContext(ExternalConstantContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterExternalConstantTerm(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitExternalConstantTerm(this);
		}
	}


}

FHIRPathParser.ExternalConstantTermContext = ExternalConstantTermContext;

class LiteralTermContext extends TermContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	literal() {
	    return this.getTypedRuleContext(LiteralContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterLiteralTerm(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitLiteralTerm(this);
		}
	}


}

FHIRPathParser.LiteralTermContext = LiteralTermContext;

class ParenthesizedTermContext extends TermContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	expression() {
	    return this.getTypedRuleContext(ExpressionContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterParenthesizedTerm(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitParenthesizedTerm(this);
		}
	}


}

FHIRPathParser.ParenthesizedTermContext = ParenthesizedTermContext;

class InvocationTermContext extends TermContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	invocation() {
	    return this.getTypedRuleContext(InvocationContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterInvocationTerm(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitInvocationTerm(this);
		}
	}


}

FHIRPathParser.InvocationTermContext = InvocationTermContext;

class LiteralContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_literal;
    }


	 
		copyFrom(ctx) {
			super.copyFrom(ctx);
		}

}


class TimeLiteralContext extends LiteralContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	TIME() {
	    return this.getToken(FHIRPathParser.TIME, 0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterTimeLiteral(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitTimeLiteral(this);
		}
	}


}

FHIRPathParser.TimeLiteralContext = TimeLiteralContext;

class NullLiteralContext extends LiteralContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }


	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterNullLiteral(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitNullLiteral(this);
		}
	}


}

FHIRPathParser.NullLiteralContext = NullLiteralContext;

class DateTimeLiteralContext extends LiteralContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	DATETIME() {
	    return this.getToken(FHIRPathParser.DATETIME, 0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterDateTimeLiteral(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitDateTimeLiteral(this);
		}
	}


}

FHIRPathParser.DateTimeLiteralContext = DateTimeLiteralContext;

class StringLiteralContext extends LiteralContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	STRING() {
	    return this.getToken(FHIRPathParser.STRING, 0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterStringLiteral(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitStringLiteral(this);
		}
	}


}

FHIRPathParser.StringLiteralContext = StringLiteralContext;

class BooleanLiteralContext extends LiteralContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }


	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterBooleanLiteral(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitBooleanLiteral(this);
		}
	}


}

FHIRPathParser.BooleanLiteralContext = BooleanLiteralContext;

class NumberLiteralContext extends LiteralContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	NUMBER() {
	    return this.getToken(FHIRPathParser.NUMBER, 0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterNumberLiteral(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitNumberLiteral(this);
		}
	}


}

FHIRPathParser.NumberLiteralContext = NumberLiteralContext;

class QuantityLiteralContext extends LiteralContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	quantity() {
	    return this.getTypedRuleContext(QuantityContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterQuantityLiteral(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitQuantityLiteral(this);
		}
	}


}

FHIRPathParser.QuantityLiteralContext = QuantityLiteralContext;

class ExternalConstantContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_externalConstant;
    }

	identifier() {
	    return this.getTypedRuleContext(IdentifierContext,0);
	};

	STRING() {
	    return this.getToken(FHIRPathParser.STRING, 0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterExternalConstant(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitExternalConstant(this);
		}
	}


}



class InvocationContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_invocation;
    }


	 
		copyFrom(ctx) {
			super.copyFrom(ctx);
		}

}


class TotalInvocationContext extends InvocationContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }


	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterTotalInvocation(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitTotalInvocation(this);
		}
	}


}

FHIRPathParser.TotalInvocationContext = TotalInvocationContext;

class ThisInvocationContext extends InvocationContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }


	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterThisInvocation(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitThisInvocation(this);
		}
	}


}

FHIRPathParser.ThisInvocationContext = ThisInvocationContext;

class IndexInvocationContext extends InvocationContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }


	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterIndexInvocation(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitIndexInvocation(this);
		}
	}


}

FHIRPathParser.IndexInvocationContext = IndexInvocationContext;

class FunctionInvocationContext extends InvocationContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	functn() {
	    return this.getTypedRuleContext(FunctnContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterFunctionInvocation(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitFunctionInvocation(this);
		}
	}


}

FHIRPathParser.FunctionInvocationContext = FunctionInvocationContext;

class MemberInvocationContext extends InvocationContext {

    constructor(parser, ctx) {
        super(parser);
        super.copyFrom(ctx);
    }

	identifier() {
	    return this.getTypedRuleContext(IdentifierContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterMemberInvocation(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitMemberInvocation(this);
		}
	}


}

FHIRPathParser.MemberInvocationContext = MemberInvocationContext;

class FunctnContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_functn;
    }

	identifier() {
	    return this.getTypedRuleContext(IdentifierContext,0);
	};

	paramList() {
	    return this.getTypedRuleContext(ParamListContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterFunctn(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitFunctn(this);
		}
	}


}



class ParamListContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_paramList;
    }

	expression = function(i) {
	    if(i===undefined) {
	        i = null;
	    }
	    if(i===null) {
	        return this.getTypedRuleContexts(ExpressionContext);
	    } else {
	        return this.getTypedRuleContext(ExpressionContext,i);
	    }
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterParamList(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitParamList(this);
		}
	}


}



class QuantityContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_quantity;
    }

	NUMBER() {
	    return this.getToken(FHIRPathParser.NUMBER, 0);
	};

	unit() {
	    return this.getTypedRuleContext(UnitContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterQuantity(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitQuantity(this);
		}
	}


}



class UnitContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_unit;
    }

	dateTimePrecision() {
	    return this.getTypedRuleContext(DateTimePrecisionContext,0);
	};

	pluralDateTimePrecision() {
	    return this.getTypedRuleContext(PluralDateTimePrecisionContext,0);
	};

	STRING() {
	    return this.getToken(FHIRPathParser.STRING, 0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterUnit(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitUnit(this);
		}
	}


}



class DateTimePrecisionContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_dateTimePrecision;
    }


	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterDateTimePrecision(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitDateTimePrecision(this);
		}
	}


}



class PluralDateTimePrecisionContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_pluralDateTimePrecision;
    }


	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterPluralDateTimePrecision(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitPluralDateTimePrecision(this);
		}
	}


}



class TypeSpecifierContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_typeSpecifier;
    }

	qualifiedIdentifier() {
	    return this.getTypedRuleContext(QualifiedIdentifierContext,0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterTypeSpecifier(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitTypeSpecifier(this);
		}
	}


}



class QualifiedIdentifierContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_qualifiedIdentifier;
    }

	identifier = function(i) {
	    if(i===undefined) {
	        i = null;
	    }
	    if(i===null) {
	        return this.getTypedRuleContexts(IdentifierContext);
	    } else {
	        return this.getTypedRuleContext(IdentifierContext,i);
	    }
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterQualifiedIdentifier(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitQualifiedIdentifier(this);
		}
	}


}



class IdentifierContext extends antlr4$1.ParserRuleContext {

    constructor(parser, parent, invokingState) {
        if(parent===undefined) {
            parent = null;
        }
        if(invokingState===undefined || invokingState===null) {
            invokingState = -1;
        }
        super(parent, invokingState);
        this.parser = parser;
        this.ruleIndex = FHIRPathParser.RULE_identifier;
    }

	IDENTIFIER() {
	    return this.getToken(FHIRPathParser.IDENTIFIER, 0);
	};

	DELIMITEDIDENTIFIER() {
	    return this.getToken(FHIRPathParser.DELIMITEDIDENTIFIER, 0);
	};

	enterRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.enterIdentifier(this);
		}
	}

	exitRule(listener) {
	    if(listener instanceof FHIRPathListener ) {
	        listener.exitIdentifier(this);
		}
	}


}




FHIRPathParser.EntireExpressionContext = EntireExpressionContext; 
FHIRPathParser.ExpressionContext = ExpressionContext; 
FHIRPathParser.TermContext = TermContext; 
FHIRPathParser.LiteralContext = LiteralContext; 
FHIRPathParser.ExternalConstantContext = ExternalConstantContext; 
FHIRPathParser.InvocationContext = InvocationContext; 
FHIRPathParser.FunctnContext = FunctnContext; 
FHIRPathParser.ParamListContext = ParamListContext; 
FHIRPathParser.QuantityContext = QuantityContext; 
FHIRPathParser.UnitContext = UnitContext; 
FHIRPathParser.DateTimePrecisionContext = DateTimePrecisionContext; 
FHIRPathParser.PluralDateTimePrecisionContext = PluralDateTimePrecisionContext; 
FHIRPathParser.TypeSpecifierContext = TypeSpecifierContext; 
FHIRPathParser.QualifiedIdentifierContext = QualifiedIdentifierContext; 
FHIRPathParser.IdentifierContext = IdentifierContext; 

var FHIRPathParser_1 = FHIRPathParser;

const antlr4 = antlr4Index;
const Lexer = FHIRPathLexer_1;
const Parser = FHIRPathParser_1;
const Listener = FHIRPathListener_1;


class ErrorListener extends antlr4.error.ErrorListener {
  constructor(errors) {
    super();
    this.errors = errors;
  }
  syntaxError(rec, sym, line, col, msg, e) {
    this.errors.push([rec, sym, line, col, msg, e]);
  }
}

var parse$1 = function(path){
  var chars = new antlr4.InputStream(path);
  var lexer = new Lexer(chars);

  var tokens  = new antlr4.CommonTokenStream(lexer);


  var parser = new Parser(tokens);
  parser.buildParseTrees = true;
  var errors = [];
  var listener = new ErrorListener(errors);

  lexer.removeErrorListeners();
  lexer.addErrorListener(listener);
  parser.removeErrorListeners();
  parser.addErrorListener(listener);

  var tree = parser.entireExpression();

  class PathListener extends Listener{
    constructor() {
      super();
    }
  }

  var ast = {};
  var node;
  var parentStack = [ast];
  for (let p of Object.getOwnPropertyNames(Listener.prototype)) {
    if (p.startsWith("enter")) {
      PathListener.prototype[p] = function(ctx) {
        let parentNode = parentStack[parentStack.length - 1];
        let nodeType = p.slice(5); // remove "enter"
        node = {type: nodeType};
        node.text = ctx.getText();
        if (!parentNode.children)
          parentNode.children = [];
        parentNode.children.push(node);
        parentStack.push(node);
        // Also collect this node's terminal nodes, if any.  Terminal nodes are
        // not walked with the rest of the tree, but include things like "+" and
        // "-", which we need.
        node.terminalNodeText = [];
        for (let c of ctx.children) {
          // Test for node type "TerminalNodeImpl".  Minimized code no longer
          // has the original function names, so we can't rely on
          // c.constructor.name.  It appears the TerminalNodeImpl is the only
          // node with a "symbol" property, so test for that.
          if (c.symbol)
            node.terminalNodeText.push(c.getText());
        }
      };
    }
    else if (p.startsWith("exit")) {
      PathListener.prototype[p] = function() {
        parentStack.pop();
      };
    }
  }

  var printer = new PathListener();
  antlr4.tree.ParseTreeWalker.DEFAULT.walk(printer, tree);

  if (errors.length > 0) {
    let errMsgs = [];
    for (let i=0, len=errors.length; i<len; ++i) {
      let err = errors[i];
      let msg = "line: "+err[2]+"; column: "+ err[3]+"; message: "+err[4];
      errMsgs.push(msg);
    }
    var e = new Error(errMsgs.join("\n"));
    e.errors = errors;
    throw e;
  }
  return ast;
};


var parser$1 = {
  parse: parse$1
};

var getTimezoneOffsetInMilliseconds;
var hasRequiredGetTimezoneOffsetInMilliseconds;

function requireGetTimezoneOffsetInMilliseconds () {
	if (hasRequiredGetTimezoneOffsetInMilliseconds) return getTimezoneOffsetInMilliseconds;
	hasRequiredGetTimezoneOffsetInMilliseconds = 1;
	var MILLISECONDS_IN_MINUTE = 60000;

	/**
	 * Google Chrome as of 67.0.3396.87 introduced timezones with offset that includes seconds.
	 * They usually appear for dates that denote time before the timezones were introduced
	 * (e.g. for 'Europe/Prague' timezone the offset is GMT+00:57:44 before 1 October 1891
	 * and GMT+01:00:00 after that date)
	 *
	 * Date#getTimezoneOffset returns the offset in minutes and would return 57 for the example above,
	 * which would lead to incorrect calculations.
	 *
	 * This function returns the timezone offset in milliseconds that takes seconds in account.
	 */
	getTimezoneOffsetInMilliseconds = function getTimezoneOffsetInMilliseconds (dirtyDate) {
	  var date = new Date(dirtyDate.getTime());
	  var baseTimezoneOffset = date.getTimezoneOffset();
	  date.setSeconds(0, 0);
	  var millisecondsPartOfTimezoneOffset = date.getTime() % MILLISECONDS_IN_MINUTE;

	  return baseTimezoneOffset * MILLISECONDS_IN_MINUTE + millisecondsPartOfTimezoneOffset
	};
	return getTimezoneOffsetInMilliseconds;
}

/**
 * @category Common Helpers
 * @summary Is the given argument an instance of Date?
 *
 * @description
 * Is the given argument an instance of Date?
 *
 * @param {*} argument - the argument to check
 * @returns {Boolean} the given argument is an instance of Date
 *
 * @example
 * // Is 'mayonnaise' a Date?
 * var result = isDate('mayonnaise')
 * //=> false
 */

var is_date;
var hasRequiredIs_date;

function requireIs_date () {
	if (hasRequiredIs_date) return is_date;
	hasRequiredIs_date = 1;
	function isDate (argument) {
	  return argument instanceof Date
	}

	is_date = isDate;
	return is_date;
}

var parse_1;
var hasRequiredParse;

function requireParse () {
	if (hasRequiredParse) return parse_1;
	hasRequiredParse = 1;
	var getTimezoneOffsetInMilliseconds = requireGetTimezoneOffsetInMilliseconds();
	var isDate = requireIs_date();

	var MILLISECONDS_IN_HOUR = 3600000;
	var MILLISECONDS_IN_MINUTE = 60000;
	var DEFAULT_ADDITIONAL_DIGITS = 2;

	var parseTokenDateTimeDelimeter = /[T ]/;
	var parseTokenPlainTime = /:/;

	// year tokens
	var parseTokenYY = /^(\d{2})$/;
	var parseTokensYYY = [
	  /^([+-]\d{2})$/, // 0 additional digits
	  /^([+-]\d{3})$/, // 1 additional digit
	  /^([+-]\d{4})$/ // 2 additional digits
	];

	var parseTokenYYYY = /^(\d{4})/;
	var parseTokensYYYYY = [
	  /^([+-]\d{4})/, // 0 additional digits
	  /^([+-]\d{5})/, // 1 additional digit
	  /^([+-]\d{6})/ // 2 additional digits
	];

	// date tokens
	var parseTokenMM = /^-(\d{2})$/;
	var parseTokenDDD = /^-?(\d{3})$/;
	var parseTokenMMDD = /^-?(\d{2})-?(\d{2})$/;
	var parseTokenWww = /^-?W(\d{2})$/;
	var parseTokenWwwD = /^-?W(\d{2})-?(\d{1})$/;

	// time tokens
	var parseTokenHH = /^(\d{2}([.,]\d*)?)$/;
	var parseTokenHHMM = /^(\d{2}):?(\d{2}([.,]\d*)?)$/;
	var parseTokenHHMMSS = /^(\d{2}):?(\d{2}):?(\d{2}([.,]\d*)?)$/;

	// timezone tokens
	var parseTokenTimezone = /([Z+-].*)$/;
	var parseTokenTimezoneZ = /^(Z)$/;
	var parseTokenTimezoneHH = /^([+-])(\d{2})$/;
	var parseTokenTimezoneHHMM = /^([+-])(\d{2}):?(\d{2})$/;

	/**
	 * @category Common Helpers
	 * @summary Convert the given argument to an instance of Date.
	 *
	 * @description
	 * Convert the given argument to an instance of Date.
	 *
	 * If the argument is an instance of Date, the function returns its clone.
	 *
	 * If the argument is a number, it is treated as a timestamp.
	 *
	 * If an argument is a string, the function tries to parse it.
	 * Function accepts complete ISO 8601 formats as well as partial implementations.
	 * ISO 8601: http://en.wikipedia.org/wiki/ISO_8601
	 *
	 * If all above fails, the function passes the given argument to Date constructor.
	 *
	 * @param {Date|String|Number} argument - the value to convert
	 * @param {Object} [options] - the object with options
	 * @param {0 | 1 | 2} [options.additionalDigits=2] - the additional number of digits in the extended year format
	 * @returns {Date} the parsed date in the local time zone
	 *
	 * @example
	 * // Convert string '2014-02-11T11:30:30' to date:
	 * var result = parse('2014-02-11T11:30:30')
	 * //=> Tue Feb 11 2014 11:30:30
	 *
	 * @example
	 * // Parse string '+02014101',
	 * // if the additional number of digits in the extended year format is 1:
	 * var result = parse('+02014101', {additionalDigits: 1})
	 * //=> Fri Apr 11 2014 00:00:00
	 */
	function parse (argument, dirtyOptions) {
	  if (isDate(argument)) {
	    // Prevent the date to lose the milliseconds when passed to new Date() in IE10
	    return new Date(argument.getTime())
	  } else if (typeof argument !== 'string') {
	    return new Date(argument)
	  }

	  var options = dirtyOptions || {};
	  var additionalDigits = options.additionalDigits;
	  if (additionalDigits == null) {
	    additionalDigits = DEFAULT_ADDITIONAL_DIGITS;
	  } else {
	    additionalDigits = Number(additionalDigits);
	  }

	  var dateStrings = splitDateString(argument);

	  var parseYearResult = parseYear(dateStrings.date, additionalDigits);
	  var year = parseYearResult.year;
	  var restDateString = parseYearResult.restDateString;

	  var date = parseDate(restDateString, year);

	  if (date) {
	    var timestamp = date.getTime();
	    var time = 0;
	    var offset;

	    if (dateStrings.time) {
	      time = parseTime(dateStrings.time);
	    }

	    if (dateStrings.timezone) {
	      offset = parseTimezone(dateStrings.timezone) * MILLISECONDS_IN_MINUTE;
	    } else {
	      var fullTime = timestamp + time;
	      var fullTimeDate = new Date(fullTime);

	      offset = getTimezoneOffsetInMilliseconds(fullTimeDate);

	      // Adjust time when it's coming from DST
	      var fullTimeDateNextDay = new Date(fullTime);
	      fullTimeDateNextDay.setDate(fullTimeDate.getDate() + 1);
	      var offsetDiff =
	        getTimezoneOffsetInMilliseconds(fullTimeDateNextDay) -
	        getTimezoneOffsetInMilliseconds(fullTimeDate);
	      if (offsetDiff > 0) {
	        offset += offsetDiff;
	      }
	    }

	    return new Date(timestamp + time + offset)
	  } else {
	    return new Date(argument)
	  }
	}

	function splitDateString (dateString) {
	  var dateStrings = {};
	  var array = dateString.split(parseTokenDateTimeDelimeter);
	  var timeString;

	  if (parseTokenPlainTime.test(array[0])) {
	    dateStrings.date = null;
	    timeString = array[0];
	  } else {
	    dateStrings.date = array[0];
	    timeString = array[1];
	  }

	  if (timeString) {
	    var token = parseTokenTimezone.exec(timeString);
	    if (token) {
	      dateStrings.time = timeString.replace(token[1], '');
	      dateStrings.timezone = token[1];
	    } else {
	      dateStrings.time = timeString;
	    }
	  }

	  return dateStrings
	}

	function parseYear (dateString, additionalDigits) {
	  var parseTokenYYY = parseTokensYYY[additionalDigits];
	  var parseTokenYYYYY = parseTokensYYYYY[additionalDigits];

	  var token;

	  // YYYY or YYYYY
	  token = parseTokenYYYY.exec(dateString) || parseTokenYYYYY.exec(dateString);
	  if (token) {
	    var yearString = token[1];
	    return {
	      year: parseInt(yearString, 10),
	      restDateString: dateString.slice(yearString.length)
	    }
	  }

	  // YY or YYY
	  token = parseTokenYY.exec(dateString) || parseTokenYYY.exec(dateString);
	  if (token) {
	    var centuryString = token[1];
	    return {
	      year: parseInt(centuryString, 10) * 100,
	      restDateString: dateString.slice(centuryString.length)
	    }
	  }

	  // Invalid ISO-formatted year
	  return {
	    year: null
	  }
	}

	function parseDate (dateString, year) {
	  // Invalid ISO-formatted year
	  if (year === null) {
	    return null
	  }

	  var token;
	  var date;
	  var month;
	  var week;

	  // YYYY
	  if (dateString.length === 0) {
	    date = new Date(0);
	    date.setUTCFullYear(year);
	    return date
	  }

	  // YYYY-MM
	  token = parseTokenMM.exec(dateString);
	  if (token) {
	    date = new Date(0);
	    month = parseInt(token[1], 10) - 1;
	    date.setUTCFullYear(year, month);
	    return date
	  }

	  // YYYY-DDD or YYYYDDD
	  token = parseTokenDDD.exec(dateString);
	  if (token) {
	    date = new Date(0);
	    var dayOfYear = parseInt(token[1], 10);
	    date.setUTCFullYear(year, 0, dayOfYear);
	    return date
	  }

	  // YYYY-MM-DD or YYYYMMDD
	  token = parseTokenMMDD.exec(dateString);
	  if (token) {
	    date = new Date(0);
	    month = parseInt(token[1], 10) - 1;
	    var day = parseInt(token[2], 10);
	    date.setUTCFullYear(year, month, day);
	    return date
	  }

	  // YYYY-Www or YYYYWww
	  token = parseTokenWww.exec(dateString);
	  if (token) {
	    week = parseInt(token[1], 10) - 1;
	    return dayOfISOYear(year, week)
	  }

	  // YYYY-Www-D or YYYYWwwD
	  token = parseTokenWwwD.exec(dateString);
	  if (token) {
	    week = parseInt(token[1], 10) - 1;
	    var dayOfWeek = parseInt(token[2], 10) - 1;
	    return dayOfISOYear(year, week, dayOfWeek)
	  }

	  // Invalid ISO-formatted date
	  return null
	}

	function parseTime (timeString) {
	  var token;
	  var hours;
	  var minutes;

	  // hh
	  token = parseTokenHH.exec(timeString);
	  if (token) {
	    hours = parseFloat(token[1].replace(',', '.'));
	    return (hours % 24) * MILLISECONDS_IN_HOUR
	  }

	  // hh:mm or hhmm
	  token = parseTokenHHMM.exec(timeString);
	  if (token) {
	    hours = parseInt(token[1], 10);
	    minutes = parseFloat(token[2].replace(',', '.'));
	    return (hours % 24) * MILLISECONDS_IN_HOUR +
	      minutes * MILLISECONDS_IN_MINUTE
	  }

	  // hh:mm:ss or hhmmss
	  token = parseTokenHHMMSS.exec(timeString);
	  if (token) {
	    hours = parseInt(token[1], 10);
	    minutes = parseInt(token[2], 10);
	    var seconds = parseFloat(token[3].replace(',', '.'));
	    return (hours % 24) * MILLISECONDS_IN_HOUR +
	      minutes * MILLISECONDS_IN_MINUTE +
	      seconds * 1000
	  }

	  // Invalid ISO-formatted time
	  return null
	}

	function parseTimezone (timezoneString) {
	  var token;
	  var absoluteOffset;

	  // Z
	  token = parseTokenTimezoneZ.exec(timezoneString);
	  if (token) {
	    return 0
	  }

	  // hh
	  token = parseTokenTimezoneHH.exec(timezoneString);
	  if (token) {
	    absoluteOffset = parseInt(token[2], 10) * 60;
	    return (token[1] === '+') ? -absoluteOffset : absoluteOffset
	  }

	  // hh:mm or hhmm
	  token = parseTokenTimezoneHHMM.exec(timezoneString);
	  if (token) {
	    absoluteOffset = parseInt(token[2], 10) * 60 + parseInt(token[3], 10);
	    return (token[1] === '+') ? -absoluteOffset : absoluteOffset
	  }

	  return 0
	}

	function dayOfISOYear (isoYear, week, day) {
	  week = week || 0;
	  day = day || 0;
	  var date = new Date(0);
	  date.setUTCFullYear(isoYear, 0, 4);
	  var fourthOfJanuaryDay = date.getUTCDay() || 7;
	  var diff = week * 7 + day + 1 - fourthOfJanuaryDay;
	  date.setUTCDate(date.getUTCDate() + diff);
	  return date
	}

	parse_1 = parse;
	return parse_1;
}

var add_milliseconds;
var hasRequiredAdd_milliseconds;

function requireAdd_milliseconds () {
	if (hasRequiredAdd_milliseconds) return add_milliseconds;
	hasRequiredAdd_milliseconds = 1;
	var parse = requireParse();

	/**
	 * @category Millisecond Helpers
	 * @summary Add the specified number of milliseconds to the given date.
	 *
	 * @description
	 * Add the specified number of milliseconds to the given date.
	 *
	 * @param {Date|String|Number} date - the date to be changed
	 * @param {Number} amount - the amount of milliseconds to be added
	 * @returns {Date} the new date with the milliseconds added
	 *
	 * @example
	 * // Add 750 milliseconds to 10 July 2014 12:45:30.000:
	 * var result = addMilliseconds(new Date(2014, 6, 10, 12, 45, 30, 0), 750)
	 * //=> Thu Jul 10 2014 12:45:30.750
	 */
	function addMilliseconds (dirtyDate, dirtyAmount) {
	  var timestamp = parse(dirtyDate).getTime();
	  var amount = Number(dirtyAmount);
	  return new Date(timestamp + amount)
	}

	add_milliseconds = addMilliseconds;
	return add_milliseconds;
}

var addMilliseconds = requireAdd_milliseconds();

var MILLISECONDS_IN_MINUTE = 60000;

/**
 * @category Minute Helpers
 * @summary Add the specified number of minutes to the given date.
 *
 * @description
 * Add the specified number of minutes to the given date.
 *
 * @param {Date|String|Number} date - the date to be changed
 * @param {Number} amount - the amount of minutes to be added
 * @returns {Date} the new date with the minutes added
 *
 * @example
 * // Add 30 minutes to 10 July 2014 12:00:00:
 * var result = addMinutes(new Date(2014, 6, 10, 12, 0), 30)
 * //=> Thu Jul 10 2014 12:30:00
 */
function addMinutes$1 (dirtyDate, dirtyAmount) {
  var amount = Number(dirtyAmount);
  return addMilliseconds(dirtyDate, amount * MILLISECONDS_IN_MINUTE)
}

var add_minutes = addMinutes$1;

var ucumPkg = {};

var config = {};

var hasRequiredConfig;

function requireConfig () {
	if (hasRequiredConfig) return config;
	hasRequiredConfig = 1;

	Object.defineProperty(config, "__esModule", {
	  value: true
	});
	config.Ucum = void 0;
	/*
	 * This defines the namespace for the UCUM classes and provides
	 * a place for the definition of global variables and constants.
	 *
	 * The javascript for this UCUM implementation uses syntax as
	 * defined by the ECMAScript 6 standard
	 */

	var Ucum = {
	  /**
	   *  Flag indicating whether or not we're using case sensitive labels
	   *  I don't think we need this.  I think we're just going with
	   *  case sensitive, per Clem.   Gunther's code has this flag, but I
	   *  am removing it, at least for now.  lm, 6/2016
	   */
	  //caseSensitive_: true ,

	  /**
	   *  The number of elements in a Dimension array.   Currently this
	   *  is set as a configuration variable, but when we get to the point
	   *  of loading the unit definitions from a file, this value will be
	   *  set from that.
	   */
	  dimLen_: 7,
	  /**
	   *  The characters used as valid operators in a UCUM unit expression,
	   *  where '.' is for multiplication and '/' is for division.
	   */
	  validOps_: ['.', '/'],
	  /**
	   * The string used to separate a unit code and unit name when they
	   * are displayed together
	   */
	  codeSep_: ': ',
	  // Message text variations for validation methods and conversion methods
	  valMsgStart_: 'Did you mean ',
	  valMsgEnd_: '?',
	  cnvMsgStart_: 'We assumed you meant ',
	  cnvMsgEnd_: '.',
	  /**
	     * Default opening string used to emphasize portions of error messages.
	     * Used when NOT displaying messages on a web site, i.e., for output
	     * from the library methods or to a file.
	     */
	  openEmph_: ' ->',
	  /**
	   * Default closing string used to emphasize portions of error messages.
	   * Used when NOT displaying messages on a web site, i.e., for output
	   * from the library methods or to a file.
	   */
	  closeEmph_: '<- ',
	  /**
	   * Opening HTML used to emphasize portions of error messages.  Used when
	   * displaying messages on a web site; should be blank when output is
	   * to a file.
	   */
	  openEmphHTML_: ' <span class="emphSpan">',
	  /**
	   * Closing HTML used to emphasize portions of error messages.  Used when
	   * displaying messages on a web site; should be blank when output is
	   * to a file.
	   */
	  closeEmphHTML_: '</span> ',
	  /**
	   * Message that is displayed when annotations are included in a unit
	   * string, to let the user know how they are interpreted.
	   */
	  bracesMsg_: 'FYI - annotations (text in curly braces {}) are ignored, ' + 'except that an annotation without a leading symbol implies ' + 'the default unit 1 (the unity).',
	  /**
	   * Message that is displayed or returned when a conversion is requested
	   * for two units where (only) a mass<->moles conversion is appropriate
	   * but no molecular weight was specified.
	   */
	  needMoleWeightMsg_: 'Did you wish to convert between mass and moles?  The ' + 'molecular weight of the substance represented by the ' + 'units is required to perform the conversion.',
	  /**
	   * Hash that matches unit column names to names used in the csv file
	   * that is submitted to the data updater.
	   */
	  csvCols_: {
	    'case-sensitive code': 'csCode_',
	    'LOINC property': 'loincProperty_',
	    'name (display)': 'name_',
	    'synonyms': 'synonyms_',
	    'source': 'source_',
	    'category': 'category_',
	    'Guidance': 'guidance_'
	  },
	  /**
	   * Name of the column in the csv file that serves as the key
	   */
	  inputKey_: 'case-sensitive code',
	  /**
	   * Special codes that contain operators within brackets.  The operator
	   * within these codes causes them to parse incorrectly if they are preceded
	   * by a prefix, because the parsing algorithm splits them up on the operator.
	   * So we use this object to identify them and substitute placeholders to
	   * avoid that.
	   */
	  specUnits_: {
	    'B[10.nV]': 'specialUnitOne',
	    '[m/s2/Hz^(1/2)]': 'specialUnitTwo'
	  }
	};
	config.Ucum = Ucum;
	
	return config;
}

var ucumLhcUtils = {};

var ucumJsonDefs = {};

var prefix = {};

var hasRequiredPrefix;

function requirePrefix () {
	if (hasRequiredPrefix) return prefix;
	hasRequiredPrefix = 1;

	Object.defineProperty(prefix, "__esModule", {
	  value: true
	});
	prefix.Prefix = void 0;
	/**
	 * Prefix objects are defined in this file.
	 */

	/**
	 * This class implements the prefix object.  Prefixes are used as multipliers
	 * for units, e.g., km for kilometers
	 *
	 * @author Lee Mericle, based on java version by Gunther Schadow
	 *
	 */
	requireConfig();
	class Prefix {
	  /**
	   * Creates a single prefix object.
	   *
	   * @param attrs a hash of the values to use in creating the prefix object.
	   *  They should be:
	   *   code_ - which is the case-sensitive code used for the prefix,
	   *    e.g., k for kilo
	   *   ciCode_ - which is the case-insensitive code used for the prefix,
	   *    e.g., K for kilo
	   *   name_ - which is the name of the prefix, e.g., kilo
	   *   printSymbol_ - which is the print symbol for the prefix, e.g., k for kilo
	   *   value_ - which is teh value to use in multiplying the magnitude of
	   *    a unit, e.g., for a prefix of c the value will be .01.
	   *   exp_ - which is the exponent used to get the value. For decimal based
	   *    prefixes the base is 10 and the exp_ is applied to 10, e.g., for a
	   *    prefix of c, the exponent will be -2.  For prefixes that are not
	   *    decimal based, this will be null (but must not be undefined).
	   *
	   * @throws an error if the not all required parameters are provided
	   */
	  constructor(attrs) {
	    if (attrs['code_'] === undefined || attrs['code_'] === null || attrs['name_'] === undefined || attrs['name_'] === null || attrs['value_'] === undefined || attrs['value_'] === null || attrs['exp_'] === undefined) {
	      throw new Error('Prefix constructor called missing one or more parameters.  ' + 'Prefix codes (cs or ci), name, value and exponent must all be specified ' + 'and all but the exponent must not be null.');
	    }

	    /**
	     * The prefix code, e.g., k for kilo.  This should be the case-sensitive
	     * code.  Since there's no way to check to see if it's the case-sensitive
	     * one as opposed to the case-insensitive one (because although
	     * case-insensitive codes all seem to be uppercase, some case-sensitive
	     * codes are also all uppercase), we'll just have to believe that the
	     * right one was passed in.
	     */
	    this.code_ = attrs['code_'];

	    /**
	     * The case-insensitive code, e.g., K for kilo
	     */
	    this.ciCode_ = attrs['ciCode_'];

	    /**
	     * The prefix name, e.g., kilo
	     */
	    this.name_ = attrs['name_'];

	    /**
	     * The printSymbol for the prefix, e.g., k for kilo
	     */
	    this.printSymbol_ = attrs['printSymbol_'];

	    /**
	     * The value to use in multiplying the magnitude of a unit
	     */
	    if (typeof attrs['value_'] === 'string') this.value_ = parseFloat(attrs['value_']);else this.value_ = attrs['value_'];

	    /**
	     * The exponent used to create the value from 10.  For prefixes that are
	     * not based on 10, this will be null.
	     */
	    this.exp_ = attrs['exp_'];
	  } // end constructor

	  /**
	   * Returns the value for the current prefix object
	   * @return the value for the prefix object with the specified code
	   * */
	  getValue() {
	    return this.value_;
	  }

	  /**
	   * Returns the prefix code for the current prefix object
	   * @return the code for the current prefix object
	   */
	  getCode() {
	    return this.code_;
	  }

	  /**
	   * Returns the case-insensitive code for the current prefix object
	   * @return the case_insensitive code for the current prefix object
	   */
	  getCiCode() {
	    return this.ciCode_;
	  }

	  /**
	   * Returns the prefix name for the current prefix object
	   * @return the name for the current prefix object
	   */
	  getName() {
	    return this.name_;
	  }

	  /**
	   * Returns the print symbol for the current prefix object
	   * @return the print symbol for the current prefix object
	   */
	  getPrintSymbol() {
	    return this.printSymbol_;
	  }

	  /**
	   * Returns the exponent for the current prefix object
	   * @return the exponent for the current prefix object
	   */
	  getExp() {
	    return this.exp_;
	  }

	  /**
	   * Provides way to tell if one prefix equals another.  The second prefix
	   * must match all attribute values.
	   *
	   * @param prefix2 prefix object to check for a match
	   * @return true for a match; false if one or more attributes don't match
	   */
	  equals(prefix2) {
	    return this.code_ === prefix2.code_ && this.ciCode_ === prefix2.ciCode_ && this.name_ === prefix2.name_ && this.printSymbol_ === prefix2.printSymbol_ && this.value_ === prefix2.value_ && this.exp_ === prefix2.exp_;
	  }
	} // end Prefix class
	prefix.Prefix = Prefix;
	
	return prefix;
}

var prefixTables = {};

var hasRequiredPrefixTables;

function requirePrefixTables () {
	if (hasRequiredPrefixTables) return prefixTables;
	hasRequiredPrefixTables = 1;

	Object.defineProperty(prefixTables, "__esModule", {
	  value: true
	});
	prefixTables.PrefixTables = prefixTables.PrefixTablesFactory = void 0;
	/**
	 * The tables of defined prefixes is defined in this file.
	 */

	/**
	 * This class implements the table of multiplier prefixes.
	 *
	 * @author Lee Mericle, based on java version by Gunther Schadow
	 *
	 */
	class PrefixTablesFactory {
	  /**
	   * Constructor.  This creates the empty PrefixTable hashes once.
	   * There is one hash whose key is the prefix code and one whose
	   * key is the prefix value.
	   *
	   * Implementation of this as a singleton is based on the UnitTables
	   * implementation.  See that class for details.
	   */
	  constructor() {
	    this.byCode_ = {};
	    this.byValue_ = {};
	  }

	  /**
	   * Provides the number of prefix objects in each table
	   * @returns count of the number of prefix objects in each table
	   */
	  prefixCount() {
	    return Object.keys(this.byCode_).length;
	  }

	  /**
	   * This is used to get all prefix objects by value.  Currently it is used
	   * to create a csv file with all prefixes and units.
	   * @returns csv string containing all prefix objects, ordered by value.
	   */
	  allPrefixesByValue() {
	    let prefixBuff = '';
	    let pList = Object.keys(this.byValue_);
	    //pList.sort() ;
	    let pLen = pList.length;
	    for (let p = 0; p < pLen; p++) {
	      let pfx = this.getPrefixByValue(pList[p]);
	      prefixBuff += pfx.code_ + ',' + pfx.name_ + ',,' + pfx.value_ + '\r\n';
	    }
	    return prefixBuff;
	  }

	  /**
	   * This is used to get all prefix objects.  Currently it is used
	   * to get the objects to write to the json ucum definitions file
	   * that is used to provide prefix and unit definition objects for
	   * conversions and validations.
	   *
	   * @returns an array containing all prefix objects, ordered by code.
	   */
	  allPrefixesByCode() {
	    let prefixList = [];
	    let pList = Object.keys(this.byCode_);
	    pList.sort();
	    let pLen = pList.length;
	    for (let p = 0; p < pLen; p++) {
	      prefixList.push(this.getPrefixByCode(pList[p]));
	    }
	    return prefixList;
	  }

	  /**
	   * Adds a prefix object to the tables
	   *
	   * @param prefixObj the object to be added to the tables
	   */
	  add(prefixObj) {
	    this.byCode_[prefixObj.getCode()] = prefixObj;
	    this.byValue_[prefixObj.getValue()] = prefixObj;
	  }

	  /**
	   * Tests whether a prefix object is found for a specified code.  This
	   * is used to determine whether or not a prefix object has been created
	   * for the code.
	   *
	   * @param code the code to be used to find the prefix object
	   * @return boolean indicating whether or not a prefix object was found
	   *  for the specified code
	   */
	  isDefined(code) {
	    return this.byCode_[code] !== null && this.byCode_[code] !== undefined;
	  }

	  /**
	   * Obtains a prefix object for a specified code.
	   *
	   * @param code the code to be used to find the prefix object
	   * @return the prefix object found, or null if nothing was found
	   */
	  getPrefixByCode(code) {
	    return this.byCode_[code];
	  }

	  /**
	   * Obtains a prefix object for a specified value.
	   *
	   * @param value the value to be used to find the prefix object
	   * @return the prefix object found, or null if nothing was found
	   */
	  getPrefixByValue(value) {
	    return this.byValue_[value];
	  }
	} // end PrefixTablesFactory class

	// Create a singleton instance and (to preserve the existing API) an object that
	// provides that instance via getInstance().
	prefixTables.PrefixTablesFactory = PrefixTablesFactory;
	var prefixTablesInstance = new PrefixTablesFactory();
	const PrefixTables = {
	  getInstance: function () {
	    return prefixTablesInstance;
	  }
	};
	prefixTables.PrefixTables = PrefixTables;
	
	return prefixTables;
}

var unit = {};

var ucumFunctions = {};

var hasRequiredUcumFunctions;

function requireUcumFunctions () {
	if (hasRequiredUcumFunctions) return ucumFunctions;
	hasRequiredUcumFunctions = 1;

	Object.defineProperty(ucumFunctions, "__esModule", {
	  value: true
	});
	ucumFunctions.default = void 0;
	/*
	 * This class manages the special functions used by some units.
	 *
	 * @author Lee Mericle, based on java version by Gunther Schadow
	 *
	 */

	class UcumFunctions {
	  /**
	   * Constructor
	   *
	   * Creates the singleton object that contains the list of functions used
	   * to convert special units.
	   */
	  constructor() {
	    // Create the hash containing the function pairs
	    this.funcs = {};

	    // Celsius - convert to Celsius from kelvin and from Celsius to kelvin
	    // where kelvin is the base unit for temperature
	    this.funcs['cel'] = {
	      cnvTo: function (x) {
	        return x - 273.15;
	      },
	      cnvFrom: function (x) {
	        return x + 273.15;
	      }
	    };

	    // Fahrenheit - convert to Fahrenheit from kelvin and from Fahrenheit to
	    // kelvin - which is the base unit for temperature
	    this.funcs['degf'] = {
	      cnvTo: function (x) {
	        return x - 459.67;
	      },
	      cnvFrom: function (x) {
	        return x + 459.67;
	      }
	    };

	    // Reaumur - convert between Reaumur and Kelvin.   Because of the way the
	    // calling code in the Units class is set up (in the convertFrom method),
	    // what is given here as the convertTo function is actually the convert
	    // from method and vice versa.
	    //this.funcs['degre'] = {cnvTo   : function(x){return x + 273.15;},
	    //                    cnvFrom : function(x){return x - 273.15;}};
	    this.funcs['degre'] = {
	      cnvTo: function (x) {
	        return x - 273.15;
	      },
	      cnvFrom: function (x) {
	        return x + 273.15;
	      }
	    };

	    // pH - convert to pH from moles per liter and from moles per liter to pH
	    // where a mole is an amount of a substance (a count of particles)
	    this.funcs['ph'] = {
	      cnvTo: function (x) {
	        return -Math.log(x) / Math.LN10;
	      },
	      cnvFrom: function (x) {
	        return Math.pow(10, -x);
	      }
	    };

	    // ln - natural logarithm (base e 2.71828) - apply (cnvTo) and invert (cnvFrom)
	    // and 2ln - two times the natural logarithm
	    this.funcs['ln'] = {
	      cnvTo: function (x) {
	        return Math.log(x);
	      },
	      cnvFrom: function (x) {
	        return Math.exp(x);
	      }
	    };
	    this.funcs['2ln'] = {
	      cnvTo: function (x) {
	        return 2 * Math.log(x);
	      },
	      cnvFrom: function (x) {
	        return Math.exp(x / 2);
	      }
	    };

	    // lg - the decadic logarithm (base 10)
	    this.funcs['lg'] = {
	      cnvTo: function (x) {
	        return Math.log(x) / Math.LN10;
	      },
	      cnvFrom: function (x) {
	        return Math.pow(10, x);
	      }
	    };
	    this.funcs['10lg'] = {
	      cnvTo: function (x) {
	        return 10 * Math.log(x) / Math.LN10;
	      },
	      cnvFrom: function (x) {
	        return Math.pow(10, x / 10);
	      }
	    };
	    this.funcs['20lg'] = {
	      cnvTo: function (x) {
	        return 20 * Math.log(x) / Math.LN10;
	      },
	      cnvFrom: function (x) {
	        return Math.pow(10, x / 20);
	      }
	    };
	    // The plain text ucum units file uses '2lg'
	    this.funcs['2lg'] = {
	      cnvTo: function (x) {
	        return 2 * Math.log(x) / Math.LN10;
	      },
	      cnvFrom: function (x) {
	        return Math.pow(10, x / 2);
	      }
	    };
	    // The xml essence ucum file uses lgTimes2
	    this.funcs['lgtimes2'] = this.funcs['2lg'];

	    // ld - dual logarithm (base 2)
	    this.funcs['ld'] = {
	      cnvTo: function (x) {
	        return Math.log(x) / Math.LN2;
	      },
	      cnvFrom: function (x) {
	        return Math.pow(2, x);
	      }
	    };

	    // tan - tangent
	    this.funcs['100tan'] = {
	      cnvTo: function (x) {
	        return Math.tan(x) * 100;
	      },
	      cnvFrom: function (x) {
	        return Math.atan(x / 100);
	      }
	    };
	    // the xml essence ucum file uses both 100tan and tanTimes100
	    this.funcs['tanTimes100'] = this.funcs['100tan'];

	    // sqrt - square root
	    this.funcs['sqrt'] = {
	      cnvTo: function (x) {
	        return Math.sqrt(x);
	      },
	      cnvFrom: function (x) {
	        return x * x;
	      }
	    };

	    // inv - inverse
	    this.funcs['inv'] = {
	      cnvTo: function (x) {
	        return 1.0 / x;
	      },
	      cnvFrom: function (x) {
	        return 1.0 / x;
	      }
	    };

	    // homeopathic potency functions
	    this.funcs['hpX'] = {
	      cnvTo: function (x) {
	        return -this.funcs['lg'](x);
	      },
	      cnvFrom: function (x) {
	        return Math.pow(10, -x);
	      }
	    };
	    this.funcs['hpC'] = {
	      cnvTo: function (x) {
	        return -this.func['ln'](x) / this.funcs['ln'](100);
	      },
	      cnvFrom: function (x) {
	        return Math.pow(100, -x);
	      }
	    };
	    this.funcs['hpM'] = {
	      cnvTo: function (x) {
	        return -this.funcs['ln'](x) / this.funcs['ln'](1000);
	      },
	      cnvFrom: function (x) {
	        return Math.pow(1000, -x);
	      }
	    };
	    this.funcs['hpQ'] = {
	      cnvTo: function (x) {
	        return -this.funcs['ln'](x) / this.funcs['ln'](50000);
	      },
	      cnvFrom: function (x) {
	        return Math.pow(50000, -x);
	      }
	    };
	  } // end of constructor

	  /**
	   * Returns the function with the name specified
	   *
	   * @param fname name of the function to be returned
	   * @return the function with the specified name
	   * @throws an error message if the function is not found
	   */
	  forName(fname) {
	    fname = fname.toLowerCase();
	    let f = this.funcs[fname];
	    if (f === null) throw new Error(`Requested function ${fname} is not defined`);
	    return f;
	  }

	  /**
	   * Returns a flag indicating whether or not the function has been
	   * defined.
	   *
	   * @param fname name of the function in question
	   * @return true if it has been defined; false if not
	   */
	  isDefined(fname) {
	    fname = fname.toLowerCase();
	    return this.funcs[fname] !== null;
	  }
	} // end of UcumFunctions class
	var _default = new UcumFunctions(); // one singleton instance
	ucumFunctions.default = _default;
	
	return ucumFunctions;
}

var ucumInternalUtils = {};

var unitTables = {};

var hasRequiredUnitTables;

function requireUnitTables () {
	if (hasRequiredUnitTables) return unitTables;
	hasRequiredUnitTables = 1;

	Object.defineProperty(unitTables, "__esModule", {
	  value: true
	});
	unitTables.UnitTables = void 0;
	/**
	 * This class manages Hashtables that provide references to
	 * defined units.
	 *
	 * @author Lee Mericle, based on java version by Gunther Schadow
	 *
	 */

	var Ucum = requireConfig().Ucum;
	class UnitTablesFactory {
	  /**
	   * Constructor.  This creates the empty unit tables (hashes) once. After the
	   * tables are created, it redefines this constructor to throw an error
	   * stating that the constructor is no longer available and that the
	   * getInstance function must be used.   Here's a description of the first
	   * and then all subsequent calls to this constructor.
	   *
	   * First call to constructor:
	   * 1. creates  OBJECT1
	   * 2. initializes attributes of OBJECT1
	   * 3. stores reference to OBJECT1.prototype in holdthis local variable
	   * 4. redefines OBJECT1 as a function that throws an error
	   * 5. defines the getInstance function (which is also defined outside of
	   *    the class definition - see below).
	   *
	   * All subsequent calls to constructor:
	   * 1. throw error message referring to getInstance
	   * 2. call getInstance, returns this - which is OBJECT1.
	   */
	  constructor() {
	    /**
	     * Tracks units by name
	     * @type hash - key is the name;
	     *              value is an array of references to the Unit objects
	     *              with the name.  More than one unit may have the same
	     *              name, e.g., "second", which is shared by the base unit
	     *              with the code = "s" and the unit with code = "'".
	     */
	    this.unitNames_ = {};

	    /**
	     * Tracks units by code using case-sensitive version.
	     *
	     * @type hash - key is the code;
	     *              value is the reference to the Unit object.  Codes must
	     *              be unique.
	     */
	    this.unitCodes_ = {};

	    /**
	     * Keeps track of the order in which units are defined.  The order is
	     * important because unit definitions build on previous definitions.
	     *
	     * @type {Array}
	     */
	    this.codeOrder_ = [];

	    /**
	     * Tracks units by unit strings, e.g., cm-1
	     *
	     * @type hash - key is the unit string
	     *              value is an array of unit objects with that ciUnitString.
	     */
	    this.unitStrings_ = {};

	    /**
	     * Tracks units by Dimension vector
	     *
	     * @type hash - key is the dimension vector (not the object, just the
	     *              vector);
	     *              value is an array of references to the Unit objects
	     *              with that vector.  More than one unit may have the same
	     *              unit vector, and this can be used to provide a list
	     *              of commensurable units.
	     */
	    this.unitDimensions_ = {};

	    /**
	     * Maps synonyms to units.   Not built until first requested.
	     *
	     * @type hash - key is the synonym
	     *              value is an array of references to Unit objects that
	     *              include that synonym.
	     */
	    this.unitSynonyms_ = {};

	    /*
	     * Holds onto the index of the index of the dimension vector flag for
	     * the base mass unit (gram).  This is set when the base unit (gram) is
	     * created, and is stored here so that it doesn't have to be found
	     * over and over again to try to determine whether or not a unit is
	     * mass-based (for mole<->mass conversions)
	     *
	     * @type integer
	     */
	    this.massDimIndex_ = 0;

	    /**
	     *  Map of indices in the dimension vector to base unit symbols.
	     */
	    this.dimVecIndexToBaseUnit_ = {};
	  }

	  /**
	   * Provides the number of unit objects written to the tables, using the
	   * codes table since codes must be unique.
	   *
	   * @returns count of the number of unit objects in the unitCodes_ table.
	   */
	  unitsCount() {
	    return Object.keys(this.unitCodes_).length;
	  }

	  /**
	   * Adds a Unit object to the tables.
	   *
	   * @param theUnit the unit to be added
	   * @returns nothing
	   * @throws passes on an error if one is thrown by the called functions for
	   *  a problem with the unit code or unit name
	   */
	  addUnit(theUnit) {
	    let uName = theUnit['name_'];
	    if (uName) {
	      this.addUnitName(theUnit);
	    }
	    this.addUnitCode(theUnit);
	    this.addUnitString(theUnit);
	    try {
	      if (theUnit['dim_'].getProperty('dimVec_')) this.addUnitDimension(theUnit);
	    } catch (err) {
	      // do nothing - throws error if the property is null
	      // and that's OK here.
	    }
	    if (theUnit.isBase_) {
	      const dimVec = theUnit.dim_.dimVec_;
	      let nonZeroIndex;
	      for (let i = 0, len = dimVec.length; nonZeroIndex == undefined && i < len; ++i) {
	        if (dimVec[i] != 0) nonZeroIndex = i;
	      }
	      this.dimVecIndexToBaseUnit_[nonZeroIndex] = theUnit.csCode_;
	    }
	  } // end addUnit

	  /**
	   * Adds a Unit object to the unitNames_ table.  More than one unit
	   * can have the same name, e.g., the two units with the name "second",
	   * where the code for one of them is 's' and the code for the other is
	   * "'".  Because of this, an array of unit objects is stored for the
	   * name.  In most cases it will be an array of one object, but this
	   * clarifies that there may be more than one.
	   *
	   * @param theUnit the unit to be added
	   * @returns nothing
	   * @throws an error if the unit has no name
	   */
	  addUnitName(theUnit) {
	    let uName = theUnit['name_'];
	    if (uName) {
	      if (this.unitNames_[uName]) this.unitNames_[uName].push(theUnit);else this.unitNames_[uName] = [theUnit];
	    } else throw new Error('UnitTables.addUnitName called for a unit with no name.  ' + `Unit code = ${theUnit['csCode_']}.`);
	  } // end addUnitName

	  /**
	   * Adds a Unit object to the unitCodes_, unitUcCodes_, unitLcCodes_ and
	   * codeOrder_ tables.  This also sets the mass dimension index when the
	   * base mass unit (gram) is read.
	   *
	   * @param theUnit the unit to be added
	   * @returns nothing
	   * @throws an error if the unitCodes_ table already contains a unit with
	   *  the code
	   */
	  addUnitCode(theUnit) {
	    let uCode = theUnit['csCode_'];
	    if (uCode) {
	      if (this.unitCodes_[uCode]) throw new Error(`UnitTables.addUnitCode called, already contains entry for ` + `unit with code = ${uCode}`);else {
	        this.unitCodes_[uCode] = theUnit;
	        this.codeOrder_.push(uCode);
	        if (uCode == 'g') {
	          let dimVec = theUnit.dim_.dimVec_;
	          let d = 0;
	          for (; d < dimVec.length && dimVec[d] < 1; d++);
	          this.massDimIndex_ = d;
	        }
	      }
	    } else throw new Error('UnitTables.addUnitCode called for unit that has ' + 'no code.');
	  } // end addUnitCode

	  /**
	   * Adds a unit object to the unitStrings_ table.  More than one unit
	   * can have the same string, so an array of unit objects is stored
	   * for the string.  The unit string is the string that creates a non-base
	   * unit, e.g., a Newton has a unit code of N, a name of Newton, and a
	   * unitString of kg.m/s2.
	   *
	   * If the unit has no string, nothing is stored and no error is reported.
	   *
	   * @param theUnit the unit to be added
	   * @returns nothing
	   */
	  addUnitString(theUnit) {
	    let uString = null;
	    if (Ucum.caseSensitive_ == true) uString = theUnit['csUnitString_'];else uString = theUnit['ciUnitString_'];
	    if (uString) {
	      let uEntry = {
	        mag: theUnit['baseFactorStr_'],
	        unit: theUnit
	      };
	      if (this.unitStrings_[uString]) this.unitStrings_[uString].push(uEntry);else this.unitStrings_[uString] = [uEntry];
	    }
	  } // end addUnitString

	  /**
	   * Adds a Unit object to the unitDimensions_ table.  More than one unit
	   * can have the same dimension (commensurable units have the same dimension).
	   * Because of this, an array of unit objects is stored for the
	   * dimension.
	   *
	   * @param theUnit the unit to be added
	   * @returns nothing
	   * @throws an error if the unit has no dimension
	   */
	  addUnitDimension(theUnit) {
	    let uDim = theUnit['dim_'].getProperty('dimVec_');
	    if (uDim) {
	      if (this.unitDimensions_[uDim]) this.unitDimensions_[uDim].push(theUnit);else this.unitDimensions_[uDim] = [theUnit];
	    } else throw new Error('UnitTables.addUnitDimension called for a unit with no dimension.  ' + `Unit code = ${theUnit['csCode_']}.`);
	  } // end addUnitDimension

	  /**
	   * Builds the unitSynonyms_ table. This is called the first time the
	   * getUnitsBySynonym method is called.  The table/hash contains each word
	   * (once) from each synonym as well as each word from each unit name.
	   *
	   * Hash keys are the words.  Hash values are an array of unit codes for
	   * each unit that has that word in its synonyms or name.
	   *
	   * @returns nothing
	   */
	  buildUnitSynonyms() {
	    for (let code in this.unitCodes_) {
	      let theUnit = this.unitCodes_[code];
	      let uSyns = theUnit.synonyms_;

	      // If the current unit has synonyms, process each synonym (often multiples)
	      if (uSyns) {
	        let synsAry = uSyns.split(';');
	        if (synsAry[0] !== '') {
	          let aLen = synsAry.length;
	          for (let a = 0; a < aLen; a++) {
	            let theSyn = synsAry[a].trim();

	            // call addSynonymCodes to process each word in the
	            // synonym, e.g., "British fluid ounces"
	            this.addSynonymCodes(code, theSyn);
	          } // end do for each synonym
	        } // end if the current unit has a non-null synonym attribute
	      } // end if the unit has any synonyms

	      // Now call addSynonymCodes to process each word in the unit's name
	      this.addSynonymCodes(code, theUnit.name_);
	    } // end do for each unit
	  } // end buildUnitSynonyms

	  /**
	   * Adds unit code entries to the synonyms table for a string containing
	   * one or more words to be considered as synonyms.
	   *
	   * @param theCode the unit code to be connected to the synonyms
	   * @param theSynonyms a string containing one or more words to be
	   *  considered synonyms (and thus to be added to the unitSynonyms hash).
	   */
	  addSynonymCodes(theCode, theSynonyms) {
	    let words = theSynonyms.split(' ');
	    let wLen = words.length;
	    for (let w = 0; w < wLen; w++) {
	      let word = words[w];

	      // if there is already a synonyms entry for the word,
	      // get the array of unit codes currently assigned to
	      // the word and add the code for the current word to
	      // the synonyms array if it's not already there.
	      if (this.unitSynonyms_[word]) {
	        let synCodes = this.unitSynonyms_[word];
	        if (synCodes.indexOf(theCode) === -1) {
	          this.unitSynonyms_[word].push(theCode);
	        }
	      }
	      // else there are no synonyms entry for the word.  Create a
	      // synonyms array for the word, setting it to contain the unit code.
	      else {
	        this.unitSynonyms_[word] = [theCode];
	      }
	    } // end do for each word in the synonyms being processed
	  } // end addSynonymCodes

	  /**
	   *  Returns a unit object with a case-sensitive code matching the
	   *  uCode parameter, or null if no unit is found with that code.
	   *
	   *  @param uCode the code of the unit to be returned
	   *  @returns the unit object or null if it is not found
	   */
	  getUnitByCode(uCode) {
	    let retUnit = null;
	    if (uCode) {
	      retUnit = this.unitCodes_[uCode];
	    }
	    return retUnit;
	  }

	  /**
	   *  Returns a array of unit objects based on the unit's name.  Usually this
	   *  will be an array of one, but there may be more, since unit names are
	   *  not necessarily unique.
	   *
	   *  @param uName the name of the unit to be returned.  If more than one
	   *  unit has the same name and you only want one specific unit, append the
	   *  csCode of the unit you want to the end of the name, separated by the
	   *  Ucum.codeSep_ value, e.g., inch - [in_i] vs. inch - [in_us].
	   *  @returns null if no unit was found for the specified name OR an array of
	   *  unit objects with the specified name.  Normally this will be an array
	   *  of one object.
	   *  @throws an error if no name is provided to search on
	   */
	  getUnitByName(uName) {
	    if (uName === null || uName === undefined) {
	      throw new Error('Unable to find unit by name because no name was provided.');
	    }
	    let sepPos = uName.indexOf(Ucum.codeSep_);
	    let uCode = null;
	    if (sepPos >= 1) {
	      uCode = uName.substr(sepPos + Ucum.codeSep_.length);
	      uName = uName.substr(0, sepPos);
	    }
	    let retUnits = this.unitNames_[uName];
	    if (retUnits) {
	      let uLen = retUnits.length;
	      if (uCode && uLen > 1) {
	        let i = 0;
	        for (; retUnits[i].csCode_ !== uCode && i < uLen; i++);
	        if (i < uLen) retUnits = [retUnits[i]];else {
	          retUnits = null;
	        }
	      } // end if we need to find both a name and a code
	    } // end if we got an array of units
	    return retUnits;
	  } // end getUnitByName

	  /**
	   *  Returns an array of unit objects with the specified unit string.
	   *  The array may contain one or more unit reference objects.
	   *  Or none, if no units have a matching unit string (which is not
	   *  considered an error)
	   *
	   *  @param name the name of the unit to be returned
	   *  @returns the array of unit references or null if none were found
	   */
	  getUnitByString(uString) {
	    let retAry = null;
	    if (uString) {
	      retAry = this.unitStrings_[uString];
	      if (retAry === undefined) retAry = null;
	    }
	    return retAry;
	  }

	  /**
	   *  Returns a array of unit objects based on the unit's dimension vector.
	   *
	   *  @param uName the dimension vector of the units to be returned.
	   *
	   *  @returns null if no unit was found for the specified vector OR an array of
	   *  one or more unit objects with the specified vector.
	   *  @throws an error if no vector is provided to search on
	   *  logs an error to the console if no unit is found
	   */
	  getUnitsByDimension(uDim) {
	    let unitsArray = null;
	    if (uDim === null || uDim === undefined) {
	      throw new Error('Unable to find unit by because no dimension ' + 'vector was provided.');
	    }
	    unitsArray = this.unitDimensions_[uDim];
	    if (unitsArray === undefined || unitsArray === null) {
	      console.log(`Unable to find unit with dimension = ${uDim}`);
	    }
	    return unitsArray;
	  } // end getUnitsByDimension

	  /**
	   *  Returns a array of unit objects that include the specified synonym.
	   *
	   *  @param uSyn the synonym of the units to be returned.
	   *
	   *  @returns an object with two of the following three elements:
	   *   'status' will be error, failed or succeeded
	   *   'msg' will be included for returns with status = error or failed and
	   *     will explain why the request did not return any units
	   *   'units' any array of unit objects with the specified synonym will be
	   *     returned for requests with status = succeeded
	   */
	  getUnitBySynonym(uSyn) {
	    let retObj = {};
	    let unitsArray = [];
	    try {
	      if (uSyn === null || uSyn === undefined) {
	        retObj['status'] = 'error';
	        throw new Error('Unable to find unit by synonym because no synonym ' + 'was provided.');
	      }
	      // If this is the first request for a unit by synonym, build the hash map
	      if (Object.keys(this.unitSynonyms_).length === 0) {
	        this.buildUnitSynonyms();
	      }
	      let foundCodes = [];
	      foundCodes = this.unitSynonyms_[uSyn];
	      if (foundCodes) {
	        retObj['status'] = 'succeeded';
	        let fLen = foundCodes.length;
	        for (let f = 0; f < fLen; f++) {
	          unitsArray.push(this.unitCodes_[foundCodes[f]]);
	        }
	        retObj['units'] = unitsArray;
	      }
	      if (unitsArray.length === 0) {
	        retObj['status'] = 'failed';
	        retObj['msg'] = `Unable to find any units with synonym = ${uSyn}`;
	      }
	    } catch (err) {
	      retObj['msg'] = err.message;
	    }
	    return retObj;
	  } // end getUnitBySynonym

	  /**
	   * Gets a list of all unit names in the Unit tables
	   *
	   * @returns an array of the unit names
	   */
	  getAllUnitNames() {
	    return Object.keys(this.unitNames_);
	  } // end getAllUnitNames

	  /**
	   * Gets a list of all unit names in the tables.  Where more than one
	   * unit has the same name, the unit code, in parentheses, is appended
	   * to the end of the name.
	   *
	   * @returns {Array}
	   */
	  getUnitNamesList() {
	    let nameList = [];
	    let codes = Object.keys(this.unitCodes_);
	    codes.sort(this.compareCodes);
	    let uLen = codes.length;
	    for (let i = 0; i < uLen; i++) {
	      nameList[i] = codes[i] + Ucum.codeSep_ + this.unitCodes_[codes[i]].name_;
	    } // end do for each code
	    return nameList;
	  }

	  /*
	   * Returns the mass dimension index
	   * @returns this.massDimIndex_
	   */
	  getMassDimensionIndex() {
	    return this.massDimIndex_;
	  }

	  /**
	   * This provides a sort function for unit codes so that sorting ignores
	   * square brackets and case.
	   *
	   * @param a first value
	   * @param b second value
	   * @returns -1 if a is should fall before b; otherwise 1.
	   */
	  compareCodes(a, b) {
	    a = a.replace(/[\[\]]/g, '');
	    a = a.toLowerCase();
	    b = b.replace(/[\[\]]/g, '');
	    b = b.toLowerCase();
	    return a < b ? -1 : 1;
	  }

	  /**
	   * Gets a list of all unit codes in the Unit tables
	   *
	   * @returns an array of the unit names
	   */
	  getAllUnitCodes() {
	    return Object.keys(this.unitCodes_);
	  } // end getAllUnitNames

	  /**
	   * This is used to get all unit objects.  Currently it is used
	   * to get the objects to write to the json ucum definitions file
	   * that is used to provide prefix and unit definition objects for
	   * conversions and validations.
	   *
	   * @returns an array containing all unit objects, ordered by definition
	   * order
	   */
	  allUnitsByDef() {
	    let unitsList = [];
	    let uLen = this.codeOrder_.length;
	    for (let u = 0; u < uLen; u++) {
	      unitsList.push(this.getUnitByCode(this.codeOrder_[u]));
	    }
	    return unitsList;
	  } // end allUnitsByDef

	  /**
	   * This is used to get all unit objects, ordered by unit name.  Currently it
	   * is used to create a csv list of all units.
	   * @param sep separator character (or string) to be used to separate each
	   *  column in the output.  Optional, defaults to '|' if not specified.
	   *  (Used to use ; but the synonyms use that extensively).  Don't use a
	   *  comma or any other punctuation found in the output data.
	   * @returns a buffer containing all unit objects, ordered by name
	   * order
	   */
	  allUnitsByName(cols, sep) {
	    if (sep === undefined || sep === null) sep = '|';
	    let unitBuff = '';
	    let unitsList = this.getAllUnitNames();
	    let uLen = unitsList.length;
	    let cLen = cols.length;
	    for (let i = 0; i < uLen; i++) {
	      let nameRecs = this.getUnitByName(unitsList[i]);
	      for (let u = 0; u < nameRecs.length; u++) {
	        let rec = nameRecs[u];
	        for (let c = 0; c < cLen; c++) {
	          if (c > 0) unitBuff += sep;
	          if (cols[c] === 'dim_') {
	            if (rec.dim_ !== null && rec.dim_ !== undefined && rec.dim_.dimVec_ instanceof Array) unitBuff += '[' + rec.dim_.dimVec_.join(',') + ']';else unitBuff += '';
	          } else {
	            let cbuf = rec[cols[c]];
	            if (typeof cbuf === 'string') unitBuff += cbuf.replace(/[\n\r]/g, ' ');else unitBuff += cbuf;
	          }
	        } // end do for each column requested
	        unitBuff += '\r\n';
	      } // end do for each unit in the unit names array
	    }
	    return unitBuff;
	  } // end allUnitsByName

	  /**
	   * This creates a list of all units in the tables.  It uses the byCode
	   * table, and uses the codeOrder_ array to determine the order in which
	   * the units are listed.
	   *
	   * @param doLong boolean indicating how much to output.  If true, all data
	   *  from the unit objects is included.   If false, only a few major values
	   *  are included.
	   * @param sep separator character (or string) to be used to separate each
	   *  column in the output.  Optional, defaults to '|' if not specified.
	   *  (Used to use ; but the synonyms use that extensively).
	   * @returns {string} buffer containing all the listings
	   */
	  printUnits(doLong, sep) {
	    if (doLong === undefined) doLong = false;
	    if (sep === undefined) sep = '|';
	    let codeList = '';
	    let uLen = this.codeOrder_.length;
	    let unitString = 'csCode' + sep;
	    if (doLong) {
	      unitString += 'ciCode' + sep;
	    }
	    unitString += 'name' + sep;
	    if (doLong) unitString += 'isBase' + sep;
	    unitString += 'magnitude' + sep + 'dimension' + sep + 'from unit(s)' + sep + 'value' + sep + 'function' + sep;
	    if (doLong) unitString += 'property' + sep + 'printSymbol' + sep + 'synonyms' + sep + 'source' + sep + 'class' + sep + 'isMetric' + sep + 'variable' + sep + 'isSpecial' + sep + 'isAbitrary' + sep;
	    unitString += 'comment';
	    codeList = unitString + '\n';
	    for (let u = 0; u < uLen; u++) {
	      let curUnit = this.getUnitByCode(this.codeOrder_[u]);
	      unitString = this.codeOrder_[u] + sep;
	      if (doLong) {
	        unitString += curUnit.getProperty('ciCode_') + sep;
	      }
	      unitString += curUnit.getProperty('name_') + sep;
	      if (doLong) {
	        if (curUnit.getProperty('isBase_')) unitString += 'true' + sep;else unitString += 'false' + sep;
	      }
	      unitString += curUnit.getProperty('magnitude_') + sep;
	      let curDim = curUnit.getProperty('dim_');
	      if (curDim) {
	        unitString += curDim.dimVec_ + sep;
	      } else {
	        unitString += 'null' + sep;
	      }
	      if (curUnit.csUnitString_) unitString += curUnit.csUnitString_ + sep + curUnit.baseFactor_ + sep;else unitString += 'null' + sep + 'null' + sep;
	      if (curUnit.cnv_) unitString += curUnit.cnv_ + sep;else unitString += 'null' + sep;
	      if (doLong) {
	        unitString += curUnit.getProperty('property_') + sep + curUnit.getProperty('printSymbol_') + sep + curUnit.getProperty('synonyms_') + sep + curUnit.getProperty('source_') + sep + curUnit.getProperty('class_') + sep + curUnit.getProperty('isMetric_') + sep + curUnit.getProperty('variable_') + sep + curUnit.getProperty('isSpecial_') + sep + curUnit.getProperty('isArbitrary_') + sep;
	      }
	      if (curUnit.defError_) unitString += 'problem parsing this one, deferred to later.';
	      codeList += unitString + '\n';
	    }
	    return codeList;
	  }
	} // end UnitTablesFactory

	// Create a singleton instance and (to preserve the existing API) an object that
	// provides that instance via getInstance().
	var unitTablesInstance = new UnitTablesFactory();
	const UnitTables = {
	  getInstance: function () {
	    return unitTablesInstance;
	  }
	};
	unitTables.UnitTables = UnitTables;
	
	return unitTables;
}

var hasRequiredUcumInternalUtils;

function requireUcumInternalUtils () {
	if (hasRequiredUcumInternalUtils) return ucumInternalUtils;
	hasRequiredUcumInternalUtils = 1;

	Object.defineProperty(ucumInternalUtils, "__esModule", {
	  value: true
	});
	ucumInternalUtils.isNumericString = isNumericString;
	ucumInternalUtils.isIntegerUnit = isIntegerUnit;
	ucumInternalUtils.getSynonyms = getSynonyms;
	/**
	 * Internal utilities used by multiple UCUM classes.  For example,
	 * isNumericString is used by both the UnitString and UcumLhcUtils
	 * classes.  If it's in the UnitString class the UcumLhcUtils class
	 * needs to require the UnitString class.  But the checkSynonyms
	 * class is used by the UnitString class - but was in the UcumLhcUtils
	 * class.  Requiring the UcumLhcUtils class from the UnitString class
	 * made everything break (cyclical requires).
	 *
	 * So now they're here.
	 */

	/**
	 * This module implements internal ucum utilities.
	 *
	 * @author Lee Mericle, based on java version by Gunther Schadow
	 *
	 */

	var UnitTables = requireUnitTables().UnitTables;

	/**
	 * This function tests a string to see if it contains only numbers (digits,
	 * a period, leading - or +).  This code was taken from a stackoverflow
	 * solution:
	 * https://stackoverflow.com/questions/175739/is-there-a-built-in-way-in-javascript-to-check-if-a-string-is-a-valid-number/42356340#42356340
	 *
	 * @params theString
	 * @returns true if the string contains only numbers; false otherwise
	 */
	function isNumericString(theString) {
	  let num = "" + theString; //coerce num to be a string
	  return !isNaN(num) && !isNaN(parseFloat(num));
	} // end isNumericString

	/**
	 *  Checks whether a string qualifies as an integer unit.  Section 2.2.8 ("integer
	 *  numbers", says, "A positive integer number may appear in place of a simple
	 *  unit symbol.  Only a pure string of decimal digits (09) is
	 *  interpreted as a number."
	 *  Note:  This leaves open the question of whether "0" is a valid unit, since
	 *  it is positive, but you can't measure anything in units of zero.
	 * @param str the string to check
	 */
	function isIntegerUnit(str) {
	  return /^\d+$/.test(str);
	}

	/**
	 * This method accepts a term and looks for units that include it as
	 * a synonym - or that include the term in its name.
	 *
	 * @param theSyn the term to search for.  This is assumed to be
	 *  a string and not undefined.  The calling method should do any
	 *  necessary checking before calling this.
	 * @returns a hash with up to three elements:
	 *  'status' contains the status of the request, which can be 'error',
	 *    'failed' or succeeded';
	 *  'msg' which contains a message for an error or if no units were found; and
	 *  'units' which is an array that contains one array for each unit found:
	 *    the unit's csCode_, the unit's name_, and the unit's guidance_
	 *
	 */
	function getSynonyms(theSyn) {
	  let retObj = {};
	  let utab = UnitTables.getInstance();
	  let resp = {};
	  resp = utab.getUnitBySynonym(theSyn);

	  // If we didn't get any units, transfer the status and message
	  if (!resp['units']) {
	    retObj['status'] = resp['status'];
	    retObj['msg'] = resp['msg'];
	  } else {
	    retObj['status'] = 'succeeded';
	    let aLen = resp['units'].length;
	    retObj['units'] = [];
	    for (let a = 0; a < aLen; a++) {
	      let theUnit = resp['units'][a];
	      retObj['units'][a] = {
	        'code': theUnit.csCode_,
	        'name': theUnit.name_,
	        'guidance': theUnit.guidance_
	      };
	    } // end do for all units returned
	  } // end if we got a units list
	  return retObj;
	} // end getSynonyms
	
	return ucumInternalUtils;
}

var dimension = {};

var _isFinite;
var hasRequired_isFinite;

function require_isFinite () {
	if (hasRequired_isFinite) return _isFinite;
	hasRequired_isFinite = 1;

	_isFinite = Number.isFinite || function (value) {
		return !(typeof value !== 'number' || value !== value || value === Infinity || value === -Infinity);
	};
	return _isFinite;
}

var isInteger;
var hasRequiredIsInteger;

function requireIsInteger () {
	if (hasRequiredIsInteger) return isInteger;
	hasRequiredIsInteger = 1;
	// https://github.com/paulmillr/es6-shim
	// http://people.mozilla.org/~jorendorff/es6-draft.html#sec-number.isinteger
	var isFinite = require_isFinite();
	isInteger = Number.isInteger || function(val) {
	  return typeof val === "number" &&
	    isFinite(val) &&
	    Math.floor(val) === val;
	};
	return isInteger;
}

var hasRequiredDimension;

function requireDimension () {
	if (hasRequiredDimension) return dimension;
	hasRequiredDimension = 1;

	Object.defineProperty(dimension, "__esModule", {
	  value: true
	});
	dimension.Dimension = void 0;
	/**
	 * This class implements an object containing the vector of exponents for
	 * a unit and its operations for addition, subtraction, and multiplication
	 * with a scalar.
	 *
	 * This object should exist for each unit that can be expressed as a
	 * vector of numbers.   This excludes arbitrary units, e.g., (10*23), and
	 * units that are not numbers but are an expression based solely on numbers,
	 * e.g., mol (mole) which is based on 10*23.
	 *
	 * @author Lee Mericle, based on java version by Gunther Schadow
	 */
	var UC = requireConfig();
	var isInteger = requireIsInteger();
	class Dimension {
	  /**
	   * Constructor.
	   *
	   * @param dimSetting an optional parameter that may be:
	   *  null, which means that the dimVec_ attribute for this object will be null; or
	   *  an array, which must be the length defined by Ucum.dimLen_, and
	   *    whose contents will be copied to this new object's vector; or
	   *  an integer, which must be between 0 and 1 less than the vector length
	   *    defined by Ucum.dimLen_.  This new object's vector will be
	   *    initialized to zero for all elements except the one whose index
	   *    matches the number passed in.  That element will be set to one.
	    * @throws an error if the dimSetting parameter does not meet the types
	   *  listed above.
	   *  An error will also be thrown if Ucum.dimLen_ has not been set yet,
	   *  i.e., is still zero.   Currently that won't happen, because the
	   *  value is set in the config.js file.  But further down the road
	   *  the setting will come from a definitions input file, so we check
	   *  here anyway.
	   *
	   */
	  constructor(dimSetting) {
	    if (UC.Ucum.dimLen_ === 0) {
	      throw new Error('Dimension.setDimensionLen must be called before ' + 'Dimension constructor');
	    }
	    if (dimSetting === undefined || dimSetting === null) {
	      this.assignZero();
	    } else if (dimSetting instanceof Array) {
	      if (dimSetting.length !== UC.Ucum.dimLen_) {
	        throw new Error('Parameter error, incorrect length of vector passed to ' + `Dimension constructor, vector = ${JSON.stringify(dimSetting)}`);
	      }
	      this.dimVec_ = [];
	      for (let d = 0; d < UC.Ucum.dimLen_; d++) this.dimVec_.push(dimSetting[d]);
	    }

	    // In es6 this should be Number.isInteger(dimSetting).  But Babel
	    // doesn't transpile that correctly, so we need to use the isInteger
	    // module.  :0
	    else if (isInteger(dimSetting)) {
	      if (dimSetting < 0 || dimSetting >= UC.Ucum.dimLen_) {
	        throw new Error('Parameter error, invalid element number specified for ' + 'Dimension constructor');
	      }
	      this.assignZero();
	      this.dimVec_[dimSetting] = 1;
	    }
	  } // end constructor

	  /**
	   * Sets the element at the specified position to a specified value.  The
	   * default value is 1.  If the dimension vector is null when this is called
	   * a zero-filled vector is created and then the indicated position is set.
	   *
	   * @param indexPos the index of the element to be set
	   * @param value the value to assign to the specified element; optional,
	   *  default value is 1
	   * @throws an exception if the specified position is invalid, i.e., not a
	   *   number or is less than 0 or greater than Ucum.dimLen_
	   **/
	  setElementAt(indexPos, value) {
	    if (!isInteger(indexPos) || indexPos < 0 || indexPos >= UC.Ucum.dimLen_) {
	      throw new Error(`Dimension.setElementAt called with an invalid index ` + `position (${indexPos})`);
	    }
	    if (!this.dimVec_) {
	      this.assignZero();
	    }
	    if (value === undefined || value === null) value = 1;
	    this.dimVec_[indexPos] = value;
	  }

	  /**
	   * Gets the value of the element at the specified position
	   *
	   * @param indexPos the index of the element whose value is to be returned
	   * @return the value of the element at indexPos, or null if the dimension
	   *  vector is null
	   * @throws an exception if the specified position is invalid, i.e., not a
	   *   number or is less than 0 or greater than Ucum.dimLen_
	   **/
	  getElementAt(indexPos) {
	    if (!isInteger(indexPos) || indexPos < 0 || indexPos >= UC.Ucum.dimLen_) {
	      throw new Error(`Dimension.getElementAt called with an invalid index ` + `position (${indexPos})`);
	    }
	    let ret = null;
	    if (this.dimVec_) ret = this.dimVec_[indexPos];
	    return ret;
	  }

	  /**
	   * This returns the value of the property named by the parameter
	   * passed in.  Although we currently only have one property, dimVec_,
	   * that this will get, it's possible that we'll have additional
	   * properties.   If we don't this could just be replaced by a
	   * getVector function.
	   *
	   * @param propertyName name of the property to be returned, with
	   *        or without the trailing underscore.
	   * @return the requested property, if found for this Dimension
	   * @throws an error if the property is not found for this Dimension
	   */
	  getProperty(propertyName) {
	    let uProp = propertyName.charAt(propertyName.length - 1) === '_' ? propertyName : propertyName + '_';
	    return this[uProp];
	  } // end getProperty

	  /**
	   * Return a string that represents the dimension vector.  Returns null if
	   * the dimension vector is null.
	   *
	   * @return the string that represents the dimension vector.  The
	   *         values are enclosed in square brackets, each separated
	   *         by a comma and a space
	   **/
	  toString() {
	    let ret = null;
	    if (this.dimVec_) ret = '[' + this.dimVec_.join(', ') + ']';
	    return ret;
	  }

	  /**
	   * Adds the vector of the dimension object passed in to this
	   * dimension object's vector.  This object's vector is changed.
	   * If either dimension vector is null, no changes are made to this object.
	   *
	   *
	   * @param dim2 the dimension whose vector is to be added to this one
	   * @return this object
	   * @throws an exception if dim2 is not a Dimension object
	   **/
	  add(dim2) {
	    if (!dim2 instanceof Dimension) {
	      throw new Error(`Dimension.add called with an invalid parameter - ` + `${typeof dim2} instead of a Dimension object`);
	    }
	    if (this.dimVec_ && dim2.dimVec_) {
	      for (let i = 0; i < UC.Ucum.dimLen_; i++) this.dimVec_[i] += dim2.dimVec_[i];
	    }
	    return this;
	  }

	  /**
	   * Subtracts the vector of the dimension object passed in from this
	   * dimension object's vector.  This object's vector is changed.
	   * If either dimension vector is null, no changes are made to this object.
	   *
	   * @param dim2 the dimension whose vector is to be subtracted from this one
	   * @return this object
	   * @throws an exception if dim2 is not a Dimension object
	   **/
	  sub(dim2) {
	    if (!dim2 instanceof Dimension) {
	      throw new Error(`Dimension.sub called with an invalid parameter - ` + `${typeof dim2} instead of a Dimension object`);
	    }
	    if (this.dimVec_ && dim2.dimVec_) {
	      for (let i = 0; i < UC.Ucum.dimLen_; i++) this.dimVec_[i] -= dim2.dimVec_[i];
	    }
	    return this;
	  }

	  /**
	   * Inverts this dimension object's vector (by multiplying each element
	   * by negative 1).  This object's vector is changed - unless it is null,
	   * in which case it stays that way.
	   *
	   * @return this object
	   **/
	  minus() {
	    if (this.dimVec_) {
	      for (let i = 0; i < UC.Ucum.dimLen_; i++) this.dimVec_[i] = -this.dimVec_[i];
	    }
	    return this;
	  }

	  /**
	   * Multiplies this dimension object's vector with a scalar.  This is used
	   * when a unit is raised to a power.  This object's vector is changed unless
	   * the vector is null, in which case it stays that way.
	   *
	   * @param s the scalar to use
	   * @return this object
	   * @throws an exception if s is not a number
	   */
	  mul(s) {
	    if (!isInteger(s)) {
	      throw new Error(`Dimension.sub called with an invalid parameter - ` + `${typeof dim2} instead of a number`);
	    }
	    if (this.dimVec_) {
	      for (let i = 0; i < UC.Ucum.dimLen_; i++) this.dimVec_[i] *= s;
	    }
	    return this;
	  }

	  /**
	   * Tests for equality of this dimension object's vector and that of
	   * the dimension object passed in.  If the dimension vector for one of
	   * the objects is null, the dimension vector for the other object must
	   * also be null for the two to be equal.  (I know - duh.  still)
	   *
	   * @param dim2 the dimension object whose vector is to be compared to this one
	   * @return true if the two vectors are equal; false otherwise.
	   * @throws an exception if dim2 is not a Dimension object
	   */
	  equals(dim2) {
	    if (!dim2 instanceof Dimension) {
	      throw new Error(`Dimension.equals called with an invalid parameter - ` + `${typeof dim2} instead of a Dimension object`);
	    }
	    let isEqual = true;
	    let dimVec2 = dim2.dimVec_;
	    if (this.dimVec_ && dimVec2) {
	      for (let i = 0; isEqual && i < UC.Ucum.dimLen_; i++) isEqual = this.dimVec_[i] === dimVec2[i];
	    } else {
	      isEqual = this.dimVec_ === null && dimVec2 === null;
	    }
	    return isEqual;
	  }

	  /**
	   * Assigns the contents of the vector belonging to the dimension object
	   * passed in to this dimension's vector.  If this dimension vector is null
	   * and the other is not, this one will get the contents of the other.  If
	   * this dimension vector is not null but the one passed in is null, this
	   * one will be set to null.
	   *
	   * @param dim2 the dimension object with the vector whose contents are
	   *  to be assigned to this dimension's vector
	   * @return this object (not sure why)
	   * @throws an exception if dim2 is not a Dimension object
	   */
	  assignDim(dim2) {
	    if (!dim2 instanceof Dimension) {
	      throw new Error(`Dimension.assignDim called with an invalid parameter - ` + `${typeof dim2} instead of a Dimension object`);
	    }
	    if (dim2.dimVec_ === null) this.dimVec_ = null;else {
	      if (this.dimVec_ === null) {
	        this.dimVec_ = [];
	      }
	      for (let i = 0; i < UC.Ucum.dimLen_; i++) this.dimVec_[i] = dim2.dimVec_[i];
	    }
	    return this;
	  }

	  /**
	   * Sets all elements of this dimension object's vector to zero.
	   * If this object's vector is null, it is created as a zero-filled vector.
	   *
	   * @return this object (not sure why)
	   */
	  assignZero() {
	    if (this.dimVec_ === null || this.dimVec_ === undefined) this.dimVec_ = [];
	    for (let i = 0; i < UC.Ucum.dimLen_; i++) {
	      this.dimVec_.push(0);
	    }
	    return this;
	  }

	  /**
	   * Tests for a dimension vector set to all zeroes.
	   *
	   * @return true if exponents (elements) of this dimension's vector are all
	   * zero; false otherwise (including if the current vector is null).
	   *
	   */
	  isZero() {
	    let allZero = this.dimVec_ !== null;
	    if (this.dimVec_) {
	      for (let i = 0; allZero && i < UC.Ucum.dimLen_; i++) allZero = this.dimVec_[i] === 0;
	    }
	    return allZero;
	  }

	  /**
	   * Tests for a Dimension object with no dimension vector (dimVec_ is null).
	   *
	   * @return true the dimension vector is null; false if it is not
	   *
	   */
	  isNull() {
	    return this.dimVec_ === null;
	  }

	  /**
	   * Creates and returns a clone of this Dimension object
	   *
	   * @return the clone
	   */
	  clone() {
	    let that = new Dimension();
	    that.assignDim(this);
	    return that;
	  }
	} // end Dimension class
	dimension.Dimension = Dimension;
	
	return dimension;
}

var hasRequiredUnit;

function requireUnit () {
	if (hasRequiredUnit) return unit;
	hasRequiredUnit = 1;

	Object.defineProperty(unit, "__esModule", {
	  value: true
	});
	unit.Unit = void 0;
	var _ucumFunctions = _interopRequireDefault(requireUcumFunctions());
	var intUtils_ = _interopRequireWildcard(requireUcumInternalUtils());
	function _getRequireWildcardCache() { if (typeof WeakMap !== "function") return null; var cache = new WeakMap(); _getRequireWildcardCache = function () { return cache; }; return cache; }
	function _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== "object" && typeof obj !== "function") { return { default: obj }; } var cache = _getRequireWildcardCache(); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }
	function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }
	/**
	 * This class represents one unit of measure.  It includes
	 * functions to cover constructor, accessor, and assignment tasks as
	 * well as operators to calculate multiplication, division and raising
	 * to a power.
	 *
	 * @author Lee Mericle, based on java version by Gunther Schadow
	 *
	 */
	var Ucum = requireConfig().Ucum;
	var Dimension = requireDimension().Dimension;
	var UnitTables;
	var isInteger = requireIsInteger();
	class Unit {
	  /**
	   * Constructor.
	   *
	   * @param attrs an optional parameter that may be:
	   *  a string, which is parsed by the unit parser, which creates
	   *  the unit from the parsed string; or
	   *  a hash containing all or some values for the attributes of
	   *  the unit, where the keys are the attribute names, without a
	   *  trailing underscore, e.g., name instead of name_; or
	   *  null, in which case an empty hash is created and used to
	   *  set the values forthe attributes.
	   *  If a hash (empty or not) is used, attributes for which no value
	   *  is specified are assigned a default value.
	   *
	   */
	  constructor(attrs = {}) {
	    // Process the attrs hash passed in, which may be empty.
	    // Create and assign values (from the attrs hash or defaults) to all
	    // attributes.  From Class Declarations in Understanding ECMAScript,
	    // https://leanpub.com/understandinges6/read/#leanpub-auto-class-declarations,
	    //   "Own properties, properties that occur on the instance rather than the
	    //    prototype, can only be created inside of a class constructor or method.
	    //    It's recommended to create all possible own properties inside of the
	    //    constructor function so there's a single place that's responsible for
	    //    all of them."

	    /*
	     * Flag indicating whether or not this is a base unit
	     */
	    this.isBase_ = attrs['isBase_'] || false;

	    /*
	     * The unit name, e.g., meter
	     */
	    this.name_ = attrs['name_'] || '';

	    /*
	     * The unit's case-sensitive code, e.g., m
	     */
	    this.csCode_ = attrs['csCode_'] || '';

	    /*
	     * The unit's case-insensitive code, e.g., M
	     */
	    this.ciCode_ = attrs['ciCode_'] || '';

	    /*
	     * The unit's property, e.g., length
	     */
	    this.property_ = attrs['property_'] || '';

	    /*
	     * The magnitude of the unit, e.g., 3600/3937 for a yard,
	     * where a yard - 3600/3973 * m(eter).  The Dimension
	     * property specifies the meter - which is the unit on which
	     * a yard is based, and this magnitude specifies how to figure
	     * this unit based on the base unit.
	     */
	    this.magnitude_ = attrs['magnitude_'] || 1;

	    /*
	     * The Dimension object of the unit
	     */
	    if (attrs['dim_'] === undefined || attrs['dim_'] === null) {
	      this.dim_ = new Dimension();
	    }
	    // When the unit data stored in json format is reloaded, the dimension data
	    // is recognized as a a hash, not as a Dimension object.
	    else if (attrs['dim_']['dimVec_'] !== undefined) {
	      this.dim_ = new Dimension(attrs['dim_']['dimVec_']);
	    } else if (attrs['dim_'] instanceof Dimension) {
	      this.dim_ = attrs['dim_'];
	    } else if (attrs['dim_'] instanceof Array || isInteger(attrs['dim_'])) {
	      this.dim_ = new Dimension(attrs['dim_']);
	    } else {
	      this.dim_ = new Dimension();
	    }
	    /*
	     * The print symbol of the unit, e.g., m
	     */
	    this.printSymbol_ = attrs['printSymbol_'] || null;

	    /*
	     * The class of the unit, where given, e.g., dimless
	     */
	    this.class_ = attrs['class_'] || null;

	    /*
	     * A flag indicating whether or not the unit is metric
	     */
	    this.isMetric_ = attrs['isMetric_'] || false;

	    /*
	     * The "variable" - which I think is used only for base units
	     * The symbol for the variable as used in equations, e.g., s for distance
	     */
	    this.variable_ = attrs['variable_'] || null; // comes from 'dim' in XML

	    /*
	     * The conversion function
	     */
	    this.cnv_ = attrs['cnv_'] || null;

	    /*
	     * The conversion prefix
	     */
	    this.cnvPfx_ = attrs['cnvPfx_'] || 1;

	    /*
	     * Flag indicating whether or not this is a "special" unit, i.e., is
	     * constructed using a function specific to the measurement, e.g.,
	     * fahrenheit and celsius
	     */
	    this.isSpecial_ = attrs['isSpecial_'] || false;

	    /*
	     * Flag indicating whether or not this is an arbitrary unit
	     */
	    this.isArbitrary_ = attrs['isArbitrary_'] || false;

	    /*
	     * Integer indicating what level of exponent applies to a mole-based portion
	     * of the unit.  So, for the unit "mol", this will be 1.  For "mol2" this
	     * will be 2.  For "1/mol" this will be -1.  Any unit that does not include
	     * a mole will have a 0 in this field.  This is used to determine
	     * commensurability for mole<->mass conversions.
	     */
	    this.moleExp_ = attrs['moleExp_'] || 0;

	    /*
	     * Added when added LOINC list of units
	     * synonyms are used by the autocompleter to enhance lookup capabilities
	     * while source says where the unit first shows up.  Current sources are
	     * UCUM - which are units from the unitsofmeasure.org list and LOINC -
	     * which are units from the LOINC data.
	     */
	    this.synonyms_ = attrs['synonyms_'] || null;
	    this.source_ = attrs['source_'] || null;
	    this.loincProperty_ = attrs['loincProperty_'] || null;
	    this.category_ = attrs['category_'] || null;
	    this.guidance_ = attrs['guidance_'] || null;

	    /*
	     * Used to compute dimension; storing for now until I complete
	     * unit definition parsing
	     */
	    /*
	     * Case sensitive (cs) and case insensitive (ci) base unit strings,
	     * includes exponent and prefix if applicable - specified in
	     * <value Unit=x UNIT=X value="nnn">nnn</value> -- the unit part --
	     * in the ucum-essence.xml file, and may be specified by a user
	     * when requesting conversion or validation of a unit string.  The
	     * magnitude (base factor) is used with this to determine the new unit.
	     * For example, a Newton (unit code N) is created from the string
	     * kg.m/s2, and the value of 1 (base factor defined below). An hour
	     * (unit code h) is created from the unit min (minute) with a value
	     * of 60.
	     */
	    this.csUnitString_ = attrs['csUnitString_'] || null;
	    this.ciUnitString_ = attrs['ciUnitString_'] || null;

	    /*
	     * String and numeric versions of factor applied to unit specified in
	     * <value Unit=x UNIT=X value="nnn">nnn</value> -- the value part
	     */
	    this.baseFactorStr_ = attrs['baseFactorStr_'] || null;
	    this.baseFactor_ = attrs['baseFactor_'] || null;

	    /*
	     * Flag used to indicate units where the definition process failed
	     * when parsing units from the official units definitions file
	     * (currently using the ucum-essence.xml file).  We keep these
	     * so that we can use them to at least validate them as valid
	     * units, but we don't try to convert them.   This is temporary
	     * and only to account for instances where the code does not
	     * take into account various special cases in the xml file.
	     *
	     * This is NOT used when trying to validate a unit string
	     * submitted during a conversion or validation attempt.
	     */
	    this.defError_ = attrs['defError_'] || false;
	  } // end constructor

	  /**
	   * Assign the unity (= dimensionless unit 1) to this unit.
	   *
	   * @return this unit
	   */
	  assignUnity() {
	    this.name_ = "";
	    this.magnitude_ = 1;
	    if (!this.dim_) this.dim_ = new Dimension();
	    this.dim_.assignZero();
	    this.cnv_ = null;
	    this.cnvPfx_ = 1;
	    return this;
	  } // end assignUnity

	  /**
	   * This assigns one or more values, as provided in the hash passed in,
	   * to this unit.
	   *
	   * @param vals hash of values to be assigned to the attributes
	   *        specified by the key(s), which should be the attribute
	   *        name without the trailing underscore, e.g., name instead
	   *        of name_.
	   * @return nothing
	   */
	  assignVals(vals) {
	    for (let key in vals) {
	      let uKey = !key.charAt(key.length - 1) === '_' ? key + '_' : key;
	      if (this.hasOwnProperty(uKey)) this[uKey] = vals[key];else throw new Error(`Parameter error; ${key} is not a property of a Unit`);
	    }
	  } // end assignVals

	  /**
	   * This creates a clone of this unit.
	   *
	   * @return the clone
	   */
	  clone() {
	    let retUnit = new Unit();
	    Object.getOwnPropertyNames(this).forEach(val => {
	      if (val === 'dim_') {
	        if (this['dim_']) retUnit['dim_'] = this['dim_'].clone();else retUnit['dim_'] = null;
	      } else retUnit[val] = this[val];
	    });
	    return retUnit;
	  } // end clone

	  /**
	   * This assigns all properties of a unit passed to it to this unit.
	   *
	   * @param unit2 the unit whose properties are to be assigned to this one.
	   * @return nothing; this unit is updated
	   */
	  assign(unit2) {
	    Object.getOwnPropertyNames(unit2).forEach(val => {
	      if (val === 'dim_') {
	        if (unit2['dim_']) this['dim_'] = unit2['dim_'].clone();else this['dim_'] = null;
	      } else {
	        this[val] = unit2[val];
	      }
	    });
	  } // end assign

	  /**
	   * This determines whether or not object properties of the unit
	   * passed in are equal to the corresponding properties in this unit.
	   * The following properties are the only ones checked:
	   *   magnitude_, dim_, cnv_ and cnvPfx_
	   *
	   * @param unit2 the unit whose properties are to be checked.
	   * @return boolean indicating whether or not they match
	   */
	  equals(unit2) {
	    return this.magnitude_ === unit2.magnitude_ && this.cnv_ === unit2.cnv_ && this.cnvPfx_ === unit2.cnvPfx_ && (this.dim_ === null && unit2.dim_ === null || this.dim_.equals(unit2.dim_));
	  } // end equals

	  /**
	   * This method compares every attribute of two objects to determine
	   * if they all match.
	   *
	   * @param unit2 the unit that is to be compared to this unit
	   * @return boolean indicating whether or not every attribute matches
	   */
	  fullEquals(unit2) {
	    let thisAttr = Object.keys(this).sort();
	    let u2Attr = Object.keys(unit2).sort();
	    let keyLen = thisAttr.length;
	    let match = keyLen === u2Attr.length;

	    // check each attribute.   Dimension objects have to checked using
	    // the equals function of the Dimension class.
	    for (let k = 0; k < keyLen && match; k++) {
	      if (thisAttr[k] === u2Attr[k]) {
	        if (thisAttr[k] === 'dim_') match = this.dim_.equals(unit2.dim_);else match = this[thisAttr[k]] === unit2[thisAttr[k]];
	      } else match = false;
	    } // end do for each key and attribute
	    return match;
	  } // end of fullEquals

	  /**
	   * This returns the value of the property named by the parameter
	   * passed in.
	   *
	   * @param propertyName name of the property to be returned, with
	   *        or without the trailing underscore.
	   * @return the requested property, if found for this unit
	   * @throws an error if the property is not found for this unit
	   */
	  getProperty(propertyName) {
	    let uProp = propertyName.charAt(propertyName.length - 1) === '_' ? propertyName : propertyName + '_';
	    return this[uProp];
	  } // end getProperty

	  /**
	   * Takes a measurement consisting of a number of units and a unit and returns
	   * the equivalent number of this unit.  So, 15 mL would translate
	   * to 1 tablespoon if this object is a tablespoon.
	   *
	   * Note that the number returned may not be what is normally expected.
	   * For example, converting 10 Celsius units to Fahrenheit would "normally"
	   * return a value of 50.   But in this case you'll get back something like
	   * 49.99999999999994.
	   *
	   * If either unit is an arbitrary unit an exception is raised.
	   *
	   * @param num the magnitude for the unit to be translated (e.g. 15 for 15 mL)
	   * @param fromUnit the unit to be translated to one of this type (e.g. a mL unit)
	   *
	   * @return the number of converted units (e.g. 1 for 1 tablespoon)
	   * @throws an error if the dimension of the fromUnit differs from this unit's
	   * dimension
	   */
	  convertFrom(num, fromUnit) {
	    let newNum = 0.0;
	    if (this.isArbitrary_) throw new Error(`Attempt to convert to arbitrary unit "${this.csCode_}"`);
	    if (fromUnit.isArbitrary_) throw new Error(`Attempt to convert arbitrary unit "${fromUnit.csCode_}"`);

	    // reject request if both units have dimensions that are not equal
	    if (fromUnit.dim_ && this.dim_ && !fromUnit.dim_.equals(this.dim_)) {
	      // check first to see if a mole<->mass conversion is appropriate
	      if (this.isMoleMassCommensurable(fromUnit)) {
	        throw new Error(Ucum.needMoleWeightMsg_);
	      } else {
	        throw new Error(`Sorry.  ${fromUnit.csCode_} cannot be converted ` + `to ${this.csCode_}.`);
	      }
	    }
	    // reject request if there is a "from" dimension but no "to" dimension
	    if (fromUnit.dim_ && (!this.dim_ || this.dim_.isNull())) {
	      throw new Error(`Sorry.  ${fromUnit.csCode_} cannot be converted ` + `to ${this.csCode_}.`);
	    }

	    // reject request if there is a "to" dimension but no "from" dimension
	    if (this.dim_ && (!fromUnit.dim_ || fromUnit.dim_.isNull())) {
	      throw new Error(`Sorry.  ${fromUnit.csCode_} cannot be converted ` + `to ${this.csCode_}.`);
	    }
	    let fromCnv = fromUnit.cnv_;
	    let fromMag = fromUnit.magnitude_;
	    let x;
	    if (fromCnv != null) {
	      // turn num * fromUnit.magnitude into its ratio scale equivalent,
	      // e.g., convert Celsius to Kelvin
	      let fromFunc = _ucumFunctions.default.forName(fromCnv);
	      x = fromFunc.cnvFrom(num * fromUnit.cnvPfx_) * fromMag;
	      //x = fromFunc.cnvFrom(num * fromMag) * fromUnit.cnvPfx_;
	    } else {
	      x = num * fromMag;
	    }
	    if (this.cnv_ != null) {
	      // turn mag * origUnit on ratio scale into a non-ratio unit,
	      // e.g. convert Kelvin to Fahrenheit
	      let toFunc = _ucumFunctions.default.forName(this.cnv_);
	      newNum = toFunc.cnvTo(x / this.magnitude_) / this.cnvPfx_;
	    } else {
	      newNum = x / this.magnitude_;
	    }
	    return newNum;
	  } // end convertFrom

	  /**
	   * Takes a number and a target unit and returns the number for a measurement
	   * of this unit that corresponds to the number of the target unit passed in.
	   * So, 1 tablespoon (where this unit represents a tablespoon) would translate
	   * to 15 mL.
	   *
	   * See the note on convertFrom about return values.
	   *
	   * @param mag the magnitude for this unit (e.g. 1 for 1 tablespoon)
	   * @param toUnit the unit to which this unit is to be translated
	   *  (e.g. an mL unit)
	   *
	   * @return the converted number value (e.g. 15 mL)
	   * @throws an error if the dimension of the toUnit differs from this unit's
	   *   dimension
	   */
	  convertTo(num, toUnit) {
	    return toUnit.convertFrom(num, this);
	  } // end convertTo

	  /**
	   * Takes a given number of this unit returns the number of this unit
	   * if it is converted into a coherent unit.  Does not change this unit.
	   *
	   * If this is a coherent unit already, just gives back the number
	   * passed in.
	   *
	   * @param num the number for the coherent version of this unit
	   * @return the number for the coherent version of this unit
	   */
	  convertCoherent(num) {
	    // convert mag' * u' into canonical number * u on ratio scale
	    if (this.cnv_ !== null) num = this.cnv_.f_from(num / this.cnvPfx_) * this.magnitude_;
	    return num;
	  } // end convertCoherent

	  /**
	   * Mutates this unit into a coherent unit and converts a given number of
	   * units to the appropriate value for this unit as a coherent unit
	   *
	   * @param num the number for this unit before conversion
	   * @return the number of this unit after conversion
	   * @throws an error if the dimensions differ
	   */
	  mutateCoherent(num) {
	    // convert mu' * u' into canonical mu * u on ratio scale
	    num = this.convertCoherent(num);

	    // mutate to coherent unit
	    this.magnitude_ = 1;
	    this.cnv_ = null;
	    this.cnvPfx_ = 1;
	    this.name_ = "";

	    // build a name as a term of coherent base units
	    // This is probably ALL WRONG and a HORRIBLE MISTAKE
	    // but until we figure out what the heck the name being
	    // built here really is, it will have to stay.
	    for (let i = 0, max = Dimension.getMax(); i < max; i++) {
	      let elem = this.dim_.getElementAt(i);
	      let tabs = this._getUnitTables();
	      let uA = tabs.getUnitsByDimension(new Dimension(i));
	      if (uA == null) throw new Error(`Can't find base unit for dimension ${i}`);
	      this.name_ = uA.name + elem;
	    }
	    return num;
	  } // end mutateCoherent

	  /**
	   * Calculates the number of units that would result from converting a unit
	   * expressed in mass/grams to a unit expressed in moles.  The "this" unit is
	   * the unit expressed in some form of mass (g, mg, mmg, kg, whatever) and the
	   * target or "to" unit - the molUnit parameter - is a unit expressed in moles
	   * - mol, umol, mmol, etc.  The unit expressions surrounding the moles and
	   * mass must be convertible.  No validation of this requirement is performed.
	   *
	   * @param amt the quantity of this unit to be converted
	   * @param molUnit the target/to unit for which the converted # is wanted
	   * @param molecularWeight the molecular weight of the substance for which the
	   *  conversion is being made
	   * @return the equivalent amount in molUnit
	   */
	  convertMassToMol(amt, molUnit, molecularWeight) {
	    // The prefix values that have been applied to this unit, which is the mass
	    // (grams) unit, are reflected in the magnitude.  So the number of moles
	    // represented by this unit equals the number of grams -- amount * magnitude
	    // divided by the molecular Weight
	    let molAmt = this.magnitude_ * amt / molecularWeight;
	    // The molUnit's basic magnitude, before prefixes are applied,
	    // is avogadro's number, get that and divide it out of the current magnitude.
	    let tabs = this._getUnitTables();
	    let avoNum = tabs.getUnitByCode('mol').magnitude_;
	    let molesFactor = molUnit.magnitude_ / avoNum;
	    // return the molAmt divided by the molesFactor as the number of moles
	    // for the molUnit
	    return molAmt / molesFactor;
	  }

	  /**
	   * Calculates the number of units that would result from converting a unit
	   * expressed in moles to a unit expressed in mass (grams).  The "this" unit
	   * is the unit expressed in some form of moles, e.g., mol, umol, mmol, etc.,
	   * and the target or "to" unit is a unit expressed in some form of mass, e.g.,
	   * g, mg, mmg, kg, etc.  Any unit expressions surrounding the moles and mass
	   * must be convertible. No validation of this requirement is performed.
	   *
	   * @param amt the quantity of this unit to be converted
	   * @param massUnit the target/to unit for which the converted # is wanted
	   * @param molecularWeight the molecular weight of the substance for which the
	   *  conversion is being made
	   * @return the equivalent amount in massUnit
	   */
	  convertMolToMass(amt, massUnit, molecularWeight) {
	    // A simple mole unit has a magnitude of avogadro's number.  Get that
	    // number now (since not everyone agrees on what it is, and what is
	    // being used in this system might change).
	    let tabs = this._getUnitTables();
	    let avoNum = tabs.getUnitByCode('mol').magnitude_;
	    // Determine what prefix values (mg or mg/dL, etc.) have been applied to
	    // this unit by dividing the simple mole unit magnitude out of the
	    // current mole unit magnitude.
	    let molesFactor = this.magnitude_ / avoNum;
	    // The number of grams (mass) is equal to the number of moles (amt)
	    // times the molecular weight.  We also multiply that by the prefix values
	    // applied to the current unit (molesFactor) to get the grams for this
	    // particular unit.
	    let massAmt = molesFactor * amt * molecularWeight;
	    // Finally, we return the mass amount/grams for this particular unit
	    // divided by any effects of prefixes applied to the "to" unit, which
	    // is assumed to be some form of a gram unit
	    return massAmt / massUnit.magnitude_;
	  }

	  /**
	   * Mutates this unit into a unit on a ratio scale and converts a specified
	   * number of units to an appropriate value for this converted unit
	   *
	   * @param num the number of this unit before it's converted
	   * @return the magnitude of this unit after it's converted
	   * @throw an error if the dimensions differ
	   */
	  mutateRatio(num) {
	    if (this.cnv_ == null) return this.mutateCoherent(num);else return num;
	  } // end mutateRatio

	  /**
	   * Multiplies this unit with a scalar. Special meaning for
	   * special units so that (0.1*B) is 1 dB.
	   *
	   * This function DOES NOT modify this unit.
	   *
	   * @param s the value by which this unit is to be multiplied
	   * @return a copy this unit multiplied by s
	   * */
	  multiplyThis(s) {
	    let retUnit = this.clone();
	    if (retUnit.cnv_ != null) retUnit.cnvPfx_ *= s;else retUnit.magnitude_ *= s;
	    let mulVal = s.toString();
	    retUnit.name_ = this._concatStrs(mulVal, '*', this.name_, '[', ']');
	    retUnit.csCode_ = this._concatStrs(mulVal, '.', this.csCode_, '(', ')');
	    retUnit.ciCode_ = this._concatStrs(mulVal, '.', this.ciCode_, '(', ')');
	    retUnit.printSymbol_ = this._concatStrs(mulVal, '.', this.printSymbol_, '(', ')');
	    return retUnit;
	  } // end multiplyThis

	  /**
	   * Multiplies this unit with another unit. If one of the
	   * units is a non-ratio unit the other must be dimensionless or
	   * else an exception is thrown.
	   *
	   * This function does NOT modify this unit
	   * @param unit2 the unit to be multiplied with this one
	   * @return this unit after it is multiplied
	   * @throws an error if one of the units is not on a ratio-scale
	   *         and the other is not dimensionless.
	   */
	  multiplyThese(unit2) {
	    var retUnit = this.clone();
	    if (retUnit.cnv_ != null) {
	      if (unit2.cnv_ == null && (!unit2.dim_ || unit2.dim_.isZero())) retUnit.cnvPfx_ *= unit2.magnitude_;else throw new Error(`Attempt to multiply non-ratio unit ${retUnit.name_} ` + 'failed.');
	    } // end if this unit has a conversion function
	    else if (unit2.cnv_ != null) {
	      if (!retUnit.dim_ || retUnit.dim_.isZero()) {
	        retUnit.cnvPfx_ = unit2.cnvPfx_ * retUnit.magnitude_;
	        retUnit.magnitude_ = unit2.magnitude_;
	        retUnit.cnv_ = unit2.cnv_;
	      } else throw new Error(`Attempt to multiply non-ratio unit ${unit2.name_}`);
	    } // end if unit2 has a conversion function

	    // else neither unit has a conversion function
	    else {
	      retUnit.magnitude_ *= unit2.magnitude_;
	    } // end if unit2 does not have a conversion function

	    // If this.dim_ isn't there, clone the dimension in unit2 - if dimVec_
	    // is a dimension in unit2.dim_; else just transfer it to this dimension
	    if (!retUnit.dim_ || retUnit.dim_ && !retUnit.dim_.dimVec_) {
	      if (unit2.dim_) retUnit.dim_ = unit2.dim_.clone();else retUnit.dim_ = unit2.dim_;
	    }
	    // Else this.dim_ is there.  If there is a dimension for unit2,
	    // add it to this one.
	    else if (unit2.dim_ && unit2.dim_ instanceof Dimension) {
	      retUnit.dim_.add(unit2.dim_);
	    }

	    // Concatenate the unit info (name, code, etc) for all cases
	    // where the multiplication was performed (an error wasn't thrown)
	    retUnit.name_ = this._concatStrs(retUnit.name_, '*', unit2.name_, '[', ']');
	    retUnit.csCode_ = this._concatStrs(retUnit.csCode_, '.', unit2.csCode_, '(', ')');
	    if (retUnit.ciCode_ && unit2.ciCode_) retUnit.ciCode_ = this._concatStrs(retUnit.ciCode_, '.', unit2.ciCode_, '(', ')');else if (unit2.ciCode_) retUnit.ciCode_ = unit2.ciCode_;
	    retUnit.resetFieldsForDerivedUnit();
	    if (retUnit.printSymbol_ && unit2.printSymbol_) retUnit.printSymbol_ = this._concatStrs(retUnit.printSymbol_, '.', unit2.printSymbol_, '(', ')');else if (unit2.printSymbol_) retUnit.printSymbol_ = unit2.printSymbol_;

	    // Update the mole exponent count by adding the count for unit2 to the
	    // count for this unit.
	    retUnit.moleExp_ = retUnit.moleExp_ + unit2.moleExp_;

	    // A unit that has the arbitrary attribute taints any unit created from it
	    // via an arithmetic operation.  Taint accordingly
	    // if (!retUnit.isMole_)
	    //   retUnit.isMole_ = unit2.isMole_ ;
	    if (!retUnit.isArbitrary_) retUnit.isArbitrary_ = unit2.isArbitrary_;

	    // Likewise for special units
	    if (!retUnit.isSpecial_) retUnit.isSpecial_ = unit2.isSpecial_;
	    return retUnit;
	  } // end multiplyThese

	  /**
	   *  Clears fields like isBase_, synonyms_, etc. when a unit has been cloned
	   *  from a known unit but it being used to construct a derived unit.
	   */
	  resetFieldsForDerivedUnit() {
	    this.guidance_ = '';
	    this.synonyms_ = null;
	    this.isBase_ = false;
	  }

	  /**
	   * Divides this unit by another unit. If this unit is not on a ratio
	   * scale an exception is raised. Mutating to a ratio scale unit
	   * is not possible for a unit, only for a measurement.
	   *
	   * This unit is NOT modified by this function.
	   * @param unit2 the unit by which to divide this one
	   * @return this unit after it is divided by unit2
	   * @throws an error if either of the units is not on a ratio scale.
	   * */
	  divide(unit2) {
	    var retUnit = this.clone();
	    if (retUnit.cnv_ != null) throw new Error(`Attempt to divide non-ratio unit ${retUnit.name_}`);
	    if (unit2.cnv_ != null) throw new Error(`Attempt to divide by non-ratio unit ${unit2.name_}`);
	    if (retUnit.name_ && unit2.name_) retUnit.name_ = this._concatStrs(retUnit.name_, '/', unit2.name_, '[', ']');else if (unit2.name_) retUnit.name_ = unit2.invertString(unit2.name_);
	    retUnit.csCode_ = this._concatStrs(retUnit.csCode_, '/', unit2.csCode_, '(', ')');
	    if (retUnit.ciCode_ && unit2.ciCode_) retUnit.ciCode_ = this._concatStrs(retUnit.ciCode_, '/', unit2.ciCode_, '(', ')');else if (unit2.ciCode_) retUnit.ciCode_ = unit2.invertString(unit2.ciCode_);
	    retUnit.resetFieldsForDerivedUnit();
	    retUnit.magnitude_ /= unit2.magnitude_;
	    if (retUnit.printSymbol_ && unit2.printSymbol_) retUnit.printSymbol_ = this._concatStrs(retUnit.printSymbol_, '/', unit2.printSymbol_, '(', ')');else if (unit2.printSymbol_) retUnit.printSymbol_ = unit2.invertString(unit2.printSymbol_);

	    // Continue if unit2 has a dimension object.
	    // If this object has a dimension object, subtract unit2's dim_ object from
	    // this one. The sub method will take care of cases where the dimVec_ arrays
	    // are missing on one or both dim_ objects.
	    if (unit2.dim_) {
	      if (retUnit.dim_) {
	        if (retUnit.dim_.isNull()) retUnit.dim_.assignZero();
	        retUnit.dim_ = retUnit.dim_.sub(unit2.dim_);
	      } // end if this.dim_ exists

	      // Else if this dim_ object is missing, clone unit2's dim_ object
	      // and give the inverted clone to this unit.
	      else retUnit.dim_ = unit2.dim_.clone().minus();
	    } // end if unit2 has a dimension object

	    // Update the mole exponent count by subtracting the count for unit2 from
	    // the // count for this unit.
	    retUnit.moleExp_ = retUnit.moleExp_ - unit2.moleExp_;

	    // A unit that has the arbitrary attribute taints any unit created from
	    // it via an arithmetic operation.  Taint accordingly
	    // if (!retUnit.isMole_)
	    //   retUnit.isMole_ = unit2.isMole_ ;
	    if (!retUnit.isArbitrary_) retUnit.isArbitrary_ = unit2.isArbitrary_;
	    return retUnit;
	  } // end divide

	  /**
	   * Invert this unit with respect to multiplication. If this unit is not
	   * on a ratio scale an exception is thrown. Mutating to a ratio scale unit
	   * is not possible for a unit, only for a measurement (the magnitude and
	   * dimension).
	   *
	   *  This unit is modified by this function.
	   * @return this unit after being inverted
	   * @throws and error if this unit is not on a ratio scale
	   */
	  invert() {
	    if (this.cnv_ != null) throw new Error(`Attempt to invert a non-ratio unit - ${this.name_}`);
	    this.name_ = this.invertString(this.name_);
	    this.magnitude_ = 1 / this.magnitude_;
	    this.dim_.minus();
	    return this;
	  } // end invert

	  /**
	   * Inverts a string, where the string is assumed to be a code or a name
	   * of a division operation where the string is the divisor and the dividend
	   * is blank.
	   *
	   * @param the string to be inverted
	   * @return the inverted string
	   */
	  invertString(theString) {
	    if (theString.length > 0) {
	      // replace('<!', '</') is here to make sure closing html tags like </sup> are intact. See LF-2830.
	      let stringRep = theString.replace('/', "!").replace('.', '/').replace('<!', '</').replace("!", '.');
	      switch (stringRep.charAt(0)) {
	        case '.':
	          theString = stringRep.substr(1);
	          break;
	        case '/':
	          theString = stringRep;
	          break;
	        default:
	          theString = "/" + stringRep;
	      }
	    }
	    return theString;
	  } // end invertString

	  /**
	   * This function handles concatenation of two strings and an operator.
	   * It's called to build unit data, e.g., unit name, unit code, etc., from
	   * two different units, joined by the specified operator.
	   *
	   * @param str1 the first string to appear in the result
	   * @param operator the operator ('*', '.' or '/') to appear between the strings
	   * @param str2 the second string to appear in the result
	   * @param startChar the starting character to be used, when needed, to
	   *  enclose a string
	   * @param endChar the ending character to be used, when needed, to enclose
	   *  a string
	   * @returns the built string
	   */
	  _concatStrs(str1, operator, str2, startChar, endChar) {
	    return this._buildOneString(str1, startChar, endChar) + operator + this._buildOneString(str2, startChar, endChar);
	  }

	  /**
	   * This function handles creation of one string to be included in a
	   * concatenated string.   Basically it checks to see if the string
	   * needs to be enclosed either in parentheses or square brackets.
	   *
	   * The string is enclosed if it is not a number, is not already enclosed in a pair of
	   * parentheses or square brackets, and includes a period, and asterisk,
	   * a slash or a blank space.
	   *
	   * @param str the string
	   * @param startChar starting enclosing character
	   * @param endChar ending enclosing character
	   * @returns the string
	   */
	  _buildOneString(str, startChar, endChar) {
	    let ret = '';
	    if (intUtils_.isNumericString(str)) {
	      ret = str;
	    } else {
	      if (str.charAt(0) === '(' && str.endsWith(')') || str.charAt(0) === '[' && str.endsWith(']')) {
	        ret = str;
	      } else if (/[./* ]/.test(str)) {
	        ret = startChar + str + endChar;
	      } else {
	        ret = str;
	      }
	    }
	    return ret;
	  }

	  /**
	   * Raises the unit to a power.  For example
	   *  kg.m/s2 raised to the -2 power would be kg-2.m-2/s-4
	   *
	   * If this unit is not on a ratio scale an error is thrown. Mutating
	   * to a ratio scale unit is not possible for a unit, only for a
	   * measurement (magnitude and dimension).
	   *
	   * This is based on the pow method in Gunter Schadow's java version,
	   * although it uses javascript capabilities to simplify the processing.
	   *
	   * This unit is modified by this function
	   *
	   * @param p the power to with this unit is to be raise
	   * @return this unit after it is raised
	   * @throws an error if this unit is not on a ratio scale.
	   */
	  power(p) {
	    if (this.cnv_ != null) throw new Error(`Attempt to raise a non-ratio unit, ${this.name_}, ` + 'to a power.');

	    //this.name_ = UnitString.pow(this.name_, p);
	    // the above line is replaced with the code below, as the pow method
	    // never actually existing in the UnitString class.  (Tried to use
	    // Schadow java code but this way ended up being a lot easier).
	    let uStr = this.csCode_;
	    let uArray = uStr.match(/([./]|[^./]+)/g);
	    let arLen = uArray.length;
	    for (let i = 0; i < arLen; i++) {
	      let un = uArray[i];
	      if (un !== '/' && un !== '.') {
	        let nun = parseInt(un);
	        if (isInteger(nun)) uArray[i] = Math.pow(nun, p).toString();else {
	          let uLen = un.length;
	          for (let u = uLen - 1; u >= 0; u--) {
	            let uChar = parseInt(un[u]);
	            if (!isInteger(uChar)) {
	              if (un[u] === '-' || un[u] === '+') {
	                u--;
	              }
	              if (u < uLen - 1) {
	                let exp = parseInt(un.substr(u));
	                exp = Math.pow(exp, p);
	                uArray[i] = un.substr(0, u) + exp.toString();
	                u = -1;
	              } else {
	                uArray[i] += p.toString();
	                u = -1;
	              } // end if there are/aren't some numbers at the end
	              u = -1;
	            } // end if this character is not a number
	          } // end searching backwards for start of exponent
	        } // end if this element is not a number
	      } // end if the current element is not an operator
	    } // end do for each element of the units array

	    // reassemble the updated units array to a string
	    this.csCode_ = uArray.join('');
	    this.magnitude_ = Math.pow(this.magnitude_, p);
	    if (this.dim_) {
	      this.dim_.mul(p);
	    }
	    return this;
	  } // end power

	  /*
	   * This function tests this unit against the unit passed in to see if the
	   * two are mole to mass commensurable.  It assumes that one of the units
	   * is a mole-based unit and the other is a mass-based unit.  It also assumes
	   * that the mole-based unit has a single mole unit in the numerator and that
	   * the mass-based unit has a single mass unit in the numerator.  It does NOT
	   * check to validate those assumptions.
	   *
	   * The check is made by setting the dimension vector element corresponding
	   * to the base mass unit (gram) in the mole unit, and then comparing the
	   * two dimension vectors.  If they match, the units are commensurable.
	   * Otherwise they are not.
	   *
	   * @param unit2 the unit to be compared to this one
	   * @returns boolean indicating commensurability
	   */
	  isMoleMassCommensurable(unit2) {
	    let tabs = this._getUnitTables();
	    let d = tabs.getMassDimensionIndex();
	    let commensurable = false;
	    if (this.moleExp_ === 1 && unit2.moleExp_ === 0) {
	      let testDim = this.dim_.clone();
	      let curVal = testDim.getElementAt(d);
	      testDim.setElementAt(d, curVal + this.moleExp_);
	      commensurable = testDim.equals(unit2.dim_);
	    } else if (unit2.moleExp_ === 1 && this.moleExp_ === 0) {
	      let testDim = unit2.dim_.clone();
	      let curVal = testDim.getElementAt(d);
	      testDim.setElementAt(d, curVal + unit2.moleExp_);
	      commensurable = testDim.equals(this.dim_);
	    }
	    return commensurable;
	  }

	  /**
	   * This returns the UnitTables singleton object.  Including the require
	   * statement included here causes a circular dependency condition that
	   * resulted in the UnitTables object not being defined for the Unit object.
	   * sigh.  Thanks, Paul, for figuring this out.
	   *
	   * @private
	   */
	  _getUnitTables() {
	    if (!UnitTables) UnitTables = requireUnitTables().UnitTables;
	    return UnitTables.getInstance();
	  }
	} // end Unit class
	unit.Unit = Unit;
	
	return unit;
}

var jsonArrayPack = {};

var hasRequiredJsonArrayPack;

function requireJsonArrayPack () {
	if (hasRequiredJsonArrayPack) return jsonArrayPack;
	hasRequiredJsonArrayPack = 1;

	Object.defineProperty(jsonArrayPack, "__esModule", {
	  value: true
	});
	jsonArrayPack.packArray = packArray;
	jsonArrayPack.unpackArray = unpackArray;
	/**
	 * This file provides functions to reduce the size of an array of objects of the same structure in JSON.
	 */
	const pushFn = Array.prototype.push;
	function isObject(value) {
	  return Object.prototype.toString.call(value) === '[object Object]';
	}

	/**
	 * Makes human readable config used to pack/unpack array of objects of the same structure to store with packed data.
	 * @param {Object} refObj - reference item of array of objects of the same structure
	 * @returns {Array}
	 */
	function createConfig(refObj) {
	  return Object.keys(refObj).reduce((config, key) => {
	    if (isObject(refObj[key])) {
	      pushFn.apply(config, createConfig(refObj[key]).map(keyTail => [key, ...[].concat(keyTail)]));
	    } else {
	      config.push(key);
	    }
	    return config;
	  }, []);
	}

	/**
	 * Prepares config created with createConfig function to use in packItem/unpackItem functions.
	 * @param {Array} config
	 * @returns {Array}
	 */
	function prepareConfig(config) {
	  return config.map(key => Array.isArray(key) ? key : [key]);
	}

	/**
	 * Converts an object to an array of values in the order of keys from configuration array.
	 * @param {Array} config - configuration array
	 * @param {Object} item - input object
	 * @returns {Array}
	 */
	function packItem(config, item) {
	  if (config.join() !== prepareConfig(createConfig(item)).join()) {
	    throw new Error('Object of unusual structure');
	  }
	  return config.map(keyArr => {
	    let place = item;
	    keyArr.forEach(key => {
	      place = place[key];
	      if (place === undefined) {
	        throw new Error('Object of unusual structure');
	      }
	    });
	    return place;
	  });
	}

	/**
	 * Performs the reverse of packItem function.
	 * @param {Array} config - configuration array
	 * @param {Array} item - input object
	 * @returns {Object}
	 */
	function unpackItem(config, item) {
	  let result = {};
	  config.forEach((keyArr, i) => {
	    let place = result;
	    for (let i = 0; i < keyArr.length - 1; i++) {
	      place = place[keyArr[i]] = place[keyArr[i]] || {};
	    }
	    place[keyArr[keyArr.length - 1]] = item[i];
	  });
	  return result;
	}

	/**
	 * Reduces size of an array of objects of the same structure before serialize it to JSON
	 * @param {Array} arr
	 * @returns {Object}
	 */
	function packArray(arr) {
	  if (arr && arr.length) {
	    const config = createConfig(arr[0]),
	      _config = prepareConfig(config);
	    if (config.length) {
	      return {
	        config: config,
	        data: arr.map(packItem.bind(null, _config))
	      };
	    }
	  }
	  return {
	    config: [],
	    data: arr
	  };
	}

	/**
	 * Restores an array of objects of the same structure after deserializing this object from JSON
	 * @param {Object} obj
	 * @returns {Array}
	 */
	function unpackArray(obj) {
	  const config = obj && obj.config;
	  if (config) {
	    if (config.length && obj.data) {
	      const _config = prepareConfig(config);
	      return obj.data.map(unpackItem.bind(null, _config));
	    } else {
	      return obj.data;
	    }
	  }
	  return obj;
	}
	
	return jsonArrayPack;
}

var license = "The following data (prefixes and units) was generated by the UCUM LHC code from the UCUM data and selected LOINC combinations of UCUM units.  The license for the UCUM LHC code (demo and library code as well as the combined units) is located at https://github.com/lhncbc/ucum-lhc/blob/LICENSE.md.";
var prefixes = {
	config: [
		"code_",
		"ciCode_",
		"name_",
		"printSymbol_",
		"value_",
		"exp_"
	],
	data: [
		[
			"E",
			"EX",
			"exa",
			"E",
			1000000000000000000,
			"18"
		],
		[
			"G",
			"GA",
			"giga",
			"G",
			1000000000,
			"9"
		],
		[
			"Gi",
			"GIB",
			"gibi",
			"Gi",
			1073741824,
			null
		],
		[
			"Ki",
			"KIB",
			"kibi",
			"Ki",
			1024,
			null
		],
		[
			"M",
			"MA",
			"mega",
			"M",
			1000000,
			"6"
		],
		[
			"Mi",
			"MIB",
			"mebi",
			"Mi",
			1048576,
			null
		],
		[
			"P",
			"PT",
			"peta",
			"P",
			1000000000000000,
			"15"
		],
		[
			"T",
			"TR",
			"tera",
			"T",
			1000000000000,
			"12"
		],
		[
			"Ti",
			"TIB",
			"tebi",
			"Ti",
			1099511627776,
			null
		],
		[
			"Y",
			"YA",
			"yotta",
			"Y",
			1e+24,
			"24"
		],
		[
			"Z",
			"ZA",
			"zetta",
			"Z",
			1e+21,
			"21"
		],
		[
			"a",
			"A",
			"atto",
			"a",
			1e-18,
			"-18"
		],
		[
			"c",
			"C",
			"centi",
			"c",
			0.01,
			"-2"
		],
		[
			"d",
			"D",
			"deci",
			"d",
			0.1,
			"-1"
		],
		[
			"da",
			"DA",
			"deka",
			"da",
			10,
			"1"
		],
		[
			"f",
			"F",
			"femto",
			"f",
			1e-15,
			"-15"
		],
		[
			"h",
			"H",
			"hecto",
			"h",
			100,
			"2"
		],
		[
			"k",
			"K",
			"kilo",
			"k",
			1000,
			"3"
		],
		[
			"m",
			"M",
			"milli",
			"m",
			0.001,
			"-3"
		],
		[
			"n",
			"N",
			"nano",
			"n",
			1e-9,
			"-9"
		],
		[
			"p",
			"P",
			"pico",
			"p",
			1e-12,
			"-12"
		],
		[
			"u",
			"U",
			"micro",
			"",
			0.000001,
			"-6"
		],
		[
			"y",
			"YO",
			"yocto",
			"y",
			1e-24,
			"-24"
		],
		[
			"z",
			"ZO",
			"zepto",
			"z",
			1e-21,
			"-21"
		]
	]
};
var units = {
	config: [
		"isBase_",
		"name_",
		"csCode_",
		"ciCode_",
		"property_",
		"magnitude_",
		[
			"dim_",
			"dimVec_"
		],
		"printSymbol_",
		"class_",
		"isMetric_",
		"variable_",
		"cnv_",
		"cnvPfx_",
		"isSpecial_",
		"isArbitrary_",
		"moleExp_",
		"synonyms_",
		"source_",
		"loincProperty_",
		"category_",
		"guidance_",
		"csUnitString_",
		"ciUnitString_",
		"baseFactorStr_",
		"baseFactor_",
		"defError_"
	],
	data: [
		[
			true,
			"meter",
			"m",
			"M",
			"length",
			1,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"m",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"meters; metres; distance",
			"UCUM",
			"Len",
			"Clinical",
			"unit of length = 1.09361 yards",
			null,
			null,
			null,
			null,
			false
		],
		[
			true,
			"second - time",
			"s",
			"S",
			"time",
			1,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"s",
			null,
			false,
			"T",
			null,
			1,
			false,
			false,
			0,
			"seconds",
			"UCUM",
			"Time",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			true,
			"gram",
			"g",
			"G",
			"mass",
			1,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"grams; gm",
			"UCUM",
			"Mass",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			true,
			"radian",
			"rad",
			"RAD",
			"plane angle",
			1,
			[
				0,
				0,
				0,
				1,
				0,
				0,
				0
			],
			"rad",
			null,
			false,
			"A",
			null,
			1,
			false,
			false,
			0,
			"radians",
			"UCUM",
			"Angle",
			"Clinical",
			"unit of angular measure where 1 radian = 1/2 turn =  57.296 degrees. ",
			null,
			null,
			null,
			null,
			false
		],
		[
			true,
			"degree Kelvin",
			"K",
			"K",
			"temperature",
			1,
			[
				0,
				0,
				0,
				0,
				1,
				0,
				0
			],
			"K",
			null,
			false,
			"C",
			null,
			1,
			false,
			false,
			0,
			"Kelvin; degrees",
			"UCUM",
			"Temp",
			"Clinical",
			"absolute, thermodynamic temperature scale ",
			null,
			null,
			null,
			null,
			false
		],
		[
			true,
			"coulomb",
			"C",
			"C",
			"electric charge",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				1,
				0
			],
			"C",
			null,
			false,
			"Q",
			null,
			1,
			false,
			false,
			0,
			"coulombs",
			"UCUM",
			"",
			"Clinical",
			"defined as amount of 1 electron charge = 6.241509310^18 e, and equivalent to 1 Ampere-second",
			null,
			null,
			null,
			null,
			false
		],
		[
			true,
			"candela",
			"cd",
			"CD",
			"luminous intensity",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				1
			],
			"cd",
			null,
			false,
			"F",
			null,
			1,
			false,
			false,
			0,
			"candelas",
			"UCUM",
			"",
			"Clinical",
			"SI base unit of luminous intensity",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"the number ten for arbitrary powers",
			"10*",
			"10*",
			"number",
			10,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"10",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^; 10 to the arbitrary powers",
			"UCUM",
			"Num",
			"Clinical",
			"10* by itself is the same as 10, but users can add digits after the *. For example, 10*3 = 1000.",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"the number ten for arbitrary powers",
			"10^",
			"10^",
			"number",
			10,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"10",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10*; 10 to the arbitrary power",
			"UCUM",
			"Num",
			"Clinical",
			"10* by itself is the same as 10, but users can add digits after the *. For example, 10*3 = 1000.",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"the number pi",
			"[pi]",
			"[PI]",
			"number",
			3.141592653589793,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"",
			"UCUM",
			"",
			"Constant",
			"a mathematical constant; the ratio of a circle's circumference to its diameter  3.14159",
			"1",
			"1",
			"3.1415926535897932384626433832795028841971693993751058209749445923",
			3.141592653589793,
			false
		],
		[
			false,
			"",
			"%",
			"%",
			"fraction",
			0.01,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"%",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"percents",
			"UCUM",
			"FR; NFR; MFR; CFR; SFR Rto; etc. ",
			"Clinical",
			"",
			"10*-2",
			"10*-2",
			"1",
			1,
			false
		],
		[
			false,
			"parts per thousand",
			"[ppth]",
			"[PPTH]",
			"fraction",
			0.001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"ppth",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"ppth; 10^-3",
			"UCUM",
			"MCnc; MCnt",
			"Clinical",
			"[ppth] is often used in solution concentrations as 1 g/L or 1 g/kg.\n\nCan be ambigous and would be better if the metric units was used directly. ",
			"10*-3",
			"10*-3",
			"1",
			1,
			false
		],
		[
			false,
			"parts per million",
			"[ppm]",
			"[PPM]",
			"fraction",
			0.000001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"ppm",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"ppm; 10^-6",
			"UCUM",
			"MCnt; MCnc; SFr",
			"Clinical",
			"[ppm] is often used in solution concentrations as 1 mg/L  or 1 mg/kg. Also used to express mole fractions as 1 mmol/mol.\n\n[ppm] is also used in nuclear magnetic resonance (NMR) to represent chemical shift - the difference of a measured frequency in parts per million from the reference frequency.\n\nCan be ambigous and would be better if the metric units was used directly. ",
			"10*-6",
			"10*-6",
			"1",
			1,
			false
		],
		[
			false,
			"parts per billion",
			"[ppb]",
			"[PPB]",
			"fraction",
			1e-9,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"ppb",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"ppb; 10^-9",
			"UCUM",
			"MCnt; MCnc; SFr",
			"Clinical",
			"[ppb] is often used in solution concentrations as 1 ug/L  or 1 ug/kg. Also used to express mole fractions as 1 umol/mol.\n\nCan be ambigous and would be better if the metric units was used directly. ",
			"10*-9",
			"10*-9",
			"1",
			1,
			false
		],
		[
			false,
			"parts per trillion",
			"[pptr]",
			"[PPTR]",
			"fraction",
			1e-12,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"pptr",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"pptr; 10^-12",
			"UCUM",
			"MCnt; MCnc; SFr",
			"Clinical",
			"[pptr] is often used in solution concentrations as 1 ng/L or 1 ng/kg. Also used to express mole fractions as 1 nmol/mol.\n\nCan be ambigous and would be better if the metric units was used directly. ",
			"10*-12",
			"10*-12",
			"1",
			1,
			false
		],
		[
			false,
			"mole",
			"mol",
			"MOL",
			"amount of substance",
			6.0221367e+23,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"moles",
			"UCUM",
			"Sub",
			"Clinical",
			"Measure the number of molecules ",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"steradian - solid angle",
			"sr",
			"SR",
			"solid angle",
			1,
			[
				0,
				0,
				0,
				2,
				0,
				0,
				0
			],
			"sr",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"square radian; rad2; rad^2",
			"UCUM",
			"Angle",
			"Clinical",
			"unit of solid angle in three-dimensional geometry analagous to radian; used in photometry which measures the perceived brightness of object by human eye (e.g. radiant intensity = watt/steradian)",
			"rad2",
			"RAD2",
			"1",
			1,
			false
		],
		[
			false,
			"hertz",
			"Hz",
			"HZ",
			"frequency",
			1,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"Hz",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"Herz; frequency; frequencies",
			"UCUM",
			"Freq; Num",
			"Clinical",
			"equal to one cycle per second",
			"s-1",
			"S-1",
			"1",
			1,
			false
		],
		[
			false,
			"newton",
			"N",
			"N",
			"force",
			1000,
			[
				1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"N",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"Newtons",
			"UCUM",
			"Force",
			"Clinical",
			"unit of force with base units kg.m/s2",
			"kg.m/s2",
			"KG.M/S2",
			"1",
			1,
			false
		],
		[
			false,
			"pascal",
			"Pa",
			"PAL",
			"pressure",
			1000,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"Pa",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"pascals",
			"UCUM",
			"Pres",
			"Clinical",
			"standard unit of pressure equal to 1 newton per square meter (N/m2)",
			"N/m2",
			"N/M2",
			"1",
			1,
			false
		],
		[
			false,
			"joule",
			"J",
			"J",
			"energy",
			1000,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"J",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"joules",
			"UCUM",
			"Enrg",
			"Clinical",
			"unit of energy defined as the work required to move an object 1 m with a force of 1 N (N.m) or an electric charge of 1 C through 1 V (C.V), or to produce 1 W for 1 s (W.s) ",
			"N.m",
			"N.M",
			"1",
			1,
			false
		],
		[
			false,
			"watt",
			"W",
			"W",
			"power",
			1000,
			[
				2,
				-3,
				1,
				0,
				0,
				0,
				0
			],
			"W",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"watts",
			"UCUM",
			"EngRat",
			"Clinical",
			"unit of power equal to 1 Joule per second (J/s) =  kgm2s3",
			"J/s",
			"J/S",
			"1",
			1,
			false
		],
		[
			false,
			"Ampere",
			"A",
			"A",
			"electric current",
			1,
			[
				0,
				-1,
				0,
				0,
				0,
				1,
				0
			],
			"A",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"Amperes",
			"UCUM",
			"ElpotRat",
			"Clinical",
			"unit of electric current equal to flow rate of electrons equal to 6.241510^18 elementary charges moving past a boundary in one second or 1 Coulomb/second",
			"C/s",
			"C/S",
			"1",
			1,
			false
		],
		[
			false,
			"volt",
			"V",
			"V",
			"electric potential",
			1000,
			[
				2,
				-2,
				1,
				0,
				0,
				-1,
				0
			],
			"V",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"volts",
			"UCUM",
			"Elpot",
			"Clinical",
			"unit of electric potential (voltage) = 1 Joule per Coulomb (J/C)",
			"J/C",
			"J/C",
			"1",
			1,
			false
		],
		[
			false,
			"farad",
			"F",
			"F",
			"electric capacitance",
			0.001,
			[
				-2,
				2,
				-1,
				0,
				0,
				2,
				0
			],
			"F",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"farads; electric capacitance",
			"UCUM",
			"",
			"Clinical",
			"CGS unit of electric capacitance with base units C/V (Coulomb per Volt)",
			"C/V",
			"C/V",
			"1",
			1,
			false
		],
		[
			false,
			"ohm",
			"Ohm",
			"OHM",
			"electric resistance",
			1000,
			[
				2,
				-1,
				1,
				0,
				0,
				-2,
				0
			],
			"",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"; resistance; ohms",
			"UCUM",
			"",
			"Clinical",
			"unit of electrical resistance with units of Volt per Ampere",
			"V/A",
			"V/A",
			"1",
			1,
			false
		],
		[
			false,
			"siemens",
			"S",
			"SIE",
			"electric conductance",
			0.001,
			[
				-2,
				1,
				-1,
				0,
				0,
				2,
				0
			],
			"S",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"Reciprocal ohm; mho; 1; conductance",
			"UCUM",
			"",
			"Clinical",
			"unit of electric conductance (the inverse of electrical resistance) equal to ohm^-1",
			"Ohm-1",
			"OHM-1",
			"1",
			1,
			false
		],
		[
			false,
			"weber",
			"Wb",
			"WB",
			"magnetic flux",
			1000,
			[
				2,
				-1,
				1,
				0,
				0,
				-1,
				0
			],
			"Wb",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"magnetic flux; webers",
			"UCUM",
			"",
			"Clinical",
			"unit of magnetic flux equal to Volt second",
			"V.s",
			"V.S",
			"1",
			1,
			false
		],
		[
			false,
			"degree Celsius",
			"Cel",
			"CEL",
			"temperature",
			1,
			[
				0,
				0,
				0,
				0,
				1,
				0,
				0
			],
			"C",
			"si",
			true,
			null,
			"Cel",
			1,
			true,
			false,
			0,
			"C; degrees",
			"UCUM",
			"Temp",
			"Clinical",
			"",
			"K",
			null,
			null,
			1,
			false
		],
		[
			false,
			"tesla",
			"T",
			"T",
			"magnetic flux density",
			1000,
			[
				0,
				-1,
				1,
				0,
				0,
				-1,
				0
			],
			"T",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"Teslas; magnetic field",
			"UCUM",
			"",
			"Clinical",
			"SI unit of magnetic field strength for magnetic field B equal to 1 Weber/square meter =  1 kg/(s2*A)",
			"Wb/m2",
			"WB/M2",
			"1",
			1,
			false
		],
		[
			false,
			"henry",
			"H",
			"H",
			"inductance",
			1000,
			[
				2,
				0,
				1,
				0,
				0,
				-2,
				0
			],
			"H",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"henries; inductance",
			"UCUM",
			"",
			"Clinical",
			"unit of electrical inductance; usually expressed in millihenrys (mH) or microhenrys (uH).",
			"Wb/A",
			"WB/A",
			"1",
			1,
			false
		],
		[
			false,
			"lumen",
			"lm",
			"LM",
			"luminous flux",
			1,
			[
				0,
				0,
				0,
				2,
				0,
				0,
				1
			],
			"lm",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"luminous flux; lumens",
			"UCUM",
			"",
			"Clinical",
			"unit of luminous flux defined as 1 lm = 1 cdsr (candela times sphere)",
			"cd.sr",
			"CD.SR",
			"1",
			1,
			false
		],
		[
			false,
			"lux",
			"lx",
			"LX",
			"illuminance",
			1,
			[
				-2,
				0,
				0,
				2,
				0,
				0,
				1
			],
			"lx",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"illuminance; luxes",
			"UCUM",
			"",
			"Clinical",
			"unit of illuminance equal to one lumen per square meter. ",
			"lm/m2",
			"LM/M2",
			"1",
			1,
			false
		],
		[
			false,
			"becquerel",
			"Bq",
			"BQ",
			"radioactivity",
			1,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"Bq",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"activity; radiation; becquerels",
			"UCUM",
			"",
			"Clinical",
			"measure of the atomic radiation rate with units s^-1",
			"s-1",
			"S-1",
			"1",
			1,
			false
		],
		[
			false,
			"gray",
			"Gy",
			"GY",
			"energy dose",
			1,
			[
				2,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"Gy",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"absorbed doses; ionizing radiation doses; kerma; grays",
			"UCUM",
			"EngCnt",
			"Clinical",
			"unit of ionizing radiation dose with base units of 1 joule of radiation energy per kilogram of matter",
			"J/kg",
			"J/KG",
			"1",
			1,
			false
		],
		[
			false,
			"sievert",
			"Sv",
			"SV",
			"dose equivalent",
			1,
			[
				2,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"Sv",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"sieverts; radiation dose quantities; equivalent doses; effective dose; operational dose; committed dose",
			"UCUM",
			"",
			"Clinical",
			"SI unit for radiation dose equivalent equal to 1 Joule/kilogram.",
			"J/kg",
			"J/KG",
			"1",
			1,
			false
		],
		[
			false,
			"degree - plane angle",
			"deg",
			"DEG",
			"plane angle",
			0.017453292519943295,
			[
				0,
				0,
				0,
				1,
				0,
				0,
				0
			],
			"",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"; degree of arc; arc degree; arcdegree; angle",
			"UCUM",
			"Angle",
			"Clinical",
			"one degree is equivalent to /180 radians.",
			"[pi].rad/360",
			"[PI].RAD/360",
			"2",
			2,
			false
		],
		[
			false,
			"gon",
			"gon",
			"GON",
			"plane angle",
			0.015707963267948967,
			[
				0,
				0,
				0,
				1,
				0,
				0,
				0
			],
			"<sup>g</sup>",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"gon (grade); gons",
			"UCUM",
			"Angle",
			"Nonclinical",
			"unit of plane angle measurement equal to 1/400 circle",
			"deg",
			"DEG",
			"0.9",
			0.9,
			false
		],
		[
			false,
			"arc minute",
			"'",
			"'",
			"plane angle",
			0.0002908882086657216,
			[
				0,
				0,
				0,
				1,
				0,
				0,
				0
			],
			"'",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"arcminutes; arcmin; arc minutes; arc mins",
			"UCUM",
			"Angle",
			"Clinical",
			"equal to 1/60 degree; used in optometry and opthamology (e.g. visual acuity tests)",
			"deg/60",
			"DEG/60",
			"1",
			1,
			false
		],
		[
			false,
			"arc second",
			"''",
			"''",
			"plane angle",
			0.00000484813681109536,
			[
				0,
				0,
				0,
				1,
				0,
				0,
				0
			],
			"''",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"arcseconds; arcsecs",
			"UCUM",
			"Angle",
			"Clinical",
			"equal to 1/60 arcminute = 1/3600 degree; used in optometry and opthamology (e.g. visual acuity tests)",
			"'/60",
			"'/60",
			"1",
			1,
			false
		],
		[
			false,
			"Liters",
			"l",
			"L",
			"volume",
			0.001,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"l",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"cubic decimeters; decimeters cubed; decimetres; dm3; dm^3; litres; liters, LT ",
			"UCUM",
			"Vol",
			"Clinical",
			"Because lower case \"l\" can be read as the number \"1\", though this is a valid UCUM units. UCUM strongly reccomends using  \"L\"",
			"dm3",
			"DM3",
			"1",
			1,
			false
		],
		[
			false,
			"Liters",
			"L",
			"L",
			"volume",
			0.001,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"L",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"cubic decimeters; decimeters cubed; decimetres; dm3; dm^3; litres; liters, LT ",
			"UCUM",
			"Vol",
			"Clinical",
			"Because lower case \"l\" can be read as the number \"1\", though this is a valid UCUM units. UCUM strongly reccomends using  \"L\"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"are",
			"ar",
			"AR",
			"area",
			100,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"a",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"100 m2; 100 m^2; 100 square meter; meters squared; metres",
			"UCUM",
			"Area",
			"Clinical",
			"metric base unit for area defined as 100 m^2",
			"m2",
			"M2",
			"100",
			100,
			false
		],
		[
			false,
			"minute",
			"min",
			"MIN",
			"time",
			60,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"min",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"minutes",
			"UCUM",
			"Time",
			"Clinical",
			"",
			"s",
			"S",
			"60",
			60,
			false
		],
		[
			false,
			"hour",
			"h",
			"HR",
			"time",
			3600,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"h",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"hours; hrs; age",
			"UCUM",
			"Time",
			"Clinical",
			"",
			"min",
			"MIN",
			"60",
			60,
			false
		],
		[
			false,
			"day",
			"d",
			"D",
			"time",
			86400,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"d",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"days; age; dy; 24 hours; 24 hrs",
			"UCUM",
			"Time",
			"Clinical",
			"",
			"h",
			"HR",
			"24",
			24,
			false
		],
		[
			false,
			"tropical year",
			"a_t",
			"ANN_T",
			"time",
			31556925.216,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"a<sub>t</sub>",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"solar years; a tropical; years",
			"UCUM",
			"Time",
			"Clinical",
			"has an average of 365.242181 days but is constantly changing.",
			"d",
			"D",
			"365.24219",
			365.24219,
			false
		],
		[
			false,
			"mean Julian year",
			"a_j",
			"ANN_J",
			"time",
			31557600,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"a<sub>j</sub>",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"mean Julian yr; a julian; years",
			"UCUM",
			"Time",
			"Clinical",
			"has an average of 365.25 days, and in everyday use, has been replaced by the Gregorian year. However, this unit is used in astronomy to calculate light year. ",
			"d",
			"D",
			"365.25",
			365.25,
			false
		],
		[
			false,
			"mean Gregorian year",
			"a_g",
			"ANN_G",
			"time",
			31556952,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"a<sub>g</sub>",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"mean Gregorian yr; a gregorian; years",
			"UCUM",
			"Time",
			"Clinical",
			"has an average of 365.2425 days and is the most internationally used civil calendar.",
			"d",
			"D",
			"365.2425",
			365.2425,
			false
		],
		[
			false,
			"year",
			"a",
			"ANN",
			"time",
			31557600,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"a",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"years; a; yr, yrs; annum",
			"UCUM",
			"Time",
			"Clinical",
			"",
			"a_j",
			"ANN_J",
			"1",
			1,
			false
		],
		[
			false,
			"week",
			"wk",
			"WK",
			"time",
			604800,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"wk",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"weeks; wks",
			"UCUM",
			"Time",
			"Clinical",
			"",
			"d",
			"D",
			"7",
			7,
			false
		],
		[
			false,
			"synodal month",
			"mo_s",
			"MO_S",
			"time",
			2551442.976,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"mo<sub>s</sub>",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Moon; synodic month; lunar month; mo-s; mo s; months; moons",
			"UCUM",
			"Time",
			"Nonclinical",
			"has an average of 29.53 days per month, unit used in astronomy",
			"d",
			"D",
			"29.53059",
			29.53059,
			false
		],
		[
			false,
			"mean Julian month",
			"mo_j",
			"MO_J",
			"time",
			2629800,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"mo<sub>j</sub>",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"mo-julian; mo Julian; months",
			"UCUM",
			"Time",
			"Clinical",
			"has an average of 30.435 days per month",
			"a_j/12",
			"ANN_J/12",
			"1",
			1,
			false
		],
		[
			false,
			"mean Gregorian month",
			"mo_g",
			"MO_G",
			"time",
			2629746,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"mo<sub>g</sub>",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"months; month-gregorian; mo-gregorian",
			"UCUM",
			"Time",
			"Clinical",
			"has an average 30.436875 days per month and is from the most internationally used civil calendar.",
			"a_g/12",
			"ANN_G/12",
			"1",
			1,
			false
		],
		[
			false,
			"month",
			"mo",
			"MO",
			"time",
			2629800,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"mo",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"months; duration",
			"UCUM",
			"Time",
			"Clinical",
			"based on Julian calendar which has an average of 30.435 days per month (this unit is used in astronomy but not in everyday life - see mo_g)",
			"mo_j",
			"MO_J",
			"1",
			1,
			false
		],
		[
			false,
			"metric ton",
			"t",
			"TNE",
			"mass",
			1000000,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"t",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"tonnes; megagrams; tons",
			"UCUM",
			"Mass",
			"Nonclinical",
			"equal to 1000 kg used in the US (recognized by NIST as metric ton), and internationally (recognized as tonne)",
			"kg",
			"KG",
			"1e3",
			1000,
			false
		],
		[
			false,
			"bar",
			"bar",
			"BAR",
			"pressure",
			100000000,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"bar",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"bars",
			"UCUM",
			"Pres",
			"Nonclinical",
			"unit of pressure equal to 10^5 Pascals, primarily used by meteorologists and in weather forecasting",
			"Pa",
			"PAL",
			"1e5",
			100000,
			false
		],
		[
			false,
			"unified atomic mass unit",
			"u",
			"AMU",
			"mass",
			1.6605402e-24,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"u",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"unified atomic mass units; amu; Dalton; Da",
			"UCUM",
			"Mass",
			"Clinical",
			"the mass of 1/12 of an unbound Carbon-12 atom nuclide equal to 1.6606x10^-27 kg ",
			"g",
			"G",
			"1.6605402e-24",
			1.6605402e-24,
			false
		],
		[
			false,
			"astronomic unit",
			"AU",
			"ASU",
			"length",
			149597870691,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"AU",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"AU; units",
			"UCUM",
			"Len",
			"Clinical",
			"unit of length used in astronomy for measuring distance in Solar system",
			"Mm",
			"MAM",
			"149597.870691",
			149597.870691,
			false
		],
		[
			false,
			"parsec",
			"pc",
			"PRS",
			"length",
			30856780000000000,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"pc",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"parsecs",
			"UCUM",
			"Len",
			"Clinical",
			"unit of length equal to 3.26 light years, and used to measure large distances to objects outside our Solar System",
			"m",
			"M",
			"3.085678e16",
			30856780000000000,
			false
		],
		[
			false,
			"velocity of light in a vacuum",
			"[c]",
			"[C]",
			"velocity",
			299792458,
			[
				1,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"<i>c</i>",
			"const",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"speed of light",
			"UCUM",
			"Vel",
			"Constant",
			"equal to 299792458 m/s (approximately 3 x 10^8 m/s)",
			"m/s",
			"M/S",
			"299792458",
			299792458,
			false
		],
		[
			false,
			"Planck constant",
			"[h]",
			"[H]",
			"action",
			6.6260755e-31,
			[
				2,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"<i>h</i>",
			"const",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"Planck's constant",
			"UCUM",
			"",
			"Constant",
			"constant = 6.62607004  10-34 m2.kg/s; defined as quantum of action",
			"J.s",
			"J.S",
			"6.6260755e-34",
			6.6260755e-34,
			false
		],
		[
			false,
			"Boltzmann constant",
			"[k]",
			"[K]",
			"(unclassified)",
			1.380658e-20,
			[
				2,
				-2,
				1,
				0,
				-1,
				0,
				0
			],
			"<i>k</i>",
			"const",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"k; kB",
			"UCUM",
			"",
			"Constant",
			"physical constant relating energy at the individual particle level with temperature = 1.38064852 10^23 J/K",
			"J/K",
			"J/K",
			"1.380658e-23",
			1.380658e-23,
			false
		],
		[
			false,
			"permittivity of vacuum - electric",
			"[eps_0]",
			"[EPS_0]",
			"electric permittivity",
			8.854187817000001e-15,
			[
				-3,
				2,
				-1,
				0,
				0,
				2,
				0
			],
			"<i><sub><r>0</r></sub></i>",
			"const",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"0; Electric Constant; vacuum permittivity; permittivity of free space ",
			"UCUM",
			"",
			"Constant",
			"approximately equal to 8.854 10^12 F/m (farads per meter)",
			"F/m",
			"F/M",
			"8.854187817e-12",
			8.854187817e-12,
			false
		],
		[
			false,
			"permeability of vacuum - magnetic",
			"[mu_0]",
			"[MU_0]",
			"magnetic permeability",
			0.0012566370614359172,
			[
				1,
				0,
				1,
				0,
				0,
				-2,
				0
			],
			"<i><sub><r>0</r></sub></i>",
			"const",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"0; vacuum permeability; permeability of free space; magnetic constant",
			"UCUM",
			"",
			"Constant",
			"equal to 410^7 N/A2 (Newtons per square ampere)  1.256610^6 H/m (Henry per meter)",
			"N/A2",
			"4.[PI].10*-7.N/A2",
			"1",
			0.0000012566370614359173,
			false
		],
		[
			false,
			"elementary charge",
			"[e]",
			"[E]",
			"electric charge",
			1.60217733e-19,
			[
				0,
				0,
				0,
				0,
				0,
				1,
				0
			],
			"<i>e</i>",
			"const",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"e; q; electric charges",
			"UCUM",
			"",
			"Constant",
			"the magnitude of the electric charge carried by a single electron or proton  1.6021710^-19 Coulombs",
			"C",
			"C",
			"1.60217733e-19",
			1.60217733e-19,
			false
		],
		[
			false,
			"electronvolt",
			"eV",
			"EV",
			"energy",
			1.60217733e-16,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"eV",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"Electron Volts; electronvolts",
			"UCUM",
			"Eng",
			"Clinical",
			"unit of kinetic energy = 1 V * 1.60210^19 C = 1.61019 Joules",
			"[e].V",
			"[E].V",
			"1",
			1,
			false
		],
		[
			false,
			"electron mass",
			"[m_e]",
			"[M_E]",
			"mass",
			9.1093897e-28,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"<i>m<sub><r>e</r></sub></i>",
			"const",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"electron rest mass; me",
			"UCUM",
			"Mass",
			"Constant",
			"approximately equal to 9.10938356  10-31 kg; defined as the mass of a stationary electron",
			"g",
			"g",
			"9.1093897e-28",
			9.1093897e-28,
			false
		],
		[
			false,
			"proton mass",
			"[m_p]",
			"[M_P]",
			"mass",
			1.6726231e-24,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"<i>m<sub><r>p</r></sub></i>",
			"const",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mp; masses",
			"UCUM",
			"Mass",
			"Constant",
			"approximately equal to 1.6726221027 kg",
			"g",
			"g",
			"1.6726231e-24",
			1.6726231e-24,
			false
		],
		[
			false,
			"Newtonian constant of gravitation",
			"[G]",
			"[GC]",
			"(unclassified)",
			6.67259e-14,
			[
				3,
				-2,
				-1,
				0,
				0,
				0,
				0
			],
			"<i>G</i>",
			"const",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"G; gravitational constant; Newton's constant",
			"UCUM",
			"",
			"Constant",
			"gravitational constant = 6.6741011 Nm2/kg2",
			"m3.kg-1.s-2",
			"M3.KG-1.S-2",
			"6.67259e-11",
			6.67259e-11,
			false
		],
		[
			false,
			"standard acceleration of free fall",
			"[g]",
			"[G]",
			"acceleration",
			9.80665,
			[
				1,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"<i>g<sub>n</sub></i>",
			"const",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"standard gravity; g; 0; n",
			"UCUM",
			"Accel",
			"Constant",
			"defined by standard = 9.80665 m/s2",
			"m/s2",
			"M/S2",
			"980665e-5",
			9.80665,
			false
		],
		[
			false,
			"Torr",
			"Torr",
			"Torr",
			"pressure",
			133322,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"Torr",
			"const",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"torrs",
			"UCUM",
			"Pres",
			"Clinical",
			"1 torr = 1 mmHg; unit used to measure blood pressure",
			"Pa",
			"PAL",
			"133.322",
			133.322,
			false
		],
		[
			false,
			"standard atmosphere",
			"atm",
			"ATM",
			"pressure",
			101325000,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"atm",
			"const",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"reference pressure; atmos; std atmosphere",
			"UCUM",
			"Pres",
			"Clinical",
			"defined as being precisely equal to 101,325 Pa",
			"Pa",
			"PAL",
			"101325",
			101325,
			false
		],
		[
			false,
			"light-year",
			"[ly]",
			"[LY]",
			"length",
			9460730472580800,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"l.y.",
			"const",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"light years; ly",
			"UCUM",
			"Len",
			"Constant",
			"unit of astronomal distance = 5.8810^12 mi",
			"[c].a_j",
			"[C].ANN_J",
			"1",
			1,
			false
		],
		[
			false,
			"gram-force",
			"gf",
			"GF",
			"force",
			9.80665,
			[
				1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"gf",
			"const",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"Newtons; gram forces",
			"UCUM",
			"Force",
			"Clinical",
			"May be specific to unit related to cardiac output",
			"g.[g]",
			"G.[G]",
			"1",
			1,
			false
		],
		[
			false,
			"Kayser",
			"Ky",
			"KY",
			"lineic number",
			100,
			[
				-1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"K",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"wavenumbers; kaysers",
			"UCUM",
			"InvLen",
			"Clinical",
			"unit of wavelength equal to cm^-1",
			"cm-1",
			"CM-1",
			"1",
			1,
			false
		],
		[
			false,
			"Gal",
			"Gal",
			"GL",
			"acceleration",
			0.01,
			[
				1,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"Gal",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"galileos; Gals",
			"UCUM",
			"Accel",
			"Clinical",
			"unit of acceleration used in gravimetry; equivalent to cm/s2 ",
			"cm/s2",
			"CM/S2",
			"1",
			1,
			false
		],
		[
			false,
			"dyne",
			"dyn",
			"DYN",
			"force",
			0.01,
			[
				1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"dyn",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"dynes",
			"UCUM",
			"Force",
			"Clinical",
			"unit of force equal to 10^-5 Newtons",
			"g.cm/s2",
			"G.CM/S2",
			"1",
			1,
			false
		],
		[
			false,
			"erg",
			"erg",
			"ERG",
			"energy",
			0.0001,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"erg",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^-7 Joules, 10-7 Joules; 100 nJ; 100 nanoJoules; 1 dyne cm; 1 g.cm2/s2",
			"UCUM",
			"Eng",
			"Clinical",
			"unit of energy = 1 dyne centimeter = 10^-7 Joules",
			"dyn.cm",
			"DYN.CM",
			"1",
			1,
			false
		],
		[
			false,
			"Poise",
			"P",
			"P",
			"dynamic viscosity",
			100.00000000000001,
			[
				-1,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"P",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"dynamic viscosity; poises",
			"UCUM",
			"Visc",
			"Clinical",
			"unit of dynamic viscosity where 1 Poise = 1/10 Pascal second",
			"dyn.s/cm2",
			"DYN.S/CM2",
			"1",
			1,
			false
		],
		[
			false,
			"Biot",
			"Bi",
			"BI",
			"electric current",
			10,
			[
				0,
				-1,
				0,
				0,
				0,
				1,
				0
			],
			"Bi",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"Bi; abamperes; abA",
			"UCUM",
			"ElpotRat",
			"Clinical",
			"equal to 10 amperes",
			"A",
			"A",
			"10",
			10,
			false
		],
		[
			false,
			"Stokes",
			"St",
			"ST",
			"kinematic viscosity",
			0.00009999999999999999,
			[
				2,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"St",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"kinematic viscosity",
			"UCUM",
			"Visc",
			"Clinical",
			"unit of kimematic viscosity with units cm2/s",
			"cm2/s",
			"CM2/S",
			"1",
			1,
			false
		],
		[
			false,
			"Maxwell",
			"Mx",
			"MX",
			"flux of magnetic induction",
			0.00001,
			[
				2,
				-1,
				1,
				0,
				0,
				-1,
				0
			],
			"Mx",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"magnetix flux; Maxwells",
			"UCUM",
			"",
			"Clinical",
			"unit of magnetic flux",
			"Wb",
			"WB",
			"1e-8",
			1e-8,
			false
		],
		[
			false,
			"Gauss",
			"G",
			"GS",
			"magnetic flux density",
			0.1,
			[
				0,
				-1,
				1,
				0,
				0,
				-1,
				0
			],
			"Gs",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"magnetic fields; magnetic flux density; induction; B",
			"UCUM",
			"magnetic",
			"Clinical",
			"CGS unit of magnetic flux density, known as magnetic field B; defined as one maxwell unit per square centimeter (see Oersted for CGS unit for H field)",
			"T",
			"T",
			"1e-4",
			0.0001,
			false
		],
		[
			false,
			"Oersted",
			"Oe",
			"OE",
			"magnetic field intensity",
			79.57747154594767,
			[
				-1,
				-1,
				0,
				0,
				0,
				1,
				0
			],
			"Oe",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"H magnetic B field; Oersteds",
			"UCUM",
			"",
			"Clinical",
			"CGS unit of the auxiliary magnetic field H defined as 1 dyne per unit pole = 1000/4 amperes per meter (see Gauss for CGS unit for B field)",
			"A/m",
			"/[PI].A/M",
			"250",
			79.57747154594767,
			false
		],
		[
			false,
			"Gilbert",
			"Gb",
			"GB",
			"magnetic tension",
			0.7957747154594768,
			[
				0,
				-1,
				0,
				0,
				0,
				1,
				0
			],
			"Gb",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"Gi; magnetomotive force; Gilberts",
			"UCUM",
			"",
			"Clinical",
			"unit of magnetomotive force (magnetic potential)",
			"Oe.cm",
			"OE.CM",
			"1",
			1,
			false
		],
		[
			false,
			"stilb",
			"sb",
			"SB",
			"lum. intensity density",
			10000,
			[
				-2,
				0,
				0,
				0,
				0,
				0,
				1
			],
			"sb",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"stilbs",
			"UCUM",
			"",
			"Obsolete",
			"unit of luminance; equal to and replaced by unit candela per square centimeter (cd/cm2)",
			"cd/cm2",
			"CD/CM2",
			"1",
			1,
			false
		],
		[
			false,
			"Lambert",
			"Lmb",
			"LMB",
			"brightness",
			3183.098861837907,
			[
				-2,
				0,
				0,
				0,
				0,
				0,
				1
			],
			"L",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"luminance; lamberts",
			"UCUM",
			"",
			"Clinical",
			"unit of luminance defined as 1 lambert = 1/  candela per square meter",
			"cd/cm2/[pi]",
			"CD/CM2/[PI]",
			"1",
			1,
			false
		],
		[
			false,
			"phot",
			"ph",
			"PHT",
			"illuminance",
			0.0001,
			[
				-2,
				0,
				0,
				2,
				0,
				0,
				1
			],
			"ph",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"phots",
			"UCUM",
			"",
			"Clinical",
			"CGS photometric unit of illuminance, or luminous flux through an area equal to 10000 lumens per square meter = 10000 lux",
			"lx",
			"LX",
			"1e-4",
			0.0001,
			false
		],
		[
			false,
			"Curie",
			"Ci",
			"CI",
			"radioactivity",
			37000000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"Ci",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"curies",
			"UCUM",
			"",
			"Obsolete",
			"unit for measuring atomic disintegration rate; replaced by the Bequerel (Bq) unit",
			"Bq",
			"BQ",
			"37e9",
			37000000000,
			false
		],
		[
			false,
			"Roentgen",
			"R",
			"ROE",
			"ion dose",
			2.58e-7,
			[
				0,
				0,
				-1,
				0,
				0,
				1,
				0
			],
			"R",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"rntgen; Roentgens",
			"UCUM",
			"",
			"Clinical",
			"unit of exposure of X-rays and gamma rays in air; unit used primarily in the US but strongly discouraged by NIST",
			"C/kg",
			"C/KG",
			"2.58e-4",
			0.000258,
			false
		],
		[
			false,
			"radiation absorbed dose",
			"RAD",
			"[RAD]",
			"energy dose",
			0.01,
			[
				2,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"RAD",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"doses",
			"UCUM",
			"",
			"Clinical",
			"unit of radiation absorbed dose used primarily in the US with base units 100 ergs per gram of material. Also see the SI unit Gray (Gy).",
			"erg/g",
			"ERG/G",
			"100",
			100,
			false
		],
		[
			false,
			"radiation equivalent man",
			"REM",
			"[REM]",
			"dose equivalent",
			0.01,
			[
				2,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"REM",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"Roentgen Equivalent in Man; rems; dose equivalents",
			"UCUM",
			"",
			"Clinical",
			"unit of equivalent dose which measures the effect of radiation on humans equal to 0.01 sievert. Used primarily in the US. Also see SI unit Sievert (Sv)",
			"RAD",
			"[RAD]",
			"1",
			1,
			false
		],
		[
			false,
			"inch",
			"[in_i]",
			"[IN_I]",
			"length",
			0.025400000000000002,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"in",
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"inches; in; international inch; body height",
			"UCUM",
			"Len",
			"Clinical",
			"standard unit for inch in the US and internationally",
			"cm",
			"CM",
			"254e-2",
			2.54,
			false
		],
		[
			false,
			"foot",
			"[ft_i]",
			"[FT_I]",
			"length",
			0.3048,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"ft",
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"ft; fts; foot; international foot; feet; international feet; height",
			"UCUM",
			"Len",
			"Clinical",
			"unit used in the US and internationally",
			"[in_i]",
			"[IN_I]",
			"12",
			12,
			false
		],
		[
			false,
			"yard",
			"[yd_i]",
			"[YD_I]",
			"length",
			0.9144000000000001,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"yd",
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"international yards; yds; distance",
			"UCUM",
			"Len",
			"Clinical",
			"standard unit used in the US and internationally",
			"[ft_i]",
			"[FT_I]",
			"3",
			3,
			false
		],
		[
			false,
			"mile",
			"[mi_i]",
			"[MI_I]",
			"length",
			1609.344,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mi",
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"international miles; mi I; statute mile",
			"UCUM",
			"Len",
			"Clinical",
			"standard unit used in the US and internationally",
			"[ft_i]",
			"[FT_I]",
			"5280",
			5280,
			false
		],
		[
			false,
			"fathom",
			"[fth_i]",
			"[FTH_I]",
			"depth of water",
			1.8288000000000002,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"fth",
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"international fathoms",
			"UCUM",
			"Len",
			"Nonclinical",
			"unit used in the US and internationally to measure depth of water; same length as the US fathom",
			"[ft_i]",
			"[FT_I]",
			"6",
			6,
			false
		],
		[
			false,
			"nautical mile",
			"[nmi_i]",
			"[NMI_I]",
			"length",
			1852,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"n.mi",
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"nautical mile; nautical miles; international nautical mile; international nautical miles; nm; n.m.; nmi",
			"UCUM",
			"Len",
			"Nonclinical",
			"standard unit used in the US and internationally",
			"m",
			"M",
			"1852",
			1852,
			false
		],
		[
			false,
			"knot",
			"[kn_i]",
			"[KN_I]",
			"velocity",
			0.5144444444444445,
			[
				1,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"knot",
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"kn; kt; international knots",
			"UCUM",
			"Vel",
			"Nonclinical",
			"defined as equal to one nautical mile (1.852 km) per hour",
			"[nmi_i]/h",
			"[NMI_I]/H",
			"1",
			1,
			false
		],
		[
			false,
			"square inch",
			"[sin_i]",
			"[SIN_I]",
			"area",
			0.0006451600000000001,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"in2; in^2; inches squared; sq inch; inches squared; international",
			"UCUM",
			"Area",
			"Clinical",
			"standard unit used in the US and internationally",
			"[in_i]2",
			"[IN_I]2",
			"1",
			1,
			false
		],
		[
			false,
			"square foot",
			"[sft_i]",
			"[SFT_I]",
			"area",
			0.09290304,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"ft2; ft^2; ft squared; sq ft; feet; international",
			"UCUM",
			"Area",
			"Clinical",
			"standard unit used in the US and internationally",
			"[ft_i]2",
			"[FT_I]2",
			"1",
			1,
			false
		],
		[
			false,
			"square yard",
			"[syd_i]",
			"[SYD_I]",
			"area",
			0.8361273600000002,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"yd2; yd^2; sq. yds; yards squared; international",
			"UCUM",
			"Area",
			"Clinical",
			"standard unit used in the US and internationally",
			"[yd_i]2",
			"[YD_I]2",
			"1",
			1,
			false
		],
		[
			false,
			"cubic inch",
			"[cin_i]",
			"[CIN_I]",
			"volume",
			0.000016387064000000006,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"in3; in^3; in*3; inches^3; inches*3; cu. in; cu in; cubic inches; inches cubed; cin",
			"UCUM",
			"Vol",
			"Clinical",
			"standard unit used in the US and internationally",
			"[in_i]3",
			"[IN_I]3",
			"1",
			1,
			false
		],
		[
			false,
			"cubic foot",
			"[cft_i]",
			"[CFT_I]",
			"volume",
			0.028316846592000004,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"ft3; ft^3; ft*3; cu. ft; cubic feet; cubed; [ft_i]3; international",
			"UCUM",
			"Vol",
			"Clinical",
			"",
			"[ft_i]3",
			"[FT_I]3",
			"1",
			1,
			false
		],
		[
			false,
			"cubic yard",
			"[cyd_i]",
			"[CYD_I]",
			"volume",
			0.7645548579840002,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"cu.yd",
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"cubic yards; cubic yds; cu yards; CYs; yards^3; yd^3; yds^3; yd3; yds3",
			"UCUM",
			"Vol",
			"Nonclinical",
			"standard unit used in the US and internationally",
			"[yd_i]3",
			"[YD_I]3",
			"1",
			1,
			false
		],
		[
			false,
			"board foot",
			"[bf_i]",
			"[BF_I]",
			"volume",
			0.0023597372160000006,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"BDFT; FBM; BF; board feet; international",
			"UCUM",
			"Vol",
			"Nonclinical",
			"unit of volume used to measure lumber",
			"[in_i]3",
			"[IN_I]3",
			"144",
			144,
			false
		],
		[
			false,
			"cord",
			"[cr_i]",
			"[CR_I]",
			"volume",
			3.6245563637760005,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"crd I; international cords",
			"UCUM",
			"Vol",
			"Nonclinical",
			"unit of measure of dry volume used to measure firewood equal 128 ft3",
			"[ft_i]3",
			"[FT_I]3",
			"128",
			128,
			false
		],
		[
			false,
			"mil",
			"[mil_i]",
			"[MIL_I]",
			"length",
			0.000025400000000000004,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mil",
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"thou, thousandth; mils; international",
			"UCUM",
			"Len",
			"Clinical",
			"equal to 0.001 international inch",
			"[in_i]",
			"[IN_I]",
			"1e-3",
			0.001,
			false
		],
		[
			false,
			"circular mil",
			"[cml_i]",
			"[CML_I]",
			"area",
			5.067074790974979e-10,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"circ.mil",
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"circular mils; cml I; international",
			"UCUM",
			"Area",
			"Clinical",
			"",
			"[pi]/4.[mil_i]2",
			"[PI]/4.[MIL_I]2",
			"1",
			1,
			false
		],
		[
			false,
			"hand",
			"[hd_i]",
			"[HD_I]",
			"height of horses",
			0.10160000000000001,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"hd",
			"intcust",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"hands; international",
			"UCUM",
			"Len",
			"Nonclinical",
			"used to measure horse height",
			"[in_i]",
			"[IN_I]",
			"4",
			4,
			false
		],
		[
			false,
			"foot - US",
			"[ft_us]",
			"[FT_US]",
			"length",
			0.3048006096012192,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"ft<sub>us</sub>",
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US foot; foot US; us ft; ft us; height; visual distance; feet",
			"UCUM",
			"Len",
			"Obsolete",
			"Better to use [ft_i] which refers to the length used worldwide, including in the US;  [ft_us] may be confused with land survey units. ",
			"m/3937",
			"M/3937",
			"1200",
			1200,
			false
		],
		[
			false,
			"yard - US",
			"[yd_us]",
			"[YD_US]",
			"length",
			0.9144018288036575,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US yards; us yds; distance",
			"UCUM",
			"Len; Nrat",
			"Obsolete",
			"Better to use [yd_i] which refers to the length used worldwide, including in the US; [yd_us] refers to unit used in land surveys in the US",
			"[ft_us]",
			"[FT_US]",
			"3",
			3,
			false
		],
		[
			false,
			"inch - US",
			"[in_us]",
			"[IN_US]",
			"length",
			0.0254000508001016,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US inches; in us; us in; inch US",
			"UCUM",
			"Len",
			"Obsolete",
			"Better to use [in_i] which refers to the length used worldwide, including in the US",
			"[ft_us]/12",
			"[FT_US]/12",
			"1",
			1,
			false
		],
		[
			false,
			"rod - US",
			"[rd_us]",
			"[RD_US]",
			"length",
			5.029210058420117,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US rod; US rods; rd US; US rd",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[ft_us]",
			"[FT_US]",
			"16.5",
			16.5,
			false
		],
		[
			false,
			"Gunter's chain - US",
			"[ch_us]",
			"[CH_US]",
			"length",
			20.116840233680467,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"surveyor's chain; Surveyor's chain USA; Gunters measurement; surveyors measurement; Gunter's Chain USA",
			"UCUM",
			"Len",
			"Obsolete",
			"historical unit used for land survey used only in the US",
			"[rd_us]",
			"[RD_US]",
			"4",
			4,
			false
		],
		[
			false,
			"link for Gunter's chain - US",
			"[lk_us]",
			"[LK_US]",
			"length",
			0.20116840233680466,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Links for Gunter's Chain USA",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[ch_us]/100",
			"[CH_US]/100",
			"1",
			1,
			false
		],
		[
			false,
			"Ramden's chain - US",
			"[rch_us]",
			"[RCH_US]",
			"length",
			30.480060960121918,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Ramsden's chain; engineer's chains",
			"UCUM",
			"Len",
			"Obsolete",
			"distance measuring device used forland survey",
			"[ft_us]",
			"[FT_US]",
			"100",
			100,
			false
		],
		[
			false,
			"link for Ramden's chain - US",
			"[rlk_us]",
			"[RLK_US]",
			"length",
			0.3048006096012192,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"links for Ramsden's chain",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[rch_us]/100",
			"[RCH_US]/100",
			"1",
			1,
			false
		],
		[
			false,
			"fathom - US",
			"[fth_us]",
			"[FTH_US]",
			"length",
			1.828803657607315,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US fathoms; fathom USA; fth us",
			"UCUM",
			"Len",
			"Obsolete",
			"same length as the international fathom - better to use international fathom ([fth_i])",
			"[ft_us]",
			"[FT_US]",
			"6",
			6,
			false
		],
		[
			false,
			"furlong - US",
			"[fur_us]",
			"[FUR_US]",
			"length",
			201.16840233680466,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US furlongs; fur us",
			"UCUM",
			"Len",
			"Nonclinical",
			"distance unit in horse racing",
			"[rd_us]",
			"[RD_US]",
			"40",
			40,
			false
		],
		[
			false,
			"mile - US",
			"[mi_us]",
			"[MI_US]",
			"length",
			1609.3472186944373,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"U.S. Survey Miles; US statute miles; survey mi; US mi; distance",
			"UCUM",
			"Len",
			"Nonclinical",
			"Better to use [mi_i] which refers to the length used worldwide, including in the US",
			"[fur_us]",
			"[FUR_US]",
			"8",
			8,
			false
		],
		[
			false,
			"acre - US",
			"[acr_us]",
			"[ACR_US]",
			"area",
			4046.872609874252,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Acre USA Survey; Acre USA; survey acres",
			"UCUM",
			"Area",
			"Nonclinical",
			"an older unit based on pre 1959 US statute lengths that is still sometimes used in the US only for land survey purposes. ",
			"[rd_us]2",
			"[RD_US]2",
			"160",
			160,
			false
		],
		[
			false,
			"square rod - US",
			"[srd_us]",
			"[SRD_US]",
			"area",
			25.292953811714074,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"rod2; rod^2; sq. rod; rods squared",
			"UCUM",
			"Area",
			"Nonclinical",
			"Used only in the US to measure land area, based on US statute land survey length units",
			"[rd_us]2",
			"[RD_US]2",
			"1",
			1,
			false
		],
		[
			false,
			"square mile - US",
			"[smi_us]",
			"[SMI_US]",
			"area",
			2589998.470319521,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"mi2; mi^2; sq mi; miles squared",
			"UCUM",
			"Area",
			"Nonclinical",
			"historical unit used only in the US for land survey purposes (based on the US survey mile), not the internationally recognized [mi_i]",
			"[mi_us]2",
			"[MI_US]2",
			"1",
			1,
			false
		],
		[
			false,
			"section",
			"[sct]",
			"[SCT]",
			"area",
			2589998.470319521,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"sct; sections",
			"UCUM",
			"Area",
			"Nonclinical",
			"tract of land approximately equal to 1 mile square containing 640 acres",
			"[mi_us]2",
			"[MI_US]2",
			"1",
			1,
			false
		],
		[
			false,
			"township",
			"[twp]",
			"[TWP]",
			"area",
			93239944.93150276,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"twp; townships",
			"UCUM",
			"Area",
			"Nonclinical",
			"land measurement equal to 6 mile square",
			"[sct]",
			"[SCT]",
			"36",
			36,
			false
		],
		[
			false,
			"mil - US",
			"[mil_us]",
			"[MIL_US]",
			"length",
			0.0000254000508001016,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"thou, thousandth; mils",
			"UCUM",
			"Len",
			"Obsolete",
			"better to use [mil_i] which is based on the internationally recognized inch",
			"[in_us]",
			"[IN_US]",
			"1e-3",
			0.001,
			false
		],
		[
			false,
			"inch - British",
			"[in_br]",
			"[IN_BR]",
			"length",
			0.025399980000000003,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-length",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"imperial inches; imp in; br in; british inches",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"cm",
			"CM",
			"2.539998",
			2.539998,
			false
		],
		[
			false,
			"foot - British",
			"[ft_br]",
			"[FT_BR]",
			"length",
			0.30479976000000003,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-length",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British Foot; Imperial Foot; feet; imp fts; br fts",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[in_br]",
			"[IN_BR]",
			"12",
			12,
			false
		],
		[
			false,
			"rod - British",
			"[rd_br]",
			"[RD_BR]",
			"length",
			5.02919604,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-length",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British rods; br rd",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[ft_br]",
			"[FT_BR]",
			"16.5",
			16.5,
			false
		],
		[
			false,
			"Gunter's chain - British",
			"[ch_br]",
			"[CH_BR]",
			"length",
			20.11678416,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-length",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Gunter's Chain British; Gunters Chain British; Surveyor's Chain British",
			"UCUM",
			"Len",
			"Obsolete",
			"historical unit used for land survey used only in Great Britain",
			"[rd_br]",
			"[RD_BR]",
			"4",
			4,
			false
		],
		[
			false,
			"link for Gunter's chain - British",
			"[lk_br]",
			"[LK_BR]",
			"length",
			0.2011678416,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-length",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Links for Gunter's Chain British",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[ch_br]/100",
			"[CH_BR]/100",
			"1",
			1,
			false
		],
		[
			false,
			"fathom - British",
			"[fth_br]",
			"[FTH_BR]",
			"length",
			1.82879856,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-length",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British fathoms; imperial fathoms; br fth; imp fth",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[ft_br]",
			"[FT_BR]",
			"6",
			6,
			false
		],
		[
			false,
			"pace - British",
			"[pc_br]",
			"[PC_BR]",
			"length",
			0.7619994000000001,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-length",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British paces; br pc",
			"UCUM",
			"Len",
			"Nonclinical",
			"traditional unit of length equal to 152.4 centimeters, or 1.52 meter. ",
			"[ft_br]",
			"[FT_BR]",
			"2.5",
			2.5,
			false
		],
		[
			false,
			"yard - British",
			"[yd_br]",
			"[YD_BR]",
			"length",
			0.91439928,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-length",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British yards; Br yds; distance",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[ft_br]",
			"[FT_BR]",
			"3",
			3,
			false
		],
		[
			false,
			"mile - British",
			"[mi_br]",
			"[MI_BR]",
			"length",
			1609.3427328000002,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-length",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"imperial miles; British miles; English statute miles; imp mi, br mi",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[ft_br]",
			"[FT_BR]",
			"5280",
			5280,
			false
		],
		[
			false,
			"nautical mile - British",
			"[nmi_br]",
			"[NMI_BR]",
			"length",
			1853.1825408000002,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-length",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British nautical miles; Imperial nautical miles; Admiralty miles; n.m. br; imp nm",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[ft_br]",
			"[FT_BR]",
			"6080",
			6080,
			false
		],
		[
			false,
			"knot - British",
			"[kn_br]",
			"[KN_BR]",
			"velocity",
			0.5147729280000001,
			[
				1,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-length",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British knots; kn br; kt",
			"UCUM",
			"Vel",
			"Obsolete",
			"based on obsolete British nautical mile ",
			"[nmi_br]/h",
			"[NMI_BR]/H",
			"1",
			1,
			false
		],
		[
			false,
			"acre",
			"[acr_br]",
			"[ACR_BR]",
			"area",
			4046.850049400269,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-length",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Imperial acres; British; a; ac; ar; acr",
			"UCUM",
			"Area",
			"Nonclinical",
			"the standard unit for acre used in the US and internationally",
			"[yd_br]2",
			"[YD_BR]2",
			"4840",
			4840,
			false
		],
		[
			false,
			"gallon - US",
			"[gal_us]",
			"[GAL_US]",
			"fluid volume",
			0.0037854117840000014,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US gallons; US liquid gallon; gal us; Queen Anne's wine gallon",
			"UCUM",
			"Vol",
			"Nonclinical",
			"only gallon unit used in the US; [gal_us] is only used in some other countries in South American and Africa to measure gasoline volume",
			"[in_i]3",
			"[IN_I]3",
			"231",
			231,
			false
		],
		[
			false,
			"barrel - US",
			"[bbl_us]",
			"[BBL_US]",
			"fluid volume",
			0.15898729492800007,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"bbl",
			"UCUM",
			"Vol",
			"Nonclinical",
			"[bbl_us] is the standard unit for oil barrel, which is a unit only used in the US to measure the volume oil. ",
			"[gal_us]",
			"[GAL_US]",
			"42",
			42,
			false
		],
		[
			false,
			"quart - US",
			"[qt_us]",
			"[QT_US]",
			"fluid volume",
			0.0009463529460000004,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US quarts; us qts",
			"UCUM",
			"Vol",
			"Clinical",
			"Used only in the US",
			"[gal_us]/4",
			"[GAL_US]/4",
			"1",
			1,
			false
		],
		[
			false,
			"pint - US",
			"[pt_us]",
			"[PT_US]",
			"fluid volume",
			0.0004731764730000002,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US pints; pint US; liquid pint; pt us; us pt",
			"UCUM",
			"Vol",
			"Clinical",
			"Used only in the US",
			"[qt_us]/2",
			"[QT_US]/2",
			"1",
			1,
			false
		],
		[
			false,
			"gill - US",
			"[gil_us]",
			"[GIL_US]",
			"fluid volume",
			0.00011829411825000005,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US gills; gil us",
			"UCUM",
			"Vol",
			"Nonclinical",
			"only used in the context of alcohol volume in the US",
			"[pt_us]/4",
			"[PT_US]/4",
			"1",
			1,
			false
		],
		[
			false,
			"fluid ounce - US",
			"[foz_us]",
			"[FOZ_US]",
			"fluid volume",
			0.00002957352956250001,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"oz fl",
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US fluid ounces; fl ozs; FO; fl. oz.; foz us",
			"UCUM",
			"Vol",
			"Clinical",
			"unit used only in the US",
			"[gil_us]/4",
			"[GIL_US]/4",
			"1",
			1,
			false
		],
		[
			false,
			"fluid dram - US",
			"[fdr_us]",
			"[FDR_US]",
			"fluid volume",
			0.0000036966911953125014,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US fluid drams; fdr us",
			"UCUM",
			"Vol",
			"Nonclinical",
			"equal to 1/8 US fluid ounce = 3.69 mL; used informally to mean small amount of liquor, especially Scotch whiskey",
			"[foz_us]/8",
			"[FOZ_US]/8",
			"1",
			1,
			false
		],
		[
			false,
			"minim - US",
			"[min_us]",
			"[MIN_US]",
			"fluid volume",
			6.161151992187503e-8,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"min US; US min;  US",
			"UCUM",
			"Vol",
			"Obsolete",
			"",
			"[fdr_us]/60",
			"[FDR_US]/60",
			"1",
			1,
			false
		],
		[
			false,
			"cord - US",
			"[crd_us]",
			"[CRD_US]",
			"fluid volume",
			3.6245563637760005,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US cord; US cords; crd us; us crd",
			"UCUM",
			"Vol",
			"Nonclinical",
			"unit of measure of dry volume used to measure firewood equal 128 ft3 (the same as international cord [cr_i])",
			"[ft_i]3",
			"[FT_I]3",
			"128",
			128,
			false
		],
		[
			false,
			"bushel - US",
			"[bu_us]",
			"[BU_US]",
			"dry volume",
			0.035239070166880014,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US bushels; US bsh; US bu",
			"UCUM",
			"Vol",
			"Obsolete",
			"Historical unit of dry volume that is rarely used today",
			"[in_i]3",
			"[IN_I]3",
			"2150.42",
			2150.42,
			false
		],
		[
			false,
			"gallon - historical",
			"[gal_wi]",
			"[GAL_WI]",
			"dry volume",
			0.004404883770860002,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Corn Gallon British; Dry Gallon US; Gallons Historical; Grain Gallon British; Winchester Corn Gallon; historical winchester gallons; wi gal",
			"UCUM",
			"Vol",
			"Obsolete",
			"historical unit of dry volume no longer used",
			"[bu_us]/8",
			"[BU_US]/8",
			"1",
			1,
			false
		],
		[
			false,
			"peck - US",
			"[pk_us]",
			"[PK_US]",
			"dry volume",
			0.008809767541720004,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"US pecks; US pk",
			"UCUM",
			"Vol",
			"Nonclinical",
			"unit of dry volume rarely used today (can be used to measure volume of apples)",
			"[bu_us]/4",
			"[BU_US]/4",
			"1",
			1,
			false
		],
		[
			false,
			"dry quart - US",
			"[dqt_us]",
			"[DQT_US]",
			"dry volume",
			0.0011012209427150004,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"dry quarts; dry quart US; US dry quart; dry qt; us dry qt; dqt; dqt us",
			"UCUM",
			"Vol",
			"Nonclinical",
			"historical unit of dry volume only in the US, but is rarely used today",
			"[pk_us]/8",
			"[PK_US]/8",
			"1",
			1,
			false
		],
		[
			false,
			"dry pint - US",
			"[dpt_us]",
			"[DPT_US]",
			"dry volume",
			0.0005506104713575002,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"dry pints; dry pint US; US dry pint; dry pt; dpt; dpt us",
			"UCUM",
			"Vol",
			"Nonclinical",
			"historical unit of dry volume only in the US, but is rarely used today",
			"[dqt_us]/2",
			"[DQT_US]/2",
			"1",
			1,
			false
		],
		[
			false,
			"tablespoon - US",
			"[tbs_us]",
			"[TBS_US]",
			"volume",
			0.000014786764781250006,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Tbs; tbsp; tbs us; US tablespoons",
			"UCUM",
			"Vol",
			"Clinical",
			"unit defined as 0.5 US fluid ounces or 3 teaspoons - used only in the US. See [tbs_m] for the unit used internationally and in the US for nutrional labelling. ",
			"[foz_us]/2",
			"[FOZ_US]/2",
			"1",
			1,
			false
		],
		[
			false,
			"teaspoon - US",
			"[tsp_us]",
			"[TSP_US]",
			"volume",
			0.000004928921593750002,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"tsp; t; US teaspoons",
			"UCUM",
			"Vol",
			"Nonclinical",
			"unit defined as 1/6 US fluid ounces - used only in the US. See [tsp_m] for the unit used internationally and in the US for nutrional labelling. ",
			"[tbs_us]/3",
			"[TBS_US]/3",
			"1",
			1,
			false
		],
		[
			false,
			"cup - US customary",
			"[cup_us]",
			"[CUP_US]",
			"volume",
			0.0002365882365000001,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"cup us; us cups",
			"UCUM",
			"Vol",
			"Nonclinical",
			"Unit defined as 1/2 US pint or 16 US tablespoons  236.59 mL, which is not the standard unit defined by the FDA of 240 mL - see [cup_m] (metric cup)",
			"[tbs_us]",
			"[TBS_US]",
			"16",
			16,
			false
		],
		[
			false,
			"fluid ounce - metric",
			"[foz_m]",
			"[FOZ_M]",
			"fluid volume",
			0.000029999999999999997,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"oz fl",
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"metric fluid ounces; fozs m; fl ozs m",
			"UCUM",
			"Vol",
			"Clinical",
			"unit used only in the US for nutritional labelling, as set by the FDA",
			"mL",
			"ML",
			"30",
			30,
			false
		],
		[
			false,
			"cup - US legal",
			"[cup_m]",
			"[CUP_M]",
			"volume",
			0.00023999999999999998,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"cup m; metric cups",
			"UCUM",
			"Vol",
			"Clinical",
			"standard unit equal to 240 mL used in the US for nutritional labelling, as defined by the FDA. Note that this is different from the US customary cup (236.59 mL) and the metric cup used in Commonwealth nations (250 mL).",
			"mL",
			"ML",
			"240",
			240,
			false
		],
		[
			false,
			"teaspoon - metric",
			"[tsp_m]",
			"[TSP_M]",
			"volume",
			0.0000049999999999999996,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"tsp; t; metric teaspoons",
			"UCUM",
			"Vol",
			"Clinical",
			"standard unit used in the US and internationally",
			"mL",
			"mL",
			"5",
			5,
			false
		],
		[
			false,
			"tablespoon - metric",
			"[tbs_m]",
			"[TBS_M]",
			"volume",
			0.000014999999999999999,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"us-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"metric tablespoons; Tbs; tbsp; T; tbs m",
			"UCUM",
			"Vol",
			"Clinical",
			"standard unit used in the US and internationally",
			"mL",
			"mL",
			"15",
			15,
			false
		],
		[
			false,
			"gallon- British",
			"[gal_br]",
			"[GAL_BR]",
			"volume",
			0.004546090000000001,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"imperial gallons, UK gallons; British gallons; br gal; imp gal",
			"UCUM",
			"Vol",
			"Nonclinical",
			"Used only in Great Britain and other Commonwealth countries",
			"l",
			"L",
			"4.54609",
			4.54609,
			false
		],
		[
			false,
			"peck - British",
			"[pk_br]",
			"[PK_BR]",
			"volume",
			0.009092180000000002,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"imperial pecks; British pecks; br pk; imp pk",
			"UCUM",
			"Vol",
			"Nonclinical",
			"unit of dry volume rarely used today (can be used to measure volume of apples)",
			"[gal_br]",
			"[GAL_BR]",
			"2",
			2,
			false
		],
		[
			false,
			"bushel - British",
			"[bu_br]",
			"[BU_BR]",
			"volume",
			0.03636872000000001,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British bushels; imperial; br bsh; br bu; imp",
			"UCUM",
			"Vol",
			"Obsolete",
			"Historical unit of dry volume that is rarely used today",
			"[pk_br]",
			"[PK_BR]",
			"4",
			4,
			false
		],
		[
			false,
			"quart - British",
			"[qt_br]",
			"[QT_BR]",
			"volume",
			0.0011365225000000002,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British quarts; imperial quarts; br qts",
			"UCUM",
			"Vol",
			"Clinical",
			"Used only in Great Britain and other Commonwealth countries",
			"[gal_br]/4",
			"[GAL_BR]/4",
			"1",
			1,
			false
		],
		[
			false,
			"pint - British",
			"[pt_br]",
			"[PT_BR]",
			"volume",
			0.0005682612500000001,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British pints; imperial pints; pt br; br pt; imp pt; pt imp",
			"UCUM",
			"Vol",
			"Clinical",
			"Used only in Great Britain and other Commonwealth countries",
			"[qt_br]/2",
			"[QT_BR]/2",
			"1",
			1,
			false
		],
		[
			false,
			"gill - British",
			"[gil_br]",
			"[GIL_BR]",
			"volume",
			0.00014206531250000003,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"imperial gills; British gills; imp gill, br gill",
			"UCUM",
			"Vol",
			"Nonclinical",
			"only used in the context of alcohol volume in Great Britain",
			"[pt_br]/4",
			"[PT_BR]/4",
			"1",
			1,
			false
		],
		[
			false,
			"fluid ounce - British",
			"[foz_br]",
			"[FOZ_BR]",
			"volume",
			0.000028413062500000005,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British fluid ounces; Imperial fluid ounces; br fozs; imp fozs; br fl ozs",
			"UCUM",
			"Vol",
			"Clinical",
			"Used only in Great Britain and other Commonwealth countries",
			"[gil_br]/5",
			"[GIL_BR]/5",
			"1",
			1,
			false
		],
		[
			false,
			"fluid dram - British",
			"[fdr_br]",
			"[FDR_BR]",
			"volume",
			0.0000035516328125000006,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British fluid drams; fdr br",
			"UCUM",
			"Vol",
			"Nonclinical",
			"equal to 1/8 Imperial fluid ounce = 3.55 mL; used informally to mean small amount of liquor, especially Scotch whiskey",
			"[foz_br]/8",
			"[FOZ_BR]/8",
			"1",
			1,
			false
		],
		[
			false,
			"minim - British",
			"[min_br]",
			"[MIN_BR]",
			"volume",
			5.919388020833334e-8,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"brit-volumes",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"min br; br min;  br",
			"UCUM",
			"Vol",
			"Obsolete",
			"",
			"[fdr_br]/60",
			"[FDR_BR]/60",
			"1",
			1,
			false
		],
		[
			false,
			"grain",
			"[gr]",
			"[GR]",
			"mass",
			0.06479891,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"avoirdupois",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"gr; grains",
			"UCUM",
			"Mass",
			"Nonclinical",
			"an apothecary measure of mass rarely used today",
			"mg",
			"MG",
			"64.79891",
			64.79891,
			false
		],
		[
			false,
			"pound",
			"[lb_av]",
			"[LB_AV]",
			"mass",
			453.59237,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"lb",
			"avoirdupois",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"avoirdupois pounds, international pounds; av lbs; pounds",
			"UCUM",
			"Mass",
			"Clinical",
			"standard unit used in the US and internationally",
			"[gr]",
			"[GR]",
			"7000",
			7000,
			false
		],
		[
			false,
			"pound force - US",
			"[lbf_av]",
			"[LBF_AV]",
			"force",
			4448.2216152605,
			[
				1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"lbf",
			"const",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"lbfs; US lbf; US pound forces",
			"UCUM",
			"Force",
			"Clinical",
			"only rarely needed in health care - see [lb_av] which is the more common unit to express weight",
			"[lb_av].[g]",
			"[LB_AV].[G]",
			"1",
			1,
			false
		],
		[
			false,
			"ounce",
			"[oz_av]",
			"[OZ_AV]",
			"mass",
			28.349523125,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"oz",
			"avoirdupois",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"ounces; international ounces; avoirdupois ounces; av ozs",
			"UCUM",
			"Mass",
			"Clinical",
			"standard unit used in the US and internationally",
			"[lb_av]/16",
			"[LB_AV]/16",
			"1",
			1,
			false
		],
		[
			false,
			"Dram mass unit",
			"[dr_av]",
			"[DR_AV]",
			"mass",
			1.7718451953125,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"avoirdupois",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Dram; drams avoirdupois; avoidupois dram; international dram",
			"UCUM",
			"Mass",
			"Clinical",
			"unit from the avoirdupois system, which is used in the US and internationally",
			"[oz_av]/16",
			"[OZ_AV]/16",
			"1",
			1,
			false
		],
		[
			false,
			"short hundredweight",
			"[scwt_av]",
			"[SCWT_AV]",
			"mass",
			45359.237,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"avoirdupois",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"hundredweights; s cwt; scwt; avoirdupois",
			"UCUM",
			"Mass",
			"Nonclinical",
			"Used only in the US to equal 100 pounds",
			"[lb_av]",
			"[LB_AV]",
			"100",
			100,
			false
		],
		[
			false,
			"long hundredweight",
			"[lcwt_av]",
			"[LCWT_AV]",
			"mass",
			50802.345440000005,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"avoirdupois",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"imperial hundredweights; imp cwt; lcwt; avoirdupois",
			"UCUM",
			"Mass",
			"Obsolete",
			"",
			"[lb_av]",
			"[LB_AV]",
			"112",
			112,
			false
		],
		[
			false,
			"short ton - US",
			"[ston_av]",
			"[STON_AV]",
			"mass",
			907184.74,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"avoirdupois",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"ton; US tons; avoirdupois tons",
			"UCUM",
			"Mass",
			"Clinical",
			"Used only in the US",
			"[scwt_av]",
			"[SCWT_AV]",
			"20",
			20,
			false
		],
		[
			false,
			"long ton - British",
			"[lton_av]",
			"[LTON_AV]",
			"mass",
			1016046.9088000001,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"avoirdupois",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"imperial tons; weight tons; British long tons; long ton avoirdupois",
			"UCUM",
			"Mass",
			"Nonclinical",
			"Used only in Great Britain and other Commonwealth countries",
			"[lcwt_av]",
			"[LCWT_AV]",
			"20",
			20,
			false
		],
		[
			false,
			"stone - British",
			"[stone_av]",
			"[STONE_AV]",
			"mass",
			6350.293180000001,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"avoirdupois",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British stones; avoirdupois",
			"UCUM",
			"Mass",
			"Nonclinical",
			"Used primarily in the UK and Ireland to measure body weight",
			"[lb_av]",
			"[LB_AV]",
			"14",
			14,
			false
		],
		[
			false,
			"pennyweight - troy",
			"[pwt_tr]",
			"[PWT_TR]",
			"mass",
			1.5551738400000001,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"troy",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"dwt; denarius weights",
			"UCUM",
			"Mass",
			"Obsolete",
			"historical unit used to measure mass and cost of precious metals",
			"[gr]",
			"[GR]",
			"24",
			24,
			false
		],
		[
			false,
			"ounce - troy",
			"[oz_tr]",
			"[OZ_TR]",
			"mass",
			31.103476800000003,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"troy",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"troy ounces; tr ozs",
			"UCUM",
			"Mass",
			"Nonclinical",
			"unit of mass for precious metals and gemstones only",
			"[pwt_tr]",
			"[PWT_TR]",
			"20",
			20,
			false
		],
		[
			false,
			"pound - troy",
			"[lb_tr]",
			"[LB_TR]",
			"mass",
			373.2417216,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"troy",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"troy pounds; tr lbs",
			"UCUM",
			"Mass",
			"Nonclinical",
			"only used for weighing precious metals",
			"[oz_tr]",
			"[OZ_TR]",
			"12",
			12,
			false
		],
		[
			false,
			"scruple",
			"[sc_ap]",
			"[SC_AP]",
			"mass",
			1.2959782,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"apoth",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"scruples; sc ap",
			"UCUM",
			"Mass",
			"Obsolete",
			"",
			"[gr]",
			"[GR]",
			"20",
			20,
			false
		],
		[
			false,
			"dram - apothecary",
			"[dr_ap]",
			"[DR_AP]",
			"mass",
			3.8879346,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"apoth",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"; drachm; apothecaries drams; dr ap; dram ap",
			"UCUM",
			"Mass",
			"Nonclinical",
			"unit still used in the US occasionally to measure amount of drugs in pharmacies",
			"[sc_ap]",
			"[SC_AP]",
			"3",
			3,
			false
		],
		[
			false,
			"ounce - apothecary",
			"[oz_ap]",
			"[OZ_AP]",
			"mass",
			31.1034768,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"apoth",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"apothecary ounces; oz ap; ap ozs; ozs ap",
			"UCUM",
			"Mass",
			"Obsolete",
			"",
			"[dr_ap]",
			"[DR_AP]",
			"8",
			8,
			false
		],
		[
			false,
			"pound - apothecary",
			"[lb_ap]",
			"[LB_AP]",
			"mass",
			373.2417216,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"apoth",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"apothecary pounds; apothecaries pounds; ap lb; lb ap; ap lbs; lbs ap",
			"UCUM",
			"Mass",
			"Obsolete",
			"",
			"[oz_ap]",
			"[OZ_AP]",
			"12",
			12,
			false
		],
		[
			false,
			"ounce - metric",
			"[oz_m]",
			"[OZ_M]",
			"mass",
			28,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"apoth",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"metric ounces; m ozs",
			"UCUM",
			"Mass",
			"Clinical",
			"see [oz_av] (the avoirdupois ounce) for the standard ounce used internationally; [oz_m] is equal to 28 grams and is based on the apothecaries' system of mass units which is used in some US pharmacies. ",
			"g",
			"g",
			"28",
			28,
			false
		],
		[
			false,
			"line",
			"[lne]",
			"[LNE]",
			"length",
			0.002116666666666667,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"typeset",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"British lines; br L; L; l",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[in_i]/12",
			"[IN_I]/12",
			"1",
			1,
			false
		],
		[
			false,
			"point (typography)",
			"[pnt]",
			"[PNT]",
			"length",
			0.0003527777777777778,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"typeset",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"DTP points; desktop publishing point; pt; pnt",
			"UCUM",
			"Len",
			"Nonclinical",
			"typography unit for typesetter's length",
			"[lne]/6",
			"[LNE]/6",
			"1",
			1,
			false
		],
		[
			false,
			"pica (typography)",
			"[pca]",
			"[PCA]",
			"length",
			0.004233333333333334,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"typeset",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"picas",
			"UCUM",
			"Len",
			"Nonclinical",
			"typography unit for typesetter's length",
			"[pnt]",
			"[PNT]",
			"12",
			12,
			false
		],
		[
			false,
			"Printer's point (typography)",
			"[pnt_pr]",
			"[PNT_PR]",
			"length",
			0.00035145980000000004,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"typeset",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"pnt pr",
			"UCUM",
			"Len",
			"Nonclinical",
			"typography unit for typesetter's length",
			"[in_i]",
			"[IN_I]",
			"0.013837",
			0.013837,
			false
		],
		[
			false,
			"Printer's pica  (typography)",
			"[pca_pr]",
			"[PCA_PR]",
			"length",
			0.004217517600000001,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"typeset",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"pca pr; Printer's picas",
			"UCUM",
			"Len",
			"Nonclinical",
			"typography unit for typesetter's length",
			"[pnt_pr]",
			"[PNT_PR]",
			"12",
			12,
			false
		],
		[
			false,
			"pied",
			"[pied]",
			"[PIED]",
			"length",
			0.3248,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"typeset",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"pieds du roi; Paris foot; royal; French; feet",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"cm",
			"CM",
			"32.48",
			32.48,
			false
		],
		[
			false,
			"pouce",
			"[pouce]",
			"[POUCE]",
			"length",
			0.027066666666666666,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"typeset",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"historical French inches; French royal inches",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[pied]/12",
			"[PIED]/12",
			"1",
			1,
			false
		],
		[
			false,
			"ligne",
			"[ligne]",
			"[LIGNE]",
			"length",
			0.0022555555555555554,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"typeset",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Paris lines; lignes",
			"UCUM",
			"Len",
			"Obsolete",
			"",
			"[pouce]/12",
			"[POUCE]/12",
			"1",
			1,
			false
		],
		[
			false,
			"didot",
			"[didot]",
			"[DIDOT]",
			"length",
			0.0003759259259259259,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"typeset",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Didot point; dd; Didots Point; didots; points",
			"UCUM",
			"Len",
			"Obsolete",
			"typography unit for typesetter's length",
			"[ligne]/6",
			"[LIGNE]/6",
			"1",
			1,
			false
		],
		[
			false,
			"cicero",
			"[cicero]",
			"[CICERO]",
			"length",
			0.004511111111111111,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"typeset",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Didot's pica; ciceros; picas",
			"UCUM",
			"Len",
			"Obsolete",
			"typography unit for typesetter's length",
			"[didot]",
			"[DIDOT]",
			"12",
			12,
			false
		],
		[
			false,
			"degrees Fahrenheit",
			"[degF]",
			"[DEGF]",
			"temperature",
			0.5555555555555556,
			[
				0,
				0,
				0,
				0,
				1,
				0,
				0
			],
			"F",
			"heat",
			false,
			null,
			"degF",
			1,
			true,
			false,
			0,
			"F; deg F",
			"UCUM",
			"Temp",
			"Clinical",
			"",
			"K",
			null,
			null,
			0.5555555555555556,
			false
		],
		[
			false,
			"degrees Rankine",
			"[degR]",
			"[degR]",
			"temperature",
			0.5555555555555556,
			[
				0,
				0,
				0,
				0,
				1,
				0,
				0
			],
			"R",
			"heat",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"R; Ra; Rankine",
			"UCUM",
			"Temp",
			"Obsolete",
			"Replaced by Kelvin",
			"K/9",
			"K/9",
			"5",
			5,
			false
		],
		[
			false,
			"degrees Raumur",
			"[degRe]",
			"[degRe]",
			"temperature",
			1.25,
			[
				0,
				0,
				0,
				0,
				1,
				0,
				0
			],
			"R",
			"heat",
			false,
			null,
			"degRe",
			1,
			true,
			false,
			0,
			"R, Re, r; Raumur; degree Reaumur; Reaumur",
			"UCUM",
			"Temp",
			"Obsolete",
			"replaced by Celsius",
			"K",
			null,
			null,
			1.25,
			false
		],
		[
			false,
			"calorie at 15C",
			"cal_[15]",
			"CAL_[15]",
			"energy",
			4185.8,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"cal<sub>15C</sub>",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"calorie 15 C; cals 15 C; calories at 15 C",
			"UCUM",
			"Enrg",
			"Nonclinical",
			"equal to 4.1855 joules; calorie most often used in engineering",
			"J",
			"J",
			"4.18580",
			4.1858,
			false
		],
		[
			false,
			"calorie at 20C",
			"cal_[20]",
			"CAL_[20]",
			"energy",
			4181.9,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"cal<sub>20C</sub>",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"calorie 20 C; cal 20 C; calories at 20 C",
			"UCUM",
			"Enrg",
			"Clinical",
			"equal to 4.18190  joules. ",
			"J",
			"J",
			"4.18190",
			4.1819,
			false
		],
		[
			false,
			"mean calorie",
			"cal_m",
			"CAL_M",
			"energy",
			4190.0199999999995,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"cal<sub>m</sub>",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mean cals; mean calories",
			"UCUM",
			"Enrg",
			"Clinical",
			"equal to 4.19002 joules. ",
			"J",
			"J",
			"4.19002",
			4.19002,
			false
		],
		[
			false,
			"international table calorie",
			"cal_IT",
			"CAL_IT",
			"energy",
			4186.8,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"cal<sub>IT</sub>",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"calories IT; IT cals; international steam table calories",
			"UCUM",
			"Enrg",
			"Nonclinical",
			"used in engineering steam tables and defined as 1/860 international watt-hour; equal to 4.1868 joules",
			"J",
			"J",
			"4.1868",
			4.1868,
			false
		],
		[
			false,
			"thermochemical calorie",
			"cal_th",
			"CAL_TH",
			"energy",
			4184,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"cal<sub>th</sub>",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"thermochemical calories; th cals",
			"UCUM",
			"Enrg",
			"Clinical",
			"equal to 4.184 joules; used as the unit in medicine and biochemistry (equal to cal)",
			"J",
			"J",
			"4.184",
			4.184,
			false
		],
		[
			false,
			"calorie",
			"cal",
			"CAL",
			"energy",
			4184,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"cal",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"gram calories; small calories",
			"UCUM",
			"Enrg",
			"Clinical",
			"equal to 4.184 joules (the same value as the thermochemical calorie, which is the most common calorie used in medicine and biochemistry)",
			"cal_th",
			"CAL_TH",
			"1",
			1,
			false
		],
		[
			false,
			"nutrition label Calories",
			"[Cal]",
			"[CAL]",
			"energy",
			4184000,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"Cal",
			"heat",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"food calories; Cal; kcal",
			"UCUM",
			"Eng",
			"Clinical",
			"",
			"kcal_th",
			"KCAL_TH",
			"1",
			1,
			false
		],
		[
			false,
			"British thermal unit at 39F",
			"[Btu_39]",
			"[BTU_39]",
			"energy",
			1059670,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"Btu<sub>39F</sub>",
			"heat",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"BTU 39F; BTU 39 F; B.T.U. 39 F; B.Th.U. 39 F; BThU 39 F; British thermal units",
			"UCUM",
			"Eng",
			"Nonclinical",
			"equal to 1.05967 kJ; used as a measure of power in the electric power, steam generation, heating, and air conditioning industries",
			"kJ",
			"kJ",
			"1.05967",
			1.05967,
			false
		],
		[
			false,
			"British thermal unit at 59F",
			"[Btu_59]",
			"[BTU_59]",
			"energy",
			1054800,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"Btu<sub>59F</sub>",
			"heat",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"BTU 59 F; BTU 59F; B.T.U. 59 F; B.Th.U. 59 F; BThU 59F; British thermal units",
			"UCUM",
			"Eng",
			"Nonclinical",
			"equal to  1.05480 kJ; used as a measure of power in the electric power, steam generation, heating, and air conditioning industries",
			"kJ",
			"kJ",
			"1.05480",
			1.0548,
			false
		],
		[
			false,
			"British thermal unit at 60F",
			"[Btu_60]",
			"[BTU_60]",
			"energy",
			1054680,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"Btu<sub>60F</sub>",
			"heat",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"BTU 60 F; BTU 60F; B.T.U. 60 F; B.Th.U. 60 F; BThU 60 F; British thermal units 60 F",
			"UCUM",
			"Eng",
			"Nonclinical",
			"equal to 1.05468 kJ; used as a measure of power in the electric power, steam generation, heating, and air conditioning industries",
			"kJ",
			"kJ",
			"1.05468",
			1.05468,
			false
		],
		[
			false,
			"mean British thermal unit",
			"[Btu_m]",
			"[BTU_M]",
			"energy",
			1055870,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"Btu<sub>m</sub>",
			"heat",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"BTU mean; B.T.U. mean; B.Th.U. mean; BThU mean; British thermal units mean; ",
			"UCUM",
			"Eng",
			"Nonclinical",
			"equal to 1.05587 kJ; used as a measure of power in the electric power, steam generation, heating, and air conditioning industries",
			"kJ",
			"kJ",
			"1.05587",
			1.05587,
			false
		],
		[
			false,
			"international table British thermal unit",
			"[Btu_IT]",
			"[BTU_IT]",
			"energy",
			1055055.85262,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"Btu<sub>IT</sub>",
			"heat",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"BTU IT; B.T.U. IT; B.Th.U. IT; BThU IT; British thermal units IT",
			"UCUM",
			"Eng",
			"Nonclinical",
			"equal to 1.055 kJ; used as a measure of power in the electric power, steam generation, heating, and air conditioning industries",
			"kJ",
			"kJ",
			"1.05505585262",
			1.05505585262,
			false
		],
		[
			false,
			"thermochemical British thermal unit",
			"[Btu_th]",
			"[BTU_TH]",
			"energy",
			1054350,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"Btu<sub>th</sub>",
			"heat",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"BTU Th; B.T.U. Th; B.Th.U. Th; BThU Th; thermochemical British thermal units",
			"UCUM",
			"Eng",
			"Nonclinical",
			"equal to 1.054350 kJ; used as a measure of power in the electric power, steam generation, heating, and air conditioning industries",
			"kJ",
			"kJ",
			"1.054350",
			1.05435,
			false
		],
		[
			false,
			"British thermal unit",
			"[Btu]",
			"[BTU]",
			"energy",
			1054350,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"btu",
			"heat",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"BTU; B.T.U. ; B.Th.U.; BThU; British thermal units",
			"UCUM",
			"Eng",
			"Nonclinical",
			"equal to the thermochemical British thermal unit equal to 1.054350 kJ; used as a measure of power in the electric power, steam generation, heating, and air conditioning industries",
			"[Btu_th]",
			"[BTU_TH]",
			"1",
			1,
			false
		],
		[
			false,
			"horsepower - mechanical",
			"[HP]",
			"[HP]",
			"power",
			745699.8715822703,
			[
				2,
				-3,
				1,
				0,
				0,
				0,
				0
			],
			null,
			"heat",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"imperial horsepowers",
			"UCUM",
			"EngRat",
			"Nonclinical",
			"refers to mechanical horsepower, which is unit used to measure engine power primarily in the US. ",
			"[ft_i].[lbf_av]/s",
			"[FT_I].[LBF_AV]/S",
			"550",
			550,
			false
		],
		[
			false,
			"tex",
			"tex",
			"TEX",
			"linear mass density (of textile thread)",
			0.001,
			[
				-1,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"tex",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"linear mass density; texes",
			"UCUM",
			"",
			"Clinical",
			"unit of linear mass density for fibers equal to gram per 1000 meters",
			"g/km",
			"G/KM",
			"1",
			1,
			false
		],
		[
			false,
			"Denier (linear mass density)",
			"[den]",
			"[DEN]",
			"linear mass density (of textile thread)",
			0.0001111111111111111,
			[
				-1,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"den",
			"heat",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"den; deniers",
			"UCUM",
			"",
			"Nonclinical",
			"equal to the mass in grams per 9000 meters of the fiber (1 denier = 1 strand of silk)",
			"g/9/km",
			"G/9/KM",
			"1",
			1,
			false
		],
		[
			false,
			"meter of water column",
			"m[H2O]",
			"M[H2O]",
			"pressure",
			9806650,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"mHO<sub><r>2</r></sub>",
			"clinical",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mH2O; m H2O; meters of water column; metres; pressure",
			"UCUM",
			"Pres",
			"Clinical",
			"",
			"kPa",
			"KPAL",
			"980665e-5",
			9.80665,
			false
		],
		[
			false,
			"meter of mercury column",
			"m[Hg]",
			"M[HG]",
			"pressure",
			133322000,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"mHg",
			"clinical",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mHg; m Hg; meters of mercury column; metres; pressure",
			"UCUM",
			"Pres",
			"Clinical",
			"",
			"kPa",
			"KPAL",
			"133.3220",
			133.322,
			false
		],
		[
			false,
			"inch of water column",
			"[in_i'H2O]",
			"[IN_I'H2O]",
			"pressure",
			249088.91000000003,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"inHO<sub><r>2</r></sub>",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"inches WC; inAq; in H2O; inch of water gauge; iwg; pressure",
			"UCUM",
			"Pres",
			"Clinical",
			"unit of pressure, especially in respiratory and ventilation care",
			"m[H2O].[in_i]/m",
			"M[H2O].[IN_I]/M",
			"1",
			1,
			false
		],
		[
			false,
			"inch of mercury column",
			"[in_i'Hg]",
			"[IN_I'HG]",
			"pressure",
			3386378.8000000003,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"inHg",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"inHg; in Hg; pressure; inches",
			"UCUM",
			"Pres",
			"Clinical",
			"unit of pressure used in US to measure barometric pressure and occasionally blood pressure (see mm[Hg] for unit used internationally)",
			"m[Hg].[in_i]/m",
			"M[HG].[IN_I]/M",
			"1",
			1,
			false
		],
		[
			false,
			"peripheral vascular resistance unit",
			"[PRU]",
			"[PRU]",
			"fluid resistance",
			133322000000,
			[
				-4,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"P.R.U.",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"peripheral vascular resistance units; peripheral resistance unit; peripheral resistance units; PRU",
			"UCUM",
			"FldResist",
			"Clinical",
			"used to assess blood flow in the capillaries; equal to 1 mmH.min/mL = 133.3 Pamin/mL",
			"mm[Hg].s/ml",
			"MM[HG].S/ML",
			"1",
			1,
			false
		],
		[
			false,
			"Wood unit",
			"[wood'U]",
			"[WOOD'U]",
			"fluid resistance",
			7999320000,
			[
				-4,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"Wood U.",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"hybrid reference units; HRU; mmHg.min/L; vascular resistance",
			"UCUM",
			"Pres",
			"Clinical",
			"simplified unit of measurement for for measuring pulmonary vascular resistance that uses pressure; equal to mmHg.min/L",
			"mm[Hg].min/L",
			"MM[HG].MIN/L",
			"1",
			1,
			false
		],
		[
			false,
			"diopter (lens)",
			"[diop]",
			"[DIOP]",
			"refraction of a lens",
			1,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"dpt",
			"clinical",
			false,
			null,
			"inv",
			1,
			false,
			false,
			0,
			"diopters; diop; dioptre; dpt; refractive power",
			"UCUM",
			"InvLen",
			"Clinical",
			"unit of optical power of lens represented by inverse meters (m^-1)",
			"m",
			"/M",
			"1",
			1,
			false
		],
		[
			false,
			"prism diopter (magnifying power)",
			"[p'diop]",
			"[P'DIOP]",
			"refraction of a prism",
			1,
			[
				0,
				0,
				0,
				1,
				0,
				0,
				0
			],
			"PD",
			"clinical",
			false,
			null,
			"tanTimes100",
			1,
			true,
			false,
			0,
			"diopters; dioptres; p diops; pdiop; dpt; pdptr; ; cm/m; centimeter per meter; centimetre; metre",
			"UCUM",
			"Angle",
			"Clinical",
			"unit for prism correction in eyeglass prescriptions",
			"rad",
			null,
			null,
			1,
			false
		],
		[
			false,
			"percent of slope",
			"%[slope]",
			"%[SLOPE]",
			"slope",
			0.017453292519943295,
			[
				0,
				0,
				0,
				1,
				0,
				0,
				0
			],
			"%",
			"clinical",
			false,
			null,
			"100tan",
			1,
			true,
			false,
			0,
			"% slope; %slope; percents slopes",
			"UCUM",
			"VelFr; ElpotRatFr; VelRtoFr; AccelFr",
			"Clinical",
			"",
			"deg",
			null,
			null,
			1,
			false
		],
		[
			false,
			"mesh",
			"[mesh_i]",
			"[MESH_I]",
			"lineic number",
			0.025400000000000002,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"clinical",
			false,
			null,
			"inv",
			1,
			false,
			false,
			0,
			"meshes",
			"UCUM",
			"NLen (lineic number)",
			"Clinical",
			"traditional unit of length defined as the number of strands or particles per inch",
			"[in_i]",
			"/[IN_I]",
			"1",
			1,
			false
		],
		[
			false,
			"French (catheter gauge) ",
			"[Ch]",
			"[CH]",
			"gauge of catheters",
			0.0003333333333333333,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"Ch",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Charrires, French scales; French gauges; Fr, Fg, Ga, FR, Ch",
			"UCUM",
			"Len; Circ; Diam",
			"Clinical",
			"",
			"mm/3",
			"MM/3",
			"1",
			1,
			false
		],
		[
			false,
			"drop - metric (1/20 mL)",
			"[drp]",
			"[DRP]",
			"volume",
			5e-8,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"drp",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"drop dosing units; metric drops; gtt",
			"UCUM",
			"Vol",
			"Clinical",
			"standard unit used in the US and internationally for clinical medicine but note that although [drp] is defined as 1/20 milliliter, in practice, drop sizes will vary due to external factors",
			"ml/20",
			"ML/20",
			"1",
			1,
			false
		],
		[
			false,
			"Hounsfield unit",
			"[hnsf'U]",
			"[HNSF'U]",
			"x-ray attenuation",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"HF",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"HU; units",
			"UCUM",
			"",
			"Clinical",
			"used to measure X-ray attenuation, especially in CT scans.",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"Metabolic Equivalent of Task ",
			"[MET]",
			"[MET]",
			"metabolic cost of physical activity",
			5.833333333333334e-11,
			[
				3,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"MET",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"metabolic equivalents",
			"UCUM",
			"RelEngRat",
			"Clinical",
			"unit used to measure rate of energy expenditure per power in treadmill and other functional tests",
			"mL/min/kg",
			"ML/MIN/KG",
			"3.5",
			3.5,
			false
		],
		[
			false,
			"homeopathic potency of decimal series (retired)",
			"[hp'_X]",
			"[HP'_X]",
			"homeopathic potency (retired)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"X",
			"clinical",
			false,
			null,
			"hpX",
			1,
			true,
			false,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			null,
			null,
			1,
			false
		],
		[
			false,
			"homeopathic potency of centesimal series (retired)",
			"[hp'_C]",
			"[HP'_C]",
			"homeopathic potency (retired)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"C",
			"clinical",
			false,
			null,
			"hpC",
			1,
			true,
			false,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			null,
			null,
			1,
			false
		],
		[
			false,
			"homeopathic potency of millesimal series (retired)",
			"[hp'_M]",
			"[HP'_M]",
			"homeopathic potency (retired)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"M",
			"clinical",
			false,
			null,
			"hpM",
			1,
			true,
			false,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			null,
			null,
			1,
			false
		],
		[
			false,
			"homeopathic potency of quintamillesimal series (retired)",
			"[hp'_Q]",
			"[HP'_Q]",
			"homeopathic potency (retired)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"Q",
			"clinical",
			false,
			null,
			"hpQ",
			1,
			true,
			false,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			null,
			null,
			1,
			false
		],
		[
			false,
			"homeopathic potency of decimal hahnemannian series",
			"[hp_X]",
			"[HP_X]",
			"homeopathic potency (Hahnemann)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"X",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"homeopathic potency of centesimal hahnemannian series",
			"[hp_C]",
			"[HP_C]",
			"homeopathic potency (Hahnemann)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"C",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"homeopathic potency of millesimal hahnemannian series",
			"[hp_M]",
			"[HP_M]",
			"homeopathic potency (Hahnemann)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"M",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"homeopathic potency of quintamillesimal hahnemannian series",
			"[hp_Q]",
			"[HP_Q]",
			"homeopathic potency (Hahnemann)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"Q",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"homeopathic potency of decimal korsakovian series",
			"[kp_X]",
			"[KP_X]",
			"homeopathic potency (Korsakov)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"X",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"homeopathic potency of centesimal korsakovian series",
			"[kp_C]",
			"[KP_C]",
			"homeopathic potency (Korsakov)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"C",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"homeopathic potency of millesimal korsakovian series",
			"[kp_M]",
			"[KP_M]",
			"homeopathic potency (Korsakov)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"M",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"homeopathic potency of quintamillesimal korsakovian series",
			"[kp_Q]",
			"[KP_Q]",
			"homeopathic potency (Korsakov)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"Q",
			"clinical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"equivalent",
			"eq",
			"EQ",
			"amount of substance",
			6.0221367e+23,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"eq",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"equivalents",
			"UCUM",
			"Sub",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"osmole",
			"osm",
			"OSM",
			"amount of substance (dissolved particles)",
			6.0221367e+23,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"osm",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"osmoles; osmols",
			"UCUM",
			"Osmol",
			"Clinical",
			"the number of moles of solute that contribute to the osmotic pressure of a solution",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"pH",
			"[pH]",
			"[PH]",
			"acidity",
			6.0221366999999994e+26,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"pH",
			"chemical",
			false,
			null,
			"pH",
			1,
			true,
			false,
			0,
			"pH scale",
			"UCUM",
			"LogCnc",
			"Clinical",
			"Log concentration of H+",
			"mol/l",
			null,
			null,
			1,
			false
		],
		[
			false,
			"gram percent",
			"g%",
			"G%",
			"mass concentration",
			10000,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g%",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"gram %; gram%; grams per deciliter; g/dL; gm per dL; gram percents",
			"UCUM",
			"MCnc",
			"Clinical",
			"equivalent to unit gram per deciliter (g/dL), a unit often used in medical tests to represent solution concentrations",
			"g/dl",
			"G/DL",
			"1",
			1,
			false
		],
		[
			false,
			"Svedberg unit",
			"[S]",
			"[S]",
			"sedimentation coefficient",
			1e-13,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"S",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Sv; 10^-13 seconds; 100 fs; 100 femtoseconds",
			"UCUM",
			"Time",
			"Clinical",
			"unit of time used in measuring particle's sedimentation rate, usually after centrifugation. ",
			"s",
			"10*-13.S",
			"1",
			1e-13,
			false
		],
		[
			false,
			"high power field (microscope)",
			"[HPF]",
			"[HPF]",
			"view area in microscope",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"HPF",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"HPF",
			"UCUM",
			"Area",
			"Clinical",
			"area visible under the maximum magnification power of the objective in microscopy (usually 400x)\n",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"low power field (microscope)",
			"[LPF]",
			"[LPF]",
			"view area in microscope",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"LPF",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"LPF; fields",
			"UCUM",
			"Area",
			"Clinical",
			"area visible under the low magnification of the objective in microscopy (usually 100 x)\n",
			"1",
			"1",
			"100",
			100,
			false
		],
		[
			false,
			"katal",
			"kat",
			"KAT",
			"catalytic activity",
			6.0221367e+23,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"kat",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mol/secs; moles per second; mol*sec-1; mol*s-1; mol.s-1; katals; catalytic activity; enzymatic; enzyme units; activities",
			"UCUM",
			"CAct",
			"Clinical",
			"kat is a unit of catalytic activity with base units = mol/s. Rarely used because its units are too large to practically express catalytic activity. See enzyme unit [U] which is the standard unit for catalytic activity.",
			"mol/s",
			"MOL/S",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit",
			"U",
			"U",
			"catalytic activity",
			10036894500000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"U",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"micromoles per minute; umol/min; umol per minute; umol min-1; enzymatic activity; enzyme activity",
			"UCUM",
			"CAct",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"international unit - arbitrary",
			"[iU]",
			"[IU]",
			"arbitrary",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"IU",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"international units; IE; F2",
			"UCUM",
			"Arb",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"international unit - arbitrary",
			"[IU]",
			"[IU]",
			"arbitrary",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"i.U.",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"international units; IE; F2",
			"UCUM",
			"Arb",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"arbitary unit",
			"[arb'U]",
			"[ARB'U]",
			"arbitrary",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"arb. U",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"arbitary units; arb units; arbU",
			"UCUM",
			"Arb",
			"Clinical",
			"relative unit of measurement to show the ratio of test measurement to reference measurement",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"United States Pharmacopeia unit",
			"[USP'U]",
			"[USP'U]",
			"arbitrary",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"U.S.P.",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"USP U; USP'U",
			"UCUM",
			"Arb",
			"Clinical",
			"a dose unit to express potency of drugs and vitamins defined by the United States Pharmacopoeia; usually 1 USP = 1 IU",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"GPL unit",
			"[GPL'U]",
			"[GPL'U]",
			"biologic activity of anticardiolipin IgG",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"GPL Units; GPL U; IgG anticardiolipin units; IgG Phospholipid",
			"UCUM",
			"ACnc; AMass",
			"Clinical",
			"Units for an antiphospholipid test",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"MPL unit",
			"[MPL'U]",
			"[MPL'U]",
			"biologic activity of anticardiolipin IgM",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"MPL units; MPL U; MPL'U; IgM anticardiolipin units; IgM Phospholipid Units ",
			"UCUM",
			"ACnc",
			"Clinical",
			"units for antiphospholipid test",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"APL unit",
			"[APL'U]",
			"[APL'U]",
			"biologic activity of anticardiolipin IgA",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"APL units; APL U; IgA anticardiolipin; IgA Phospholipid; biologic activity of",
			"UCUM",
			"AMass; ACnc",
			"Clinical",
			"Units for an anti phospholipid syndrome test",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"Bethesda unit",
			"[beth'U]",
			"[BETH'U]",
			"biologic activity of factor VIII inhibitor",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"BU",
			"UCUM",
			"ACnc",
			"Clinical",
			"measures of blood coagulation inhibitior for many blood factors",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"anti factor Xa unit",
			"[anti'Xa'U]",
			"[ANTI'XA'U]",
			"biologic activity of factor Xa inhibitor (heparin)",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"units",
			"UCUM",
			"ACnc",
			"Clinical",
			"[anti'Xa'U] unit is equivalent to and can be converted to IU/mL. ",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"Todd unit",
			"[todd'U]",
			"[TODD'U]",
			"biologic activity antistreptolysin O",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"units",
			"UCUM",
			"InvThres; RtoThres",
			"Clinical",
			"the unit for the results of the testing for antistreptolysin O (ASO)",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"Dye unit",
			"[dye'U]",
			"[DYE'U]",
			"biologic activity of amylase",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"units",
			"UCUM",
			"CCnc",
			"Obsolete",
			"equivalent to the Somogyi unit, which is an enzyme unit for amylase but better to use U, the standard enzyme unit for measuring catalytic activity",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"Somogyi unit",
			"[smgy'U]",
			"[SMGY'U]",
			"biologic activity of amylase",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"Somogyi units; smgy U",
			"UCUM",
			"CAct",
			"Clinical",
			"measures the enzymatic activity of amylase in blood serum - better to use base units mg/mL ",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"Bodansky unit",
			"[bdsk'U]",
			"[BDSK'U]",
			"biologic activity of phosphatase",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"",
			"UCUM",
			"ACnc",
			"Obsolete",
			"Enzyme unit specific to alkaline phosphatase - better to use standard enzyme unit of U",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"King-Armstrong unit",
			"[ka'U]",
			"[KA'U]",
			"biologic activity of phosphatase",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"King-Armstrong Units; King units",
			"UCUM",
			"AMass",
			"Obsolete",
			"enzyme units for acid phosphatase - better to use enzyme unit [U]",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"Kunkel unit",
			"[knk'U]",
			"[KNK'U]",
			"arbitrary biologic activity",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			null,
			"UCUM",
			null,
			null,
			null,
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"Mac Lagan unit",
			"[mclg'U]",
			"[MCLG'U]",
			"arbitrary biologic activity",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"galactose index; galactose tolerance test; thymol turbidity test unit; mclg U; units; indexes",
			"UCUM",
			"ACnc",
			"Obsolete",
			"unit for liver tests - previously used in thymol turbidity tests for liver disease diagnoses, and now is sometimes referred to in the oral galactose tolerance test",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"tuberculin unit",
			"[tb'U]",
			"[TB'U]",
			"biologic activity of tuberculin",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"TU; units",
			"UCUM",
			"Arb",
			"Clinical",
			"amount of tuberculin antigen -usually in reference to a TB skin test ",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"50% cell culture infectious dose",
			"[CCID_50]",
			"[CCID_50]",
			"biologic activity (infectivity) of an infectious agent preparation",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"CCID<sub>50</sub>",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"CCID50; 50% cell culture infective doses",
			"UCUM",
			"NumThres",
			"Clinical",
			"",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"50% tissue culture infectious dose",
			"[TCID_50]",
			"[TCID_50]",
			"biologic activity (infectivity) of an infectious agent preparation",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"TCID<sub>50</sub>",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"TCID50; 50% tissue culture infective dose",
			"UCUM",
			"NumThres",
			"Clinical",
			"",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"50% embryo infectious dose",
			"[EID_50]",
			"[EID_50]",
			"biologic activity (infectivity) of an infectious agent preparation",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"EID<sub>50</sub>",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"EID50; 50% embryo infective doses; EID50 Egg Infective Dosage",
			"UCUM",
			"thresNum",
			"Clinical",
			"",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"plaque forming units",
			"[PFU]",
			"[PFU]",
			"amount of an infectious agent",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"PFU",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"PFU",
			"UCUM",
			"ACnc",
			"Clinical",
			"tests usually report unit as number of PFU per unit volume",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"focus forming units (cells)",
			"[FFU]",
			"[FFU]",
			"amount of an infectious agent",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"FFU",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"FFU",
			"UCUM",
			"EntNum",
			"Clinical",
			"",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"colony forming units",
			"[CFU]",
			"[CFU]",
			"amount of a proliferating organism",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"CFU",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"CFU",
			"UCUM",
			"Num",
			"Clinical",
			"",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"index of reactivity (allergen)",
			"[IR]",
			"[IR]",
			"amount of an allergen callibrated through in-vivo testing using the Stallergenes method.",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"IR",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"IR; indexes",
			"UCUM",
			"Acnc",
			"Clinical",
			"amount of an allergen callibrated through in-vivo testing using the Stallergenes method. Usually reported in tests as IR/mL",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"bioequivalent allergen unit",
			"[BAU]",
			"[BAU]",
			"amount of an allergen callibrated through in-vivo testing based on the ID50EAL method of (intradermal dilution for 50mm sum of erythema diameters",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"BAU",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"BAU; Bioequivalent Allergy Units; bioequivalent allergen units",
			"UCUM",
			"Arb",
			"Clinical",
			"",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"allergy unit",
			"[AU]",
			"[AU]",
			"procedure defined amount of an allergen using some reference standard",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"AU",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"allergy units; allergen units; AU",
			"UCUM",
			"Arb",
			"Clinical",
			"Most standard test allergy units are reported as [IU] or as %. ",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"allergen unit for Ambrosia artemisiifolia",
			"[Amb'a'1'U]",
			"[AMB'A'1'U]",
			"procedure defined amount of the major allergen of ragweed.",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"Amb a 1 U",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"Amb a 1 unit; Antigen E; AgE U; allergen units",
			"UCUM",
			"Arb",
			"Clinical",
			"Amb a 1 is the major allergen in short ragweed, and can be converted Bioequivalent allergen units (BAU) where 350 Amb a 1 U/mL = 100,000 BAU/mL",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"protein nitrogen unit (allergen testing)",
			"[PNU]",
			"[PNU]",
			"procedure defined amount of a protein substance",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"PNU",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"protein nitrogen units; PNU",
			"UCUM",
			"Mass",
			"Clinical",
			"defined as 0.01 ug of phosphotungstic acid-precipitable protein nitrogen. Being replaced by bioequivalent allergy units (BAU).",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"Limit of flocculation",
			"[Lf]",
			"[LF]",
			"procedure defined amount of an antigen substance",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"Lf",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"Lf doses",
			"UCUM",
			"Arb",
			"Clinical",
			"the antigen content  forming 1:1 ratio against 1 unit of antitoxin",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"D-antigen unit (polio)",
			"[D'ag'U]",
			"[D'AG'U]",
			"procedure defined amount of a poliomyelitis d-antigen substance",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"DAgU; units",
			"UCUM",
			"Acnc",
			"Clinical",
			"unit of potency of poliovirus vaccine used for poliomyelitis prevention reported as D antigen units/mL. The unit is poliovirus type-specific.",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"fibrinogen equivalent units",
			"[FEU]",
			"[FEU]",
			"amount of fibrinogen broken down into the measured d-dimers",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"FEU",
			"UCUM",
			"MCnc",
			"Clinical",
			"Note both the FEU and DDU units are used to report D-dimer measurements. 1 DDU = 1/2 FFU",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"ELISA unit",
			"[ELU]",
			"[ELU]",
			"arbitrary ELISA unit",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"Enzyme-Linked Immunosorbent Assay Units; ELU; EL. U",
			"UCUM",
			"ACnc",
			"Clinical",
			"",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"Ehrlich units (urobilinogen)",
			"[EU]",
			"[EU]",
			"Ehrlich unit",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"EU/dL; mg{urobilinogen}/dL",
			"UCUM",
			"ACnc",
			"Clinical",
			"",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"neper",
			"Np",
			"NEP",
			"level",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"Np",
			"levels",
			true,
			null,
			"ln",
			1,
			true,
			false,
			0,
			"nepers",
			"UCUM",
			"LogRto",
			"Clinical",
			"logarithmic unit for ratios of measurements of physical field and power quantities, such as gain and loss of electronic signals",
			"1",
			null,
			null,
			1,
			false
		],
		[
			false,
			"bel",
			"B",
			"B",
			"level",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"B",
			"levels",
			true,
			null,
			"lg",
			1,
			true,
			false,
			0,
			"bels",
			"UCUM",
			"LogRto",
			"Clinical",
			"Logarithm of the ratio of power- or field-type quantities; usually expressed in decibels ",
			"1",
			null,
			null,
			1,
			false
		],
		[
			false,
			"bel sound pressure",
			"B[SPL]",
			"B[SPL]",
			"pressure level",
			0.019999999999999997,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"B(SPL)",
			"levels",
			true,
			null,
			"lgTimes2",
			1,
			true,
			false,
			0,
			"bel SPL; B SPL; sound pressure bels",
			"UCUM",
			"LogRto",
			"Clinical",
			"used to measure sound level in acoustics",
			"Pa",
			null,
			null,
			0.000019999999999999998,
			false
		],
		[
			false,
			"bel volt",
			"B[V]",
			"B[V]",
			"electric potential level",
			1000,
			[
				2,
				-2,
				1,
				0,
				0,
				-1,
				0
			],
			"B(V)",
			"levels",
			true,
			null,
			"lgTimes2",
			1,
			true,
			false,
			0,
			"bel V; B V; volts bels",
			"UCUM",
			"LogRtoElp",
			"Clinical",
			"used to express power gain in electrical circuits",
			"V",
			null,
			null,
			1,
			false
		],
		[
			false,
			"bel millivolt",
			"B[mV]",
			"B[MV]",
			"electric potential level",
			1,
			[
				2,
				-2,
				1,
				0,
				0,
				-1,
				0
			],
			"B(mV)",
			"levels",
			true,
			null,
			"lgTimes2",
			1,
			true,
			false,
			0,
			"bel mV; B mV; millivolt bels; 10^-3V bels; 10*-3V ",
			"UCUM",
			"LogRtoElp",
			"Clinical",
			"used to express power gain in electrical circuits",
			"mV",
			null,
			null,
			1,
			false
		],
		[
			false,
			"bel microvolt",
			"B[uV]",
			"B[UV]",
			"electric potential level",
			0.001,
			[
				2,
				-2,
				1,
				0,
				0,
				-1,
				0
			],
			"B(V)",
			"levels",
			true,
			null,
			"lgTimes2",
			1,
			true,
			false,
			0,
			"bel uV; B uV; microvolts bels; 10^-6V bel; 10*-6V bel",
			"UCUM",
			"LogRto",
			"Clinical",
			"used to express power gain in electrical circuits",
			"uV",
			null,
			null,
			1,
			false
		],
		[
			false,
			"bel 10 nanovolt",
			"B[10.nV]",
			"B[10.NV]",
			"electric potential level",
			0.000010000000000000003,
			[
				2,
				-2,
				1,
				0,
				0,
				-1,
				0
			],
			"B(10 nV)",
			"levels",
			true,
			null,
			"lgTimes2",
			1,
			true,
			false,
			0,
			"bel 10 nV; B 10 nV; 10 nanovolts bels",
			"UCUM",
			"LogRtoElp",
			"Clinical",
			"used to express power gain in electrical circuits",
			"nV",
			null,
			null,
			10,
			false
		],
		[
			false,
			"bel watt",
			"B[W]",
			"B[W]",
			"power level",
			1000,
			[
				2,
				-3,
				1,
				0,
				0,
				0,
				0
			],
			"B(W)",
			"levels",
			true,
			null,
			"lg",
			1,
			true,
			false,
			0,
			"bel W; b W; b Watt; Watts bels",
			"UCUM",
			"LogRto",
			"Clinical",
			"used to express power",
			"W",
			null,
			null,
			1,
			false
		],
		[
			false,
			"bel kilowatt",
			"B[kW]",
			"B[KW]",
			"power level",
			1000000,
			[
				2,
				-3,
				1,
				0,
				0,
				0,
				0
			],
			"B(kW)",
			"levels",
			true,
			null,
			"lg",
			1,
			true,
			false,
			0,
			"bel kW; B kW; kilowatt bel; kW bel; kW B",
			"UCUM",
			"LogRto",
			"Clinical",
			"used to express power",
			"kW",
			null,
			null,
			1,
			false
		],
		[
			false,
			"stere",
			"st",
			"STR",
			"volume",
			1,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"st",
			"misc",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"stre; m3; cubic meter; m^3; meters cubed; metre",
			"UCUM",
			"Vol",
			"Nonclinical",
			"equal to one cubic meter, usually used for measuring firewood",
			"m3",
			"M3",
			"1",
			1,
			false
		],
		[
			false,
			"ngstrm",
			"Ao",
			"AO",
			"length",
			1.0000000000000002e-10,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"",
			"misc",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"; Angstroms; Ao; ngstrms",
			"UCUM",
			"Len",
			"Clinical",
			"equal to 10^-10 meters; used to express wave lengths and atom scaled differences ",
			"nm",
			"NM",
			"0.1",
			0.1,
			false
		],
		[
			false,
			"barn",
			"b",
			"BRN",
			"action area",
			1.0000000000000001e-28,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"b",
			"misc",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"barns",
			"UCUM",
			"Area",
			"Clinical",
			"used in high-energy physics to express cross-sectional areas",
			"fm2",
			"FM2",
			"100",
			100,
			false
		],
		[
			false,
			"technical atmosphere",
			"att",
			"ATT",
			"pressure",
			98066500,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"at",
			"misc",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"at; tech atm; tech atmosphere; kgf/cm2; atms; atmospheres",
			"UCUM",
			"Pres",
			"Obsolete",
			"non-SI unit of pressure equal to one kilogram-force per square centimeter",
			"kgf/cm2",
			"KGF/CM2",
			"1",
			1,
			false
		],
		[
			false,
			"mho",
			"mho",
			"MHO",
			"electric conductance",
			0.001,
			[
				-2,
				1,
				-1,
				0,
				0,
				2,
				0
			],
			"mho",
			"misc",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"siemens; ohm reciprocals; ^1; -1 ",
			"UCUM",
			"",
			"Obsolete",
			"unit of electric conductance (the inverse of electrical resistance) equal to ohm^-1",
			"S",
			"S",
			"1",
			1,
			false
		],
		[
			false,
			"pound per square inch",
			"[psi]",
			"[PSI]",
			"pressure",
			6894757.293168359,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"psi",
			"misc",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"psi; lb/in2; lb per in2",
			"UCUM",
			"Pres",
			"Clinical",
			"",
			"[lbf_av]/[in_i]2",
			"[LBF_AV]/[IN_I]2",
			"1",
			1,
			false
		],
		[
			false,
			"circle - plane angle",
			"circ",
			"CIRC",
			"plane angle",
			6.283185307179586,
			[
				0,
				0,
				0,
				1,
				0,
				0,
				0
			],
			"circ",
			"misc",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"angles; circles",
			"UCUM",
			"Angle",
			"Clinical",
			"",
			"[pi].rad",
			"[PI].RAD",
			"2",
			2,
			false
		],
		[
			false,
			"spere - solid angle",
			"sph",
			"SPH",
			"solid angle",
			12.566370614359172,
			[
				0,
				0,
				0,
				2,
				0,
				0,
				0
			],
			"sph",
			"misc",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"speres",
			"UCUM",
			"Angle",
			"Clinical",
			"equal to the solid angle of an entire sphere = 4sr (sr = steradian) ",
			"[pi].sr",
			"[PI].SR",
			"4",
			4,
			false
		],
		[
			false,
			"metric carat",
			"[car_m]",
			"[CAR_M]",
			"mass",
			0.2,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"ct<sub>m</sub>",
			"misc",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"carats; ct; car m",
			"UCUM",
			"Mass",
			"Nonclinical",
			"unit of mass for gemstones",
			"g",
			"G",
			"2e-1",
			0.2,
			false
		],
		[
			false,
			"carat of gold alloys",
			"[car_Au]",
			"[CAR_AU]",
			"mass fraction",
			0.041666666666666664,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"ct<sub><r>Au</r></sub>",
			"misc",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"karats; k; kt; car au; carats",
			"UCUM",
			"MFr",
			"Nonclinical",
			"unit of purity for gold alloys",
			"/24",
			"/24",
			"1",
			1,
			false
		],
		[
			false,
			"Smoot",
			"[smoot]",
			"[SMOOT]",
			"length",
			1.7018000000000002,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"misc",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"",
			"UCUM",
			"Len",
			"Nonclinical",
			"prank unit of length from MIT",
			"[in_i]",
			"[IN_I]",
			"67",
			67,
			false
		],
		[
			false,
			"meter per square seconds per square root of hertz",
			"[m/s2/Hz^(1/2)]",
			"[M/S2/HZ^(1/2)]",
			"amplitude spectral density",
			1,
			[
				2,
				-3,
				0,
				0,
				0,
				0,
				0
			],
			null,
			"misc",
			false,
			null,
			"sqrt",
			1,
			true,
			false,
			0,
			"m/s2/(Hz^.5); m/s2/(Hz^(1/2)); m per s2 per Hz^1/2",
			"UCUM",
			"",
			"Constant",
			"measures amplitude spectral density, and is equal to the square root of power spectral density\n ",
			"m2/s4/Hz",
			null,
			null,
			1,
			false
		],
		[
			false,
			"bit - logarithmic",
			"bit_s",
			"BIT_S",
			"amount of information",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"bit<sub>s</sub>",
			"infotech",
			false,
			null,
			"ld",
			1,
			true,
			false,
			0,
			"bit-s; bit s; bit logarithmic",
			"UCUM",
			"LogA",
			"Nonclinical",
			"defined as the log base 2 of the number of distinct signals; cannot practically be used to express more than 1000 bits\n\nIn information theory, the definition of the amount of self-information and information entropy is often expressed with the binary logarithm (log base 2)",
			"1",
			null,
			null,
			1,
			false
		],
		[
			false,
			"bit",
			"bit",
			"BIT",
			"amount of information",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"bit",
			"infotech",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"bits",
			"UCUM",
			"",
			"Nonclinical",
			"dimensionless information unit of 1 used in computing and digital communications",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"byte",
			"By",
			"BY",
			"amount of information",
			8,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"B",
			"infotech",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"bytes",
			"UCUM",
			"",
			"Nonclinical",
			"equal to 8 bits",
			"bit",
			"bit",
			"8",
			8,
			false
		],
		[
			false,
			"baud",
			"Bd",
			"BD",
			"signal transmission rate",
			1,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"Bd",
			"infotech",
			true,
			null,
			"inv",
			1,
			false,
			false,
			0,
			"Bd; bauds",
			"UCUM",
			"Freq",
			"Nonclinical",
			"unit to express rate in symbols per second or pulses per second. ",
			"s",
			"/s",
			"1",
			1,
			false
		],
		[
			false,
			"per twelve hour",
			"/(12.h)",
			"1/(12.HR)",
			"",
			0.000023148148148148147,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"/h",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"per 12 hours; 12hrs; 12 hrs; /12hrs",
			"LOINC",
			"Rat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per arbitrary unit",
			"/[arb'U]",
			"1/[ARB'U]",
			"",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/arb/ U",
			null,
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"/arbU",
			"LOINC",
			"InvA ",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per high power field",
			"/[HPF]",
			"1/[HPF]",
			"",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/HPF",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/HPF; per HPF",
			"LOINC",
			"Naric",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per international unit",
			"/[IU]",
			"1/[IU]",
			"",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/i/U.",
			null,
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"international units; /IU; per IU",
			"LOINC",
			"InvA",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per low power field",
			"/[LPF]",
			"1/[LPF]",
			"",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/LPF",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/LPF; per LPF",
			"LOINC",
			"Naric",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per 10 billion  ",
			"/10*10",
			"1/(10*10)",
			"",
			1e-10,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/10<sup>10</sup>",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/10^10; per 10*10",
			"LOINC",
			"NFr",
			"Clinical",
			"used for counting entities, e.g. blood cells; usually these kinds of terms have numerators such as moles or milligrams, and counting that amount per the number in the denominator",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per trillion ",
			"/10*12",
			"1/(10*12)",
			"",
			1e-12,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/10<sup>12</sup>",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/10^12; per 10*12",
			"LOINC",
			"NFr",
			"Clinical",
			"used for counting entities, e.g. blood cells; usually these kinds of terms have numerators such as moles or milligrams, and counting that amount per the number in the denominator",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per thousand",
			"/10*3",
			"1/(10*3)",
			"",
			0.001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/10<sup>3</sup>",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/10^3; per 10*3",
			"LOINC",
			"NFr",
			"Clinical",
			"used for counting entities, e.g. blood cells; usually these kinds of terms have numerators such as moles or milligrams, and counting that amount per the number in the denominator",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per million",
			"/10*6",
			"1/(10*6)",
			"",
			0.000001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/10<sup>6</sup>",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/10^6; per 10*6;",
			"LOINC",
			"NFr",
			"Clinical",
			"used for counting entities, e.g. blood cells; usually these kinds of terms have numerators such as moles or milligrams, and counting that amount per the number in the denominator",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per billion",
			"/10*9",
			"1/(10*9)",
			"",
			1e-9,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/10<sup>9</sup>",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/10^9; per 10*9",
			"LOINC",
			"NFr",
			"Clinical",
			"used for counting entities, e.g. blood cells; usually these kinds of terms have numerators such as moles or milligrams, and counting that amount per the number in the denominator",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per 100",
			"/100",
			"1/100",
			"",
			0.01,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"per hundred; 10^2; 10*2",
			"LOINC",
			"NFr",
			"Clinical",
			"used for counting entities, e.g. blood cells; usually these kinds of terms have numerators such as moles or milligrams, and counting that amount per the number in the denominator",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per 100 cells",
			"/100{cells}",
			"1/100",
			"",
			0.01,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/100 cells; /100cells; per hundred",
			"LOINC",
			"EntMass; EntNum; NFr",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per 100 neutrophils",
			"/100{neutrophils}",
			"1/100",
			"",
			0.01,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/100 neutrophils; /100neutrophils; per hundred",
			"LOINC",
			"EntMass; EntNum; NFr",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per 100 spermatozoa",
			"/100{spermatozoa}",
			"1/100",
			"",
			0.01,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/100 spermatozoa; /100spermatozoa; per hundred",
			"LOINC",
			"NFr",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per 100 white blood cells",
			"/100{WBCs}",
			"1/100",
			"",
			0.01,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/100 WBCs; /100WBCs; per hundred",
			"LOINC",
			"Ratio; NFr",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per year",
			"/a",
			"1/ANN",
			"",
			3.168808781402895e-8,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"/a",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/Years; /yrs; yearly",
			"LOINC",
			"NRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per centimeter of water",
			"/cm[H2O]",
			"1/CM[H2O]",
			"",
			0.000010197162129779282,
			[
				1,
				2,
				-1,
				0,
				0,
				0,
				0
			],
			"/cmHO<sub><r>2</r></sub>",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/cmH2O; /cm H2O; centimeters; centimetres",
			"LOINC",
			"InvPress",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per day",
			"/d",
			"1/D",
			"",
			0.000011574074074074073,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"/d",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/dy; per day",
			"LOINC",
			"NRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per deciliter",
			"/dL",
			"1/DL",
			"",
			10000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/dL",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"per dL; /deciliter; decilitre",
			"LOINC",
			"NCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per gram",
			"/g",
			"1/G",
			"",
			1,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"/g",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/gm; /gram; per g",
			"LOINC",
			"NCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per hour",
			"/h",
			"1/HR",
			"",
			0.0002777777777777778,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"/h",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/hr; /hour; per hr",
			"LOINC",
			"NRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per kilogram",
			"/kg",
			"1/KG",
			"",
			0.001,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"/kg",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"per kg; per kilogram",
			"LOINC",
			"NCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per liter",
			"/L",
			"1/L",
			"",
			1000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/L",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/liter; litre",
			"LOINC",
			"NCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per square meter",
			"/m2",
			"1/M2",
			"",
			1,
			[
				-2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/m<sup>2</sup>",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/m^2; /m*2; /sq. m; per square meter; meter squared; metre",
			"LOINC",
			"Naric",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per cubic meter",
			"/m3",
			"1/M3",
			"",
			1,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/m<sup>3</sup>",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/m^3; /m*3; /cu. m; per cubic meter; meter cubed; per m3; metre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per milligram",
			"/mg",
			"1/MG",
			"",
			1000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"/mg",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/milligram; per mg",
			"LOINC",
			"NCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per minute",
			"/min",
			"1/MIN",
			"",
			0.016666666666666666,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"/min",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/minute; per mins; breaths beats per minute",
			"LOINC",
			"NRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per milliliter",
			"/mL",
			"1/ML",
			"",
			1000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/mL",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/milliliter; per mL; millilitre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per millimeter",
			"/mm",
			"1/MM",
			"",
			1000,
			[
				-1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/mm",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/millimeter; per mm; millimetre",
			"LOINC",
			"InvLen",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per month",
			"/mo",
			"1/MO",
			"",
			3.802570537683474e-7,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"/mo",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/month; per mo; monthly; month",
			"LOINC",
			"NRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per second",
			"/s",
			"1/S",
			"",
			1,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"/s",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/second; /sec; per sec; frequency; Hertz; Herz; Hz; becquerels; Bq; s-1; s^-1",
			"LOINC",
			"NRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per enzyme unit",
			"/U",
			"1/U",
			"",
			9.963241120049633e-17,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"/U",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			-1,
			"/enzyme units; per U",
			"LOINC",
			"InvC; NCat",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per microliter",
			"/uL",
			"1/UL",
			"",
			999999999.9999999,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/L",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/microliter; microlitre; /mcl; per uL",
			"LOINC",
			"ACnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"per week",
			"/wk",
			"1/WK",
			"",
			0.0000016534391534391535,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"/wk",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"/week; per wk; weekly, weeks",
			"LOINC",
			"NRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"APL unit per milliliter",
			"[APL'U]/mL",
			"[APL'U]/ML",
			"biologic activity of anticardiolipin IgA",
			1000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/mL",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"APL/mL; APL'U/mL; APL U/mL; APL/milliliter; IgA anticardiolipin units per milliliter; IgA Phospholipid Units; millilitre; biologic activity of",
			"LOINC",
			"ACnc",
			"Clinical",
			"Units for an anti phospholipid syndrome test",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"arbitrary unit per milliliter",
			"[arb'U]/mL",
			"[ARB'U]/ML",
			"arbitrary",
			1000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(arb. U)/mL",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"arb'U/mL; arbU/mL; arb U/mL; arbitrary units per milliliter; millilitre",
			"LOINC",
			"ACnc",
			"Clinical",
			"relative unit of measurement to show the ratio of test measurement to reference measurement",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"colony forming units per liter",
			"[CFU]/L",
			"[CFU]/L",
			"amount of a proliferating organism",
			1000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"CFU/L",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"CFU per Liter; CFU/L",
			"LOINC",
			"NCnc",
			"Clinical",
			"",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"colony forming units per milliliter",
			"[CFU]/mL",
			"[CFU]/ML",
			"amount of a proliferating organism",
			1000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"CFU/mL",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"CFU per mL; CFU/mL",
			"LOINC",
			"NCnc",
			"Clinical",
			"",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"foot per foot - US",
			"[ft_us]/[ft_us]",
			"[FT_US]/[FT_US]",
			"length",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(ft<sub>us</sub>)/(ft<sub>us</sub>)",
			"us-lengths",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"ft/ft; ft per ft; feet per feet; visual acuity",
			"",
			"LenRto",
			"Clinical",
			"distance ratio to measure 20:20 vision",
			"m/3937",
			"M/3937",
			"1200",
			1200,
			false
		],
		[
			false,
			"GPL unit per milliliter",
			"[GPL'U]/mL",
			"[GPL'U]/ML",
			"biologic activity of anticardiolipin IgG",
			1000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/mL",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"GPL U/mL; GPL'U/mL; GPL/mL; GPL U per mL; IgG Phospholipid Units per milliliters; IgG anticardiolipin units; millilitres ",
			"LOINC",
			"ACnc; AMass",
			"Clinical",
			"Units for an antiphospholipid test",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"international unit per 2 hour",
			"[IU]/(2.h)",
			"[IU]/(2.HR)",
			"arbitrary",
			0.0001388888888888889,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(i.U.)/h",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"IU/2hrs; IU/2 hours; IU per 2 hrs; international units per 2 hours",
			"LOINC",
			"ARat",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"international unit per 24 hour",
			"[IU]/(24.h)",
			"[IU]/(24.HR)",
			"arbitrary",
			0.000011574074074074073,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(i.U.)/h",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"IU/24hr; IU/24 hours; IU per 24 hrs; international units per 24 hours",
			"LOINC",
			"ARat",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"international unit per day",
			"[IU]/d",
			"[IU]/D",
			"arbitrary",
			0.000011574074074074073,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(i.U.)/d",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"IU/dy; IU/days; IU per dys; international units per day",
			"LOINC",
			"ARat",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"international unit per deciliter",
			"[IU]/dL",
			"[IU]/DL",
			"arbitrary",
			10000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(i.U.)/dL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"IU/dL; IU per dL; international units per deciliters; decilitres",
			"LOINC",
			"ACnc",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"international unit per gram",
			"[IU]/g",
			"[IU]/G",
			"arbitrary",
			1,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"(i.U.)/g",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"IU/gm; IU/gram; IU per gm; IU per g; international units per gram",
			"LOINC",
			"ACnt",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"international unit per hour",
			"[IU]/h",
			"[IU]/HR",
			"arbitrary",
			0.0002777777777777778,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(i.U.)/h",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"IU/hrs; IU per hours; international units per hour",
			"LOINC",
			"ARat",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"international unit per kilogram",
			"[IU]/kg",
			"[IU]/KG",
			"arbitrary",
			0.001,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"(i.U.)/kg",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"IU/kg; IU/kilogram; IU per kg; units",
			"LOINC",
			"ACnt",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"international unit per kilogram per day",
			"[IU]/kg/d",
			"([IU]/KG)/D",
			"arbitrary",
			1.1574074074074074e-8,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"((i.U.)/kg)/d",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"IU/kg/dy; IU/kg/day; IU/kilogram/day; IU per kg per day; units",
			"LOINC",
			"ACntRat",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"international unit per liter",
			"[IU]/L",
			"[IU]/L",
			"arbitrary",
			1000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(i.U.)/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"IU/L; IU/liter; IU per liter; units; litre",
			"LOINC",
			"ACnc",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"international unit per minute",
			"[IU]/min",
			"[IU]/MIN",
			"arbitrary",
			0.016666666666666666,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(i.U.)/min",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"IU/min; IU/minute; IU per minute; international units",
			"LOINC",
			"ARat",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"international unit per milliliter",
			"[IU]/mL",
			"[IU]/ML",
			"arbitrary",
			1000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(i.U.)/mL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"IU/mL; IU per mL; international units per milliliter; millilitre",
			"LOINC",
			"ACnc",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"MPL unit per milliliter",
			"[MPL'U]/mL",
			"[MPL'U]/ML",
			"biologic activity of anticardiolipin IgM",
			1000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/mL",
			"chemical",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"MPL/mL; MPL U/mL; MPL'U/mL; IgM anticardiolipin units; IgM Phospholipid Units; millilitre ",
			"LOINC",
			"ACnc",
			"Clinical",
			"units for antiphospholipid test\n",
			"1",
			"1",
			"1",
			1,
			false
		],
		[
			false,
			"number per high power field",
			"{#}/[HPF]",
			"{#}/[HPF]",
			"",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/HPF",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"#/HPF; # per HPF; number/HPF; numbers per high power field",
			"LOINC",
			"Naric",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"number per low power field",
			"{#}/[LPF]",
			"{#}/[LPF]",
			"",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"/LPF",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"#/LPF; # per LPF; number/LPF; numbers per low power field",
			"LOINC",
			"Naric",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"IgA antiphosphatidylserine unit ",
			"{APS'U}",
			"{APS'U}",
			"",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"APS Unit; Phosphatidylserine Antibody IgA Units",
			"LOINC",
			"ACnc",
			"Clinical",
			"unit for antiphospholipid test",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"EIA index",
			"{EIA_index}",
			"{EIA_index}",
			"",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"enzyme immunoassay index",
			"LOINC",
			"ACnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kaolin clotting time",
			"{KCT'U}",
			"{KCT'U}",
			"",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"KCT",
			"LOINC",
			"Time",
			"Clinical",
			"sensitivetest to detectlupus anticoagulants; measured in seconds",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"IgM antiphosphatidylserine unit",
			"{MPS'U}",
			"{MPS'U}",
			"",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			null,
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"Phosphatidylserine Antibody IgM Measurement ",
			"LOINC",
			"ACnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"trillion per liter",
			"10*12/L",
			"(10*12)/L",
			"number",
			1000000000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>12</sup>)/L",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^12/L; 10*12 per Liter; trillion per liter; litre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"10^3 (used for cell count)",
			"10*3",
			"10*3",
			"number",
			1000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"10<sup>3</sup>",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^3; thousand",
			"LOINC",
			"Num",
			"Clinical",
			"usually used for counting entities (e.g. blood cells) per volume",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"thousand per liter",
			"10*3/L",
			"(10*3)/L",
			"number",
			1000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>3</sup>)/L",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^3/L; 10*3 per liter; litre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"thousand per milliliter",
			"10*3/mL",
			"(10*3)/ML",
			"number",
			1000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>3</sup>)/mL",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^3/mL; 10*3 per mL; thousand per milliliter; millilitre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"thousand per microliter",
			"10*3/uL",
			"(10*3)/UL",
			"number",
			999999999999.9999,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>3</sup>)/L",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^3/uL; 10*3 per uL; thousand per microliter; microlitre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"10 thousand per microliter",
			"10*4/uL",
			"(10*4)/UL",
			"number",
			10000000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>4</sup>)/L",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^4/uL; 10*4 per uL; microlitre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"10^5 ",
			"10*5",
			"10*5",
			"number",
			100000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"10<sup>5</sup>",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"one hundred thousand",
			"LOINC",
			"Num",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"10^6",
			"10*6",
			"10*6",
			"number",
			1000000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"10<sup>6</sup>",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"",
			"LOINC",
			"Num",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"million colony forming unit per liter",
			"10*6.[CFU]/L",
			"((10*6).[CFU])/L",
			"number",
			1000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"((10<sup>6</sup>).CFU)/L",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"10*6 CFU/L; 10^6 CFU/L; 10^6CFU; 10^6 CFU per liter; million colony forming units; litre",
			"LOINC",
			"ACnc",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"million international unit",
			"10*6.[IU]",
			"(10*6).[IU]",
			"number",
			1000000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>6</sup>).(i.U.)",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			true,
			0,
			"10*6 IU; 10^6 IU; international units",
			"LOINC",
			"arb",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"million per 24 hour",
			"10*6/(24.h)",
			"(10*6)/(24.HR)",
			"number",
			11.574074074074074,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>6</sup>)/h",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10*6/24hrs; 10^6/24 hrs; 10*6 per 24 hrs; 10^6 per 24 hours",
			"LOINC",
			"NRat",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"million per kilogram",
			"10*6/kg",
			"(10*6)/KG",
			"number",
			1000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"(10<sup>6</sup>)/kg",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^6/kg; 10*6 per kg; 10*6 per kilogram; millions",
			"LOINC",
			"NCnt",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"million per liter",
			"10*6/L",
			"(10*6)/L",
			"number",
			1000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>6</sup>)/L",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^6/L; 10*6 per Liter; 10^6 per Liter; litre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"million per milliliter",
			"10*6/mL",
			"(10*6)/ML",
			"number",
			1000000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>6</sup>)/mL",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^6/mL; 10*6 per mL; 10*6 per milliliter; millilitre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"million per microliter",
			"10*6/uL",
			"(10*6)/UL",
			"number",
			1000000000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>6</sup>)/L",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^6/uL; 10^6 per uL; 10^6/mcl; 10^6 per mcl; 10^6 per microliter; microlitre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"10^8",
			"10*8",
			"10*8",
			"number",
			100000000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"10<sup>8</sup>",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"100 million; one hundred million; 10^8",
			"LOINC",
			"Num",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"billion per liter",
			"10*9/L",
			"(10*9)/L",
			"number",
			1000000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>9</sup>)/L",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^9/L; 10*9 per Liter; litre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"billion per milliliter",
			"10*9/mL",
			"(10*9)/ML",
			"number",
			1000000000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>9</sup>)/mL",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^9/mL; 10*9 per mL; 10^9 per mL; 10*9 per milliliter; millilitre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"billion per microliter",
			"10*9/uL",
			"(10*9)/UL",
			"number",
			1000000000000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(10<sup>9</sup>)/L",
			"dimless",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10^9/uL; 10^9 per uL; 10^9/mcl; 10^9 per mcl; 10*9 per uL; 10*9 per mcl; 10*9/mcl; 10^9 per microliter; microlitre",
			"LOINC",
			"NCncn",
			"Clinical",
			"",
			"1",
			"1",
			"10",
			10,
			false
		],
		[
			false,
			"10 liter per minute per square meter",
			"10.L/(min.m2)",
			"(10.L)/(MIN.M2)",
			"",
			0.00016666666666666666,
			[
				1,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"L/(min.(m<sup>2</sup>))",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10 liters per minutes per square meter; 10 L per min per m2; m^2; 10 L/(min*m2); 10L/(min*m^2); litres; sq. meter; metre; meters squared",
			"LOINC",
			"ArVRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"10 liter per minute",
			"10.L/min",
			"(10.L)/MIN",
			"",
			0.00016666666666666666,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"L/min",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"10 liters per minute; 10 L per min; 10L; 10 L/min; litre",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"10 micronewton second per centimeter to the fifth power per square meter",
			"10.uN.s/(cm5.m2)",
			"((10.UN).S)/(CM5.M2)",
			"",
			100000000,
			[
				-6,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"(N.s)/(cm<sup>5</sup>).(m<sup>2</sup>)",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"dyne seconds per centimeter5 and square meter; dyn.s/(cm5.m2); dyn.s/cm5/m2; cm^5; m^2",
			"LOINC",
			"",
			"Clinical",
			"unit to measure systemic vascular resistance per body surface area",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"24 hour",
			"24.h",
			"24.HR",
			"",
			86400,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"h",
			null,
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"24hrs; 24 hrs; 24 hours; days; dy",
			"LOINC",
			"Time",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"ampere per meter",
			"A/m",
			"A/M",
			"electric current",
			1,
			[
				-1,
				-1,
				0,
				0,
				0,
				1,
				0
			],
			"A/m",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"A/m; amp/meter; magnetic field strength; H; B; amperes per meter; metre",
			"LOINC",
			"",
			"Clinical",
			"unit of magnetic field strength",
			"C/s",
			"C/S",
			"1",
			1,
			false
		],
		[
			false,
			"centigram",
			"cg",
			"CG",
			"mass",
			0.01,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"cg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"centigrams; cg; cgm",
			"LOINC",
			"Mass",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"centiliter",
			"cL",
			"CL",
			"volume",
			0.00001,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"cL",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"centiliters; centilitres",
			"LOINC",
			"Vol",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"centimeter",
			"cm",
			"CM",
			"length",
			0.01,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"cm",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"centimeters; centimetres",
			"LOINC",
			"Len",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"centimeter of water",
			"cm[H2O]",
			"CM[H2O]",
			"pressure",
			98066.5,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"cmHO<sub><r>2</r></sub>",
			"clinical",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"cm H2O; cmH2O; centimetres; pressure",
			"LOINC",
			"Pres",
			"Clinical",
			"unit of pressure mostly applies to blood pressure",
			"kPa",
			"KPAL",
			"980665e-5",
			9.80665,
			false
		],
		[
			false,
			"centimeter of water per liter per second",
			"cm[H2O]/L/s",
			"(CM[H2O]/L)/S",
			"pressure",
			98066500,
			[
				-4,
				-3,
				1,
				0,
				0,
				0,
				0
			],
			"((cmHO<sub><r>2</r></sub>)/L)/s",
			"clinical",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"cm[H2O]/(L/s); cm[H2O].s/L; cm H2O/L/sec; cmH2O/L/sec; cmH2O/Liter; cmH2O per L per secs; centimeters of water per liters per second; centimetres; litres; cm[H2O]/(L/s)",
			"LOINC",
			"PresRat",
			"Clinical",
			"unit used to measure mean pulmonary resistance",
			"kPa",
			"KPAL",
			"980665e-5",
			9.80665,
			false
		],
		[
			false,
			"centimeter of water per second per meter",
			"cm[H2O]/s/m",
			"(CM[H2O]/S)/M",
			"pressure",
			98066.5,
			[
				-2,
				-3,
				1,
				0,
				0,
				0,
				0
			],
			"((cmHO<sub><r>2</r></sub>)/s)/m",
			"clinical",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"cm[H2O]/(s.m); cm H2O/s/m; cmH2O; cmH2O/sec/m; cmH2O per secs per meters; centimeters of water per seconds per meter; centimetres; metre",
			"LOINC",
			"PresRat",
			"Clinical",
			"unit used to measure pulmonary pressure time product",
			"kPa",
			"KPAL",
			"980665e-5",
			9.80665,
			false
		],
		[
			false,
			"centimeter of mercury",
			"cm[Hg]",
			"CM[HG]",
			"pressure",
			1333220,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"cmHg",
			"clinical",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"centimeters of mercury; centimetres; cmHg; cm Hg",
			"LOINC",
			"Pres",
			"Clinical",
			"unit of pressure where 1 cmHg = 10 torr",
			"kPa",
			"KPAL",
			"133.3220",
			133.322,
			false
		],
		[
			false,
			"square centimeter",
			"cm2",
			"CM2",
			"length",
			0.0001,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"cm<sup>2</sup>",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"cm^2; sq cm; centimeters squared; square centimeters; centimetre; area",
			"LOINC",
			"Area",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"square centimeter per second",
			"cm2/s",
			"CM2/S",
			"length",
			0.0001,
			[
				2,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(cm<sup>2</sup>)/s",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"cm^2/sec; square centimeters per second; sq cm per sec; cm2; centimeters squared; centimetres",
			"LOINC",
			"AreaRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"centipoise",
			"cP",
			"CP",
			"dynamic viscosity",
			1.0000000000000002,
			[
				-1,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"cP",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"cps; centiposes",
			"LOINC",
			"Visc",
			"Clinical",
			"unit of dynamic viscosity in the CGS system with base units: 10^3 Pa.s = 1 mPa.s (1 millipascal second)",
			"dyn.s/cm2",
			"DYN.S/CM2",
			"1",
			1,
			false
		],
		[
			false,
			"centistoke",
			"cSt",
			"CST",
			"kinematic viscosity",
			0.000001,
			[
				2,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"cSt",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"centistokes",
			"LOINC",
			"Visc",
			"Clinical",
			"unit for kinematic viscosity with base units of mm^2/s (square millimeter per second)",
			"cm2/s",
			"CM2/S",
			"1",
			1,
			false
		],
		[
			false,
			"dekaliter per minute",
			"daL/min",
			"DAL/MIN",
			"volume",
			0.00016666666666666666,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"daL/min",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"dekalitres; dekaliters per minute; per min",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"dekaliter per minute per square meter",
			"daL/min/m2",
			"(DAL/MIN)/M2",
			"volume",
			0.00016666666666666666,
			[
				1,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(daL/min)/(m<sup>2</sup>)",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"daL/min/m^2; daL/minute/m2; sq. meter; dekaliters per minutes per square meter; meter squared; dekalitres; metre",
			"LOINC",
			"ArVRat",
			"Clinical",
			"The area usually is the body surface area used to normalize cardiovascular measures for patient's size",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"decibel",
			"dB",
			"DB",
			"level",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"dB",
			"levels",
			true,
			null,
			"lg",
			0.1,
			true,
			false,
			0,
			"decibels",
			"LOINC",
			"LogRto",
			"Clinical",
			"unit most commonly used in acoustics as unit of sound pressure level. (also see B[SPL] or bel sound pressure level). ",
			"1",
			null,
			null,
			1,
			false
		],
		[
			false,
			"degree per second",
			"deg/s",
			"DEG/S",
			"plane angle",
			0.017453292519943295,
			[
				0,
				-1,
				0,
				1,
				0,
				0,
				0
			],
			"/s",
			"iso1000",
			false,
			null,
			null,
			1,
			false,
			false,
			0,
			"deg/sec; deg per sec; /sec; twist rate; angular speed; rotational speed",
			"LOINC",
			"ARat",
			"Clinical",
			"unit of angular (rotational) speed used to express turning rate",
			"[pi].rad/360",
			"[PI].RAD/360",
			"2",
			2,
			false
		],
		[
			false,
			"decigram",
			"dg",
			"DG",
			"mass",
			0.1,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"dg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"decigrams; dgm; 0.1 grams; 1/10 gm",
			"LOINC",
			"Mass",
			"Clinical",
			"equal to 1/10 gram",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"deciliter",
			"dL",
			"DL",
			"volume",
			0.0001,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"dL",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"deciliters; decilitres; 0.1 liters; 1/10 L",
			"LOINC",
			"Vol",
			"Clinical",
			"equal to 1/10 liter",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"decimeter",
			"dm",
			"DM",
			"length",
			0.1,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"dm",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"decimeters; decimetres; 0.1 meters; 1/10 m; 10 cm; centimeters",
			"LOINC",
			"Len",
			"Clinical",
			"equal to 1/10 meter or 10 centimeters",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"square decimeter per square second",
			"dm2/s2",
			"DM2/S2",
			"length",
			0.010000000000000002,
			[
				2,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"(dm<sup>2</sup>)/(s<sup>2</sup>)",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"dm2 per s2; dm^2/s^2; decimeters squared per second squared; sq dm; sq sec",
			"LOINC",
			"EngMass (massic energy)",
			"Clinical",
			"units for energy per unit mass or Joules per kilogram (J/kg = kg.m2/s2/kg = m2/s2) ",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"dyne second per centimeter per square meter",
			"dyn.s/(cm.m2)",
			"(DYN.S)/(CM.M2)",
			"force",
			1,
			[
				-2,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"(dyn.s)/(cm.(m<sup>2</sup>))",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"(dyn*s)/(cm*m2); (dyn*s)/(cm*m^2); dyn s per cm per m2; m^2; dyne seconds per centimeters per square meter; centimetres; sq. meter; squared",
			"LOINC",
			"",
			"Clinical",
			"",
			"g.cm/s2",
			"G.CM/S2",
			"1",
			1,
			false
		],
		[
			false,
			"dyne second per centimeter",
			"dyn.s/cm",
			"(DYN.S)/CM",
			"force",
			1,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"(dyn.s)/cm",
			"cgs",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"(dyn*s)/cm; dyn sec per cm; seconds; centimetre; dyne seconds",
			"LOINC",
			"",
			"Clinical",
			"",
			"g.cm/s2",
			"G.CM/S2",
			"1",
			1,
			false
		],
		[
			false,
			"equivalent per liter",
			"eq/L",
			"EQ/L",
			"amount of substance",
			6.0221366999999994e+26,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"eq/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"eq/liter; eq/litre; eqs; equivalents per liter; litre",
			"LOINC",
			"SCnc",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"equivalent per milliliter",
			"eq/mL",
			"EQ/ML",
			"amount of substance",
			6.0221367e+29,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"eq/mL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"equivalent/milliliter; equivalents per milliliter; eq per mL; millilitre",
			"LOINC",
			"SCnc",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"equivalent per millimole",
			"eq/mmol",
			"EQ/MMOL",
			"amount of substance",
			1000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"eq/mmol",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"equivalent/millimole; equivalents per millimole; eq per mmol",
			"LOINC",
			"SRto",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"equivalent per micromole",
			"eq/umol",
			"EQ/UMOL",
			"amount of substance",
			1000000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"eq/mol",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"equivalent/micromole; equivalents per micromole; eq per umol",
			"LOINC",
			"SRto",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"femtogram",
			"fg",
			"FG",
			"mass",
			1e-15,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"fg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"fg; fgm; femtograms; weight",
			"LOINC",
			"Mass",
			"Clinical",
			"equal to 10^-15 grams",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"femtoliter",
			"fL",
			"FL",
			"volume",
			1e-18,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"fL",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"femtolitres; femtoliters",
			"LOINC",
			"Vol; EntVol",
			"Clinical",
			"equal to 10^-15 liters",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"femtometer",
			"fm",
			"FM",
			"length",
			1e-15,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"fm",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"femtometres; femtometers",
			"LOINC",
			"Len",
			"Clinical",
			"equal to 10^-15 meters",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"femtomole",
			"fmol",
			"FMOL",
			"amount of substance",
			602213670,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"fmol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"femtomoles",
			"LOINC",
			"EntSub",
			"Clinical",
			"equal to 10^-15 moles",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"femtomole per gram",
			"fmol/g",
			"FMOL/G",
			"amount of substance",
			602213670,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"fmol/g",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"femtomoles; fmol/gm; fmol per gm",
			"LOINC",
			"SCnt",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"femtomole per liter",
			"fmol/L",
			"FMOL/L",
			"amount of substance",
			602213670000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"fmol/L",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"femtomoles; fmol per liter; litre",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"femtomole per milligram",
			"fmol/mg",
			"FMOL/MG",
			"amount of substance",
			602213670000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"fmol/mg",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"fmol per mg; femtomoles",
			"LOINC",
			"SCnt",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"femtomole per milliliter",
			"fmol/mL",
			"FMOL/ML",
			"amount of substance",
			602213670000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"fmol/mL",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"femtomoles; millilitre; fmol per mL; fmol per milliliter",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"gram meter",
			"g.m",
			"G.M",
			"mass",
			1,
			[
				1,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g.m",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"g*m; gxm; meters; metres",
			"LOINC",
			"Enrg",
			"Clinical",
			"Unit for measuring stroke work (heart work)",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per 100 gram",
			"g/(100.g)",
			"G/(100.G)",
			"mass",
			0.01,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"g/g",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"g/100 gm; 100gm; grams per 100 grams; gm per 100 gm",
			"LOINC",
			"MCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per 12 hour",
			"g/(12.h)",
			"G/(12.HR)",
			"mass",
			0.000023148148148148147,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm/12hrs; 12 hrs; gm per 12 hrs; 12hrs; grams per 12 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per 24 hour",
			"g/(24.h)",
			"G/(24.HR)",
			"mass",
			0.000011574074074074073,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm/24hrs; gm/24 hrs; gm per 24 hrs; 24hrs; grams per 24 hours; gm/dy; gm per dy; grams per day",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per 3 days",
			"g/(3.d)",
			"G/(3.D)",
			"mass",
			0.000003858024691358025,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/d",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm/3dy; gm/3 dy; gm per 3 days; grams",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per 4 hour",
			"g/(4.h)",
			"G/(4.HR)",
			"mass",
			0.00006944444444444444,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm/4hrs; gm/4 hrs; gm per 4 hrs; 4hrs; grams per 4 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per 48 hour",
			"g/(48.h)",
			"G/(48.HR)",
			"mass",
			0.000005787037037037037,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm/48hrs; gm/48 hrs; gm per 48 hrs; 48hrs; grams per 48 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per 5 hour",
			"g/(5.h)",
			"G/(5.HR)",
			"mass",
			0.00005555555555555556,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm/5hrs; gm/5 hrs; gm per 5 hrs; 5hrs; grams per 5 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per 6 hour",
			"g/(6.h)",
			"G/(6.HR)",
			"mass",
			0.000046296296296296294,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm/6hrs; gm/6 hrs; gm per 6 hrs; 6hrs; grams per 6 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per 72 hour",
			"g/(72.h)",
			"G/(72.HR)",
			"mass",
			0.000003858024691358025,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm/72hrs; gm/72 hrs; gm per 72 hrs; 72hrs; grams per 72 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per cubic centimeter",
			"g/cm3",
			"G/CM3",
			"mass",
			999999.9999999999,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g/(cm<sup>3</sup>)",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"g/cm^3; gm per cm3; g per cm^3; grams per centimeter cubed; cu. cm; centimetre; g/mL; gram per milliliter; millilitre",
			"LOINC",
			"MCnc",
			"Clinical",
			"g/cm3 = g/mL",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per day",
			"g/d",
			"G/D",
			"mass",
			0.000011574074074074073,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/d",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm/dy; gm per dy; grams per day; gm/24hrs; gm/24 hrs; gm per 24 hrs; 24hrs; grams per 24 hours; serving",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per deciliter",
			"g/dL",
			"G/DL",
			"mass",
			10000,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g/dL",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm/dL; gm per dL; grams per deciliter; decilitre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per gram",
			"g/g",
			"G/G",
			"mass",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"g/g",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm; grams",
			"LOINC",
			"MRto ",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per hour",
			"g/h",
			"G/HR",
			"mass",
			0.0002777777777777778,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm/hr; gm per hr; grams; intake; output",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per hour per square meter",
			"g/h/m2",
			"(G/HR)/M2",
			"mass",
			0.0002777777777777778,
			[
				-2,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"(g/h)/(m<sup>2</sup>)",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm/hr/m2; gm/h/m2; /m^2; sq. m; g per hr per m2; grams per hours per square meter; meter squared; metre",
			"LOINC",
			"ArMRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per kilogram",
			"g/kg ",
			"G/KG",
			"mass",
			0.001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"g/kg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"g per kg; gram per kilograms",
			"LOINC",
			"MCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per kilogram per 8 hour ",
			"g/kg/(8.h)",
			"(G/KG)/(8.HR)",
			"mass",
			3.472222222222222e-8,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(g/kg)/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"g/(8.kg.h); gm/kg/8hrs; 8 hrs; g per kg per 8 hrs; 8hrs; grams per kilograms per 8 hours; shift",
			"LOINC",
			"MCntRat; RelMRat",
			"Clinical",
			"unit often used to describe mass in grams of protein consumed in a 8 hours, divided by the subject's body weight in kilograms. Also used to measure mass dose rate per body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per kilogram per day",
			"g/kg/d",
			"(G/KG)/D",
			"mass",
			1.1574074074074074e-8,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(g/kg)/d",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"g/(kg.d); gm/kg/dy; gm per kg per dy; grams per kilograms per day",
			"LOINC",
			"RelMRat",
			"Clinical",
			"unit often used to describe mass in grams of protein consumed in a day, divided by the subject's body weight in kilograms. Also used to measure mass dose rate per body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per kilogram per hour",
			"g/kg/h",
			"(G/KG)/HR",
			"mass",
			2.7777777777777776e-7,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(g/kg)/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"g/(kg.h); g/kg/hr; g per kg per hrs; grams per kilograms per hour",
			"LOINC",
			"MCntRat; RelMRat",
			"Clinical",
			"unit used to measure mass dose rate per body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per kilogram per minute",
			"g/kg/min",
			"(G/KG)/MIN",
			"mass",
			0.000016666666666666667,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(g/kg)/min",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"g/(kg.min); g/kg/min; g per kg per min; grams per kilograms per minute",
			"LOINC",
			"MCntRat; RelMRat",
			"Clinical",
			"unit used to measure mass dose rate per body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per liter",
			"g/L",
			"G/L",
			"mass",
			1000,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g/L",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"gm per liter; g/liter; grams per liter; litre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per square meter",
			"g/m2",
			"G/M2",
			"mass",
			1,
			[
				-2,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g/(m<sup>2</sup>)",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"g/m^2; gram/square meter; g/sq m; g per m2; g per m^2; grams per square meter; meters squared; metre",
			"LOINC",
			"ArMass",
			"Clinical",
			"Tests measure myocardial mass (heart ventricle system) per body surface area; unit used to measure mass dose per body surface area",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per milligram",
			"g/mg",
			"G/MG",
			"mass",
			1000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"g/mg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"g per mg; grams per milligram",
			"LOINC",
			"MCnt; MRto",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per minute",
			"g/min",
			"G/MIN",
			"mass",
			0.016666666666666666,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/min",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"g per min; grams per minute; gram/minute",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per milliliter",
			"g/mL",
			"G/ML",
			"mass",
			1000000,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g/mL",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"g per mL; grams per milliliter; millilitre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"gram per millimole",
			"g/mmol",
			"G/MMOL",
			"mass",
			1.6605401866749388e-21,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g/mmol",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			-1,
			"grams per millimole; g per mmol",
			"LOINC",
			"Ratio",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"joule per liter",
			"J/L",
			"J/L",
			"energy",
			1000000,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"J/L",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"joules per liter; litre; J per L",
			"LOINC",
			"EngCnc",
			"Clinical",
			"",
			"N.m",
			"N.M",
			"1",
			1,
			false
		],
		[
			false,
			"degree Kelvin per Watt",
			"K/W",
			"K/W",
			"temperature",
			0.001,
			[
				-2,
				3,
				-1,
				0,
				1,
				0,
				0
			],
			"K/W",
			null,
			false,
			"C",
			null,
			1,
			false,
			false,
			0,
			"degree Kelvin/Watt; K per W; thermal ohm; thermal resistance; degrees",
			"LOINC",
			"TempEngRat",
			"Clinical",
			"unit for absolute thermal resistance equal to the reciprocal of thermal conductance. Unit used for tests to measure work of breathing",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kilo international unit per liter",
			"k[IU]/L",
			"K[IU]/L",
			"arbitrary",
			1000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(ki.U.)/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"kIU/L; kIU per L; kIU per liter; kilo international units; litre; allergens; allergy units",
			"LOINC",
			"ACnc",
			"Clinical",
			"IgE has an WHO reference standard so IgE allergen testing can be reported as k[IU]/L",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"kilo international unit per milliliter",
			"k[IU]/mL",
			"K[IU]/ML",
			"arbitrary",
			1000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(ki.U.)/mL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"kIU/mL; kIU per mL; kIU per milliliter; kilo international units; millilitre; allergens; allergy units",
			"LOINC",
			"ACnc",
			"Clinical",
			"IgE has an WHO reference standard so IgE allergen testing can be reported as k[IU]/mL",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"katal per kilogram",
			"kat/kg",
			"KAT/KG",
			"catalytic activity",
			602213670000000000000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"kat/kg",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"kat per kg; katals per kilogram; mol/s/kg; moles per seconds per kilogram",
			"LOINC",
			"CCnt",
			"Clinical",
			"kat is a unit of catalytic activity with base units = mol/s. Rarely used because its units are too large to practically express catalytic activity. See enzyme unit [U] which is the standard unit for catalytic activity.",
			"mol/s",
			"MOL/S",
			"1",
			1,
			false
		],
		[
			false,
			"katal per liter",
			"kat/L",
			"KAT/L",
			"catalytic activity",
			6.0221366999999994e+26,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"kat/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"kat per L; katals per liter; litre; mol/s/L; moles per seconds per liter",
			"LOINC",
			"CCnc",
			"Clinical",
			"kat is a unit of catalytic activity with base units = mol/s. Rarely used because its units are too large to practically express catalytic activity. See enzyme unit [U] which is the standard unit for catalytic activity.",
			"mol/s",
			"MOL/S",
			"1",
			1,
			false
		],
		[
			false,
			"kilocalorie",
			"kcal",
			"KCAL",
			"energy",
			4184000,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"kcal",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"kilogram calories; large calories; food calories; kcals",
			"LOINC",
			"EngRat",
			"Clinical",
			"It is equal to 1000 calories (equal to 4.184 kJ). But in practical usage, kcal refers to food calories which excludes caloric content in fiber and other constitutes that is not digestible by humans. Also see nutrition label Calories ([Cal])",
			"cal_th",
			"CAL_TH",
			"1",
			1,
			false
		],
		[
			false,
			"kilocalorie per 24 hour",
			"kcal/(24.h)",
			"KCAL/(24.HR)",
			"energy",
			48.425925925925924,
			[
				2,
				-3,
				1,
				0,
				0,
				0,
				0
			],
			"kcal/h",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"kcal/24hrs; kcal/24 hrs; kcal per 24hrs; kilocalories per 24 hours; kilojoules; kJ/24hr; kJ/(24.h); kJ/dy; kilojoules per days; intake; calories burned; metabolic rate; food calories",
			"",
			"EngRat",
			"Clinical",
			"",
			"cal_th",
			"CAL_TH",
			"1",
			1,
			false
		],
		[
			false,
			"kilocalorie per ounce",
			"kcal/[oz_av]",
			"KCAL/[OZ_AV]",
			"energy",
			147586.25679704445,
			[
				2,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"kcal/oz",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"kcal/oz; kcal per ozs; large calories per ounces; food calories; servings; international",
			"LOINC",
			"EngCnt",
			"Clinical",
			"used in nutrition to represent calorie of food",
			"cal_th",
			"CAL_TH",
			"1",
			1,
			false
		],
		[
			false,
			"kilocalorie per day",
			"kcal/d",
			"KCAL/D",
			"energy",
			48.425925925925924,
			[
				2,
				-3,
				1,
				0,
				0,
				0,
				0
			],
			"kcal/d",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"kcal/dy; kcal per day; kilocalories per days; kilojoules; kJ/dy; kilojoules per days; intake; calories burned; metabolic rate; food calories",
			"LOINC",
			"EngRat",
			"Clinical",
			"unit in nutrition for food intake (measured in calories) in a day",
			"cal_th",
			"CAL_TH",
			"1",
			1,
			false
		],
		[
			false,
			"kilocalorie per hour",
			"kcal/h",
			"KCAL/HR",
			"energy",
			1162.2222222222222,
			[
				2,
				-3,
				1,
				0,
				0,
				0,
				0
			],
			"kcal/h",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"kcal/hrs; kcals per hr; intake; kilocalories per hours; kilojoules",
			"LOINC",
			"EngRat",
			"Clinical",
			"used in nutrition to represent caloric requirement or consumption",
			"cal_th",
			"CAL_TH",
			"1",
			1,
			false
		],
		[
			false,
			"kilocalorie per kilogram per 24 hour",
			"kcal/kg/(24.h)",
			"(KCAL/KG)/(24.HR)",
			"energy",
			0.04842592592592593,
			[
				2,
				-3,
				0,
				0,
				0,
				0,
				0
			],
			"(kcal/kg)/h",
			"heat",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"kcal/kg/24hrs; 24 hrs; kcal per kg per 24hrs; kilocalories per kilograms per 24 hours; kilojoules",
			"LOINC",
			"EngCntRat",
			"Clinical",
			"used in nutrition to represent caloric requirement per day based on subject's body weight in kilograms",
			"cal_th",
			"CAL_TH",
			"1",
			1,
			false
		],
		[
			false,
			"kilogram",
			"kg",
			"KG",
			"mass",
			1000,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"kg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"kilograms; kgs",
			"LOINC",
			"Mass",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kilogram meter per second",
			"kg.m/s",
			"(KG.M)/S",
			"mass",
			1000,
			[
				1,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"(kg.m)/s",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"kg*m/s; kg.m per sec; kg*m per sec; p; momentum",
			"LOINC",
			"",
			"Clinical",
			"unit for momentum =  mass times velocity",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kilogram per second per square meter",
			"kg/(s.m2)",
			"KG/(S.M2)",
			"mass",
			1000,
			[
				-2,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"kg/(s.(m<sup>2</sup>))",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"kg/(s*m2); kg/(s*m^2); kg per s per m2; per sec; per m^2; kilograms per seconds per square meter; meter squared; metre",
			"LOINC",
			"ArMRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kilogram per hour",
			"kg/h",
			"KG/HR",
			"mass",
			0.2777777777777778,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"kg/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"kg/hr; kg per hr; kilograms per hour",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kilogram per liter",
			"kg/L",
			"KG/L",
			"mass",
			1000000,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"kg/L",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"kg per liter; litre; kilograms",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kilogram per square meter",
			"kg/m2",
			"KG/M2",
			"mass",
			1000,
			[
				-2,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"kg/(m<sup>2</sup>)",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"kg/m^2; kg/sq. m; kg per m2; per m^2; per sq. m; kilograms; meter squared; metre; BMI",
			"LOINC",
			"Ratio",
			"Clinical",
			"units for body mass index (BMI)",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kilogram per cubic meter",
			"kg/m3",
			"KG/M3",
			"mass",
			1000,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"kg/(m<sup>3</sup>)",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"kg/m^3; kg/cu. m; kg per m3; per m^3; per cu. m; kilograms; meters cubed; metre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kilogram per minute",
			"kg/min",
			"KG/MIN",
			"mass",
			16.666666666666668,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"kg/min",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"kilogram/minute; kg per min; kilograms per minute",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kilogram per mole",
			"kg/mol",
			"KG/MOL",
			"mass",
			1.6605401866749388e-21,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"kg/mol",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			-1,
			"kilogram/mole; kg per mol; kilograms per mole",
			"LOINC",
			"SCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kilogram per second",
			"kg/s",
			"KG/S",
			"mass",
			1000,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"kg/s",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"kg/sec; kilogram/second; kg per sec; kilograms; second",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kiloliter",
			"kL",
			"KL",
			"volume",
			1,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"kL",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"kiloliters; kilolitres; m3; m^3; meters cubed; metre",
			"LOINC",
			"Vol",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"kilometer",
			"km",
			"KM",
			"length",
			1000,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"km",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"kilometers; kilometres; distance",
			"LOINC",
			"Len",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kilopascal",
			"kPa",
			"KPAL",
			"pressure",
			1000000,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"kPa",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"kilopascals; pressure",
			"LOINC",
			"Pres; PPresDiff",
			"Clinical",
			"",
			"N/m2",
			"N/M2",
			"1",
			1,
			false
		],
		[
			false,
			"kilosecond",
			"ks",
			"KS",
			"time",
			1000,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"ks",
			null,
			false,
			"T",
			null,
			1,
			false,
			false,
			0,
			"kiloseconds; ksec",
			"LOINC",
			"Time",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"kilo enzyme unit",
			"kU",
			"KU",
			"catalytic activity",
			10036894500000000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"kU",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"units; mmol/min; millimoles per minute",
			"LOINC",
			"CAct",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 kU = 1 mmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"kilo enzyme unit per gram",
			"kU/g",
			"KU/G",
			"catalytic activity",
			10036894500000000000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"kU/g",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"units per grams; kU per gm",
			"LOINC",
			"CCnt",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 kU = 1 mmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"kilo enzyme unit per liter",
			"kU/L",
			"KU/L",
			"catalytic activity",
			1.00368945e+22,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"kU/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"units per liter; litre; enzymatic activity; enzyme activity per volume; activities",
			"LOINC",
			"ACnc; CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 kU = 1 mmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"kilo enzyme unit per milliliter",
			"kU/mL",
			"KU/ML",
			"catalytic activity",
			1.00368945e+25,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"kU/mL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"kU per mL; units per milliliter; millilitre; enzymatic activity per volume; enzyme activities",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 kU = 1 mmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"Liters per 24 hour",
			"L/(24.h)",
			"L/(24.HR)",
			"volume",
			1.1574074074074074e-8,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"L/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"L/24hrs; L/24 hrs; L per 24hrs; liters per 24 hours; day; dy; litres; volume flow rate",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"Liters per 8 hour",
			"L/(8.h)",
			"L/(8.HR)",
			"volume",
			3.472222222222222e-8,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"L/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"L/8hrs; L/8 hrs; L per 8hrs; liters per 8 hours; litres; volume flow rate; shift",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"Liters per minute per square meter",
			"L/(min.m2) ",
			"L/(MIN.M2)",
			"volume",
			0.000016666666666666667,
			[
				1,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"L/(min.(m<sup>2</sup>))",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"L/(min.m2); L/min/m^2; L/min/sq. meter; L per min per m2; m^2; liters per minutes per square meter; meter squared; litres; metre ",
			"LOINC",
			"ArVRat",
			"Clinical",
			"unit for tests that measure cardiac output per body surface area (cardiac index)",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"Liters per day",
			"L/d",
			"L/D",
			"volume",
			1.1574074074074074e-8,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"L/d",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"L/dy; L per day; 24hrs; 24 hrs; 24 hours; liters; litres",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"Liters per hour",
			"L/h",
			"L/HR",
			"volume",
			2.7777777777777776e-7,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"L/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"L/hr; L per hr; litres",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"Liters per kilogram",
			"L/kg",
			"L/KG",
			"volume",
			0.000001,
			[
				3,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"L/kg",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"L per kg; litre",
			"LOINC",
			"VCnt",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"Liters per liter",
			"L/L",
			"L/L",
			"volume",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"L/L",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"L per L; liter/liter; litre",
			"LOINC",
			"VFr",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"Liters per minute",
			"L/min",
			"L/MIN",
			"volume",
			0.000016666666666666667,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"L/min",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"liters per minute; litre",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"Liters per minute per square meter",
			"L/min/m2",
			"(L/MIN)/M2",
			"volume",
			0.000016666666666666667,
			[
				1,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(L/min)/(m<sup>2</sup>)",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"L/(min.m2); L/min/m^2; L/min/sq. meter; L per min per m2; m^2; liters per minutes per square meter; meter squared; litres; metre ",
			"",
			"ArVRat",
			"Clinical",
			"unit for tests that measure cardiac output per body surface area (cardiac index)",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"Liters per second",
			"L/s",
			"L/S",
			"volume",
			0.001,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"L/s",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"L per sec; litres",
			"LOINC",
			"VRat",
			"Clinical",
			"unit used often to measure gas flow and peak expiratory flow",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"Liters per second per square second",
			"L/s/s2",
			"(L/S)/S2",
			"volume",
			0.001,
			[
				3,
				-3,
				0,
				0,
				0,
				0,
				0
			],
			"(L/s)/(s<sup>2</sup>)",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"L/s/s^2; L/sec/sec2; L/sec/sec^2; L/sec/sq. sec; L per s per s2; L per sec per sec2; s^2; sec^2; liters per seconds per square second; second squared; litres ",
			"LOINC",
			"ArVRat",
			"Clinical",
			"unit for tests that measure cardiac output/body surface area",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"lumen square meter",
			"lm.m2",
			"LM.M2",
			"luminous flux",
			1,
			[
				2,
				0,
				0,
				2,
				0,
				0,
				1
			],
			"lm.(m<sup>2</sup>)",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"lm*m2; lm*m^2; lumen meters squared; lumen sq. meters; metres",
			"LOINC",
			"",
			"Clinical",
			"",
			"cd.sr",
			"CD.SR",
			"1",
			1,
			false
		],
		[
			false,
			"meter per second",
			"m/s",
			"M/S",
			"length",
			1,
			[
				1,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"m/s",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"meter/second; m per sec; meters per second; metres; velocity; speed",
			"LOINC",
			"Vel",
			"Clinical",
			"unit of velocity",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"meter per square second",
			"m/s2",
			"M/S2",
			"length",
			1,
			[
				1,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"m/(s<sup>2</sup>)",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"m/s^2; m/sq. sec; m per s2; per s^2; meters per square second; second squared; sq second; metres; acceleration",
			"LOINC",
			"Accel",
			"Clinical",
			"unit of acceleration",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milli international unit per liter",
			"m[IU]/L",
			"M[IU]/L",
			"arbitrary",
			1,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(mi.U.)/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"mIU/L; m IU/L; mIU per liter; units; litre",
			"LOINC",
			"ACnc",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"milli  international unit per milliliter",
			"m[IU]/mL",
			"M[IU]/ML",
			"arbitrary",
			1000.0000000000001,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(mi.U.)/mL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"mIU/mL; m IU/mL; mIU per mL; milli international units per milliliter; millilitre",
			"LOINC",
			"ACnc",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"square meter",
			"m2",
			"M2",
			"length",
			1,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"m<sup>2</sup>",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"m^2; sq m; square meters; meters squared; metres",
			"LOINC",
			"Area",
			"Clinical",
			"unit often used to represent body surface area",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"square meter per second",
			"m2/s",
			"M2/S",
			"length",
			1,
			[
				2,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(m<sup>2</sup>)/s",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"m^2/sec; m2 per sec; m^2 per sec; sq m/sec; meters squared/seconds; sq m per sec; meters squared; metres",
			"LOINC",
			"ArRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"cubic meter per second",
			"m3/s",
			"M3/S",
			"length",
			1,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(m<sup>3</sup>)/s",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"m^3/sec; m3 per sec; m^3 per sec; cu m/sec; cubic meters per seconds; meters cubed; metres",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milliampere",
			"mA",
			"MA",
			"electric current",
			0.001,
			[
				0,
				-1,
				0,
				0,
				0,
				1,
				0
			],
			"mA",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mamp; milliamperes",
			"LOINC",
			"ElpotRat",
			"Clinical",
			"unit of electric current",
			"C/s",
			"C/S",
			"1",
			1,
			false
		],
		[
			false,
			"millibar",
			"mbar",
			"MBAR",
			"pressure",
			100000,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"mbar",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"millibars",
			"LOINC",
			"Pres",
			"Clinical",
			"unit of pressure",
			"Pa",
			"PAL",
			"1e5",
			100000,
			false
		],
		[
			false,
			"millibar second per liter",
			"mbar.s/L",
			"(MBAR.S)/L",
			"pressure",
			100000000,
			[
				-4,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"(mbar.s)/L",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mbar*s/L; mbar.s per L; mbar*s per L; millibar seconds per liter; millibar second per litre",
			"LOINC",
			"",
			"Clinical",
			"unit to measure expiratory resistance",
			"Pa",
			"PAL",
			"1e5",
			100000,
			false
		],
		[
			false,
			"millibar per liter per second",
			"mbar/L/s",
			"(MBAR/L)/S",
			"pressure",
			100000000,
			[
				-4,
				-3,
				1,
				0,
				0,
				0,
				0
			],
			"(mbar/L)/s",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mbar/(L.s); mbar/L/sec; mbar/liter/second; mbar per L per sec; mbar per liter per second; millibars per liters per seconds; litres",
			"LOINC",
			"PresCncRat",
			"Clinical",
			"unit to measure expiratory resistance",
			"Pa",
			"PAL",
			"1e5",
			100000,
			false
		],
		[
			false,
			"milliequivalent",
			"meq",
			"MEQ",
			"amount of substance",
			602213670000000000000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"meq",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"milliequivalents; meqs",
			"LOINC",
			"Sub",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per 2 hour",
			"meq/(2.h)",
			"MEQ/(2.HR)",
			"amount of substance",
			83640787500000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"meq/h",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"meq/2hrs; meq/2 hrs; meq per 2 hrs; milliequivalents per 2 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per 24 hour",
			"meq/(24.h)",
			"MEQ/(24.HR)",
			"amount of substance",
			6970065625000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"meq/h",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"meq/24hrs; meq/24 hrs; meq per 24 hrs; milliequivalents per 24 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per 8 hour",
			"meq/(8.h)",
			"MEQ/(8.HR)",
			"amount of substance",
			20910196875000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"meq/h",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"meq/8hrs; meq/8 hrs; meq per 8 hrs; milliequivalents per 8 hours; shift",
			"LOINC",
			"SRat",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per day",
			"meq/d",
			"MEQ/D",
			"amount of substance",
			6970065625000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"meq/d",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"meq/dy; meq per day; milliquivalents per days; meq/24hrs; meq/24 hrs; meq per 24 hrs; milliequivalents per 24 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per deciliter",
			"meq/dL",
			"MEQ/DL",
			"amount of substance",
			6.022136699999999e+24,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"meq/dL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"meq per dL; milliequivalents per deciliter; decilitre",
			"LOINC",
			"SCnc",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per gram",
			"meq/g",
			"MEQ/G",
			"amount of substance",
			602213670000000000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"meq/g",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mgq/gm; meq per gm; milliequivalents per gram",
			"LOINC",
			"MCnt",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per hour",
			"meq/h",
			"MEQ/HR",
			"amount of substance",
			167281575000000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"meq/h",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"meq/hrs; meq per hrs; milliequivalents per hour",
			"LOINC",
			"SRat",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per kilogram",
			"meq/kg",
			"MEQ/KG",
			"amount of substance",
			602213670000000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"meq/kg",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"meq per kg; milliequivalents per kilogram",
			"LOINC",
			"SCnt",
			"Clinical",
			"equivalence equals moles per valence; used to measure dose per patient body mass",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per kilogram per hour",
			"meq/kg/h",
			"(MEQ/KG)/HR",
			"amount of substance",
			167281575000000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(meq/kg)/h",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"meq/(kg.h); meq/kg/hr; meq per kg per hr; milliequivalents per kilograms per hour",
			"LOINC",
			"SCntRat",
			"Clinical",
			"equivalence equals moles per valence; unit used to measure dose rate per patient body mass",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per liter",
			"meq/L",
			"MEQ/L",
			"amount of substance",
			6.0221367e+23,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"meq/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"milliequivalents per liter; litre; meq per l; acidity",
			"LOINC",
			"SCnc",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per square meter",
			"meq/m2",
			"MEQ/M2",
			"amount of substance",
			602213670000000000000,
			[
				-2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"meq/(m<sup>2</sup>)",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"meq/m^2; meq/sq. m; milliequivalents per square meter; meter squared; metre",
			"LOINC",
			"ArSub",
			"Clinical",
			"equivalence equals moles per valence; note that the use of m2 in clinical units ofter refers to body surface area",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per minute",
			"meq/min",
			"MEQ/MIN",
			"amount of substance",
			10036894500000000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"meq/min",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"meq per min; milliequivalents per minute",
			"LOINC",
			"SRat",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliequivalent per milliliter",
			"meq/mL",
			"MEQ/ML",
			"amount of substance",
			6.0221367e+26,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"meq/mL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"meq per mL; milliequivalents per milliliter; millilitre",
			"LOINC",
			"SCnc",
			"Clinical",
			"equivalence equals moles per valence",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milligram",
			"mg",
			"MG",
			"mass",
			0.001,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"mg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"milligrams",
			"LOINC",
			"Mass",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per 10 hour",
			"mg/(10.h)",
			"MG/(10.HR)",
			"mass",
			2.7777777777777777e-8,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"mg/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/10hrs; mg/10 hrs; mg per 10 hrs; milligrams per 10 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per 12 hour",
			"mg/(12.h)",
			"MG/(12.HR)",
			"mass",
			2.3148148148148148e-8,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"mg/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/12hrs; mg/12 hrs; per 12 hrs; 12hrs; milligrams per 12 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"units used for tests in urine",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per 2 hour",
			"mg/(2.h)",
			"MG/(2.HR)",
			"mass",
			1.3888888888888888e-7,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"mg/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/2hrs; mg/2 hrs; mg per 2 hrs; 2hrs; milligrams per 2 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"units used for tests in urine",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per 24 hour",
			"mg/(24.h)",
			"MG/(24.HR)",
			"mass",
			1.1574074074074074e-8,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"mg/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/24hrs; mg/24 hrs; milligrams per 24 hours; mg/kg/dy; mg per kg per day; milligrams per kilograms per days",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per 6 hour",
			"mg/(6.h)",
			"MG/(6.HR)",
			"mass",
			4.6296296296296295e-8,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"mg/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/6hrs; mg/6 hrs; mg per 6 hrs; 6hrs; milligrams per 6 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per 72 hour",
			"mg/(72.h)",
			"MG/(72.HR)",
			"mass",
			3.858024691358025e-9,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"mg/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/72hrs; mg/72 hrs; 72 hrs; 72hrs; milligrams per 72 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per 8 hour",
			"mg/(8.h)",
			"MG/(8.HR)",
			"mass",
			3.472222222222222e-8,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"mg/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/8hrs; mg/8 hrs; milligrams per 8 hours; shift",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per day",
			"mg/d",
			"MG/D",
			"mass",
			1.1574074074074074e-8,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"mg/d",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/24hrs; mg/24 hrs; milligrams per 24 hours; mg/dy; mg per day; milligrams",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per deciliter",
			"mg/dL",
			"MG/DL",
			"mass",
			10,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"mg/dL",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg per dL; milligrams per deciliter; decilitre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per gram",
			"mg/g",
			"MG/G",
			"mass",
			0.001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mg/g",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg per gm; milligrams per gram",
			"LOINC",
			"MCnt; MRto",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per hour",
			"mg/h",
			"MG/HR",
			"mass",
			2.7777777777777776e-7,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"mg/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/hr; mg per hr; milligrams",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per kilogram",
			"mg/kg",
			"MG/KG",
			"mass",
			0.000001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mg/kg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg per kg; milligrams per kilograms",
			"LOINC",
			"MCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per kilogram per 8 hour",
			"mg/kg/(8.h)",
			"(MG/KG)/(8.HR)",
			"mass",
			3.472222222222222e-11,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(mg/kg)/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/(8.h.kg); mg/kg/8hrs; mg/kg/8 hrs; mg per kg per 8hrs; 8 hrs; milligrams per kilograms per 8 hours; shift",
			"LOINC",
			"RelMRat; MCntRat",
			"Clinical",
			"unit used to measure mass dose rate per patient body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per kilogram per day",
			"mg/kg/d",
			"(MG/KG)/D",
			"mass",
			1.1574074074074074e-11,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(mg/kg)/d",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/(kg.d); mg/(kg.24.h)mg/kg/dy; mg per kg per day; milligrams per kilograms per days; mg/kg/(24.h); mg/kg/24hrs; 24 hrs; 24 hours",
			"LOINC",
			"RelMRat ",
			"Clinical",
			"unit used to measure mass dose rate per patient body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per kilogram per hour",
			"mg/kg/h",
			"(MG/KG)/HR",
			"mass",
			2.7777777777777777e-10,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(mg/kg)/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/(kg.h); mg/kg/hr; mg per kg per hr; milligrams per kilograms per hour",
			"LOINC",
			"RelMRat; MCntRat",
			"Clinical",
			"unit used to measure mass dose rate per patient body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per kilogram per minute",
			"mg/kg/min",
			"(MG/KG)/MIN",
			"mass",
			1.6666666666666667e-8,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(mg/kg)/min",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/(kg.min); mg per kg per min; milligrams per kilograms per minute",
			"LOINC",
			"RelMRat; MCntRat",
			"Clinical",
			"unit used to measure mass dose rate per patient body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per liter",
			"mg/L",
			"MG/L",
			"mass",
			1,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"mg/L",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg per l; milligrams per liter; litre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per square meter",
			"mg/m2",
			"MG/M2",
			"mass",
			0.001,
			[
				-2,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"mg/(m<sup>2</sup>)",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/m^2; mg/sq. m; mg per m2; mg per m^2; mg per sq. milligrams; meter squared; metre",
			"LOINC",
			"ArMass",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per cubic meter",
			"mg/m3",
			"MG/M3",
			"mass",
			0.001,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"mg/(m<sup>3</sup>)",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/m^3; mg/cu. m; mg per m3; milligrams per cubic meter; meter cubed; metre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per milligram",
			"mg/mg",
			"MG/MG",
			"mass",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mg/mg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg per mg; milligrams; milligram/milligram",
			"LOINC",
			"MRto",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per minute",
			"mg/min",
			"MG/MIN",
			"mass",
			0.000016666666666666667,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"mg/min",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg per min; milligrams per minutes; milligram/minute",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per milliliter",
			"mg/mL",
			"MG/ML",
			"mass",
			1000.0000000000001,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"mg/mL",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg per mL; milligrams per milliliters; millilitre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per millimole",
			"mg/mmol",
			"MG/MMOL",
			"mass",
			1.660540186674939e-24,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"mg/mmol",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			-1,
			"mg per mmol; milligrams per millimole; ",
			"LOINC",
			"Ratio",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milligram per week",
			"mg/wk",
			"MG/WK",
			"mass",
			1.6534391534391535e-9,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"mg/wk",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mg/week; mg per wk; milligrams per weeks; milligram/week",
			"LOINC",
			"Mrat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milliliter",
			"mL",
			"ML",
			"volume",
			0.000001,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mL",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"milliliters; millilitres",
			"LOINC",
			"Vol",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per 10 hour",
			"mL/(10.h)",
			"ML/(10.HR)",
			"volume",
			2.7777777777777777e-11,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"ml/10hrs; ml/10 hrs; mL per 10hrs; 10 hrs; milliliters per 10 hours; millilitres",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per 12 hour",
			"mL/(12.h)",
			"ML/(12.HR)",
			"volume",
			2.3148148148148147e-11,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"ml/12hrs; ml/12 hrs; mL per 12hrs; 12 hrs; milliliters per 12 hours; millilitres",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per 2 hour",
			"mL/(2.h)",
			"ML/(2.HR)",
			"volume",
			1.3888888888888888e-10,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"ml/2hrs; ml/2 hrs; mL per 2hrs; 2 hrs; milliliters per 2 hours; millilitres ",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per 24 hour",
			"mL/(24.h)",
			"ML/(24.HR)",
			"volume",
			1.1574074074074074e-11,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"ml/24hrs; ml/24 hrs; mL per 24hrs; 24 hrs; milliliters per 24 hours; millilitres; ml/dy; /day; ml per dy; days; fluid outputs; fluid inputs; flow rate",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per 4 hour",
			"mL/(4.h)",
			"ML/(4.HR)",
			"volume",
			6.944444444444444e-11,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"ml/4hrs; ml/4 hrs; mL per 4hrs; 4 hrs; milliliters per 4 hours; millilitres",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per 5 hour",
			"mL/(5.h)",
			"ML/(5.HR)",
			"volume",
			5.5555555555555553e-11,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"ml/5hrs; ml/5 hrs; mL per 5hrs; 5 hrs; milliliters per 5 hours; millilitres",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per 6 hour",
			"mL/(6.h)",
			"ML/(6.HR)",
			"volume",
			4.6296296296296294e-11,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"ml/6hrs; ml/6 hrs; mL per 6hrs; 6 hrs; milliliters per 6 hours; millilitres",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per 72 hour",
			"mL/(72.h)",
			"ML/(72.HR)",
			"volume",
			3.8580246913580245e-12,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"ml/72hrs; ml/72 hrs; mL per 72hrs; 72 hrs; milliliters per 72 hours; millilitres",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per 8 hour",
			"mL/(8.h)",
			"ML/(8.HR)",
			"volume",
			3.472222222222222e-11,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"ml/8hrs; ml/8 hrs; mL per 8hrs; 8 hrs; milliliters per 8 hours; millilitres; shift",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per 8 hour per kilogram",
			"mL/(8.h)/kg",
			"(ML/(8.HR))/KG",
			"volume",
			3.472222222222222e-14,
			[
				3,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(mL/h)/kg",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL/kg/(8.h); ml/8h/kg; ml/8 h/kg; ml/8hr/kg; ml/8 hr/kgr; mL per 8h per kg; 8 h; 8hr; 8 hr; milliliters per 8 hours per kilogram; millilitres; shift",
			"LOINC",
			"VRatCnt",
			"Clinical",
			"unit used to measure renal excretion volume rate per body mass",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per square inch (international)",
			"mL/[sin_i]",
			"ML/[SIN_I]",
			"volume",
			0.0015500031000061998,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mL",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL/sin; mL/in2; mL/in^2; mL per sin; in2; in^2; sq. in; milliliters per square inch; inch squared",
			"LOINC",
			"ArVol",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per centimeter of water",
			"mL/cm[H2O]",
			"ML/CM[H2O]",
			"volume",
			1.0197162129779282e-11,
			[
				4,
				2,
				-1,
				0,
				0,
				0,
				0
			],
			"mL/(cmHO<sub><r>2</r></sub>)",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"milliliters per centimeter of water; millilitre per centimetre of water; millilitres per centimetre of water; mL/cmH2O; mL/cm H2O; mL per cmH2O; mL per cm H2O",
			"LOINC",
			"Compli",
			"Clinical",
			"unit used to measure dynamic lung compliance",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per day",
			"mL/d",
			"ML/D",
			"volume",
			1.1574074074074074e-11,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/d",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"ml/day; ml per day; milliliters per day; 24 hours; 24hrs; millilitre;",
			"LOINC",
			"VRat",
			"Clinical",
			"usually used to measure fluid output or input; flow rate",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per deciliter",
			"mL/dL",
			"ML/DL",
			"volume",
			0.009999999999999998,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mL/dL",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL per dL; millilitres; decilitre; milliliters",
			"LOINC",
			"VFr; VFrDiff",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per hour",
			"mL/h",
			"ML/HR",
			"volume",
			2.7777777777777777e-10,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL/hr; mL per hr; milliliters per hour; millilitres; fluid intake; fluid output",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per kilogram",
			"mL/kg",
			"ML/KG",
			"volume",
			9.999999999999999e-10,
			[
				3,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"mL/kg",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL per kg; milliliters per kilogram; millilitres",
			"LOINC",
			"VCnt",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per kilogram per 8 hour",
			"mL/kg/(8.h)",
			"(ML/KG)/(8.HR)",
			"volume",
			3.472222222222222e-14,
			[
				3,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(mL/kg)/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL/(8.h.kg); mL/kg/8hrs; mL/kg/8 hrs; mL per kg per 8hrs; 8 hrs; milliliters per kilograms per 8 hours; millilitres; shift",
			"LOINC",
			"VCntRat; RelEngRat",
			"Clinical",
			"unit used to measure renal excretion volume rate per body mass",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per kilogram per day",
			"mL/kg/d",
			"(ML/KG)/D",
			"volume",
			1.1574074074074072e-14,
			[
				3,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(mL/kg)/d",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL/(kg.d); mL/kg/dy; mL per kg per day; milliliters per kilograms per day; mg/kg/24hrs; 24 hrs; per 24 hours millilitres",
			"LOINC",
			"VCntRat; RelEngRat",
			"Clinical",
			"unit used to measure renal excretion volume rate per body mass",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per kilogram per hour",
			"mL/kg/h",
			"(ML/KG)/HR",
			"volume",
			2.7777777777777774e-13,
			[
				3,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(mL/kg)/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL/(kg.h); mL/kg/hr; mL per kg per hr; milliliters per kilograms per hour; millilitres",
			"LOINC",
			"VCntRat; RelEngRat",
			"Clinical",
			"unit used to measure renal excretion volume rate per body mass",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per kilogram per minute",
			"mL/kg/min",
			"(ML/KG)/MIN",
			"volume",
			1.6666666666666664e-11,
			[
				3,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(mL/kg)/min",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL/(kg.min); mL/kg/dy; mL per kg per day; milliliters per kilograms per day; millilitres",
			"LOINC",
			"RelEngRat",
			"Clinical",
			"used for tests that measure activity metabolic rate compared to standard resting metabolic rate ",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per square meter",
			"mL/m2",
			"ML/M2",
			"volume",
			0.000001,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mL/(m<sup>2</sup>)",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL/m^2; mL/sq. meter; mL per m2; m^2; sq. meter; milliliters per square meter; millilitres; meter squared",
			"LOINC",
			"ArVol",
			"Clinical",
			"used for tests that relate to heart work - e.g. ventricular stroke volume; atrial volume per body surface area",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per millibar",
			"mL/mbar",
			"ML/MBAR",
			"volume",
			1e-11,
			[
				4,
				2,
				-1,
				0,
				0,
				0,
				0
			],
			"mL/mbar",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL per mbar; milliliters per millibar; millilitres",
			"LOINC",
			"",
			"Clinical",
			"unit used to measure dynamic lung compliance",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per minute",
			"mL/min",
			"ML/MIN",
			"volume",
			1.6666666666666667e-8,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/min",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL per min; milliliters; millilitres",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per minute per square meter",
			"mL/min/m2",
			"(ML/MIN)/M2",
			"volume",
			1.6666666666666667e-8,
			[
				1,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(mL/min)/(m<sup>2</sup>)",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"ml/min/m^2; ml/min/sq. meter; mL per min per m2; m^2; sq. meter; milliliters per minutes per square meter; millilitres; metre; meter squared",
			"LOINC",
			"ArVRat",
			"Clinical",
			"unit used to measure volume per body surface area; oxygen consumption index",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per millimeter",
			"mL/mm",
			"ML/MM",
			"volume",
			0.001,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mL/mm",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mL per mm; milliliters per millimeter; millilitres; millimetre",
			"LOINC",
			"Lineic Volume",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"milliliter per second",
			"mL/s",
			"ML/S",
			"volume",
			0.000001,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mL/s",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"ml/sec; mL per sec; milliliters per second; millilitres",
			"LOINC",
			"Vel; VelRat; VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"millimeter",
			"mm",
			"MM",
			"length",
			0.001,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mm",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"millimeters; millimetres; height; length; diameter; thickness; axis; curvature; size",
			"LOINC",
			"Len",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"millimeter per hour",
			"mm/h",
			"MM/HR",
			"length",
			2.7777777777777776e-7,
			[
				1,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mm/h",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"mm/hr; mm per hr; millimeters per hour; millimetres",
			"LOINC",
			"Vel",
			"Clinical",
			"unit to measure sedimentation rate",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"millimeter per minute",
			"mm/min",
			"MM/MIN",
			"length",
			0.000016666666666666667,
			[
				1,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mm/min",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"mm per min; millimeters per minute; millimetres",
			"LOINC",
			"Vel",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"millimeter of water",
			"mm[H2O]",
			"MM[H2O]",
			"pressure",
			9806.65,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"mmHO<sub><r>2</r></sub>",
			"clinical",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mmH2O; mm H2O; millimeters of water; millimetres",
			"LOINC",
			"Pres",
			"Clinical",
			"",
			"kPa",
			"KPAL",
			"980665e-5",
			9.80665,
			false
		],
		[
			false,
			"millimeter of mercury",
			"mm[Hg]",
			"MM[HG]",
			"pressure",
			133322,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"mmHg",
			"clinical",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mmHg; mm Hg; millimeters of mercury; millimetres",
			"LOINC",
			"Pres; PPres; Ratio",
			"Clinical",
			"1 mm[Hg] = 1 torr; unit to measure blood pressure",
			"kPa",
			"KPAL",
			"133.3220",
			133.322,
			false
		],
		[
			false,
			"square millimeter",
			"mm2",
			"MM2",
			"length",
			0.000001,
			[
				2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mm<sup>2</sup>",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"mm^2; sq. mm.; sq. millimeters; millimeters squared; millimetres",
			"LOINC",
			"Area",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"millimole",
			"mmol",
			"MMOL",
			"amount of substance",
			602213670000000000000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mmol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"millimoles",
			"LOINC",
			"Sub",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per 12 hour",
			"mmol/(12.h)",
			"MMOL/(12.HR)",
			"amount of substance",
			13940131250000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/12hrs; mmol/12 hrs; mmol per 12 hrs; 12hrs; millimoles per 12 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"unit for tests related to urine",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per 2 hour",
			"mmol/(2.h)",
			"MMOL/(2.HR)",
			"amount of substance",
			83640787500000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/2hrs; mmol/2 hrs; mmol per 2 hrs; 2hrs; millimoles per 2 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"unit for tests related to urine",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per 24 hour",
			"mmol/(24.h)",
			"MMOL/(24.HR)",
			"amount of substance",
			6970065625000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/24hrs; mmol/24 hrs; mmol per 24 hrs; 24hrs; millimoles per 24 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per 5 hour",
			"mmol/(5.h)",
			"MMOL/(5.HR)",
			"amount of substance",
			33456315000000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/5hrs; mmol/5 hrs; mmol per 5 hrs; 5hrs; millimoles per 5 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"unit for tests related to doses",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per 6 hour",
			"mmol/(6.h)",
			"MMOL/(6.HR)",
			"amount of substance",
			27880262500000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/6hrs; mmol/6 hrs; mmol per 6 hrs; 6hrs; millimoles per 6 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"unit for tests related to urine",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per 8 hour",
			"mmol/(8.h)",
			"MMOL/(8.HR)",
			"amount of substance",
			20910196875000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/8hrs; mmol/8 hrs; mmol per 8 hrs; 8hrs; millimoles per 8 hours; shift",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per day",
			"mmol/d",
			"MMOL/D",
			"amount of substance",
			6970065625000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/d",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/24hrs; mmol/24 hrs; mmol per 24 hrs; 24hrs; millimoles per 24 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per deciliter",
			"mmol/dL",
			"MMOL/DL",
			"amount of substance",
			6.022136699999999e+24,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/dL",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol per dL; millimoles; decilitre",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per gram",
			"mmol/g",
			"MMOL/G",
			"amount of substance",
			602213670000000000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"mmol/g",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol per gram; millimoles",
			"LOINC",
			"SCnt",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per hour",
			"mmol/h",
			"MMOL/HR",
			"amount of substance",
			167281575000000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/hr; mmol per hr; millimoles per hour",
			"LOINC",
			"SRat",
			"Clinical",
			"unit for tests related to urine",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per kilogram",
			"mmol/kg",
			"MMOL/KG",
			"amount of substance",
			602213670000000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"mmol/kg",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol per kg; millimoles per kilogram",
			"LOINC",
			"SCnt",
			"Clinical",
			"unit for tests related to stool",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per kilogram per 8 hour",
			"mmol/kg/(8.h)",
			"(MMOL/KG)/(8.HR)",
			"amount of substance",
			20910196875000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(mmol/kg)/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/(8.h.kg); mmol/kg/8hrs; mmol/kg/8 hrs; mmol per kg per 8hrs; 8 hrs; millimoles per kilograms per 8 hours; shift",
			"LOINC",
			"CCnt",
			"Clinical",
			"unit used to measure molar dose rate per patient body mass",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per kilogram per day",
			"mmol/kg/d",
			"(MMOL/KG)/D",
			"amount of substance",
			6970065625000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(mmol/kg)/d",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/kg/dy; mmol/kg/day; mmol per kg per dy; millimoles per kilograms per day",
			"LOINC",
			"RelSRat",
			"Clinical",
			"unit used to measure molar dose rate per patient body mass",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per kilogram per hour",
			"mmol/kg/h",
			"(MMOL/KG)/HR",
			"amount of substance",
			167281575000000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(mmol/kg)/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/kg/hr; mmol per kg per hr; millimoles per kilograms per hour",
			"LOINC",
			"CCnt",
			"Clinical",
			"unit used to measure molar dose rate per patient body mass",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per kilogram per minute",
			"mmol/kg/min",
			"(MMOL/KG)/MIN",
			"amount of substance",
			10036894500000000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(mmol/kg)/min",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/(kg.min); mmol/kg/min; mmol per kg per min; millimoles per kilograms per minute",
			"LOINC",
			"CCnt",
			"Clinical",
			"unit used to measure molar dose rate per patient body mass; note that the unit for the enzyme unit U = umol/min. mmol/kg/min = kU/kg; ",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per liter",
			"mmol/L",
			"MMOL/L",
			"amount of substance",
			6.0221367e+23,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/L",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol per L; millimoles per liter; litre",
			"LOINC",
			"SCnc",
			"Clinical",
			"unit for tests related to doses",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per square meter",
			"mmol/m2",
			"MMOL/M2",
			"amount of substance",
			602213670000000000000,
			[
				-2,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/(m<sup>2</sup>)",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/m^2; mmol/sq. meter; mmol per m2; m^2; sq. meter; millimoles; meter squared; metre",
			"LOINC",
			"ArSub",
			"Clinical",
			"unit used to measure molar dose per patient body surface area",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per minute",
			"mmol/min",
			"MMOL/MIN",
			"amount of substance",
			10036894500000000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/min",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol per min; millimoles per minute",
			"LOINC",
			"Srat; CAct",
			"Clinical",
			"unit for the enzyme unit U = umol/min. mmol/min = kU",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per millimole",
			"mmol/mmol",
			"MMOL/MMOL",
			"amount of substance",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/mmol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mmol per mmol; millimoles per millimole",
			"LOINC",
			"SRto",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per mole",
			"mmol/mol",
			"MMOL/MOL",
			"amount of substance",
			0.001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mmol/mol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mmol per mol; millimoles per mole",
			"LOINC",
			"SRto",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"millimole per second per liter",
			"mmol/s/L",
			"(MMOL/S)/L",
			"amount of substance",
			6.0221367e+23,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(mmol/s)/L",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mmol/sec/L; mmol per s per L; per sec; millimoles per seconds per liter; litre",
			"LOINC",
			"CCnc ",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"mole per kilogram",
			"mol/kg",
			"MOL/KG",
			"amount of substance",
			602213670000000000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"mol/kg",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mol per kg; moles; mols",
			"LOINC",
			"SCnt",
			"Clinical",
			"unit for tests related to stool",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"mole per kilogram per second",
			"mol/kg/s",
			"(MOL/KG)/S",
			"amount of substance",
			602213670000000000000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(mol/kg)/s",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mol/kg/sec; mol per kg per sec; moles per kilograms per second; mols",
			"LOINC",
			"CCnt",
			"Clinical",
			"unit of catalytic activity (mol/s) per mass (kg)",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"mole per liter",
			"mol/L",
			"MOL/L",
			"amount of substance",
			6.0221366999999994e+26,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mol/L",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mol per L; moles per liter; litre; moles; mols",
			"LOINC",
			"SCnc",
			"Clinical",
			"unit often used in tests measuring oxygen content",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"mole per cubic meter",
			"mol/m3",
			"MOL/M3",
			"amount of substance",
			6.0221367e+23,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mol/(m<sup>3</sup>)",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mol/m^3; mol/cu. m; mol per m3; m^3; cu. meter; mols; moles; meters cubed; metre; mole per kiloliter; kilolitre; mol/kL",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"mole per milliliter",
			"mol/mL",
			"MOL/ML",
			"amount of substance",
			6.0221367e+29,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mol/mL",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mol per mL; moles; millilitre; mols",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"mole per mole",
			"mol/mol",
			"MOL/MOL",
			"amount of substance",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mol/mol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mol per mol; moles per mol; mols",
			"LOINC",
			"SRto",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"mole per second",
			"mol/s",
			"MOL/S",
			"amount of substance",
			6.0221367e+23,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mol/s",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mol per sec; moles per second; mols",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"milliosmole",
			"mosm",
			"MOSM",
			"amount of substance (dissolved particles)",
			602213670000000000000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mosm",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"milliosmoles",
			"LOINC",
			"Osmol",
			"Clinical",
			"equal to 1/1000 of an osmole",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliosmole per kilogram",
			"mosm/kg",
			"MOSM/KG",
			"amount of substance (dissolved particles)",
			602213670000000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"mosm/kg",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mosm per kg; milliosmoles per kilogram",
			"LOINC",
			"Osmol",
			"Clinical",
			"",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"milliosmole per liter",
			"mosm/L",
			"MOSM/L",
			"amount of substance (dissolved particles)",
			6.0221367e+23,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mosm/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mosm per liter; litre; milliosmoles",
			"LOINC",
			"Osmol",
			"Clinical",
			"",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"millipascal",
			"mPa",
			"MPAL",
			"pressure",
			1,
			[
				-1,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"mPa",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"millipascals",
			"LOINC",
			"Pres",
			"Clinical",
			"unit of pressure",
			"N/m2",
			"N/M2",
			"1",
			1,
			false
		],
		[
			false,
			"millipascal second",
			"mPa.s",
			"MPAL.S",
			"pressure",
			1,
			[
				-1,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"mPa.s",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"mPa*s; millipoise; mP; dynamic viscosity",
			"LOINC",
			"Visc",
			"Clinical",
			"base units for millipoise, a measurement of dynamic viscosity",
			"N/m2",
			"N/M2",
			"1",
			1,
			false
		],
		[
			false,
			"megasecond",
			"Ms",
			"MAS",
			"time",
			1000000,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"Ms",
			null,
			false,
			"T",
			null,
			1,
			false,
			false,
			0,
			"megaseconds",
			"LOINC",
			"Time",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"millisecond",
			"ms",
			"MS",
			"time",
			0.001,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"ms",
			null,
			false,
			"T",
			null,
			1,
			false,
			false,
			0,
			"milliseconds; duration",
			"LOINC",
			"Time",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"milli enzyme unit per gram",
			"mU/g",
			"MU/G",
			"catalytic activity",
			10036894500000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"mU/g",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mU per gm; milli enzyme units per gram; enzyme activity; enzymatic activity per mass",
			"LOINC",
			"CCnt",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 mU = 1 nmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"milli enzyme unit per liter",
			"mU/L",
			"MU/L",
			"catalytic activity",
			10036894500000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mU/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mU per liter; litre; milli enzyme units enzymatic activity per volume; enzyme activity",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 mU = 1 nmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"milli enzyme unit per milligram",
			"mU/mg",
			"MU/MG",
			"catalytic activity",
			10036894500000000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"mU/mg",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mU per mg; milli enzyme units per milligram",
			"LOINC",
			"CCnt",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 mU = 1 nmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"milli enzyme unit per milliliter",
			"mU/mL",
			"MU/ML",
			"catalytic activity",
			10036894500000000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mU/mL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mU per mL; milli enzyme units per milliliter; millilitre; enzymatic activity per volume; enzyme activity",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 mU = 1 nmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"milli enzyme unit per milliliter per minute",
			"mU/mL/min",
			"(MU/ML)/MIN",
			"catalytic activity",
			167281575000000000,
			[
				-3,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"(mU/mL)/min",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"mU per mL per min; mU per milliliters per minute; millilitres; milli enzyme units; enzymatic activity; enzyme activity",
			"LOINC",
			"CCncRat",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 mU = 1 nmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"millivolt",
			"mV",
			"MV",
			"electric potential",
			1,
			[
				2,
				-2,
				1,
				0,
				0,
				-1,
				0
			],
			"mV",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"millivolts",
			"LOINC",
			"Elpot",
			"Clinical",
			"unit of electric potential (voltage)",
			"J/C",
			"J/C",
			"1",
			1,
			false
		],
		[
			false,
			"Newton centimeter",
			"N.cm",
			"N.CM",
			"force",
			10,
			[
				2,
				-2,
				1,
				0,
				0,
				0,
				0
			],
			"N.cm",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"N*cm; Ncm; N cm; Newton*centimeters; Newton* centimetres; torque; work",
			"LOINC",
			"",
			"Clinical",
			"as a measurement of work, N.cm = 1/100 Joules;\nnote that N.m is the standard unit of measurement for torque (although dimensionally equivalent to Joule), and N.cm can also be thought of as a torqe unit",
			"kg.m/s2",
			"KG.M/S2",
			"1",
			1,
			false
		],
		[
			false,
			"Newton second",
			"N.s",
			"N.S",
			"force",
			1000,
			[
				1,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"N.s",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"Newton*seconds; N*s; N s; Ns; impulse; imp",
			"LOINC",
			"",
			"Clinical",
			"standard unit of impulse",
			"kg.m/s2",
			"KG.M/S2",
			"1",
			1,
			false
		],
		[
			false,
			"nanogram",
			"ng",
			"NG",
			"mass",
			1e-9,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"ng",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"nanograms",
			"LOINC",
			"Mass",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per 24 hour",
			"ng/(24.h)",
			"NG/(24.HR)",
			"mass",
			1.1574074074074075e-14,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"ng/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/24hrs; ng/24 hrs; nanograms per 24 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per 8 hour",
			"ng/(8.h)",
			"NG/(8.HR)",
			"mass",
			3.4722222222222224e-14,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"ng/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/8hrs; ng/8 hrs; nanograms per 8 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per million",
			"ng/10*6",
			"NG/(10*6)",
			"mass",
			1e-15,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"ng/(10<sup>6</sup>)",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/10^6; ng per 10*6; 10^6; nanograms",
			"LOINC",
			"MNum",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per day",
			"ng/d",
			"NG/D",
			"mass",
			1.1574074074074075e-14,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"ng/d",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/dy; ng per day; nanograms ",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per deciliter",
			"ng/dL",
			"NG/DL",
			"mass",
			0.00001,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"ng/dL",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng per dL; nanograms per deciliter; decilitre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per gram",
			"ng/g",
			"NG/G",
			"mass",
			1e-9,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"ng/g",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/gm; ng per gm; nanograms per gram",
			"LOINC",
			"MCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per hour",
			"ng/h",
			"NG/HR",
			"mass",
			2.777777777777778e-13,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"ng/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/hr; ng per hr; nanograms per hour",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per kilogram",
			"ng/kg",
			"NG/KG",
			"mass",
			1e-12,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"ng/kg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng per kg; nanograms per kilogram",
			"LOINC",
			"MCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per kilogram per 8 hour",
			"ng/kg/(8.h)",
			"(NG/KG)/(8.HR)",
			"mass",
			3.472222222222222e-17,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(ng/kg)/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/(8.h.kg); ng/kg/8hrs; ng/kg/8 hrs; ng per kg per 8hrs; 8 hrs; nanograms per kilograms per 8 hours; shift",
			"LOINC",
			"MRtoRat ",
			"Clinical",
			"unit used to measure mass dose rate per patient body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per kilogram per hour",
			"ng/kg/h",
			"(NG/KG)/HR",
			"mass",
			2.7777777777777775e-16,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(ng/kg)/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/(kg.h); ng/kg/hr; ng per kg per hr; nanograms per kilograms per hour",
			"LOINC",
			"MRtoRat ",
			"Clinical",
			"unit used to measure mass dose rate per patient body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per kilogram per minute",
			"ng/kg/min",
			"(NG/KG)/MIN",
			"mass",
			1.6666666666666667e-14,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(ng/kg)/min",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/(kg.min); ng per kg per min; nanograms per kilograms per minute",
			"LOINC",
			"MRtoRat ",
			"Clinical",
			"unit used to measure mass dose rate per patient body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per liter",
			"ng/L",
			"NG/L",
			"mass",
			0.000001,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"ng/L",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng per L; nanograms per liter; litre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per square meter",
			"ng/m2",
			"NG/M2",
			"mass",
			1e-9,
			[
				-2,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"ng/(m<sup>2</sup>)",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/m^2; ng/sq. m; ng per m2; m^2; sq. meter; nanograms; meter squared; metre",
			"LOINC",
			"ArMass",
			"Clinical",
			"unit used to measure mass dose per patient body surface area",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per milligram",
			"ng/mg",
			"NG/MG",
			"mass",
			0.000001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"ng/mg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng per mg; nanograms",
			"LOINC",
			"MCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per milligram per hour",
			"ng/mg/h",
			"(NG/MG)/HR",
			"mass",
			2.7777777777777777e-10,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(ng/mg)/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/mg/hr; ng per mg per hr; nanograms per milligrams per hour",
			"LOINC",
			"MRtoRat ",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per minute",
			"ng/min",
			"NG/MIN",
			"mass",
			1.6666666666666667e-11,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"ng/min",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng per min; nanograms",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per millliiter",
			"ng/mL",
			"NG/ML",
			"mass",
			0.001,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"ng/mL",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng per mL; nanograms; millilitre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per milliliter per hour",
			"ng/mL/h",
			"(NG/ML)/HR",
			"mass",
			2.7777777777777776e-7,
			[
				-3,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"(ng/mL)/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/mL/hr; ng per mL per mL; nanograms per milliliter per hour; nanogram per millilitre per hour; nanograms per millilitre per hour; enzymatic activity per volume; enzyme activity per milliliters",
			"LOINC",
			"CCnc",
			"Clinical",
			"tests that measure enzymatic activity",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per second",
			"ng/s",
			"NG/S",
			"mass",
			1e-9,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"ng/s",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ng/sec; ng per sec; nanograms per second",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanogram per enzyme unit",
			"ng/U",
			"NG/U",
			"mass",
			9.963241120049634e-26,
			[
				0,
				1,
				1,
				0,
				0,
				0,
				0
			],
			"ng/U",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			-1,
			"ng per U; nanograms per enzyme unit",
			"LOINC",
			"CMass",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanokatal",
			"nkat",
			"NKAT",
			"catalytic activity",
			602213670000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"nkat",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nanokatals",
			"LOINC",
			"CAct",
			"Clinical",
			"kat is a unit of catalytic activity with base units = mol/s. Rarely used because its units are too large to practically express catalytic activity. See enzyme unit [U] which is the standard unit for catalytic activity.",
			"mol/s",
			"MOL/S",
			"1",
			1,
			false
		],
		[
			false,
			"nanoliter",
			"nL",
			"NL",
			"volume",
			1.0000000000000002e-12,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"nL",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"nanoliters; nanolitres",
			"LOINC",
			"Vol",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"nanometer",
			"nm",
			"NM",
			"length",
			1e-9,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"nm",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"nanometers; nanometres",
			"LOINC",
			"Len",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanometer per second per liter",
			"nm/s/L",
			"(NM/S)/L",
			"length",
			0.000001,
			[
				-2,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(nm/s)/L",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"nm/sec/liter; nm/sec/litre; nm per s per l; nm per sec per l; nanometers per second per liter; nanometre per second per litre; nanometres per second per litre",
			"LOINC",
			"VelCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanomole",
			"nmol",
			"NMOL",
			"amount of substance",
			602213670000000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"nmol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nanomoles",
			"LOINC",
			"Sub",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per 24 hour",
			"nmol/(24.h)",
			"NMOL/(24.HR)",
			"amount of substance",
			6970065625,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"nmol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol/24hr; nmol/24 hr; nanomoles per 24 hours; nmol/day; nanomoles per day; nmol per day; nanomole/day; nanomol/day",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per day",
			"nmol/d",
			"NMOL/D",
			"amount of substance",
			6970065625,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"nmol/d",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol/day; nanomoles per day; nmol per day; nanomole/day; nanomol/day; nmol/24hr; nmol/24 hr; nanomoles per 24 hours; ",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per deciliter",
			"nmol/dL",
			"NMOL/DL",
			"amount of substance",
			6022136700000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"nmol/dL",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol per dL; nanomoles per deciliter; nanomole per decilitre; nanomoles per decilitre; nanomole/deciliter; nanomole/decilitre; nanomol/deciliter; nanomol/decilitre",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per gram",
			"nmol/g",
			"NMOL/G",
			"amount of substance",
			602213670000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"nmol/g",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol per gram; nanomoles per gram; nanomole/gram",
			"LOINC",
			"SCnt",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per hour per liter",
			"nmol/h/L",
			"(NMOL/HR)/L",
			"amount of substance",
			167281575000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(nmol/h)/L",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol/hrs/L; nmol per hrs per L; nanomoles per hours per liter; litre; enzymatic activity per volume; enzyme activities",
			"LOINC",
			"CCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per liter",
			"nmol/L",
			"NMOL/L",
			"amount of substance",
			602213670000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"nmol/L",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol per L; nanomoles per liter; litre",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per milligram",
			"nmol/mg",
			"NMOL/MG",
			"amount of substance",
			602213670000000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"nmol/mg",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol per mg; nanomoles per milligram",
			"LOINC",
			"SCnt",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per milligram per hour",
			"nmol/mg/h",
			"(NMOL/MG)/HR",
			"amount of substance",
			167281575000000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(nmol/mg)/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol/mg/hr; nmol per mg per hr; nanomoles per milligrams per hour",
			"LOINC",
			"SCntRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per milligram of protein",
			"nmol/mg{prot}",
			"NMOL/MG",
			"amount of substance",
			602213670000000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"nmol/mg",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nanomoles; nmol/mg prot; nmol per mg prot",
			"LOINC",
			"Ratio; CCnt",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per minute",
			"nmol/min",
			"NMOL/MIN",
			"amount of substance",
			10036894500000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"nmol/min",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol per min; nanomoles per minute; milli enzyme units; enzyme activity per volume; enzymatic activity",
			"LOINC",
			"CCnc",
			"Clinical",
			"unit for the enzyme unit U = umol/min. nmol/min = mU (milli enzyme unit)",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per minute per milliliter",
			"nmol/min/mL",
			"(NMOL/MIN)/ML",
			"amount of substance",
			10036894500000000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(nmol/min)/mL",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol per min per mL; nanomoles per minutes per milliliter; millilitre; milli enzyme units per volume; enzyme activity; enzymatic activity",
			"LOINC",
			"CCnc",
			"Clinical",
			"unit for the enzyme unit U = umol/min. nmol/mL/min = mU/mL",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per milliliter",
			"nmol/mL",
			"NMOL/ML",
			"amount of substance",
			602213670000000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"nmol/mL",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol per mL; nanomoles per milliliter; millilitre",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per milliliter per hour",
			"nmol/mL/h",
			"(NMOL/ML)/HR",
			"amount of substance",
			167281575000000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(nmol/mL)/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol/mL/hr; nmol per mL per hr; nanomoles per milliliters per hour; millilitres; milli enzyme units per volume; enzyme activity; enzymatic activity",
			"LOINC",
			"CCnc",
			"Clinical",
			"unit for the enzyme unit U = umol/min.",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per milliliter per minute",
			"nmol/mL/min",
			"(NMOL/ML)/MIN",
			"amount of substance",
			10036894500000000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(nmol/mL)/min",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol per mL per min; nanomoles per milliliters per min; millilitres; milli enzyme units per volume; enzyme activity; enzymatic activity",
			"LOINC",
			"CCnc",
			"Clinical",
			"unit for the enzyme unit U = umol/min. nmol/mL/min = mU/mL",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per millimole",
			"nmol/mmol",
			"NMOL/MMOL",
			"amount of substance",
			0.000001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"nmol/mmol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"nmol per mmol; nanomoles per millimole",
			"LOINC",
			"SRto",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per millimole of creatinine",
			"nmol/mmol{creat}",
			"NMOL/MMOL",
			"amount of substance",
			0.000001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"nmol/mmol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"nanomoles",
			"LOINC",
			"SRto",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per mole",
			"nmol/mol",
			"NMOL/MOL",
			"amount of substance",
			1e-9,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"nmol/mol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"nmol per mole; nanomoles",
			"LOINC",
			"SRto",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per nanomole",
			"nmol/nmol",
			"NMOL/NMOL",
			"amount of substance",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"nmol/nmol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"nmol per nmol; nanomoles",
			"LOINC",
			"SRto",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per second",
			"nmol/s",
			"NMOL/S",
			"amount of substance",
			602213670000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"nmol/s",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol/sec; nmol per sec; nanomoles per sercond; milli enzyme units; enzyme activity; enzymatic activity",
			"LOINC",
			"CCnc",
			"Clinical",
			"unit for the enzyme unit U = umol/min.",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanomole per second per liter",
			"nmol/s/L",
			"(NMOL/S)/L",
			"amount of substance",
			602213670000000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(nmol/s)/L",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nmol/sec/L; nmol per s per L; nmol per sec per L; nanomoles per seconds per liter; litre; milli enzyme units per volume; enzyme activity; enzymatic activity",
			"LOINC",
			"CCnc",
			"Clinical",
			"unit for the enzyme unit U = umol/min.",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"nanosecond",
			"ns",
			"NS",
			"time",
			1e-9,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"ns",
			null,
			false,
			"T",
			null,
			1,
			false,
			false,
			0,
			"nanoseconds",
			"LOINC",
			"Time",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"nanoenzyme unit per milliliter",
			"nU/mL",
			"NU/ML",
			"catalytic activity",
			10036894500000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"nU/mL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"nU per mL; nanoenzyme units per milliliter; millilitre; enzymatic activity per volume; enzyme activity",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 fU = pmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"Ohm meter",
			"Ohm.m",
			"OHM.M",
			"electric resistance",
			1000,
			[
				3,
				-1,
				1,
				0,
				0,
				-2,
				0
			],
			".m",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"electric resistivity; meters; metres",
			"LOINC",
			"",
			"Clinical",
			"unit of electric resistivity",
			"V/A",
			"V/A",
			"1",
			1,
			false
		],
		[
			false,
			"osmole per kilogram",
			"osm/kg",
			"OSM/KG",
			"amount of substance (dissolved particles)",
			602213670000000000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"osm/kg",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"osm per kg; osmoles per kilogram; osmols",
			"LOINC",
			"Osmol",
			"Clinical",
			"",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"osmole per liter",
			"osm/L",
			"OSM/L",
			"amount of substance (dissolved particles)",
			6.0221366999999994e+26,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"osm/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"osm per L; osmoles per liter; litre; osmols",
			"LOINC",
			"Osmol",
			"Clinical",
			"",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"picoampere",
			"pA",
			"PA",
			"electric current",
			1e-12,
			[
				0,
				-1,
				0,
				0,
				0,
				1,
				0
			],
			"pA",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"picoamperes",
			"LOINC",
			"",
			"Clinical",
			"equal to 10^-12 amperes",
			"C/s",
			"C/S",
			"1",
			1,
			false
		],
		[
			false,
			"picogram",
			"pg",
			"PG",
			"mass",
			1e-12,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"pg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"picograms",
			"LOINC",
			"Mass; EntMass",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"picogram per deciliter",
			"pg/dL",
			"PG/DL",
			"mass",
			9.999999999999999e-9,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"pg/dL",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"pg per dL; picograms; decilitre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"picogram per liter",
			"pg/L",
			"PG/L",
			"mass",
			1e-9,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"pg/L",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"pg per L; picograms; litre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"picogram per milligram",
			"pg/mg",
			"PG/MG",
			"mass",
			1e-9,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"pg/mg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"pg per mg; picograms",
			"LOINC",
			"MCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"picogram per milliliter",
			"pg/mL",
			"PG/ML",
			"mass",
			0.000001,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"pg/mL",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"pg per mL; picograms per milliliter; millilitre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"picogram per millimeter",
			"pg/mm",
			"PG/MM",
			"mass",
			1e-9,
			[
				-1,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"pg/mm",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"pg per mm; picogram/millimeter; picogram/millimetre; picograms per millimeter; millimetre",
			"LOINC",
			"Lineic Mass",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"picokatal",
			"pkat",
			"PKAT",
			"catalytic activity",
			602213670000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"pkat",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"pkats; picokatals",
			"LOINC",
			"CAct",
			"Clinical",
			"kat is a unit of catalytic activity with base units = mol/s. Rarely used because its units are too large to practically express catalytic activity. See enzyme unit [U] which is the standard unit for catalytic activity.",
			"mol/s",
			"MOL/S",
			"1",
			1,
			false
		],
		[
			false,
			"picoliter",
			"pL",
			"PL",
			"volume",
			1e-15,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"pL",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"picoliters; picolitres",
			"LOINC",
			"Vol",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"picometer",
			"pm",
			"PM",
			"length",
			1e-12,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"pm",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"picometers; picometres",
			"LOINC",
			"Len",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"picomole",
			"pmol",
			"PMOL",
			"amount of substance",
			602213670000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"pmol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"picomoles; pmols",
			"LOINC",
			"Sub",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"picomole per 24 hour",
			"pmol/(24.h)",
			"PMOL/(24.HR)",
			"amount of substance",
			6970065.625,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"pmol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"pmol/24hrs; pmol/24 hrs; pmol per 24 hrs; 24hrs; days; dy; picomoles per 24 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"picomole per day",
			"pmol/d",
			"PMOL/D",
			"amount of substance",
			6970065.625,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"pmol/d",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"pmol/dy; pmol per day; 24 hours; 24hrs; 24 hrs; picomoles",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"picomole per deciliter",
			"pmol/dL",
			"PMOL/DL",
			"amount of substance",
			6022136700000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"pmol/dL",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"pmol per dL; picomoles per deciliter; decilitre",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"picomole per gram",
			"pmol/g",
			"PMOL/G",
			"amount of substance",
			602213670000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"pmol/g",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"pmol per gm; picomoles per gram; picomole/gram",
			"LOINC",
			"SCnt",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"picomole per hour per milliliter ",
			"pmol/h/mL",
			"(PMOL/HR)/ML",
			"amount of substance",
			167281575000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(pmol/h)/mL",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"pmol/hrs/mL; pmol per hrs per mL; picomoles per hour per milliliter; millilitre; micro enzyme units per volume; enzymatic activity; enzyme activity",
			"LOINC",
			"CCnc",
			"Clinical",
			"unit for the enzyme unit U = umol/min. ",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"picomole per liter",
			"pmol/L",
			"PMOL/L",
			"amount of substance",
			602213670000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"pmol/L",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"picomole/liter; pmol per L; picomoles; litre",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"picomole per minute",
			"pmol/min",
			"PMOL/MIN",
			"amount of substance",
			10036894500,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"pmol/min",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"picomole/minute; pmol per min; picomoles per minute; micro enzyme units; enzymatic activity; enzyme activity",
			"LOINC",
			"CCnc",
			"Clinical",
			"unit for the enzyme unit U = umol/min. pmol/min = uU (micro enzyme unit)",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"picomole per milliliter",
			"pmol/mL",
			"PMOL/ML",
			"amount of substance",
			602213670000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"pmol/mL",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"picomole/milliliter; picomole/millilitre; pmol per mL; picomoles; millilitre; picomols; pmols",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"picomole per micromole",
			"pmol/umol",
			"PMOL/UMOL",
			"amount of substance",
			0.000001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"pmol/mol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"pmol/mcgmol; picomole/micromole; pmol per umol; pmol per mcgmol; picomoles ",
			"LOINC",
			"SRto",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"picosecond",
			"ps",
			"PS",
			"time",
			1e-12,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"ps",
			null,
			false,
			"T",
			null,
			1,
			false,
			false,
			0,
			"picoseconds; psec",
			"LOINC",
			"Time",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"picotesla",
			"pT",
			"PT",
			"magnetic flux density",
			1e-9,
			[
				0,
				-1,
				1,
				0,
				0,
				-1,
				0
			],
			"pT",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"picoteslas",
			"LOINC",
			"",
			"Clinical",
			"SI unit of magnetic field strength for magnetic field B",
			"Wb/m2",
			"WB/M2",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per 12 hour",
			"U/(12.h)",
			"U/(12.HR)",
			"catalytic activity",
			232335520833.33334,
			[
				0,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"U/h",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"U/12hrs; U/ 12hrs; U per 12 hrs; 12hrs; enzyme units per 12 hours; enzyme activity; enzymatic activity per time; umol per min per 12 hours; micromoles per minute per 12 hours; umol/min/12hr",
			"LOINC",
			"CRat",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per 2 hour",
			"U/(2.h)",
			"U/(2.HR)",
			"catalytic activity",
			1394013125000,
			[
				0,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"U/h",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"U/2hrs; U/ 2hrs; U per 2 hrs; 2hrs; enzyme units per 2 hours; enzyme activity; enzymatic activity per time; umol per minute per 2 hours; micromoles per minute; umol/min/2hr; umol per min per 2hr",
			"LOINC",
			"CRat",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per 24 hour",
			"U/(24.h)",
			"U/(24.HR)",
			"catalytic activity",
			116167760416.66667,
			[
				0,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"U/h",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"U/24hrs; U/ 24hrs; U per 24 hrs; 24hrs; enzyme units per 24 hours; enzyme activity; enzymatic activity per time; micromoles per minute per 24 hours; umol/min/24hr; umol per min per 24hr",
			"LOINC",
			"CRat",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per 10",
			"U/10",
			"U/10",
			"catalytic activity",
			1003689450000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"U",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"enzyme unit/10; U per 10; enzyme units per 10; enzymatic activity; enzyme activity; micromoles per minute; umol/min/10",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per 10 billion",
			"U/10*10",
			"U/(10*10)",
			"catalytic activity",
			1003689.45,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"U/(10<sup>10</sup>)",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"U per 10*10; enzyme units per 10*10; U per 10 billion; enzyme units; enzymatic activity; micromoles per minute per 10 billion; umol/min/10*10",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per trillion",
			"U/10*12",
			"U/(10*12)",
			"catalytic activity",
			10036.8945,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"U/(10<sup>12</sup>)",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"enzyme unit/10*12; U per 10*12; enzyme units per 10*12; enzyme units per trillion; enzymatic activity; micromoles per minute per trillion; umol/min/10*12; umol per min per 10*12",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per million",
			"U/10*6",
			"U/(10*6)",
			"catalytic activity",
			10036894500,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"U/(10<sup>6</sup>)",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"enzyme unit/10*6; U per 10*6; enzyme units per 10*6; enzyme units; enzymatic activity per volume; micromoles per minute per million; umol/min/10*6; umol per min per 10*6",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per billion",
			"U/10*9",
			"U/(10*9)",
			"catalytic activity",
			10036894.5,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"U/(10<sup>9</sup>)",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"enzyme unit/10*9; U per 10*9; enzyme units per 10*9; enzymatic activity per volume; micromoles per minute per billion; umol/min/10*9; umol per min per 10*9",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per day",
			"U/d",
			"U/D",
			"catalytic activity",
			116167760416.66667,
			[
				0,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"U/d",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"U/dy; enzyme units per day; enzyme units; enzyme activity; enzymatic activity per time; micromoles per minute per day; umol/min/day; umol per min per day",
			"LOINC",
			"CRat",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per deciliter",
			"U/dL",
			"U/DL",
			"catalytic activity",
			100368945000000000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"U/dL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"U per dL; enzyme units per deciliter; decilitre; micromoles per minute per deciliter; umol/min/dL; umol per min per dL",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per gram",
			"U/g",
			"U/G",
			"catalytic activity",
			10036894500000000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"U/g",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"U/gm; U per gm; enzyme units per gram; micromoles per minute per gram; umol/min/g; umol per min per g",
			"LOINC",
			"CCnt",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per hour",
			"U/h",
			"U/HR",
			"catalytic activity",
			2788026250000,
			[
				0,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"U/h",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"U/hr; U per hr; enzyme units per hour; micromoles per minute per hour; umol/min/hr; umol per min per hr",
			"LOINC",
			"CRat",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per liter",
			"U/L",
			"U/L",
			"catalytic activity",
			10036894500000000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"U/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"enzyme unit/liter; enzyme unit/litre; U per L; enzyme units per liter; enzyme unit per litre; micromoles per minute per liter; umol/min/L; umol per min per L",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per minute",
			"U/min",
			"U/MIN",
			"catalytic activity",
			167281575000000,
			[
				0,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"U/min",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"enzyme unit/minute; U per min; enzyme units; umol/min/min; micromoles per minute per minute; micromoles per min per min; umol",
			"LOINC",
			"CRat",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per milliliter",
			"U/mL",
			"U/ML",
			"catalytic activity",
			1.00368945e+22,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"U/mL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"U per mL; enzyme units per milliliter; millilitre; micromoles per minute per milliliter; umol/min/mL; umol per min per mL",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"enzyme unit per second",
			"U/s",
			"U/S",
			"catalytic activity",
			10036894500000000,
			[
				0,
				-2,
				0,
				0,
				0,
				0,
				0
			],
			"U/s",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"U/sec; U per second; enzyme units per second; micromoles per minute per second; umol/min/sec; umol per min per sec",
			"LOINC",
			"CRat",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min)",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"micro international unit",
			"u[IU]",
			"U[IU]",
			"arbitrary",
			0.000001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"i.U.",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"uIU; u IU; microinternational units",
			"LOINC",
			"Arb",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"micro international unit per liter",
			"u[IU]/L",
			"U[IU]/L",
			"arbitrary",
			0.001,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(i.U.)/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"uIU/L; u IU/L; uIU per L; microinternational units per liter; litre; ",
			"LOINC",
			"ACnc",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"micro international unit per milliliter",
			"u[IU]/mL",
			"U[IU]/ML",
			"arbitrary",
			1,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"(i.U.)/mL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			true,
			0,
			"uIU/mL; u IU/mL; uIU per mL; microinternational units per milliliter; millilitre",
			"LOINC",
			"ACnc",
			"Clinical",
			"International units (IU) are analyte and reference specimen  specific arbitrary units (held at WHO)",
			"[iU]",
			"[IU]",
			"1",
			1,
			false
		],
		[
			false,
			"microequivalent",
			"ueq",
			"UEQ",
			"amount of substance",
			602213670000000000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"eq",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"microequivalents; 10^-6 equivalents; 10-6 equivalents",
			"LOINC",
			"Sub",
			"Clinical",
			"",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"microequivalent per liter",
			"ueq/L",
			"UEQ/L",
			"amount of substance",
			602213670000000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"eq/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"ueq per liter; litre; microequivalents",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"microequivalent per milliliter",
			"ueq/mL",
			"UEQ/ML",
			"amount of substance",
			6.0221367000000003e+23,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"eq/mL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"ueq per milliliter; millilitre; microequivalents",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			"mol",
			"MOL",
			"1",
			1,
			false
		],
		[
			false,
			"microgram",
			"ug",
			"UG",
			"mass",
			0.000001,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mcg; micrograms; 10^-6 grams; 10-6 grams",
			"LOINC",
			"Mass",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per 100 gram",
			"ug/(100.g)",
			"UG/(100.G)",
			"mass",
			1e-8,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"g/g",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/100gm; ug/100 gm; mcg; ug per 100g; 100 gm; mcg per 100g; micrograms per 100 grams",
			"LOINC",
			"MCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per 24 hour",
			"ug/(24.h)",
			"UG/(24.HR)",
			"mass",
			1.1574074074074074e-11,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/24hrs; ug/24 hrs; mcg/24hrs; ug per 24hrs; mcg per 24hrs; 24 hrs; micrograms per 24 hours",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per 8 hour",
			"ug/(8.h)",
			"UG/(8.HR)",
			"mass",
			3.472222222222222e-11,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/8hrs; ug/8 hrs; mcg/8hrs; ug per 8hrs; mcg per 8hrs; 8 hrs; micrograms per 8 hours; shift",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per square foot (international)",
			"ug/[sft_i]",
			"UG/[SFT_I]",
			"mass",
			0.000010763910416709721,
			[
				-2,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/sft; ug/ft2; ug/ft^2; ug/sq. ft; micrograms; sq. foot; foot squared",
			"LOINC",
			"ArMass",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per day",
			"ug/d",
			"UG/D",
			"mass",
			1.1574074074074074e-11,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/d",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/dy; mcg/dy; ug per day; mcg; micrograms per day",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per deciliter",
			"ug/dL",
			"UG/DL",
			"mass",
			0.009999999999999998,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g/dL",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug per dL; mcg/dl; mcg per dl; micrograms per deciliter; decilitre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per gram",
			"ug/g",
			"UG/G",
			"mass",
			0.000001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"g/g",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug per gm; mcg/gm; mcg per g; micrograms per gram",
			"LOINC",
			"MCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per hour",
			"ug/h",
			"UG/HR",
			"mass",
			2.7777777777777777e-10,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/hr; mcg/hr; mcg per hr; ug per hr; ug per hour; micrograms",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per kilogram",
			"ug/kg",
			"UG/KG",
			"mass",
			9.999999999999999e-10,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"g/kg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug per kg; mcg/kg; mcg per kg; micrograms per kilogram",
			"LOINC",
			"MCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per kilogram per 8 hour",
			"ug/kg/(8.h)",
			"(UG/KG)/(8.HR)",
			"mass",
			3.472222222222222e-14,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(g/kg)/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/kg/8hrs; mcg/kg/8hrs; ug/kg/8 hrs; mcg/kg/8 hrs; ug per kg per 8hrs; 8 hrs; mcg per kg per 8hrs; micrograms per kilograms per 8 hours; shift",
			"LOINC",
			"",
			"Clinical",
			"unit used to measure mass dose rate per patient body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per kilogram per day",
			"ug/kg/d",
			"(UG/KG)/D",
			"mass",
			1.1574074074074072e-14,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(g/kg)/d",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/(kg.d); ug/kg/dy; mcg/kg/day; ug per kg per dy; 24 hours; 24hrs; mcg; kilograms; microgram per kilogram and day",
			"LOINC",
			"",
			"Clinical",
			"unit used to measure mass dose rate per patient body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per kilogram per hour",
			"ug/kg/h",
			"(UG/KG)/HR",
			"mass",
			2.7777777777777774e-13,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(g/kg)/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/(kg.h); ug/kg/hr; mcg/kg/hr; ug per kg per hr; mcg per kg per hr; kilograms",
			"LOINC",
			"",
			"Clinical",
			"unit used to measure mass dose rate per patient body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per kilogram per minute",
			"ug/kg/min",
			"(UG/KG)/MIN",
			"mass",
			1.6666666666666664e-11,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(g/kg)/min",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/kg/min; ug/kg/min; mcg/kg/min; ug per kg per min; mcg; micrograms per kilograms per minute ",
			"LOINC",
			"",
			"Clinical",
			"unit used to measure mass dose rate per patient body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per liter",
			"ug/L",
			"UG/L",
			"mass",
			0.001,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g/L",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"mcg/L; ug per L; mcg; micrograms per liter; litre ",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per liter per 24 hour",
			"ug/L/(24.h)",
			"(UG/L)/(24.HR)",
			"mass",
			1.1574074074074074e-8,
			[
				-3,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"(g/L)/h",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/L/24hrs; ug/L/24 hrs; mcg/L/24hrs; ug per L per 24hrs; 24 hrs; day; dy mcg; micrograms per liters per 24 hours; litres",
			"LOINC",
			"",
			"Clinical",
			"unit used to measure mass dose rate per patient body mass",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per square meter",
			"ug/m2",
			"UG/M2",
			"mass",
			0.000001,
			[
				-2,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g/(m<sup>2</sup>)",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/m^2; ug/sq. m; mcg/m2; mcg/m^2; mcg/sq. m; ug per m2; m^2; sq. meter; mcg; micrograms per square meter; meter squared; metre",
			"LOINC",
			"ArMass",
			"Clinical",
			"unit used to measure mass dose per patient body surface area",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per cubic meter",
			"ug/m3",
			"UG/M3",
			"mass",
			0.000001,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g/(m<sup>3</sup>)",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug/m^3; ug/cu. m; mcg/m3; mcg/m^3; mcg/cu. m; ug per m3; ug per m^3; ug per cu. m; mcg; micrograms per cubic meter; meter cubed; metre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per milligram",
			"ug/mg",
			"UG/MG",
			"mass",
			0.001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"g/mg",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug per mg; mcg/mg; mcg per mg; micromilligrams per milligram",
			"LOINC",
			"MCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per minute",
			"ug/min",
			"UG/MIN",
			"mass",
			1.6666666666666667e-8,
			[
				0,
				-1,
				1,
				0,
				0,
				0,
				0
			],
			"g/min",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug per min; mcg/min; mcg per min; microminutes per minute",
			"LOINC",
			"MRat",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per milliliter",
			"ug/mL",
			"UG/ML",
			"mass",
			1,
			[
				-3,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g/mL",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug per mL; mcg/mL; mcg per mL; micrograms per milliliter; millilitre",
			"LOINC",
			"MCnc",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per millimole",
			"ug/mmol",
			"UG/MMOL",
			"mass",
			1.660540186674939e-27,
			[
				0,
				0,
				1,
				0,
				0,
				0,
				0
			],
			"g/mmol",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			-1,
			"ug per mmol; mcg/mmol; mcg per mmol; micrograms per millimole",
			"LOINC",
			"Ratio",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microgram per nanogram",
			"ug/ng",
			"UG/NG",
			"mass",
			999.9999999999999,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"g/ng",
			null,
			false,
			"M",
			null,
			1,
			false,
			false,
			0,
			"ug per ng; mcg/ng; mcg per ng; micrograms per nanogram",
			"LOINC",
			"MCnt",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microkatal",
			"ukat",
			"UKAT",
			"catalytic activity",
			602213670000000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"kat",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"microkatals; ukats",
			"LOINC",
			"CAct",
			"Clinical",
			"kat is a unit of catalytic activity with base units = mol/s. Rarely used because its units are too large to practically express catalytic activity. See enzyme unit [U] which is the standard unit for catalytic activity.",
			"mol/s",
			"MOL/S",
			"1",
			1,
			false
		],
		[
			false,
			"microliter",
			"uL",
			"UL",
			"volume",
			1e-9,
			[
				3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"L",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"microliters; microlitres; mcl",
			"LOINC",
			"Vol",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"microliter per 2 hour",
			"uL/(2.h)",
			"UL/(2.HR)",
			"volume",
			1.388888888888889e-13,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"L/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"uL/2hrs; uL/2 hrs; mcg/2hr; mcg per 2hr; uL per 2hr; uL per 2 hrs; microliters per 2 hours; microlitres ",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"microliter per hour",
			"uL/h",
			"UL/HR",
			"volume",
			2.777777777777778e-13,
			[
				3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"L/h",
			"iso1000",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"uL/hr; mcg/hr; mcg per hr; uL per hr; microliters per hour; microlitres",
			"LOINC",
			"VRat",
			"Clinical",
			"",
			"l",
			null,
			"1",
			1,
			false
		],
		[
			false,
			"micrometer",
			"um",
			"UM",
			"length",
			0.000001,
			[
				1,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"m",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"micrometers; micrometres; m; microns",
			"LOINC",
			"Len",
			"Clinical",
			"Unit of length that is usually used in tests related to the eye",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"microns per second",
			"um/s",
			"UM/S",
			"length",
			0.000001,
			[
				1,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"m/s",
			null,
			false,
			"L",
			null,
			1,
			false,
			false,
			0,
			"um/sec; micron/second; microns/second; um per sec; micrometers per second; micrometres",
			"LOINC",
			"Vel",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"micromole",
			"umol",
			"UMOL",
			"amount of substance",
			602213670000000000,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"micromoles; umols",
			"LOINC",
			"Sub",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per 2 hour",
			"umol/(2.h)",
			"UMOL/(2.HR)",
			"amount of substance",
			83640787500000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"umol/2hrs; umol/2 hrs; umol per 2 hrs; 2hrs; micromoles per 2 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per 24 hour",
			"umol/(24.h)",
			"UMOL/(24.HR)",
			"amount of substance",
			6970065625000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"umol/24hrs; umol/24 hrs; umol per 24 hrs; per 24hrs; micromoles per 24 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per 8 hour",
			"umol/(8.h)",
			"UMOL/(8.HR)",
			"amount of substance",
			20910196875000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"umol/8hr; umol/8 hr; umol per 8 hr; umol per 8hr; umols per 8hr; umol per 8 hours; micromoles per 8 hours; shift",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per day",
			"umol/d",
			"UMOL/D",
			"amount of substance",
			6970065625000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mol/d",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"umol/day; umol per day; umols per day; umol per days; micromoles per days; umol/24hr; umol/24 hr; umol per 24 hr; umol per 24hr; umols per 24hr; umol per 24 hours; micromoles per 24 hours",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per deciliter",
			"umol/dL",
			"UMOL/DL",
			"amount of substance",
			6.0221367e+21,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mol/dL",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"micromole/deciliter; micromole/decilitre; umol per dL; micromoles per deciliters; micromole per decilitres",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per gram",
			"umol/g",
			"UMOL/G",
			"amount of substance",
			602213670000000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"mol/g",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"micromole/gram; umol per g; micromoles per gram",
			"LOINC",
			"SCnt; Ratio",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per hour",
			"umol/h",
			"UMOL/HR",
			"amount of substance",
			167281575000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mol/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"umol/hr; umol per hr; umol per hour; micromoles per hours",
			"LOINC",
			"SRat",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per kilogram",
			"umol/kg",
			"UMOL/KG",
			"amount of substance",
			602213670000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"mol/kg",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"umol per kg; micromoles per kilogram",
			"LOINC",
			"SCnt",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per liter",
			"umol/L",
			"UMOL/L",
			"amount of substance",
			602213670000000000000,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mol/L",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"micromole/liter; micromole/litre; umol per liter; micromoles per liter; litre",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per liter per hour",
			"umol/L/h",
			"(UMOL/L)/HR",
			"amount of substance",
			167281575000000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(mol/L)/h",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"umol/liter/hr; umol/litre/hr; umol per L per hr; umol per liter per hour; micromoles per liters per hour; litre",
			"LOINC",
			"CCnc",
			"Clinical",
			"unit for the enzyme unit U = umol/min; umol/L/h is a derived unit of enzyme units",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per milligram",
			"umol/mg",
			"UMOL/MG",
			"amount of substance",
			602213670000000000000,
			[
				0,
				0,
				-1,
				0,
				0,
				0,
				0
			],
			"mol/mg",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"micromole/milligram; umol per mg; micromoles per milligram",
			"LOINC",
			"SCnt",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per minute",
			"umol/min",
			"UMOL/MIN",
			"amount of substance",
			10036894500000000,
			[
				0,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"mol/min",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"micromole/minute; umol per min; micromoles per minute; enzyme units",
			"LOINC",
			"CAct",
			"Clinical",
			"unit for the enzyme unit U = umol/min",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per minute per gram",
			"umol/min/g",
			"(UMOL/MIN)/G",
			"amount of substance",
			10036894500000000,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"(mol/min)/g",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"umol/min/gm; umol per min per gm; micromoles per minutes per gram; U/g; enzyme units",
			"LOINC",
			"CCnt",
			"Clinical",
			"unit for the enzyme unit U = umol/min. umol/min/g = U/g",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per minute per liter",
			"umol/min/L",
			"(UMOL/MIN)/L",
			"amount of substance",
			10036894500000000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(mol/min)/L",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"umol/min/liter; umol/minute/liter; micromoles per minutes per liter; litre; enzyme units; U/L",
			"LOINC",
			"CCnc",
			"Clinical",
			"unit for the enzyme unit U = umol/min. umol/min/L = U/L",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per milliliter",
			"umol/mL",
			"UMOL/ML",
			"amount of substance",
			6.0221367000000003e+23,
			[
				-3,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mol/mL",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"umol per mL; micromoles per milliliter; millilitre",
			"LOINC",
			"SCnc",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per milliliter per minute",
			"umol/mL/min",
			"(UMOL/ML)/MIN",
			"amount of substance",
			1.00368945e+22,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"(mol/mL)/min",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"umol per mL per min; micromoles per milliliters per minute; millilitres",
			"LOINC",
			"CCnc",
			"Clinical",
			"unit for the enzyme unit U = umol/min. umol/mL/min = U/mL",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per millimole",
			"umol/mmol",
			"UMOL/MMOL",
			"amount of substance",
			0.001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mol/mmol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"umol per mmol; micromoles per millimole",
			"LOINC",
			"SRto",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per mole",
			"umol/mol",
			"UMOL/MOL",
			"amount of substance",
			0.000001,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mol/mol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"umol per mol; micromoles per mole",
			"LOINC",
			"SRto",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"micromole per micromole",
			"umol/umol",
			"UMOL/UMOL",
			"amount of substance",
			1,
			[
				0,
				0,
				0,
				0,
				0,
				0,
				0
			],
			"mol/mol",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"umol per umol; micromoles per micromole",
			"LOINC",
			"Srto; SFr; EntSRto",
			"Clinical",
			"",
			"10*23",
			"10*23",
			"6.0221367",
			6.0221367,
			false
		],
		[
			false,
			"microOhm",
			"uOhm",
			"UOHM",
			"electric resistance",
			0.001,
			[
				2,
				-1,
				1,
				0,
				0,
				-2,
				0
			],
			"",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"microOhms; ",
			"LOINC",
			"",
			"Clinical",
			"unit of electric resistance",
			"V/A",
			"V/A",
			"1",
			1,
			false
		],
		[
			false,
			"microsecond",
			"us",
			"US",
			"time",
			0.000001,
			[
				0,
				1,
				0,
				0,
				0,
				0,
				0
			],
			"s",
			null,
			false,
			"T",
			null,
			1,
			false,
			false,
			0,
			"microseconds",
			"LOINC",
			"Time",
			"Clinical",
			"",
			null,
			null,
			null,
			null,
			false
		],
		[
			false,
			"micro enzyme unit per gram",
			"uU/g",
			"UU/G",
			"catalytic activity",
			10036894500,
			[
				0,
				-1,
				-1,
				0,
				0,
				0,
				0
			],
			"U/g",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"uU per gm; micro enzyme units per gram; micro enzymatic activity per mass; enzyme activity",
			"LOINC",
			"CCnt",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 uU = 1pmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"micro enzyme unit per liter",
			"uU/L",
			"UU/L",
			"catalytic activity",
			10036894500000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"U/L",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"uU per L; micro enzyme units per liter; litre; enzymatic activity per volume; enzyme activity ",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 uU = 1pmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"micro enzyme unit per milliliter",
			"uU/mL",
			"UU/ML",
			"catalytic activity",
			10036894500000000,
			[
				-3,
				-1,
				0,
				0,
				0,
				0,
				0
			],
			"U/mL",
			"chemical",
			true,
			null,
			null,
			1,
			false,
			false,
			1,
			"uU per mL; micro enzyme units per milliliter; millilitre; enzymatic activity per volume; enzyme activity",
			"LOINC",
			"CCnc",
			"Clinical",
			"1 U is the standard enzyme unit which equals 1 micromole substrate catalyzed per minute (1 umol/min); 1 uU = 1pmol/min",
			"umol/min",
			"UMOL/MIN",
			"1",
			1,
			false
		],
		[
			false,
			"microvolt",
			"uV",
			"UV",
			"electric potential",
			0.001,
			[
				2,
				-2,
				1,
				0,
				0,
				-1,
				0
			],
			"V",
			"si",
			true,
			null,
			null,
			1,
			false,
			false,
			0,
			"microvolts",
			"LOINC",
			"Elpot",
			"Clinical",
			"unit of electric potential (voltage)",
			"J/C",
			"J/C",
			"1",
			1,
			false
		]
	]
};
var require$$5 = {
	license: license,
	prefixes: prefixes,
	units: units
};

var hasRequiredUcumJsonDefs;

function requireUcumJsonDefs () {
	if (hasRequiredUcumJsonDefs) return ucumJsonDefs;
	hasRequiredUcumJsonDefs = 1;

	Object.defineProperty(ucumJsonDefs, "__esModule", {
	  value: true
	});
	ucumJsonDefs.ucumJsonDefs = ucumJsonDefs.UcumJsonDefs = void 0;
	/**
	 * This class handles opening, reading and loading the JSON file of ucum
	 * definitions (prefixes, base units, and unit atoms).
	 *
	 * @author Lee Mericle
	 *
	 */

	var Pfx = requirePrefix();
	var PfxT = requirePrefixTables();
	var Un = requireUnit();
	var Utab = requireUnitTables();
	var unpackArray = requireJsonArrayPack().unpackArray;
	class UcumJsonDefs {
	  /**
	   * This method loads the JSON prefix and unit objects into the prefix and
	   * unit tables.
	   *
	   * @returns nothing
	   */
	  loadJsonDefs() {
	    // requiring the file will take care of opening it for use
	    const jsonDefs = require$$5;
	    jsonDefs.prefixes = unpackArray(jsonDefs.prefixes);
	    jsonDefs.units = unpackArray(jsonDefs.units);
	    if (Utab.UnitTables.getInstance().unitsCount() === 0) {
	      let pTab = PfxT.PrefixTables.getInstance();
	      let prefixes = jsonDefs["prefixes"];
	      let plen = prefixes.length;
	      for (let p = 0; p < plen; p++) {
	        let newPref = new Pfx.Prefix(prefixes[p]);
	        pTab.add(newPref);
	      }
	      let uTab = Utab.UnitTables.getInstance();
	      let units = jsonDefs["units"];
	      let ulen = units.length;
	      for (let u = 0; u < ulen; u++) {
	        let newUnit = new Un.Unit(units[u]);
	        uTab.addUnit(newUnit);
	      }
	    } // end if the data has not already been loaded
	  } // end loadJsonDefs
	} // end UcumJsonDefs class
	ucumJsonDefs.UcumJsonDefs = UcumJsonDefs;
	var ucumJsonDefs$1 = new UcumJsonDefs();
	ucumJsonDefs.ucumJsonDefs = ucumJsonDefs$1;
	
	return ucumJsonDefs;
}

var unitString = {};

var hasRequiredUnitString;

function requireUnitString () {
	if (hasRequiredUnitString) return unitString;
	hasRequiredUnitString = 1;

	Object.defineProperty(unitString, "__esModule", {
	  value: true
	});
	unitString.UnitString = void 0;
	var intUtils_ = _interopRequireWildcard(requireUcumInternalUtils());
	function _getRequireWildcardCache() { if (typeof WeakMap !== "function") return null; var cache = new WeakMap(); _getRequireWildcardCache = function () { return cache; }; return cache; }
	function _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== "object" && typeof obj !== "function") { return { default: obj }; } var cache = _getRequireWildcardCache(); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }
	function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }
	/**
	 * This class handles the parsing of a unit string into a unit object
	 */

	var Ucum = requireConfig().Ucum;
	var Unit = requireUnit().Unit;
	var UnitTables = requireUnitTables().UnitTables;
	var PrefixTables = requirePrefixTables().PrefixTables;
	class UnitString {
	  /**
	   * Constructor
	   */
	  constructor() {
	    // Get instances of the unit and prefix tables and the utilities
	    this.utabs_ = UnitTables.getInstance();
	    this.pfxTabs_ = PrefixTables.getInstance();

	    // Set emphasis characters to defaults.  These are used to emphasize
	    // certain characters or strings in user messages.  They can be reset in
	    // the useHTMLInMessages method.
	    this.openEmph_ = Ucum.openEmph_;
	    this.closeEmph_ = Ucum.closeEmph_;

	    // Set the braces message to blank.  This message is displayed for each
	    // validation request on the web page, but is included separately as
	    // a note on the validation spreadsheet.  The useBraceMsgForEachString
	    // method should be used to set the message to be displayed for each
	    // unit string.
	    this.bracesMsg_ = '';

	    // Set the flags used, with indices, as place holders in unit strings
	    // for parenthetical strings and strings within braces.
	    this.parensFlag_ = "parens_placeholder"; // in lieu of Jehoshaphat
	    this.pFlagLen_ = this.parensFlag_.length;
	    this.braceFlag_ = "braces_placeholder"; // in lieu of Nebuchadnezzar
	    this.bFlagLen_ = this.braceFlag_.length;

	    // Initialize the message start/end strings, which will be set when
	    // parseString is called.
	    this.vcMsgStart_ = null;
	    this.vcMsgEnd_ = null;

	    // Arrays used by multiple methods within this class to hold persistent
	    // data.  Just gets too bulky to pass these guys around.

	    // Messages to be returned to the calling function
	    this.retMsg_ = [];

	    // Units for parenthetical unit strings
	    this.parensUnits_ = [];

	    // annotation text for annotations found in unit strings
	    this.annotations_ = [];

	    // suggestions for unit strings that for which no unit was found
	    this.suggestions = [];
	  } // end constructor

	  // The start of an error message about an invalid annotation character.

	  // A regular expression for validating annotation strings.

	  /**
	   * Sets the emphasis strings to the HTML used in the webpage display - or
	   * blanks them out, depending on the use parameter.
	   *
	   * @param use flag indicating whether or not to use the html message format;
	   *  defaults to true
	   */
	  useHTMLInMessages(use) {
	    if (use === undefined || use) {
	      this.openEmph_ = Ucum.openEmphHTML_;
	      this.closeEmph_ = Ucum.closeEmphHTML_;
	    } else {
	      this.openEmph_ = Ucum.openEmph_;
	      this.closeEmph_ = Ucum.closeEmph_;
	    }
	  } // end useHTMLInMessages

	  /**
	   * Sets the braces message to be displayed for each unit string validation
	   * requested, as appropriate.
	   *
	   * @param use flag indicating whether or not to use the braces message;
	   *  defaults to true
	   */
	  useBraceMsgForEachString(use) {
	    if (use === undefined || use) this.bracesMsg_ = Ucum.bracesMsg_;else this.bracesMsg_ = '';
	  }

	  /**
	   * Parses a unit string, returns a unit, a possibly updated version of
	   * the string passed in, and messages and suggestions where appropriate.
	   *
	   * The string returned may be updated if the input string contained unit
	   * names, e.g., "pound".  The unit code ([lb_av] for pound) is placed in
	   * the string returned, a the returned messages array includes a note
	   * explaining the substitution.
	   *
	   * @param uStr the string defining the unit
	   * @param valConv indicates what type of request this is for - a request to
	   *  validate (pass in 'validate') or a request to convert (pass in 'convert');
	   *  optional, defaults to 'validate'
	   * @param suggest a boolean to indicate whether or not suggestions are
	   *  requested for a string that cannot be resolved to a valid unit;
	   *  true indicates suggestions are wanted; false indicates they are not,
	   *  and is the default if the parameter is not specified;
	   * @returns an array containing:
	   *   the unit object or null if a unit could not be created.  In cases where
	   *     a fix was found for a problem string, .e.g., 2.mg for 2mg, a unit will
	   *     be returned but an error message will also be returned, describing
	   *     the substitution;
	   *   the possibly updated unit string passed in;
	   *   an array of any user messages (informational, error or warning)
	   *     generated (or an empty array); and
	   *   a suggestions array of hash objects (1 or more).  Each hash contains
	   *   three elements:
	   *     'msg' which is a message indicating what unit expression the
	   *       suggestions are for;
	   *     'invalidUnit' which is the unit expression the suggestions are
	   *       for; and
	   *     'units' which is an array of data for each suggested unit found.
	   *        Each array will contain the unit code, the unit name and the
	   *        unit guidance (if any).
	   *   The return array will not contain a suggestions array if a valid unit
	   *   was found or if suggestions were not requested.
	   * @throws an error if nothing was specified.
	   */
	  parseString(uStr, valConv, suggest) {
	    uStr = uStr.trim();
	    // Make sure we have something to work with
	    if (uStr === '' || uStr === null) {
	      throw new Error('Please specify a unit expression to be validated.');
	    }
	    if (valConv === 'validate') {
	      this.vcMsgStart_ = Ucum.valMsgStart_;
	      this.vcMsgEnd_ = Ucum.valMsgEnd_;
	    } else {
	      this.vcMsgStart_ = Ucum.cnvMsgStart_;
	      this.vcMsgEnd_ = Ucum.cnvMsgEnd_;
	    }
	    if (suggest === undefined || suggest === false) {
	      this.suggestions_ = null;
	    } else {
	      this.suggestions_ = [];
	    }
	    this.retMsg_ = [];
	    this.parensUnits_ = [];
	    this.annotations_ = [];
	    let origString = uStr;
	    let retObj = [];

	    // Extract any annotations, i.e., text enclosed in braces ({}) from the
	    // string before further processing.  Store each one in this.annotations_
	    // array and put a placeholder in the string for the annotation.  Do
	    // this before other processing in case an annotation contains characters
	    // that will be interpreted as parenthetical markers or operators in
	    // subsequent processing.

	    uStr = this._getAnnotations(uStr);
	    if (this.retMsg_.length > 0) {
	      retObj[0] = null;
	      retObj[1] = null;
	    } else {
	      // Flag used to block further processing on an unrecoverable error
	      this.retMsg_.length > 0;

	      // First check for one of the "special" units.  If it's one of those, put
	      // in a substitution phrase for it to avoid having it separated on its
	      // embedded operator.  This will only happen, by the way, if it is
	      // preceded by a prefix or followed by an operator and another unit.
	      let sUnit = null;
	      for (sUnit in Ucum.specUnits_) {
	        while (uStr.indexOf(sUnit) !== -1) uStr = uStr.replace(sUnit, Ucum.specUnits_[sUnit]);
	      }

	      // Check for spaces and throw an error if any are found.  The spec
	      // explicitly forbids spaces except in annotations, which is why any
	      // annotations are extracted before this check is made.
	      if (uStr.indexOf(' ') > -1) {
	        throw new Error('Blank spaces are not allowed in unit expressions.');
	      } // end if blanks were found in the string

	      // assign the array returned to retObj.  It will contain 2 elements:
	      //  the unit returned in position 0; and the origString (possibly
	      //  modified) in position 1.  The origString in position 1 will not
	      //  be changed by subsequent processing.
	      retObj = this._parseTheString(uStr, origString);
	      let finalUnit = retObj[0];

	      // Do a final check to make sure that finalUnit is a unit and not
	      // just a number.  Something like "8/{HCP}" will return a "unit" of 8
	      // - which is not a unit.  Hm - evidently it is.  So just create a unit
	      // object for it.
	      if (intUtils_.isIntegerUnit(finalUnit) || typeof finalUnit === 'number') {
	        finalUnit = new Unit({
	          'csCode_': origString,
	          'ciCode_': origString,
	          'magnitude_': finalUnit,
	          'name_': origString
	        });
	        retObj[0] = finalUnit;
	      } // end final check
	    } // end if no annotation errors were found

	    retObj[2] = this.retMsg_;
	    if (this.suggestions_ && this.suggestions_.length > 0) retObj[3] = this.suggestions_;
	    return retObj;
	  } // end parseString

	  /**
	   * Parses a unit string, returns a unit, a possibly updated version of
	   * the string passed in, and messages where appropriate.  This should
	   * only be called from within this class (or by test code).
	   *
	   * The string returned may be updated if the input string contained unit
	   * names, e.g., "pound".  The unit code ([lb_av] for pound) is placed in
	   * the string returned, a the returned messages array includes a note
	   * explaining the substitution.
	   *
	   * @param uStr the string defining the unit
	   * @param origString the original unit string passed in
	   *
	   * @returns
	   *  an array containing:
	   *    the unit object (or null if there were problems creating the unit); and
	   *    the possibly updated unit string passed in.
	   *
	   * the this.retMsg_ array will be updated with any user messages
	   *   (informational, error or warning) generated by this or called methods
	   * the this.parensUnits_ array is referenced and possibly populated by
	   *   methods called within this one
	   * the this.annotations_ array is referenced by methods called within
	   *   this one
	   * the this.suggestions_ array may be populated by methods called within
	   *   this one
	   */
	  _parseTheString(uStr, origString) {
	    // Unit to be returned
	    let finalUnit = null;

	    // Flag used to block further processing on an unrecoverable error
	    let endProcessing = this.retMsg_.length > 0;

	    // Call _processParens to search for and process any/all parenthetical
	    // strings in uStr.  Units created for parenthetical strings will be
	    // stored in the this.parensUnits_ array.
	    let parensResp = this._processParens(uStr, origString);
	    endProcessing = parensResp[2];

	    // The array used to hold the units and their operators.
	    let uArray = [];

	    // Continue if we didn't hit a problem
	    if (!endProcessing) {
	      uStr = parensResp[0];
	      origString = parensResp[1];

	      // Call _makeUnitsArray to convert the string to an array of unit
	      // descriptors with operators.
	      let mkUArray = this._makeUnitsArray(uStr, origString);
	      endProcessing = mkUArray[2];
	      if (!endProcessing) {
	        uArray = mkUArray[0];
	        origString = mkUArray[1];
	        // Create a unit object out of each un element
	        let uLen = uArray.length;
	        for (let u1 = 0; u1 < uLen; u1++) {
	          //for (let u1 = 0; u1 < uLen && !endProcessing; u1++) {
	          let curCode = uArray[u1]['un'];

	          // Determine the type of the "un" attribute of the current array element

	          // Check to see if it's a number.  If so write the number version of
	          // the number back to the "un" attribute and move on
	          if (intUtils_.isIntegerUnit(curCode)) {
	            uArray[u1]['un'] = Number(curCode);
	          } else {
	            // The current unit array element is a string.  Check now to see
	            // if it is or contains a parenthesized unit from this.parensUnits_.
	            // If so, call _getParens to process the string and get the unit.

	            if (curCode.indexOf(this.parensFlag_) >= 0) {
	              let parenUnit = this._getParensUnit(curCode, origString);
	              // if we couldn't process the string, set the end flag and bypass
	              // further processing.
	              if (!endProcessing) endProcessing = parenUnit[1];

	              // If we're good, put the unit in the uArray and replace the
	              // curCode, which contains the parentheses placeholders, etc.,
	              // with the unit's code - including any substitutions.
	              if (!endProcessing) {
	                uArray[u1]['un'] = parenUnit[0];
	              }
	            } // end if the curCode contains a parenthesized unit

	            // Else it's not a parenthetical unit and not a number. Call
	            // _makeUnit to create a unit for it.
	            else {
	              let uRet = this._makeUnit(curCode, origString);
	              // If we didn't get a unit, set the endProcessing flag.
	              if (uRet[0] === null) {
	                endProcessing = true;
	              } else {
	                uArray[u1]['un'] = uRet[0];
	                origString = uRet[1];
	              }
	            } // end if the curCode is not a parenthetical expression
	          } // end if the "un" array is a not a number
	        } // end do for each element in the units array
	      } // end if _makeUnitsArray did not return an error
	    } // end if _processParens did not find an error that causes a stop

	    // If we're still good, continue
	    if (!endProcessing) {
	      // Process the units (and numbers) to create one final unit object
	      if ((uArray[0] === null || uArray[0] === ' ' || uArray[0]['un'] === undefined || uArray[0]['un'] === null) && this.retMsg_.length === 0) {
	        // not sure what this might be, but this is a safeguard
	        this.retMsg_.push(`Unit string (${origString}) did not contain ` + `anything that could be used to create a unit, or else something ` + `that is not handled yet by this package.  Sorry`);
	        endProcessing = true;
	      }
	    }
	    if (!endProcessing) {
	      finalUnit = this._performUnitArithmetic(uArray, origString);
	    }
	    return [finalUnit, origString];
	  } // end _parseTheString

	  /**
	   * Extracts all annotations from a unit string, replacing them with
	   * placeholders for later evaluation.  The annotations are stored in the
	   * this.annotations_ array.  This should only be called from within this
	   * class (or by test code).
	   *
	   * @param uString the unit string being parsed
	   * @returns the string after the annotations are replaced with placeholders
	   *
	   * the this.retMsg_ array will be updated with any user messages
	   *   (informational, error or warning) generated by this or called methods
	   * the this.annotations_ array is populated by this method
	   */
	  _getAnnotations(uString) {
	    let openBrace = uString.indexOf('{');
	    while (openBrace >= 0) {
	      let closeBrace = uString.indexOf('}');
	      if (closeBrace < 0) {
	        this.retMsg_.push('Missing closing brace for annotation starting at ' + this.openEmph_ + uString.substr(openBrace) + this.closeEmph_);
	        openBrace = -1;
	      } else {
	        let braceStr = uString.substring(openBrace, closeBrace + 1);
	        // Check for valid characters in the annotation.
	        if (!UnitString.VALID_ANNOTATION_REGEX.test(braceStr)) {
	          this.retMsg_.push(UnitString.INVALID_ANNOTATION_CHAR_MSG + this.openEmph_ + braceStr + this.closeEmph_);
	          openBrace = -1; // end search for annotations
	        } else {
	          let aIdx = this.annotations_.length.toString();
	          uString = uString.replace(braceStr, this.braceFlag_ + aIdx + this.braceFlag_);
	          this.annotations_.push(braceStr);
	          openBrace = uString.indexOf('{');
	        }
	      }
	    } // end do while we have an opening brace

	    // check for a stray/unmatched closing brace
	    if (this.retMsg_.length == 0) {
	      // if there were no other errors above
	      let closeBrace = uString.indexOf('}');
	      if (closeBrace >= 0) this.retMsg_.push('Missing opening brace for closing brace found at ' + this.openEmph_ + uString.substring(0, closeBrace + 1) + this.closeEmph_);
	    }
	    return uString;
	  } // end _getAnnotations

	  /**
	   * Finds and processes any/all parenthesized unit strings. This should only
	   * be called from within this class (or by test code).
	   *
	   * Nested parenthesized strings are processed from the inside out.  The
	   * parseString function is called from within this one for each parenthesized
	   * unit string, and the resulting unit object is stored in this.parensUnits_,
	   * to be processed after all strings are translated to units.
	   *
	   * A placeholder is placed in the unit string returned to indicate that the
	   * unit object should be obtained from the this.parensUnits_ array.  The
	   * placeholder consists of the parenthesis flag (this.parensFlag_) followed
	   * by the index of the unit in this.parensUnits_ followed by this.parensFlag_.
	   *
	   * @param uString the unit string being parsed, where this will be the full
	   *  string the first time this is called and parenthesized strings on any
	   *  subsequent calls
	   * @param origString the original string first passed in to parseString
	   * @returns
	   *  an array containing:
	   *   the string after the parentheses are replaced;
	   *   the original string; and
	   *   a boolean flag indicating whether or not an error occurred that
	   *     should stop processing.
	   *
	   * the this.retMsg_ array will be updated with any user messages
	   *   (informational, error or warning) generated by this or called methods
	   * this this.parensUnits_ array will be populated with units found for
	   *   parenthetical unit strings
	   */
	  _processParens(uString, origString) {
	    // Unit strings array and index
	    let uStrArray = [];
	    let uStrAryPos = 0;
	    let stopProcessing = false;
	    let pu = this.parensUnits_.length;

	    // Count of characters trimmed off the beginning of the unit string (uString)
	    // as units are removed from it; used for error messages to provide
	    // context.
	    let trimmedCt = 0;

	    // Break the unit string into pieces that consist of text outside of
	    // parenthetical strings and placeholders for the parenthetical units.
	    // This method is called recursively for parenthetical strings and the units
	    // returned are stored in the this.parensUnits_ array.
	    while (uString !== "" && !stopProcessing) {
	      let openCt = 0;
	      let closeCt = 0;
	      let openPos = uString.indexOf('(');

	      // If an opening parenthesis was not found, check for an unmatched
	      // close parenthesis.  If one was found report the error and end
	      // processing.
	      if (openPos < 0) {
	        let closePos = uString.indexOf(')');
	        if (closePos >= 0) {
	          let theMsg = `Missing open parenthesis for close ` + `parenthesis at ${uString.substring(0, closePos + trimmedCt)}` + `${this.openEmph_}${uString.substr(closePos, 1)}${this.closeEmph_}`;
	          if (closePos < uString.length - 1) {
	            theMsg += `${uString.substr(closePos + 1)}`;
	          }
	          this.retMsg_.push(theMsg);
	          uStrArray[uStrAryPos] = uString;
	          stopProcessing = true;
	        } // end if a close parenthesis was found

	        // If no parentheses were found in the current unit string, transfer
	        // it to the units array and blank out the string, which will end
	        // the search for parenthetical units.
	        else {
	          uStrArray[uStrAryPos] = uString;
	          uString = "";
	        } // end if no close parenthesis was found
	      } // end if no open parenthesis was found

	      // Otherwise an open parenthesis was found. Process the string that
	      // includes the parenthetical group
	      else {
	        openCt += 1;
	        // Write the text before the parentheses (if any) to the unit strings array
	        let uLen = uString.length;
	        if (openPos > 0) {
	          uStrArray[uStrAryPos++] = uString.substr(0, openPos);
	        }

	        // Find the matching closePos, i.e., the one that closes the
	        // parenthetical group that this one opens.  Look also for
	        // another open parenthesis, in case this includes nested parenthetical
	        // strings.  This continues until it finds the same number of close
	        // parentheses as open parentheses, or runs out of string to check.
	        // In the case of nested parentheses this will identify the outer set
	        // of parentheses.
	        let closePos = 0;
	        let c = openPos + 1;
	        for (; c < uLen && openCt != closeCt; c++) {
	          if (uString[c] === '(') openCt += 1;else if (uString[c] === ')') closeCt += 1;
	        }

	        // Put a placeholder for the group in the unit strings array and recursively
	        // call this method for the parenthetical group.  Put the unit returned
	        // in this.parensUnits_.  Set the unit string to whatever follows
	        // the position of the closing parenthesis for this group, to be
	        // processed by the next iteration of this loop.  If there's nothing
	        // left uString is set to "".
	        if (openCt === closeCt) {
	          closePos = c;
	          uStrArray[uStrAryPos++] = this.parensFlag_ + pu.toString() + this.parensFlag_;
	          let parseResp = this._parseTheString(uString.substring(openPos + 1, closePos - 1), origString);
	          if (parseResp[0] === null) stopProcessing = true;else {
	            origString = parseResp[1];
	            this.parensUnits_[pu++] = parseResp[0];
	            uString = uString.substr(closePos);
	            trimmedCt = closePos;
	          }
	        } // end if the number of open and close parentheses matched

	        // If the number of open and close parentheses doesn't match, indicate
	        // an error.
	        else {
	          uStrArray.push(origString.substr(openPos));
	          this.retMsg_.push(`Missing close parenthesis for open parenthesis at ` + `${origString.substring(0, openPos + trimmedCt)}` + `${this.openEmph_}${origString.substr(openPos, 1)}` + `${this.closeEmph_}${origString.substr(openPos + 1)}`);
	          stopProcessing = true;
	        }
	      } // end if an open parenthesis was found
	    } // end do while the input string is not empty
	    if (stopProcessing) this.parensUnits_ = [];
	    return [uStrArray.join(''), origString, stopProcessing];
	  } // end _processParens

	  /**
	   * Breaks the unit string into an array of unit descriptors and operators.
	   * If a unit descriptor consists of a number preceding a unit code, with
	   * no multiplication operator, e.g., 2mg instead of 2.mg, it is handled
	   * as if it were a parenthetical expression.
	   *
	   * This should only be called from within this class (or by test code).
	   *
	   * @param uStr the unit string being parsed
	   * @param origString the original string passed to parseString
	   * @returns
	   *  an array containing:
	   *    the array representing the unit string;
	   *    the original string passed in, possibly updated with corrections; and
	   *    and a flag indicating whether or not processing can continue.
	   *
	   * the this.retMsg_ array will be updated with any user messages
	   *   (informational, error or warning) generated by this or called methods
	   */
	  _makeUnitsArray(uStr, origString) {
	    // Separate the string into pieces based on delimiters / (division) and .
	    // (multiplication).  The idea is to get an array of units on which we
	    // can then perform any operations (prefixes, multiplication, division).

	    let uArray1 = uStr.match(/([./]|[^./]+)/g);
	    let endProcessing = false;
	    let uArray = [];
	    let startNumCheck = /(^[0-9]+)(\[?[a-zA-Z\_0-9a-zA-Z\_]+\]?$)/;

	    // If the first element in the array is the division operator (/), the
	    // string started with '/'.  Add a first element containing 1 to the
	    // array, which will cause the correct computation to be performed (inversion).
	    if (uArray1[0] === "/") {
	      uArray1.unshift("1");
	    }
	    // If the first element in the array is the multiplication operator (.)
	    // return an error.
	    else if (uArray1[0] === '.') {
	      this.retMsg_.push(`${origString} is not a valid UCUM code. ` + `The multiplication operator at the beginning of the expression is ` + `not valid. A multiplication operator must appear only between ` + `two codes.`);
	      endProcessing = true;
	    }
	    if (!endProcessing) {
	      // Check to see if there is a number preceding a unit code, e.g., 2mg
	      // If so, update the first element to remove the number (2mg -> mg) and
	      // add two elements to the beginning of the array - the number and the
	      // multiplication operator.

	      if (!intUtils_.isNumericString(uArray1[0])) {
	        let numRes = uArray1[0].match(startNumCheck);
	        if (numRes && numRes.length === 3 && numRes[1] !== '' && numRes[2] !== '' && numRes[2].indexOf(this.braceFlag_) !== 0) {
	          let dispVal = numRes[2];
	          if (!endProcessing && numRes[2].indexOf(this.parensFlag_) !== -1) {
	            let parensback = this._getParensUnit(numRes[2], origString);
	            numRes[2] = parensback[0]['csCode_'];
	            dispVal = `(${numRes[2]})`;
	            endProcessing = parensback[1];
	          }
	          if (!endProcessing) {
	            this.retMsg_.push(`${numRes[1]}${dispVal} is not a valid UCUM code.` + `  ${this.vcMsgStart_}${numRes[1]}.${dispVal}${this.vcMsgEnd_}`);
	            origString = origString.replace(`${numRes[1]}${dispVal}`, `${numRes[1]}.${dispVal}`);
	            uArray1[0] = numRes[2];
	            uArray1.unshift(numRes[1], '.');
	          }
	        }
	      } // end if the first element is not a number (only)

	      // Create an array of unit/operator objects.  The unit is, for now, the
	      // string containing the unit code (e.g., Hz for hertz) including
	      // a possible prefix and exponent.   The operator is the operator to be
	      // applied to that unit and the one preceding it.  So, a.b would give
	      // us two objects.  The first will have a unit of a, and a blank operator
	      // (because it's the first unit).  The second would have a unit of b
	      // and the multiplication operator (.).
	      if (!endProcessing) {
	        let u1 = uArray1.length;
	        uArray = [{
	          op: "",
	          un: uArray1[0]
	        }];
	        for (let n = 1; n < u1; n++) {
	          // check to make sure that we don't have two operators together, e.g.,
	          // mg./K.  If so, let the user know the problem.
	          let theOp = uArray1[n++];
	          // oh wait - check to make sure something is even there, that the
	          // user didn't end the expression with an operator.
	          if (!uArray1[n]) {
	            this.retMsg_.push(`${origString} is not a valid UCUM code. ` + `It is terminated with the operator ${this.openEmph_}` + `${theOp}${this.closeEmph_}.`);
	            n = u1;
	            endProcessing = true;
	          } else if (Ucum.validOps_.indexOf(uArray1[n]) !== -1) {
	            this.retMsg_.push(`${origString} is not a valid UCUM code. ` + `A unit code is missing between${this.openEmph_}` + `${theOp}${this.closeEmph_}and${this.openEmph_}` + `${uArray1[n]}${this.closeEmph_}in${this.openEmph_}` + `${theOp}${uArray1[n]}${this.closeEmph_}.`);
	            n = u1;
	            endProcessing = true;
	          } else {
	            // Check to see if a number precedes a unit code.
	            // If so, send the element to _processParens, inserting the multiplication
	            // operator where it belongs.  Treating it as parenthetical keeps it from
	            // being interpreted incorrectly because of operator parentheses.  For
	            // example, if the whole string is mg/2kJ we don't want to rewrite it as
	            // mg/2.kJ - because mg/2 would be performed, followed by .kJ.  Instead,
	            // handling 2kJ as a parenthesized unit will make sure mg is divided by
	            // 2.kJ.
	            if (!intUtils_.isNumericString(uArray1[n])) {
	              let numRes2 = uArray1[n].match(startNumCheck);
	              if (numRes2 && numRes2.length === 3 && numRes2[1] !== '' && numRes2[2] !== '' && numRes2[2].indexOf(this.braceFlag_) !== 0) {
	                let invalidString = numRes2[0];
	                if (!endProcessing && numRes2[2].indexOf(this.parensFlag_) !== -1) {
	                  let parensback = this._getParensUnit(numRes2[2], origString);
	                  numRes2[2] = parensback[0]['csCode_'];
	                  invalidString = `(${numRes2[2]})`;
	                  endProcessing = parensback[1];
	                  if (!endProcessing) {
	                    this.retMsg_.push(`${numRes2[1]}${invalidString} is not a ` + `valid UCUM code.  ${this.vcMsgStart_}${numRes2[1]}.${invalidString}` + `${this.vcMsgEnd_}`);
	                    let parensString = `(${numRes2[1]}.${invalidString})`;
	                    origString = origString.replace(`${numRes2[1]}${invalidString}`, parensString);
	                    let nextParens = this._processParens(parensString, origString);
	                    endProcessing = nextParens[2];
	                    if (!endProcessing) {
	                      uArray.push({
	                        op: theOp,
	                        un: nextParens[0]
	                      });
	                    }
	                    //uArray.push({op: '.', un: numRes2[2]});
	                  }
	                } // end if the string represents a parenthesized unit
	                else {
	                  let parensStr = '(' + numRes2[1] + '.' + numRes2[2] + ')';
	                  let parensResp = this._processParens(parensStr, origString);
	                  // if a "stop processing" flag was returned, set the n index to end
	                  // the loop and set the endProcessing flag
	                  if (parensResp[2]) {
	                    n = u1;
	                    endProcessing = true;
	                  } else {
	                    this.retMsg_.push(`${numRes2[0]} is not a ` + `valid UCUM code.  ${this.vcMsgStart_}${numRes2[1]}.${numRes2[2]}` + `${this.vcMsgEnd_}`);
	                    origString = origString.replace(numRes2[0], parensStr);
	                    uArray.push({
	                      op: theOp,
	                      un: parensResp[0]
	                    });
	                  } // end if no error on the processParens call
	                } // end if the string does not represent a parenthesized unit
	              } // end if the string is a number followed by a string
	              else {
	                uArray.push({
	                  op: theOp,
	                  un: uArray1[n]
	                });
	              }
	            } else {
	              uArray.push({
	                op: theOp,
	                un: uArray1[n]
	              });
	            }
	          } // end if there isn't a missing operator or unit code
	        } // end do for each element in uArray1
	      } // end if a processing error didn't occur in getParensUnit
	    } // end if the string did not begin with a '.' with no following digit
	    return [uArray, origString, endProcessing];
	  } // end _makeUnitsArray

	  /**
	   * Takes a unit string containing parentheses flags and returns the unit they
	   * represent.  Any text found before and/or after the parenthetical
	   * expression is checked to see if we can tell what the user meant and
	   * let them know what it should have been.  For example, 2(mg), which
	   * would resolve to 2mg, should be 2.mg.
	   *
	   * This should only be called from within this class (or by test code).
	   *
	   * @param pStr the string being parsed
	   * @param origString the original unit string passed in; passed through
	   *  to _getAnnonText if annotation flags are found in any text preceding
	   *  or following the parenthetical unit
	   * @returns
	   *   an array containing
	   *     the unit object; and
	   *     a flag indicating whether or not processing should be ended.
	   *       True indicates that the string was invalid and no corrections
	   *         (substitutions or suggestions) could be found;
	   *       False indicates that it was either valid or substitutions/suggestions
	   *          were made.
	   *   the this.retMsg_ array will be updated with any user messages
	   *     (informational, error or warning) generated by this or called methods
	   *   this this.parensUnits_ array contains the units that are acquired by
	   *     this method
	   * @throws an error if an invalid parensUnit index was found.  This is
	   *    a processing error.
	   */
	  _getParensUnit(pStr, origString) {
	    let endProcessing = false;
	    let retUnit = null;

	    // Get the location of the flags.  We're assuming there are only two
	    // because _processParens takes care of nesting.  By the time we get
	    // here we should not be looking a nested parens.  Also get any text
	    // before and after the parentheses.  Once we get the unit we update
	    // the input string with the unit's csCode_, which will wipe out any
	    // before and after text
	    let psIdx = pStr.indexOf(this.parensFlag_);
	    let befText = null;
	    if (psIdx > 0) {
	      befText = pStr.substr(0, psIdx - 1);
	    }
	    let peIdx = pStr.lastIndexOf(this.parensFlag_);
	    let aftText = null;
	    if (peIdx + this.pFlagLen_ < pStr.length) {
	      aftText = pStr.substr(peIdx + this.pFlagLen_);
	    }

	    // Get the text between the flags
	    let pNumText = pStr.substring(psIdx + this.pFlagLen_, peIdx);

	    // Make sure the index is a number, and if it is, get the unit from the
	    // this.parensUnits_ array
	    if (intUtils_.isNumericString(pNumText)) {
	      retUnit = this.parensUnits_[Number(pNumText)];
	      if (!intUtils_.isIntegerUnit(retUnit)) {
	        pStr = retUnit.csCode_;
	      } else {
	        pStr = retUnit;
	      }
	    }
	    // If it's not a number, it's a programming error.  Throw a fit.
	    else {
	      throw new Error(`Processing error - invalid parens number ${pNumText} ` + `found in ${pStr}.`);
	    }

	    // If there's something in front of the starting parentheses flag, check to
	    // see if it's a number or an annotation.
	    if (befText) {
	      // If it's a number, assume that multiplication was assumed
	      if (intUtils_.isNumericString(befText)) {
	        let nMag = retUnit.getProperty('magnitude_');
	        nMag *= Number(befText);
	        retUnit.assignVals({
	          'magnitude_': nMag
	        });
	        pStr = `${befText}.${pStr}`;
	        this.retMsg_.push(`${befText}${pStr} is not a valid UCUM code.\n` + this.vcMsgStart_ + pStr + this.vcMsgEnd_);
	      } else {
	        if (befText.indexOf(this.braceFlag_) >= 0) {
	          let annoRet = this._getAnnoText(befText, origString);
	          // if we found not only an annotation, but text before or after
	          // the annotation (remembering that this is all before the
	          // parentheses) throw an error - because we don't know what
	          // to do with it.  Could it be missing an operator?
	          if (annoRet[1] || annoRet[2]) {
	            throw new Error(`Text found before the parentheses (` + `${befText}) included an annotation along with other text ` + `for parenthetical unit ${retUnit.csCode_}`);
	          }
	          // Otherwise put the annotation after the unit string and note
	          // the misplacement.
	          pStr += annoRet[0];
	          this.retMsg_.push(`The annotation ${annoRet[0]} before the unit ` + `code is invalid.\n` + this.vcMsgStart_ + pStr + this.vcMsgEnd_);
	        }
	        // else the text before the parentheses is neither a number nor
	        // an annotation.  If suggestions were NOT requested, record an
	        // error.
	        else if (!this.suggestions_) {
	          this.retMsg_.push(`${befText} preceding the unit code ${pStr} ` + `is invalid.  Unable to make a substitution.`);
	          endProcessing = true;
	        }
	        // otherwise try for suggestions
	        else {
	          let suggestStat = this._getSuggestions(befText);
	          endProcessing = suggestStat !== 'succeeded';
	        } // end if a brace was found or, if not, suggestions were not or
	        // were requested
	      } // end if text preceding the parentheses was not a number
	    } // end if there was text before the parentheses

	    // Process any text after the parentheses
	    if (aftText) {
	      // if it's an annotation, get it and add it to the pStr
	      if (aftText.indexOf(this.braceFlag_) >= 0) {
	        let annoRet = this._getAnnoText(aftText, origString);
	        // if we found not only an annotation, but text before or after
	        // the annotation (remembering that this is all after the
	        // parentheses) throw an error - because we don't know what
	        // to do with it.  Could it be missing an operator?
	        if (annoRet[1] || annoRet[2]) {
	          throw new Error(`Text found after the parentheses (` + `${aftText}) included an annotation along with other text ` + `for parenthetical unit ${retUnit.csCode_}`);
	        }
	        // Otherwise put the annotation after the unit string - no message
	        // needed.
	        pStr += annoRet[0];
	      }
	      // Otherwise check to see if it's an exponent.  If so, warn the
	      // user that it's not valid - but try it anyway
	      else {
	        if (intUtils_.isNumericString(aftText)) {
	          retUnit = null;
	          let msg = `An exponent (${aftText}) following a parenthesis ` + `is invalid as of revision 1.9 of the UCUM Specification.`;
	          // Add the suggestion only if the string in the parenthesis don't end with a number.
	          if (!pStr.match(/\d$/)) {
	            pStr += aftText;
	            msg += '\n  ' + this.vcMsgStart_ + pStr + this.vcMsgEnd_;
	          }
	          this.retMsg_.push(msg);
	          endProcessing = true;
	        }
	        // else the text after the parentheses is neither a number nor
	        // an annotation.  If suggestions were NOT requested, record an
	        // error.
	        else if (!this.suggestions_) {
	          this.retMsg_.push(`Text ${aftText} following the unit code ${pStr} ` + `is invalid.  Unable to make a substitution.`);
	          endProcessing = true;
	        }
	        // otherwise try for suggestions
	        else {
	          let suggestStat = this._getSuggestions(befText);
	          endProcessing = suggestStat !== 'succeeded';
	        } // end if text following the parentheses not an exponent
	      } // end if text following the parentheses is not an annotation
	    } // end if there is text following the parentheses
	    if (!endProcessing) {
	      if (!retUnit) {
	        retUnit = new Unit({
	          'csCode_': pStr,
	          'magnitude_': 1,
	          'name_': pStr
	        });
	      } else if (intUtils_.isIntegerUnit(retUnit)) {
	        retUnit = new Unit({
	          'csCode_': retUnit,
	          'magnitude_': retUnit,
	          'name_': retUnit
	        });
	      } else {
	        retUnit.csCode_ = pStr;
	      }
	    }
	    return [retUnit, endProcessing];
	  } // end _getParensUnit

	  /**
	   * Takes a unit string containing annotation flags and returns the
	   * annotation they represent.  This also returns any text found before
	   * the annotation and any found after the annotation.
	   *
	   * This should only be called from within this class (or by test code).
	   * NEEDS FIX in next branch to handle string with multiple annotations.
	   *
	   * @param pStr the string being parsed
	   * @param origString the original string being parsed; used in error msg
	   *  thrown for an invalid index to the annotations array
	   * @returns
	   *  an array containing
	   *    the annotation for the pStr;
	   *    any text found before the annotation; and
	   *    any text found after the annotation.
	   *
	   * the this.retMsg_ array will be updated with any user messages
	   *   (informational, error or warning) generated by this or called methods
	   * the this.annotations_ array is used as the source for the annotations text
	   * @throws an error if for a processing error - an invalid annotation index.
	   */
	  _getAnnoText(pStr, origString) {
	    // if the starting braces flag is not at index 0, get the starting
	    // text and the adjust the pStr to omit it.
	    let asIdx = pStr.indexOf(this.braceFlag_);
	    let startText = asIdx > 0 ? pStr.substring(0, asIdx) : null;
	    if (asIdx !== 0) {
	      pStr = pStr.substr(asIdx);
	    }

	    // Get the location of the end flag and, if text follows it, get the text
	    let aeIdx = pStr.indexOf(this.braceFlag_, 1);
	    let endText = aeIdx + this.bFlagLen_ < pStr.length ? pStr.substr(aeIdx + this.bFlagLen_) : null;

	    // Get the index of the annotation in this.annotations_.
	    // Check it to make sure it's valid, and if not, throw an error
	    let idx = pStr.substring(this.bFlagLen_, aeIdx);
	    let idxNum = Number(idx);
	    if (!intUtils_.isNumericString(idx) || idxNum >= this.annotations_.length) {
	      throw new Error(`Processing Error - invalid annotation index ${idx} found ` + `in ${pStr} that was created from ${origString}`);
	    }

	    // Replace the flags and annotation index with the annotation expression
	    pStr = this.annotations_[idxNum];
	    return [pStr, startText, endText];
	  } // end _getAnnoText

	  /**
	   * Takes a unit string and looks for suggested units.  This should be
	   * called for unit strings that cannot be resolved to unit codes.  The
	   * string is searched for in the synonyms table found in the UnitTables
	   * class.  That table includes all synonyms and unit names for the units
	   * in the unit data table.
	   *
	   * @param pStr the string being parsed
	   * @returns an object that contains an element named 'status', whose
	   *  value indicates the status of the request:
	   *   'succeeded' indicates that synonyms were found;
	   *   'failed' indicates that no synonyms were found; or
	   *   'error' which indicates that an error occurred
	   *
	   * the this.retMsg_ array will be updated with a message indicating whether
	   *  or not synonyms/suggestions  were found
	   * the this.suggestions_ array will be updated with a hash (added to the
	   *   array if it already contains others) that contains three elements:
	   *   'msg' which is a message indicating what unit expression the
	   *      suggestions are for;
	   *   'invalidUnit' which is the unit expression the suggestions are for; and
	   *   'units' which is an array of data for each suggested unit found.
	   *       Each array will contain the unit code, the unit name and the
	   *       unit guidance (if any).
	   */
	  _getSuggestions(pStr) {
	    let retObj = intUtils_.getSynonyms(pStr);
	    if (retObj['status'] === 'succeeded') {
	      let suggSet = {};
	      suggSet['msg'] = `${pStr} is not a valid UCUM code.  We found possible ` + `units that might be what was meant:`;
	      suggSet['invalidUnit'] = pStr;
	      let synLen = retObj['units'].length;
	      suggSet['units'] = [];
	      for (let s = 0; s < synLen; s++) {
	        let unit = retObj['units'][s];
	        let unitArray = [unit['code'], unit['name'], unit['guidance']];
	        suggSet['units'].push(unitArray);
	      }
	      this.suggestions_.push(suggSet);
	    } else {
	      this.retMsg_.push(`${pStr} is not a valid UCUM code.  No alternatives ` + `were found.`);
	    }
	    return retObj['status'];
	  } // end getSuggestions

	  /**
	   * Creates a unit object from a string defining one unit.  The string
	   * should consist of a unit code for a unit already defined (base or
	   * otherwise).  It may include a prefix and an exponent, e.g., cm2
	   * (centimeter squared).  This should only be called from within this
	   * class (or by test code).
	   *
	   * @params uCode the string defining the unit
	   * @param origString the original string to be parsed; used to provide
	   *  context for messages
	   * @returns
	   *  an array containing:
	   *    a unit object, or null if there were problems creating the unit; and
	   *    the origString passed in, which may be updated if a unit name was
	   *    translated to a unit code.
	   *
	   *  the this.retMsg_ array will be updated with any user messages
	   *    (informational, error or warning) generated by this or called methods
	   *  the this.suggestions_ array will be populated if no unit (with or without
	   *    substitutions) could be found and suggestions were requested
	   */
	  _makeUnit(uCode, origString) {
	    // First try the code just as is, without looking for annotations,
	    // prefixes, exponents, or elephants.
	    let retUnit = this.utabs_.getUnitByCode(uCode);
	    if (retUnit) {
	      retUnit = retUnit.clone();
	    }

	    // If we found it, we're done.  No need to parse for those elephants (or
	    // other stuff).
	    else if (uCode.indexOf(this.braceFlag_) >= 0) {
	      let getAnnoRet = this._getUnitWithAnnotation(uCode, origString);
	      retUnit = getAnnoRet[0];
	      if (retUnit) {
	        origString = getAnnoRet[1];
	      }
	      // If a unit is not found, retUnit will be returned null and
	      // the this.retMsg_ array will contain a message describing the problem.
	      // If a unit is found, of course, all is good. So ... nothing left
	      // to see here, move along.
	    } // end if the uCode includes an annotation
	    else {
	      // So we didn't find a unit for the full uCode or for one with
	      // annotations.  Try looking for a unit that uses a carat (^)
	      // instead of an asterisk (*)

	      if (uCode.indexOf('^') > -1) {
	        let tryCode = uCode.replace('^', '*');
	        retUnit = this.utabs_.getUnitByCode(tryCode);
	        if (retUnit) {
	          retUnit = retUnit.clone();
	          retUnit.csCode_ = retUnit.csCode_.replace('*', '^');
	          retUnit.ciCode_ = retUnit.ciCode_.replace('*', '^');
	        }
	      }
	      // If that didn't work, check to see if it should have brackets
	      // around it (uCode = degF when it should be [degF]
	      if (!retUnit) {
	        let addBrackets = '[' + uCode + ']';
	        retUnit = this.utabs_.getUnitByCode(addBrackets);
	        if (retUnit) {
	          retUnit = retUnit.clone();
	          origString = origString.replace(uCode, addBrackets);
	          this.retMsg_.push(`${uCode} is not a valid unit expression, but ` + `${addBrackets} is.\n` + this.vcMsgStart_ + `${addBrackets} (${retUnit.name_})${this.vcMsgEnd_}`);
	        } // end if we found the unit after adding brackets
	      } // end trying to add brackets

	      // If we didn't find it, try it as a name
	      if (!retUnit) {
	        let retUnitAry = this.utabs_.getUnitByName(uCode);
	        if (retUnitAry && retUnitAry.length > 0) {
	          retUnit = retUnitAry[0].clone();
	          let mString = 'The UCUM code for ' + uCode + ' is ' + retUnit.csCode_ + '.\n' + this.vcMsgStart_ + retUnit.csCode_ + this.vcMsgEnd_;
	          let dupMsg = false;
	          for (let r = 0; r < this.retMsg_.length && !dupMsg; r++) dupMsg = this.retMsg_[r] === mString;
	          if (!dupMsg) this.retMsg_.push(mString);
	          let rStr = new RegExp('(^|[.\/({])(' + uCode + ')($|[.\/)}])');
	          let res = origString.match(rStr);
	          origString = origString.replace(rStr, res[1] + retUnit.csCode_ + res[3]);
	          uCode = retUnit.csCode_;
	        }
	      }

	      // If we still don't have a unit, try assuming a modifier (prefix and/or
	      // exponent) and look for a unit without the modifier
	      if (!retUnit) {
	        // Well, first see if it's one of the special units.  If so,
	        // replace the placeholder text with the actual unit string, keeping
	        // whatever text (probably a prefix) goes with the unit string.
	        let sUnit = null;
	        for (sUnit in Ucum.specUnits_) {
	          if (uCode.indexOf(Ucum.specUnits_[sUnit]) !== -1) uCode = uCode.replace(Ucum.specUnits_[sUnit], sUnit);
	        }
	        retUnit = this.utabs_.getUnitByCode(uCode);
	        if (retUnit) retUnit = retUnit.clone();
	      }
	      if (!retUnit) {
	        let origCode = uCode;
	        let origUnit = null;
	        let exp = null;
	        let pfxCode = null;
	        let pfxObj = null;
	        let pfxVal = null;
	        let pfxExp = null;

	        // Look first for an exponent.  If we got one, separate it out and
	        // try to get the unit again
	        let codeAndExp = this._isCodeWithExponent(uCode);
	        if (codeAndExp) {
	          uCode = codeAndExp[0];
	          exp = codeAndExp[1];
	          origUnit = this.utabs_.getUnitByCode(uCode);
	        }

	        // If an exponent is found but it's not a valid number, e.g. "2-1",
	        // mark the unit invalid. Otherwise, the "-1" part will be ignored
	        // because parseInt("2-1") results in 2. See LF-2870.
	        if (exp && isNaN(exp)) {
	          retUnit = null;
	          this.retMsg_.push(`${origCode} is not a valid UCUM code.`);
	        } else {
	          // If we still don't have a unit, separate out the prefix, if any,
	          // and try without it.
	          if (!origUnit) {
	            // Try for a single character prefix first.
	            pfxCode = uCode.charAt(0);
	            pfxObj = this.pfxTabs_.getPrefixByCode(pfxCode);

	            // if we got a prefix, get its info and remove it from the unit code
	            if (pfxObj) {
	              pfxVal = pfxObj.getValue();
	              pfxExp = pfxObj.getExp();
	              let pCodeLen = pfxCode.length;
	              uCode = uCode.substr(pCodeLen);

	              // try again for the unit
	              origUnit = this.utabs_.getUnitByCode(uCode);

	              // If we still don't have a unit, see if the prefix could be the
	              // two character "da" (deka) prefix.  That's the only prefix with
	              // two characters, and without this check it's interpreted as "d"
	              // (deci) and the "a" is considered part of the unit code.

	              if (!origUnit && pfxCode == 'd' && uCode.substr(0, 1) == 'a') {
	                pfxCode = 'da';
	                pfxObj = this.pfxTabs_.getPrefixByCode(pfxCode);
	                pfxVal = pfxObj.getValue();
	                uCode = uCode.substr(1);

	                // try one more time for the unit
	                origUnit = this.utabs_.getUnitByCode(uCode);
	              }

	              // Reject the unit we found if it might have another prefix.
	              // Such things are in our tables through the LOINC source_
	              // (ucum.csv) which has guidance and synonyms.  I think it should be
	              // safe to exclude anything whose source is LOINC from having a
	              // prefix.
	              if (origUnit && origUnit.source_ == 'LOINC') origUnit = null;
	            } // end if we found a prefix
	          } // end if we didn't get a unit after removing an exponent

	          // If we still haven't found anything, we're done looking.
	          // (We tried with the full unit string, with the unit string
	          // without the exponent, the unit string without a prefix,
	          // common errors, etc. That's all we can try).
	          if (!origUnit) {
	            retUnit = null;
	            // BUT if the user asked for suggestions, at least look for them
	            if (this.suggestions_) {
	              this._getSuggestions(origCode);
	            } else {
	              this.retMsg_.push(`${origCode} is not a valid UCUM code.`);
	            }
	          } else {
	            // Otherwise we found a unit object.  Clone it and then apply the
	            // prefix and exponent, if any, to it.  And remove the guidance.
	            retUnit = origUnit.clone();
	            // If we are here, this is only part of the full unit string, so it is
	            // not a base unit, and the synonyms will mostly likely not be correct for the full
	            // string.
	            retUnit.resetFieldsForDerivedUnit();
	            let theDim = retUnit.getProperty('dim_');
	            let theMag = retUnit.getProperty('magnitude_');
	            let theName = retUnit.getProperty('name_');
	            let theCiCode = retUnit.getProperty('ciCode_');
	            let thePrintSymbol = retUnit.getProperty('printSymbol_');
	            // If there is an exponent for the unit, apply it to the dimension
	            // and magnitude now
	            if (exp) {
	              exp = parseInt(exp);
	              let expMul = exp;
	              if (theDim) theDim = theDim.mul(exp);
	              theMag = Math.pow(theMag, exp);
	              retUnit.assignVals({
	                'magnitude_': theMag
	              });

	              // If there is also a prefix, apply the exponent to the prefix.
	              if (pfxObj) {
	                // if the prefix base is 10 it will have an exponent.  Multiply
	                // the current prefix exponent by the exponent for the unit
	                // we're working with.  Then raise the prefix value to the level
	                // defined by the exponent.
	                if (pfxExp) {
	                  expMul *= pfxObj.getExp();
	                  pfxVal = Math.pow(10, expMul);
	                }
	                // If the prefix base is not 10, it won't have an exponent.
	                // At the moment I don't see any units using the prefixes
	                // that aren't base 10.   But if we get one the prefix value
	                // will be applied to the magnitude (below) if the unit does
	                // not have a conversion function, and to the conversion prefix
	                // if it does.
	              } // end if there's a prefix as well as the exponent
	            } // end if there's an exponent

	            // Now apply the prefix, if there is one, to the conversion
	            // prefix or the magnitude
	            if (pfxObj) {
	              if (retUnit.cnv_) {
	                retUnit.assignVals({
	                  'cnvPfx_': pfxVal
	                });
	              } else {
	                theMag *= pfxVal;
	                retUnit.assignVals({
	                  'magnitude_': theMag
	                });
	              }
	            }
	            // if we have a prefix and/or an exponent, add them to the unit
	            // attributes - name, csCode, ciCode and print symbol
	            let theCode = retUnit.csCode_;
	            if (pfxObj) {
	              theName = pfxObj.getName() + theName;
	              theCode = pfxCode + theCode;
	              theCiCode = pfxObj.getCiCode() + theCiCode;
	              thePrintSymbol = pfxObj.getPrintSymbol() + thePrintSymbol;
	              retUnit.assignVals({
	                'name_': theName,
	                'csCode_': theCode,
	                'ciCode_': theCiCode,
	                'printSymbol_': thePrintSymbol
	              });
	            }
	            if (exp) {
	              let expStr = exp.toString();
	              retUnit.assignVals({
	                'name_': theName + '<sup>' + expStr + '</sup>',
	                'csCode_': theCode + expStr,
	                'ciCode_': theCiCode + expStr,
	                'printSymbol_': thePrintSymbol + '<sup>' + expStr + '</sup>'
	              });
	            }
	          } // end if an original unit was found (without prefix and/or exponent)
	        } // end if an invalid exponent wasn't found
	      } // end if we didn't get a unit for the full unit code (w/out modifiers)
	    } // end if we didn't find the unit on the first try, before parsing
	    return [retUnit, origString];
	  } // end _makeUnit

	  /**
	   * This method handles unit creation when an annotation is included
	   * in the unit string.  This basically isolates and retrieves the
	   * annotation and then calls _makeUnit to try to get a unit from
	   * any text that precedes or follows the annotation.
	   *
	   * @param uCode the string defining the unit
	   * @param origString the original full string submitted to parseString
	   * @returns the unit object found, or null if one could not be found
	   *
	   * the this.retMsg_ array will be updated with any user messages
	   *   (informational, error or warning) generated by this or called methods
	   */
	  _getUnitWithAnnotation(uCode, origString) {
	    let retUnit = null;

	    // Get the annotation and anything that precedes or follows it.
	    let annoRet = this._getAnnoText(uCode, origString);
	    let annoText = annoRet[0];
	    let befAnnoText = annoRet[1];
	    let aftAnnoText = annoRet[2];

	    // Add the warning about annotations - just once.

	    if (this.bracesMsg_ && this.retMsg_.indexOf(this.bracesMsg_) === -1) this.retMsg_.push(this.bracesMsg_);

	    // If there's no text before or after the annotation, it's probably
	    // something that should be interpreted as a 1, e.g., {KCT'U}.
	    // HOWEVER, it could also be a case where someone used braces instead
	    // of brackets, e.g., {degF} instead of [degF].  Check for that before
	    // we assume it should be a 1.
	    let msgLen = this.retMsg_.length;
	    if (!befAnnoText && !aftAnnoText) {
	      let tryBrackets = '[' + annoText.substring(1, annoText.length - 1) + ']';
	      let mkUnitRet = this._makeUnit(tryBrackets, origString);

	      // Nearly anything inside braces is valid, so we don't want to change the
	      // unit, but we can put the found unit in the message as a sort of
	      // warning.
	      if (mkUnitRet[0]) {
	        retUnit = uCode;
	        this.retMsg_.push(`${annoText} is a valid unit expression, but ` + `did you mean ${tryBrackets} (${mkUnitRet[0].name_})?`);
	      } else {
	        // remove error message generated for trybrackets
	        if (this.retMsg_.length > msgLen) {
	          this.retMsg_.pop();
	        }
	      }

	      // This is the case where the string is only this annotation.
	      // Create and return a unit object, as we do for numeric units in
	      // parseString.
	      retUnit = new Unit({
	        'csCode_': annoText,
	        'ciCode_': annoText,
	        'magnitude_': 1,
	        'name_': annoText
	      });
	    } // end if it's only an annotation
	    else {
	      // if there's text before and no text after, assume the text before
	      // the annotation is the unit code (with an annotation following it).
	      // Call _makeUnit for the text before the annotation.
	      if (befAnnoText && !aftAnnoText) {
	        // make sure that what's before the annoText is not a number, e.g.,
	        // /100{cells}.  But f it is a number, just set the return unit to
	        // the number.
	        if (intUtils_.isIntegerUnit(befAnnoText)) {
	          retUnit = befAnnoText;
	        }
	        // Otherwise try to find a unit
	        else {
	          let mkUnitRet = this._makeUnit(befAnnoText, origString);

	          // if a unit was returned
	          if (mkUnitRet[0]) {
	            retUnit = mkUnitRet[0];
	            retUnit.csCode_ += annoText;
	            origString = mkUnitRet[1];
	          }
	          // Otherwise add a not found message
	          else {
	            this.retMsg_.push(`Unable to find a unit for ${befAnnoText} that ` + `precedes the annotation ${annoText}.`);
	          }
	        }
	      }
	      // else if there's only text after the annotation, try for a unit
	      // from the after text and assume the user put the annotation in
	      // the wrong place (and tell them)
	      else if (!befAnnoText && aftAnnoText) {
	        // Again, test for a number and if it is a number, set the return
	        // unit to the number.
	        if (intUtils_.isIntegerUnit(aftAnnoText)) {
	          retUnit = aftAnnoText + annoText;
	          this.retMsg_.push(`The annotation ${annoText} before the ``${aftAnnoText} is invalid.\n` + this.vcMsgStart_ + retUnit + this.vcMsgEnd_);
	        } else {
	          let mkUnitRet = this._makeUnit(aftAnnoText, origString);
	          if (mkUnitRet[0]) {
	            retUnit = mkUnitRet[0];
	            retUnit.csCode_ += annoText;
	            origString = retUnit.csCode_;
	            this.retMsg_.push(`The annotation ${annoText} before the unit ` + `code is invalid.\n` + this.vcMsgStart_ + retUnit.csCode_ + this.vcMsgEnd_);
	          }
	          // Otherwise add a not found message
	          else {
	            this.retMsg_.push(`Unable to find a unit for ${befAnnoText} that ` + `follows the annotation ${annoText}.`);
	          }
	        }
	      }
	      // else it's got text before AND after the annotation.  Now what?
	      // For now this is an error.  This may be a case of a missing
	      // operator but that is not handled yet.
	      else {
	        this.retMsg_.push(`Unable to find a unit for ${befAnnoText}${annoText}` + `${aftAnnoText}.\nWe are not sure how to interpret text both before ` + `and after the annotation.  Sorry`);
	      }
	    } // else if there's text before/and or after the annotation

	    return [retUnit, origString];
	  } // end _getUnitWithAnnotations

	  /**
	   * Performs unit arithmetic for the units in the units array.  That array
	   * contains units/numbers and the operators (division or multiplication) to
	   * be performed on each unit/unit or unit/number pair in the array.  This
	   * should only be called from within this class (or by test code).
	   *
	   * @params uArray the array that contains the units, numbers and operators
	   *  derived from the unit string passed in to parseString
	   * @param origString the original string to be parsed; used to provide
	   *  context for messages
	   *
	   * @returns a single unit object that is the result of the unit arithmetic
	   *
	   * the this.retMsg_ array will be updated with any user messages
	   *   (informational, error or warning) generated by this or called methods
	   */
	  _performUnitArithmetic(uArray, origString) {
	    let finalUnit = uArray[0]['un'];
	    if (intUtils_.isIntegerUnit(finalUnit)) {
	      finalUnit = new Unit({
	        'csCode_': finalUnit,
	        'ciCode_': finalUnit,
	        'magnitude_': Number(finalUnit),
	        'name_': finalUnit
	      });
	    }
	    let uLen = uArray.length;
	    let endProcessing = false;
	    // Perform the arithmetic for the units, starting with the first 2 units.
	    // We only need to do the arithmetic if we have more than one unit.
	    for (let u2 = 1; u2 < uLen && !endProcessing; u2++) {
	      let nextUnit = uArray[u2]['un'];
	      if (intUtils_.isIntegerUnit(nextUnit)) {
	        nextUnit = new Unit({
	          'csCode_': nextUnit,
	          'ciCode_': nextUnit,
	          'magnitude_': Number(nextUnit),
	          'name_': nextUnit
	        });
	      }
	      if (nextUnit === null || typeof nextUnit !== 'number' && !nextUnit.getProperty) {
	        let msgString = `Unit string (${origString}) contains unrecognized ` + 'element';
	        if (nextUnit) {
	          msgString += ` (${this.openEmph_}${nextUnit.toString()}` + `${this.closeEmph_})`;
	        }
	        msgString += '; could not parse full string.  Sorry';
	        this.retMsg_.push(msgString);
	        endProcessing = true;
	      } else {
	        try {
	          // Is the operation division?
	          let thisOp = uArray[u2]['op'];
	          let isDiv = thisOp === '/';

	          // Perform the operation.  Both the finalUnit and nextUnit
	          // are unit objects.
	          isDiv ? finalUnit = finalUnit.divide(nextUnit) : finalUnit = finalUnit.multiplyThese(nextUnit);
	        } catch (err) {
	          this.retMsg_.unshift(err.message);
	          endProcessing = true;
	          finalUnit = null;
	        }
	      } // end if we have another valid unit/number to process
	    } // end do for each unit after the first one
	    return finalUnit;
	  } // end _performUnitArithmetic

	  /**
	   * This tests a string to see if it starts with characters and ends with
	   * digits.  This is used to test for an exponent on a UCUM code (or what
	   * we think might be a UCUM code).  This is broken out to a separate
	   * function so that the regular expression can be verified to provide the
	   * results we expect, in case someone changes it.  (Per Paul Lynch)
	   * See "Test _isCodeWithExponent method" in testUnitString.spec.js
	   *
	   * This particular regex has been tweaked several times.  This one
	   * works with the following test strings:
	   * "m[H2O]-21 gives ["m[H2O]-21", "m[H2O]", "-21"]
	   * "m[H2O]+21 gives ["m[H2O]+21", "m[H2O]", "+21"]
	   * "m[H2O]21 gives ["m[H2O]-21", "m[H2O]", "21"]
	   * "s2" gives ["s2", "s, "2"]
	   * "kg" gives null
	   * "m[H2O]" gives null
	   * "m[H2O]23X" gives null
	   *
	   * @params uCode the code being tested
	   * @returns an array containing: (1) the code without the exponent (or
	   *  trailing number); and (2) the exponent/trailing number.  Returns null
	   *  if there is no trailing number or something follows the trailing
	   *  number, or if the first part is not characters.
	   */
	  _isCodeWithExponent(uCode) {
	    let ret = [];
	    let res = uCode.match(/(^[^\-\+]+?)([\-\+\d]+)$/);

	    // If we got a return with an exponent, separate the exponent from the
	    // unit and return both (as separate values)
	    if (res && res[2] && res[2] !== "") {
	      ret.push(res[1]);
	      ret.push(res[2]);
	    } // end if we got an exponent
	    else {
	      ret = null;
	    }
	    return ret;
	  } // end _isCodeWithExponent
	} // end class UnitString

	/**
	 *  This function exists ONLY until the original UnitString constructor
	 *  is called for the first time.  It's defined here in case getInstance
	 *  is called before the constructor.   This calls the constructor.
	 *
	 *  The constructor redefines the getInstance function to return the
	 *  singleton UnitString object.  This is based on the UnitTables singleton
	 *  implementation; see more detail in the UnitTables constructor description.
	 *
	 *  @return the singleton UnitString object.
	 */
	unitString.UnitString = UnitString;
	_defineProperty(UnitString, "INVALID_ANNOTATION_CHAR_MSG", 'An invalid character was found in the annotation ');
	_defineProperty(UnitString, "VALID_ANNOTATION_REGEX", /^\{[!-z|~]*\}$/);
	UnitString.getInstance = function () {
	  return new UnitString();
	};

	/*
	// Perform the first request for the object, to set the getInstance method.
	UnitString.getInstance();

	*/
	
	return unitString;
}

var hasRequiredUcumLhcUtils;

function requireUcumLhcUtils () {
	if (hasRequiredUcumLhcUtils) return ucumLhcUtils;
	hasRequiredUcumLhcUtils = 1;

	Object.defineProperty(ucumLhcUtils, "__esModule", {
	  value: true
	});
	ucumLhcUtils.UcumLhcUtils = void 0;
	var _ucumJsonDefs = requireUcumJsonDefs();
	var intUtils_ = _interopRequireWildcard(requireUcumInternalUtils());
	function _getRequireWildcardCache() { if (typeof WeakMap !== "function") return null; var cache = new WeakMap(); _getRequireWildcardCache = function () { return cache; }; return cache; }
	function _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== "object" && typeof obj !== "function") { return { default: obj }; } var cache = _getRequireWildcardCache(); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }
	/**
	 * This class provides a single point of access to the LHC UCUM utilities
	 *
	 * @author Lee Mericle
	 *
	 */
	var Ucum = requireConfig().Ucum;
	var UnitTables = requireUnitTables().UnitTables;
	var UnitString = requireUnitString().UnitString;
	/**
	 * UCUM external utilities class
	 */
	class UcumLhcUtils {
	  /**
	   * Constructor.  This loads the json prefix and unit definitions if
	   * they haven't been loaded already and creates itself as a singleton object.
	   *
	   */
	  constructor() {
	    if (UnitTables.getInstance().unitsCount() === 0) {
	      // Load the prefix and unit objects
	      _ucumJsonDefs.ucumJsonDefs.loadJsonDefs();
	    }

	    // Get the UnitString parser that will be used with this instance
	    // of the LHC Utilities
	    this.uStrParser_ = UnitString.getInstance();
	  } // end constructor

	  /**
	   * This method calls the useHTMLInMessages method on the UnitString
	   * object.  It should be called by web applications that use
	   * these utilities.
	   *
	   * @param use flag indicating whether or not to use the braces message;
	   *  defaults to true
	   */
	  useHTMLInMessages(use) {
	    if (use === undefined) use = true;
	    this.uStrParser_.useHTMLInMessages(use);
	  }

	  /**
	   * This method calls the useBraceMsgForEachString method on the UnitString
	   * object.  It should be called by web applications where unit
	   * strings are validated individually (as opposed to validating a whole
	   * file of unit strings).
	   *
	   * @param use flag indicating whether or not to use the braces message;
	   *  defaults to true
	   */
	  useBraceMsgForEachString(use) {
	    if (use === undefined) use = true;
	    this.uStrParser_.useBraceMsgForEachString(use);
	  }

	  /**
	   * This method validates a unit string.  It first checks to see if the
	   * string passed in is a unit code that is found in the unit codes table.
	   * If it is not found it parses the string to see if it resolves to a
	   * valid unit string.
	   *
	   * If a valid unit cannot be found, the string is tested for some common
	   * errors, such as missing brackets or a missing multiplication operator.
	   * If found, the error is reported in the messages array that is returned.
	   *
	   * If a valid unit cannot be found and an error cannot be discerned, this
	   * may return, if requested, a list of suggested units in the messages
	   * array that is returned.  Suggestions are based on matching the expression
	   * with unit names and synonyms.
	   *
	   * @param uStr the string to be validated
	   * @param suggest a boolean to indicate whether or not suggestions are
	   *  requested for a string that cannot be resolved to a valid unit;
	   *  true indicates suggestions are wanted; false indicates they are not,
	   *  and is the default if the parameter is not specified;
	   * @param valConv a string indicating if this validation request was initiated
	   *  by a validation task ('validate') or a conversion task ('convert'),
	   *  used only for the demo code, and the default is 'Validator' if the
	   *  parameter is not specified;
	   * @returns an object with five properties:
	   *  'status' will be 'valid' (the uStr is a valid UCUM code), 'invalid'
	   *     (the uStr is not a valid UCUM code, and substitutions or
	   *     suggestions may or may not be returned, depending on what was
	   *     requested and found); or 'error' (an input or programming error
	   *     occurred);
	   *  'ucumCode' the valid ucum code, which may differ from what was passed
	   *    in (e.g., if 'Gauss' is passed in, this will contain 'G') OR null if
	   *    the string was flagged as invalid or an error occurred;
	   *  'msg' is an array of one or more messages, if the string is invalid or
	   *        an error occurred, indicating the problem, or an explanation of a
	   *        substitution such as the substitution of 'G' for 'Gauss', or
	   *        an empty array if no messages were generated;
	   *  'unit' which is null if no unit is found, or a hash for a unit found:
	   *    'code' is the unit's ucum code (G in the above example;
	   *    'name' is the unit's name (Gauss in the above example); and
	   *    'guidance' is the unit's guidance/description data; and
	   *  'suggestions' if suggestions were requested and found, this is an array
	   *     of one or more hash objects.  Each hash contains three elements:
	   *     'msg' which is a message indicating what part of the uStr input
	   *        parameter the suggestions are for;
	   *     'invalidUnit' which is the unit expression the suggestions are
	   *        for; and
	   *     'units' which is an array of data for each suggested unit found.
	   *        Each array will contain the unit code, the unit name and the
	   *        unit guidance (if any).
	   *     If no suggestions were requested and found, this property is not
	   *     returned.
	   */
	  validateUnitString(uStr, suggest, valConv) {
	    if (suggest === undefined) suggest = false;
	    if (valConv === undefined) valConv = 'validate';
	    let resp = this.getSpecifiedUnit(uStr, valConv, suggest);
	    let theUnit = resp['unit'];
	    let retObj = !theUnit ? {
	      'ucumCode': null
	    } : {
	      'ucumCode': resp['origString'],
	      'unit': {
	        'code': theUnit.csCode_,
	        'name': theUnit.name_,
	        'guidance': theUnit.guidance_
	      }
	    };
	    retObj.status = resp.status;
	    if (resp['suggestions']) {
	      retObj['suggestions'] = resp['suggestions'];
	    }
	    retObj['msg'] = resp['retMsg'];
	    return retObj;
	  } // end validateUnitString

	  /**
	   * This method converts one unit to another
	   *
	   * @param fromUnitCode the unit code/expression/string of the unit to be converted
	   * @param fromVal the number of "from" units to be converted to "to" units
	   * @param toUnitCode the unit code/expression/string of the unit that the from
	   *  field is to be converted to
	   * @param suggest a boolean to indicate whether or not suggestions are
	   *  requested for a string that cannot be resolved to a valid unit;
	   *  true indicates suggestions are wanted; false indicates they are not,
	   *  and is the default if the parameter is not specified;
	   * @param molecularWeight the molecular weight of the substance in question
	   *  when a conversion is being requested from mass to moles and vice versa.
	   *  This is required when one of the units represents a value in moles.  It is
	   *  ignored if neither unit includes a measurement in moles.
	   * @returns a hash with six elements:
	   *  'status' that will be: 'succeeded' if the conversion was successfully
	   *     calculated; 'failed' if the conversion could not be made, e.g., if
	   *     the units are not commensurable; or 'error' if an error occurred;
	   *  'toVal' the numeric value indicating the conversion amount, or null
	   *     if the conversion failed (e.g., if the units are not commensurable);
	   *  'msg' is an array message, if the string is invalid or an error occurred,
	   *        indicating the problem, or an explanation of a substitution such as
	   *        the substitution of 'G' for 'Gauss', or an empty array if no
	   *        messages were generated;
	   *  'suggestions' if suggestions were requested and found, this is a hash
	   *     that contains at most two elements:
	   *     'from' which, if the fromUnitCode input parameter or one or more of
	   *       its components could not be found, is an array one or more hash
	   *       objects.  Each hash contains three elements:
	   *         'msg' which is a message indicating what unit expression the
	   *            suggestions are for;
	   *         'invalidUnit' which is the unit expression the suggestions
	   *            are for; and
	   *         'units' which is an array of data for each suggested unit found.
	   *            Each array will contain the unit code, the unit name and the
	   *            unit guidance (if any).
	   *       If no suggestions were found for the fromUnitCode this element
	   *       will not be included.
	   *     'to' which, if the "to" unit expression or one or more of its
	   *       components could not be found, is an array one or more hash objects.  Each hash
	   *       contains three elements:
	   *         'msg' which is a message indicating what toUnitCode input
	   *            parameter the suggestions are for;
	   *         'invalidUnit' which is the unit expression the suggestions
	   *            are for; and
	   *         'units' which is an array of data for each suggested unit found.
	   *            Each array will contain the unit code, the unit name and the
	   *            unit guidance (if any).
	   *       If no suggestions were found for the toUnitCode this element
	   *       will not be included.
	   *    No 'suggestions' element will be included in the returned hash
	   *    object if none were found, whether or not they were requested.
	   *  'fromUnit' the unit object for the fromUnitCode passed in; returned
	   *     in case it's needed for additional data from the object; and
	   *  'toUnit' the unit object for the toUnitCode passed in; returned
	   *     in case it's needed for additional data from the object.
	   */
	  convertUnitTo(fromUnitCode, fromVal, toUnitCode, suggest, molecularWeight) {
	    if (suggest === undefined) suggest = false;
	    if (molecularWeight === undefined) molecularWeight = null;
	    let returnObj = {
	      'status': 'failed',
	      'toVal': null,
	      'msg': []
	    };
	    if (fromUnitCode) {
	      fromUnitCode = fromUnitCode.trim();
	    }
	    if (!fromUnitCode || fromUnitCode == '') {
	      returnObj['status'] = 'error';
	      returnObj['msg'].push('No "from" unit expression specified.');
	    }
	    this._checkFromVal(fromVal, returnObj);
	    if (toUnitCode) {
	      toUnitCode = toUnitCode.trim();
	    }
	    if (!toUnitCode || toUnitCode == '') {
	      returnObj['status'] = 'error';
	      returnObj['msg'].push('No "to" unit expression specified.');
	    }
	    if (returnObj['status'] !== 'error') {
	      try {
	        let fromUnit = null;
	        let parseResp = this.getSpecifiedUnit(fromUnitCode, 'convert', suggest);
	        fromUnit = parseResp['unit'];
	        if (parseResp['retMsg']) returnObj['msg'] = returnObj['msg'].concat(parseResp['retMsg']);
	        if (parseResp['suggestions']) {
	          returnObj['suggestions'] = {};
	          returnObj['suggestions']['from'] = parseResp['suggestions'];
	        }
	        if (!fromUnit) {
	          returnObj['msg'].push(`Unable to find a unit for ${fromUnitCode}, ` + `so no conversion could be performed.`);
	        }
	        let toUnit = null;
	        parseResp = this.getSpecifiedUnit(toUnitCode, 'convert', suggest);
	        toUnit = parseResp['unit'];
	        if (parseResp['retMsg']) returnObj['msg'] = returnObj['msg'].concat(parseResp['retMsg']);
	        if (parseResp['suggestions']) {
	          if (!returnObj['suggestions']) returnObj['suggestions'] = {};
	          returnObj['suggestions']['to'] = parseResp['suggestions'];
	        }
	        if (!toUnit) {
	          returnObj['msg'].push(`Unable to find a unit for ${toUnitCode}, ` + `so no conversion could be performed.`);
	        }
	        if (fromUnit && toUnit) {
	          try {
	            // if no molecular weight was specified perform a normal conversion
	            if (!molecularWeight) {
	              returnObj['toVal'] = toUnit.convertFrom(fromVal, fromUnit);
	            } else {
	              if (fromUnit.moleExp_ !== 0 && toUnit.moleExp_ !== 0) {
	                throw new Error('A molecular weight was specified ' + 'but a mass <-> mole conversion cannot be executed for two ' + 'mole-based units.  No conversion was attempted.');
	              }
	              if (fromUnit.moleExp_ === 0 && toUnit.moleExp_ === 0) {
	                throw new Error('A molecular weight was specified ' + 'but a mass <-> mole conversion cannot be executed when ' + 'neither unit is mole-based.  No conversion was attempted.');
	              }
	              if (!fromUnit.isMoleMassCommensurable(toUnit)) {
	                throw new Error(`Sorry.  ${fromUnitCode} cannot be ` + `converted to ${toUnitCode}.`);
	              }

	              // if the "from" unit is a mole-based unit, assume a mole to mass
	              // request
	              if (fromUnit.moleExp_ !== 0) {
	                returnObj['toVal'] = fromUnit.convertMolToMass(fromVal, toUnit, molecularWeight);
	              }
	              // else the "to" unit must be the mole-based unit, so assume a
	              // mass to mole request
	              else {
	                returnObj['toVal'] = fromUnit.convertMassToMol(fromVal, toUnit, molecularWeight);
	              }
	            } // end if a molecular weight was specified

	            // if an error hasn't been thrown - either from convertFrom or here,
	            // set the return object to show success
	            returnObj['status'] = 'succeeded';
	            returnObj['fromUnit'] = fromUnit;
	            returnObj['toUnit'] = toUnit;
	          } catch (err) {
	            returnObj['status'] = 'failed';
	            returnObj['msg'].push(err.message);
	          }
	        } // end if we have the from and to units
	      } catch (err) {
	        if (err.message == Ucum.needMoleWeightMsg_) returnObj['status'] = 'failed';else returnObj['status'] = 'error';
	        returnObj['msg'].push(err.message);
	      }
	    }
	    return returnObj;
	  } // end convertUnitTo

	  /**
	   *  Converts the given unit string into its base units, their exponents, and
	   *  a magnitude, and returns that data.
	   * @param fromUnit the unit string to be converted to base units information
	   * @param fromVal the number of "from" units to be converted
	   * @returns an object with the properties:
	   *  'status' indicates whether the result succeeded.  The value will be one of:
	   *    'succeeded':  the conversion was successfully calculated (which can be
	   *      true even if it was already in base units);
	   *    'invalid':  fromUnit is not a valid UCUM code;
	   *    'failed':  the conversion could not be made (e.g., if it is an "arbitrary" unit);
	   *    'error':  if an error occurred (an input or programming error)
	   *  'msg': an array of messages (possibly empty) if the string is invalid or
	   *        an error occurred, indicating the problem, or a suggestion of a
	   *        substitution such as the substitution of 'G' for 'Gauss', or
	   *        an empty array if no messages were generated.  There can also be a
	   *        message that is just informational or warning.
	   *  'magnitude': the new value when fromVal units of fromUnits is expressed in the base units.
	   *  'fromUnitIsSpecial': whether the input unit fromUnit is a "special unit"
	   *         as defined in UCUM.  This means there is some function applied to convert
	   *         between fromUnit and the base units, so the returned magnitude is likely not
	   *         useful as a scale factor for other conversions (i.e., it only has validity
	   *         and usefulness for the input values that produced it).
	   *  'unitToExp': a map of base units in fromUnit to their exponent
	   */
	  convertToBaseUnits(fromUnit, fromVal) {
	    let retObj = {};
	    this._checkFromVal(fromVal, retObj);
	    if (!retObj.status) {
	      // could be set to 'error' by _checkFromVal
	      let inputUnitLookup = this.getSpecifiedUnit(fromUnit, 'validate');
	      retObj = {
	        status: inputUnitLookup.status == 'valid' ? 'succeeded' : inputUnitLookup.status
	      };
	      let unit = inputUnitLookup.unit;
	      retObj.msg = inputUnitLookup.retMsg || [];
	      if (!unit) {
	        if (inputUnitLookup.retMsg?.length == 0) retObj.msg.push('Could not find unit information for ' + fromUnit);
	      } else if (unit.isArbitrary_) {
	        retObj.msg.push('Arbitrary units cannot be converted to base units or other units.');
	        retObj.status = 'failed';
	      } else if (retObj.status == 'succeeded') {
	        let unitToExp = {};
	        let dimVec = unit.dim_?.dimVec_;
	        let baseUnitString = '1';
	        if (dimVec) {
	          let dimVecIndexToBaseUnit = UnitTables.getInstance().dimVecIndexToBaseUnit_;
	          for (let i = 0, len = dimVec.length; i < len; ++i) {
	            let exp = dimVec[i];
	            if (exp) {
	              unitToExp[dimVecIndexToBaseUnit[i]] = exp;
	              baseUnitString += '.' + dimVecIndexToBaseUnit[i] + exp;
	            }
	          }
	        }

	        // The unit might have a conversion function, which has to be applied; we
	        // cannot just assume unit_.magnitude_ is the magnitude in base units.
	        let retUnitLookup = this.getSpecifiedUnit(baseUnitString, 'validate');
	        // There should not be any error in retUnitLookup, unless there is a bug.
	        let retUnit = retUnitLookup.unit;
	        if (retUnitLookup.status !== 'valid') {
	          retObj.msg.push('Unable construct base unit string; tried ' + baseUnitString);
	          retObj.status = 'error';
	        } else {
	          try {
	            retObj.magnitude = retUnit.convertFrom(fromVal, unit);
	          } catch (e) {
	            retObj.msg.push(e.toString());
	            retObj.status = 'error';
	          }
	          if (retObj.status == 'succeeded') {
	            retObj.unitToExp = unitToExp;
	            retObj.fromUnitIsSpecial = unit.isSpecial_;
	          }
	        }
	      }
	    }
	    return retObj;
	  }

	  /**
	   *  Checks the given value as to whether it is suitable as a "from" value in a
	   *  unit conversion.  If it is not, the responseObj will have its status set
	   *  to 'error' and a message added.
	   * @param fromVal The value to check
	   * @param responseObj the object that will be updated if the value is not
	   *  usable.
	   */
	  _checkFromVal(fromVal, responseObj) {
	    if (fromVal === null || isNaN(fromVal) || typeof fromVal !== 'number' && !intUtils_.isNumericString(fromVal)) {
	      responseObj.status = 'error';
	      if (!responseObj.msg) responseObj.msg = [];
	      responseObj.msg.push('No "from" value, or an invalid "from" value, ' + 'was specified.');
	    }
	  }

	  /**
	   * This method accepts a term and looks for units that include it as
	   * a synonym - or that include the term in its name.
	   *
	   * @param theSyn the term to search for
	   * @returns a hash with up to three elements:
	   *  'status' contains the status of the request, which can be 'error',
	   *    'failed' or succeeded';
	   *  'msg' which contains a message for an error or if no units were found; and
	   *  'units' which is an array that contains one hash for each unit found:
	   *    'code' is the unit's csCode_
	   *    'name' is the unit's name_
	   *    'guidance' is the unit's guidance_
	   *
	   */
	  checkSynonyms(theSyn) {
	    let retObj = {};
	    if (theSyn === undefined || theSyn === null) {
	      retObj['status'] = 'error';
	      retObj['msg'] = 'No term specified for synonym search.';
	    } else {
	      retObj = intUtils_.getSynonyms(theSyn);
	    } // end if a search synonym was supplied

	    return retObj;
	  } // end checkSynonyms

	  /**
	   * This method parses a unit string to get (or try to get) the unit
	   * represented by the string.  It returns an error message if no string was specified
	   * or if any errors were encountered trying to get the unit.
	   *
	   * @param uName the expression/string representing the unit
	   * @param valConv indicates what type of request this is for - a request to
	   *  validate (pass in 'validate') or a request to convert (pass in 'convert')
	   * @param suggest a boolean to indicate whether or not suggestions are
	   *  requested for a string that cannot be resolved to a valid unit;
	   *  true indicates suggestions are wanted; false indicates they are not,
	   *  and is the default if the parameter is not specified;
	   * @returns a hash containing:
	   *   'status' will be 'valid' (uName is a valid UCUM code), 'invalid'
	   *     (the uStr is not a valid UCUM code, and substitutions or
	   *     suggestions may or may not be returned, depending on what was
	   *     requested and found); or 'error' (an input or programming error
	   *     occurred);
	   *   'unit' the unit object (or null if there were problems creating the
	   *     unit);
	   *   'origString' the possibly updated unit string passed in;
	   *   'retMsg' an array of user messages (informational, error or warning) if
	   *     any were generated (IF any were generated, otherwise will be an
	   *     empty array); and
	   *   'suggestions' is an array of 1 or more hash objects.  Each hash
	   *     contains three elements:
	   *       'msg' which is a message indicating what unit expression the
	   *          suggestions are for;
	   *       'invalidUnit' which is the unit expression the suggestions are
	   *          for; and
	   *       'units' which is an array of data for each suggested unit found.
	   *          Each array will contain the unit code, the unit name and the
	   *          unit guidance (if any).
	   *   The return hash will not contain a suggestions array if a valid unit
	   *   was found or if suggestions were not requested and found.
	   */
	  getSpecifiedUnit(uName, valConv, suggest) {
	    if (suggest === undefined) suggest = false;
	    let retObj = {};
	    retObj['retMsg'] = [];
	    if (!uName) {
	      retObj['retMsg'].push('No unit string specified.');
	    } else {
	      let utab = UnitTables.getInstance();
	      uName = uName.trim();

	      // go ahead and just try using the name as the code.  This may or may not
	      // work, but if it does, it cuts out a lot of parsing.
	      let theUnit = utab.getUnitByCode(uName);

	      // If we found it, set the returned unit string to what was passed in;
	      // otherwise try parsing as a unit string
	      if (theUnit) {
	        retObj['unit'] = theUnit;
	        retObj['origString'] = uName;
	      } else {
	        try {
	          let resp = this.uStrParser_.parseString(uName, valConv, suggest);
	          retObj['unit'] = resp[0];
	          retObj['origString'] = resp[1];
	          if (resp[2]) retObj['retMsg'] = resp[2];
	          retObj['suggestions'] = resp[3];
	        } catch (err) {
	          console.log(`Unit requested for unit string ${uName}.` + 'request unsuccessful; error thrown = ' + err.message);
	          retObj['retMsg'].unshift(`${uName} is not a valid unit.  ` + `${err.message}`);
	        }
	      } // end if the unit was not found as a unit name
	    } // end if a unit expression was specified

	    // Set the status field
	    if (!retObj.unit) {
	      // No unit was found; check whether origString has a value
	      retObj.status = !retObj.origString ? 'error' : 'invalid';
	    } else {
	      // Check whether substitutions were made to the unit string in order to
	      // find the unit
	      retObj.status = retObj.origString === uName ? 'valid' : 'invalid';
	    }
	    return retObj;
	  } // end getSpecifiedUnit

	  /**
	   * This method retrieves a list of units commensurable, i.e., that can be
	   * converted from and to, a specified unit.  Returns an error if the "from"
	   * unit cannot be found.
	   *
	   * @param fromName the name/unit string of the "from" unit
	   * @returns an array containing two elements;
	   *   first element is the list of commensurable units if any were found
	   *   second element is an error message if the "from" unit is not found
	   */
	  commensurablesList(fromName) {
	    let retMsg = [];
	    let commUnits = null;
	    let parseResp = this.getSpecifiedUnit(fromName, 'validate', false);
	    let fromUnit = parseResp['unit'];
	    if (parseResp['retMsg'].length > 0) retMsg = parseResp['retMsg'];
	    if (!fromUnit) {
	      retMsg.push(`Could not find unit ${fromName}.`);
	    } else {
	      let dimVec = null;
	      let fromDim = fromUnit.getProperty('dim_');
	      if (!fromDim) {
	        retMsg.push('No commensurable units were found for ' + fromName);
	      } else {
	        try {
	          dimVec = fromDim.getProperty('dimVec_');
	        } catch (err) {
	          retMsg.push(err.message);
	          if (err.message === "Dimension does not have requested property(dimVec_)") dimVec = null;
	        }
	        if (dimVec) {
	          let utab = UnitTables.getInstance();
	          commUnits = utab.getUnitsByDimension(dimVec);
	        }
	      } // end if the from unit has a dimension vector
	    } // end if we found a "from" unit
	    return [commUnits, retMsg];
	  } // end commensurablesList
	} // end UcumLhcUtils class

	/**
	 *  This function exists ONLY until the original UcumLhcUtils constructor
	 *  is called for the first time.  It's defined here in case getInstance
	 *  is called before the constructor.   This calls the constructor.
	 *
	 *  The constructor redefines the getInstance function to return the
	 *  singleton UcumLhcUtils object.  This is based on the UnitTables singleton
	 *  implementation; see more detail in the UnitTables constructor description.
	 *
	 *  NO LONGER TRUE - not implemented as a singleton.  This method retained to
	 *  avoid problems with calls to it that exist throughout the code.
	 *
	 *  @return the (formerly singleton) UcumLhcUtils object.
	 */
	ucumLhcUtils.UcumLhcUtils = UcumLhcUtils;
	UcumLhcUtils.getInstance = function () {
	  return new UcumLhcUtils();
	};
	
	return ucumLhcUtils;
}

var hasRequiredUcumPkg;

function requireUcumPkg () {
	if (hasRequiredUcumPkg) return ucumPkg;
	hasRequiredUcumPkg = 1;

	Object.defineProperty(ucumPkg, "__esModule", {
	  value: true
	});
	ucumPkg.UnitTables = ucumPkg.UcumLhcUtils = ucumPkg.Ucum = void 0;
	/**
	 * This exports definitions for ucum classes that need references to them
	 * available to the demo code.  The actual code will be in the ucumPkg
	 * library found in the dist directory.  This file provides the hooks to
	 * those classes within the library.
	 */

	var Ucum = requireConfig().Ucum;
	ucumPkg.Ucum = Ucum;
	var UcumLhcUtils = requireUcumLhcUtils().UcumLhcUtils;
	ucumPkg.UcumLhcUtils = UcumLhcUtils;
	var UnitTables = requireUnitTables().UnitTables;
	ucumPkg.UnitTables = UnitTables;
	
	return ucumPkg;
}

let numberFns = {};

// Returns the number of digits in the number after the decimal point, ignoring
// trailing zeros.
function decimalPlaces(x) {
  // Based on https://stackoverflow.com/a/9539746/360782
  // Make sure it is a number and use the builtin number -> string.
  const s = "" + (+x),
    match = /(\d+)(?:\.(\d+))?(?:[eE]([+-]?\d+))?$/.exec(s);
  // NaN or Infinity or integer.
  // We arbitrarily decide that Infinity is integral.
  if (!match) { return 0; }
  // Count the number of digits in the fraction and subtract the
  // exponent to simulate moving the decimal point left by exponent places.
  // 1.234e+2 has 1 fraction digit and '234'.length -  2 == 1
  // 1.234e-2 has 5 fraction digit and '234'.length - -2 == 5
  //var wholeNum = match[1];
  const fraction = match[2],
    exponent = match[3];
  return Math.max(
    0,  // lower limit.
    (fraction === '0' ? 0 : (fraction || '').length)  // fraction length
    - (exponent || 0));  // exponent
}

/**
 *  Rounds a number to the specified number of decimal places.
 * @param x the decimal number to be rounded
 * @param n the (maximum) number of decimal places to preserve.  (The result
 *  could contain fewer if the decimal digits in x contain zeros).
 */
function roundToDecimalPlaces (x, n) {
  const scale = Math.pow(10, n);
  return Math.round(x*scale)/scale;
}

/**
 *  The smallest representable number in FHIRPath.
 */
const PRECISION_STEP = 1e-8;

/**
 *  Rounds a number to the nearest multiple of PRECISION_STEP.
 */
const roundToMaxPrecision$1 = numberFns.roundToMaxPrecision = function (x) {
  return Math.round(x/PRECISION_STEP)*PRECISION_STEP;
};

/**
 * Determines numbers equivalence
 * @param {number} actual
 * @param {number} expected
 * @return {boolean}
 */
numberFns.isEquivalent = function(actual, expected) {
  if(Number.isInteger(actual) && Number.isInteger(expected)) {
    return actual === expected;
  }

  const prec = Math.min(decimalPlaces(actual), decimalPlaces(expected));

  if(prec === 0){
    return Math.round(actual) === Math.round(expected);
  } else {
    // Note: parseFloat(0.00000011).toPrecision(7) ===  "1.100000e-7"
    // It does # of significant digits, not decimal places.
    return roundToDecimalPlaces(actual, prec) ===
      roundToDecimalPlaces(expected, prec);
  }
};

/**
 * Determines numbers equality
 * @param {number} actual
 * @param {number} expected
 * @return {boolean}
 */
numberFns.isEqual = function(actual, expected) {
  return roundToMaxPrecision$1(actual) === roundToMaxPrecision$1(expected);
};

var numbers$2 = numberFns;

var get_days_in_month;
var hasRequiredGet_days_in_month;

function requireGet_days_in_month () {
	if (hasRequiredGet_days_in_month) return get_days_in_month;
	hasRequiredGet_days_in_month = 1;
	var parse = requireParse();

	/**
	 * @category Month Helpers
	 * @summary Get the number of days in a month of the given date.
	 *
	 * @description
	 * Get the number of days in a month of the given date.
	 *
	 * @param {Date|String|Number} date - the given date
	 * @returns {Number} the number of days in a month
	 *
	 * @example
	 * // How many days are in February 2000?
	 * var result = getDaysInMonth(new Date(2000, 1))
	 * //=> 29
	 */
	function getDaysInMonth (dirtyDate) {
	  var date = parse(dirtyDate);
	  var year = date.getFullYear();
	  var monthIndex = date.getMonth();
	  var lastDayOfMonth = new Date(0);
	  lastDayOfMonth.setFullYear(year, monthIndex + 1, 0);
	  lastDayOfMonth.setHours(0, 0, 0, 0);
	  return lastDayOfMonth.getDate()
	}

	get_days_in_month = getDaysInMonth;
	return get_days_in_month;
}

var add_months;
var hasRequiredAdd_months;

function requireAdd_months () {
	if (hasRequiredAdd_months) return add_months;
	hasRequiredAdd_months = 1;
	var parse = requireParse();
	var getDaysInMonth = requireGet_days_in_month();

	/**
	 * @category Month Helpers
	 * @summary Add the specified number of months to the given date.
	 *
	 * @description
	 * Add the specified number of months to the given date.
	 *
	 * @param {Date|String|Number} date - the date to be changed
	 * @param {Number} amount - the amount of months to be added
	 * @returns {Date} the new date with the months added
	 *
	 * @example
	 * // Add 5 months to 1 September 2014:
	 * var result = addMonths(new Date(2014, 8, 1), 5)
	 * //=> Sun Feb 01 2015 00:00:00
	 */
	function addMonths (dirtyDate, dirtyAmount) {
	  var date = parse(dirtyDate);
	  var amount = Number(dirtyAmount);
	  var desiredMonth = date.getMonth() + amount;
	  var dateWithDesiredMonth = new Date(0);
	  dateWithDesiredMonth.setFullYear(date.getFullYear(), desiredMonth, 1);
	  dateWithDesiredMonth.setHours(0, 0, 0, 0);
	  var daysInMonth = getDaysInMonth(dateWithDesiredMonth);
	  // Set the last day of the new month
	  // if the original date was the last day of the longer month
	  date.setMonth(desiredMonth, Math.min(daysInMonth, date.getDate()));
	  return date
	}

	add_months = addMonths;
	return add_months;
}

var add_years;
var hasRequiredAdd_years;

function requireAdd_years () {
	if (hasRequiredAdd_years) return add_years;
	hasRequiredAdd_years = 1;
	var addMonths = requireAdd_months();

	/**
	 * @category Year Helpers
	 * @summary Add the specified number of years to the given date.
	 *
	 * @description
	 * Add the specified number of years to the given date.
	 *
	 * @param {Date|String|Number} date - the date to be changed
	 * @param {Number} amount - the amount of years to be added
	 * @returns {Date} the new date with the years added
	 *
	 * @example
	 * // Add 5 years to 1 September 2014:
	 * var result = addYears(new Date(2014, 8, 1), 5)
	 * //=> Sun Sep 01 2019 00:00:00
	 */
	function addYears (dirtyDate, dirtyAmount) {
	  var amount = Number(dirtyAmount);
	  return addMonths(dirtyDate, amount * 12)
	}

	add_years = addYears;
	return add_years;
}

var add_days;
var hasRequiredAdd_days;

function requireAdd_days () {
	if (hasRequiredAdd_days) return add_days;
	hasRequiredAdd_days = 1;
	var parse = requireParse();

	/**
	 * @category Day Helpers
	 * @summary Add the specified number of days to the given date.
	 *
	 * @description
	 * Add the specified number of days to the given date.
	 *
	 * @param {Date|String|Number} date - the date to be changed
	 * @param {Number} amount - the amount of days to be added
	 * @returns {Date} the new date with the days added
	 *
	 * @example
	 * // Add 10 days to 1 September 2014:
	 * var result = addDays(new Date(2014, 8, 1), 10)
	 * //=> Thu Sep 11 2014 00:00:00
	 */
	function addDays (dirtyDate, dirtyAmount) {
	  var date = parse(dirtyDate);
	  var amount = Number(dirtyAmount);
	  date.setDate(date.getDate() + amount);
	  return date
	}

	add_days = addDays;
	return add_days;
}

var add_weeks;
var hasRequiredAdd_weeks;

function requireAdd_weeks () {
	if (hasRequiredAdd_weeks) return add_weeks;
	hasRequiredAdd_weeks = 1;
	var addDays = requireAdd_days();

	/**
	 * @category Week Helpers
	 * @summary Add the specified number of weeks to the given date.
	 *
	 * @description
	 * Add the specified number of week to the given date.
	 *
	 * @param {Date|String|Number} date - the date to be changed
	 * @param {Number} amount - the amount of weeks to be added
	 * @returns {Date} the new date with the weeks added
	 *
	 * @example
	 * // Add 4 weeks to 1 September 2014:
	 * var result = addWeeks(new Date(2014, 8, 1), 4)
	 * //=> Mon Sep 29 2014 00:00:00
	 */
	function addWeeks (dirtyDate, dirtyAmount) {
	  var amount = Number(dirtyAmount);
	  var days = amount * 7;
	  return addDays(dirtyDate, days)
	}

	add_weeks = addWeeks;
	return add_weeks;
}

var add_hours;
var hasRequiredAdd_hours;

function requireAdd_hours () {
	if (hasRequiredAdd_hours) return add_hours;
	hasRequiredAdd_hours = 1;
	var addMilliseconds = requireAdd_milliseconds();

	var MILLISECONDS_IN_HOUR = 3600000;

	/**
	 * @category Hour Helpers
	 * @summary Add the specified number of hours to the given date.
	 *
	 * @description
	 * Add the specified number of hours to the given date.
	 *
	 * @param {Date|String|Number} date - the date to be changed
	 * @param {Number} amount - the amount of hours to be added
	 * @returns {Date} the new date with the hours added
	 *
	 * @example
	 * // Add 2 hours to 10 July 2014 23:00:00:
	 * var result = addHours(new Date(2014, 6, 10, 23, 0), 2)
	 * //=> Fri Jul 11 2014 01:00:00
	 */
	function addHours (dirtyDate, dirtyAmount) {
	  var amount = Number(dirtyAmount);
	  return addMilliseconds(dirtyDate, amount * MILLISECONDS_IN_HOUR)
	}

	add_hours = addHours;
	return add_hours;
}

var add_seconds;
var hasRequiredAdd_seconds;

function requireAdd_seconds () {
	if (hasRequiredAdd_seconds) return add_seconds;
	hasRequiredAdd_seconds = 1;
	var addMilliseconds = requireAdd_milliseconds();

	/**
	 * @category Second Helpers
	 * @summary Add the specified number of seconds to the given date.
	 *
	 * @description
	 * Add the specified number of seconds to the given date.
	 *
	 * @param {Date|String|Number} date - the date to be changed
	 * @param {Number} amount - the amount of seconds to be added
	 * @returns {Date} the new date with the seconds added
	 *
	 * @example
	 * // Add 30 seconds to 10 July 2014 12:45:00:
	 * var result = addSeconds(new Date(2014, 6, 10, 12, 45, 0), 30)
	 * //=> Thu Jul 10 2014 12:45:30
	 */
	function addSeconds (dirtyDate, dirtyAmount) {
	  var amount = Number(dirtyAmount);
	  return addMilliseconds(dirtyDate, amount * 1000)
	}

	add_seconds = addSeconds;
	return add_seconds;
}

const addMinutes = add_minutes;
const ucumUtils$1 = requireUcumPkg().UcumLhcUtils.getInstance();
const numbers$1 = numbers$2;

const ucumSystemUrl = 'http://unitsofmeasure.org';
let timeFormat =
  '[0-9][0-9](\\:[0-9][0-9](\\:[0-9][0-9](\\.[0-9]+)?)?)?(Z|(\\+|-)[0-9][0-9]\\:[0-9][0-9])?';
let timeRE = new RegExp('^T?'+timeFormat+'$');
let dateTimeRE = new RegExp(
  '^[0-9][0-9][0-9][0-9](-[0-9][0-9](-[0-9][0-9](T'+timeFormat+')?)?)?Z?$');
let dateRE = new RegExp(
  '^[0-9][0-9][0-9][0-9](-[0-9][0-9](-[0-9][0-9])?)?$');
let instantRE = new RegExp(
  '^[0-9][0-9][0-9][0-9](-[0-9][0-9](-[0-9][0-9](T[0-9][0-9](\\:[0-9][0-9](\\:[0-9][0-9](\\.[0-9]+)?))(Z|(\\+|-)[0-9][0-9]\\:[0-9][0-9]))))$');
// FHIR date/time regular expressions are slightly different.  For now, we will
// stick with the FHIRPath regular expressions.
//let fhirTimeRE = /([01][0-9]|2[0-3]):[0-5][0-9]:([0-5][0-9]|60)(\.[0-9]+)?/;
//let fhirDateTimeRE =
///([0-9]([0-9]([0-9][1-9]|[1-9]0)|[1-9]00)|[1-9]000)(-(0[1-9]|1[0-2])(-(0[1-9]|[1-2][0-9]|3[0-1])(T([01][0-9]|2[0-3]):[0-5][0-9]:([0-5][0-9]|60)(\.[0-9]+)?(Z|(\+|-)((0[0-9]|1[0-3]):[0-5][0-9]|14:00)))?)?)?/;

/**
 *   Class FP_Type is the superclass for FHIRPath types that required special
 *   handling.
 */
let FP_Type$5 = class FP_Type {
  /**
   *  Tests whether this object is equal to another.  Returns either true,
   *  false, or undefined (where in the FHIRPath specification empty would be
   *  returned).  The undefined return value indicates that the values were the
   *  same to the shared precision, but that they had differnent levels of
   *  precision.
   */
  equals(/* otherObj */) {
    return false;
  }

  /**
   *  Tests whether this object is equivalant to another.  Returns either true,
   *  false, or undefined (where in the FHIRPath specification empty would be
   *  returned).
   */
  equivalentTo(/* otherObj */) {
    return false;
  }

  toString() {
    return this.asStr ? this.asStr : super.toString();
  }

  toJSON() {
    return this.toString();
  }

  /**
   *  Returns -1, 0, or 1 if this object is less then, equal to, or greater
   *  than otherObj.
   */
  compare(/* otherObj */) {
    throw 'Comparison not implemented for ' + this.constructor.name;
  }

  /**
   *  Adds other value to this value.
   */
  plus(/* otherObj */) {
    throw 'Addition not implemented for ' + this.constructor.name;
  }

  /**
   * Multiplies this value by another value.
   */
  mul(/* otherObj */) {
    throw 'Multiplication not implemented for ' + this.constructor.name;
  }

  /**
   * Divides this value by another value.
   */
  div(/* otherObj */) {
    throw 'Division not implemented for ' + this.constructor.name;
  }
};


/**
 *  A class for Quantities.
 */
let FP_Quantity$5 = class FP_Quantity extends FP_Type$5 {
  constructor(value, unit) {
    super();
    this.asStr = value + ' ' + unit;
    this.value = value;
    this.unit = unit;
  }

  equals(otherQuantity) {
    if (!(otherQuantity instanceof this.constructor)) {
      return false;
    }

    const thisUnitInSeconds = FP_Quantity._calendarDuration2Seconds[this.unit];
    const otherUnitInSeconds = FP_Quantity._calendarDuration2Seconds[otherQuantity.unit];

    if (
      !thisUnitInSeconds !== !otherUnitInSeconds &&
      (thisUnitInSeconds > 1 || otherUnitInSeconds > 1)
    ) {
      // If one of the operands is a calendar duration greater than seconds and
      // another one is not a calendar duration, return empty result
      return null;
    }

    if (this.unit === otherQuantity.unit) {
      return numbers$1.isEqual(this.value, otherQuantity.value);
    }

    // Special year/month comparison case: 1 year = 12 month
    const compareYearsAndMonths = this._compareYearsAndMonths(otherQuantity);
    if (compareYearsAndMonths) {
      return compareYearsAndMonths.isEqual;
    }

    // General comparison case
    const thisQuantity = FP_Quantity.toUcumQuantity(this.value, this.unit),
      normalizedOtherQuantity = FP_Quantity.toUcumQuantity(otherQuantity.value, otherQuantity.unit),
      convResult = ucumUtils$1.convertUnitTo(normalizedOtherQuantity.unit, normalizedOtherQuantity.value, thisQuantity.unit);

    if (convResult.status !== 'succeeded') {
      return false;
    }

    return numbers$1.isEqual(thisQuantity.value, convResult.toVal);
  }

  equivalentTo(otherQuantity) {
    if (!(otherQuantity instanceof this.constructor)) {
      return false;
    }

    if (this.unit === otherQuantity.unit) {
      return numbers$1.isEquivalent(this.value, otherQuantity.value);
    }

    const ucumUnitCode = FP_Quantity.getEquivalentUcumUnitCode(this.unit),
      otherUcumUnitCode = FP_Quantity.getEquivalentUcumUnitCode(otherQuantity.unit),
      convResult = ucumUtils$1.convertUnitTo(otherUcumUnitCode, otherQuantity.value, ucumUnitCode);

    if (convResult.status !== 'succeeded') {
      return false;
    }

    return numbers$1.isEquivalent(this.value, convResult.toVal);
  }

  /**
   *  Returns a number less than 0, equal to 0 or greater than 0
   *  if this quantity is less than, equal to, or greater than otherQuantity.
   *  If the quantities could not be compared, returns null, which will be
   *  converted to an empty collection in the "doInvoke" function
   *  See https://hl7.org/fhirpath/#comparison
   *  @param {FP_Quantity} otherQuantity
   *  @return {number|null}
   */
  compare(otherQuantity) {
    if (this.unit === otherQuantity.unit) {
      return this.value - otherQuantity.value;
    }

    const thisUnitInSeconds = FP_Quantity._calendarDuration2Seconds[this.unit];
    const otherUnitInSeconds = FP_Quantity._calendarDuration2Seconds[otherQuantity.unit];

    if (
      !thisUnitInSeconds !== !otherUnitInSeconds &&
      (thisUnitInSeconds > 1 || otherUnitInSeconds > 1)
    ) {
      // If one of the operands is a calendar duration greater than seconds and
      // another one is not a calendar duration, return empty result
      // For example, 1 year > 1 'a' should return []
      return null;
    }

    const ucumUnitCode = FP_Quantity.getEquivalentUcumUnitCode(this.unit),
      otherUcumUnitCode = FP_Quantity.getEquivalentUcumUnitCode(otherQuantity.unit),
      convResult = ucumUtils$1.convertUnitTo(otherUcumUnitCode, otherQuantity.value, ucumUnitCode);

    if (convResult.status !== 'succeeded') {
      return null;
    }

    return this.value - convResult.toVal;
  }

  /**
   *  Adds a quantity to this quantity.
   * @param {FP_Quantity} otherQuantity a quantity to be added to this quantity.
   * @return {FP_Quantity|null}
   */
  plus(otherQuantity) {
    const thisConvFactor = FP_Quantity._yearMonthConversionFactor[this.unit];
    const otherConvFactor = FP_Quantity._yearMonthConversionFactor[otherQuantity.unit];
    if (thisConvFactor && otherConvFactor) {
      // If the values are indicated in years and months, we use the conversion factor: 1 year = 12 months
      return new FP_Quantity(this.value + otherQuantity.value * otherConvFactor / thisConvFactor, this.unit);
    }

    const thisUnitInSeconds = FP_Quantity._calendarDuration2Seconds[this.unit];
    const otherUnitInSeconds = FP_Quantity._calendarDuration2Seconds[otherQuantity.unit];

    if (
      !thisUnitInSeconds !== !otherUnitInSeconds &&
      (thisUnitInSeconds > 1 || otherUnitInSeconds > 1)
    ) {
      // If one of the operands is a calendar duration greater than seconds and
      // another one is not a calendar duration, return empty result
      return null;
    }

    const thisUcumUnitCode = thisUnitInSeconds ? 's' : this.unit.replace(surroundingApostrophesRegex, '');
    const thisValue = (thisUnitInSeconds || 1) * this.value;

    const otherUcumUnitCode = otherUnitInSeconds ? 's' : otherQuantity.unit.replace(surroundingApostrophesRegex, '');
    const otherValue = (otherUnitInSeconds || 1) * otherQuantity.value;

    const convResult = ucumUtils$1.convertUnitTo(otherUcumUnitCode, otherValue, thisUcumUnitCode);

    if (convResult.status !== 'succeeded'
      || convResult.fromUnit.isSpecial_
      || convResult.toUnit.isSpecial_) {
      return null;
    }

    return new FP_Quantity(thisValue + convResult.toVal, thisUcumUnitCode);
  }

  /**
   * Multiplies this quantity to another quantity.
   * @param {FP_Quantity} otherQuantity a quantity by which to multiply this quantity.
   * @return {FP_Quantity}
   */
  mul(otherQuantity) {
    const thisUnitInSeconds = FP_Quantity._calendarDuration2Seconds[this.unit];
    const otherUnitInSeconds = FP_Quantity._calendarDuration2Seconds[otherQuantity.unit];

    if (
      (thisUnitInSeconds > 1 && otherQuantity.unit !== "'1'") ||
      (otherUnitInSeconds > 1 && this.unit !== "'1'")
    ) {
      // If one of the operands is a calendar duration greater than seconds and
      // another one is not a number, return empty result
      return null;
    }

    const thisQ = this.convToUcumUnits(this, thisUnitInSeconds);
    if (!thisQ) {
      // If the first operand is not a UCUM quantity or it has a special unit
      return null;
    }

    const otherQ = this.convToUcumUnits(otherQuantity, otherUnitInSeconds);
    if (!otherQ) {
      // If the second operand is not a UCUM quantity or it has a special unit
      return null;
    }

    // Do not use UCUM unit codes for durations in simple cases
    if (this.unit === "'1'") {
      return new FP_Quantity(this.value * otherQuantity.value, otherQuantity.unit);
    } else if (otherQuantity.unit === "'1'") {
      return new FP_Quantity(this.value * otherQuantity.value, this.unit);
    }

    return new FP_Quantity(
      thisQ.value * otherQ.value,
      `'(${thisQ.unit}).(${otherQ.unit})'`
    );
  }

  /**
   * Divides this quantity by another quantity.
   * @param {FP_Quantity} otherQuantity a quantity by which to divide this quantity.
   * @return {FP_Quantity}
   */
  div(otherQuantity) {
    // Division by zero always gives an empty result
    if (otherQuantity.value === 0) {
      return null;
    }

    const thisUnitInSeconds = FP_Quantity._calendarDuration2Seconds[this.unit];
    const otherUnitInSeconds = FP_Quantity._calendarDuration2Seconds[otherQuantity.unit];

    if (thisUnitInSeconds) {
      if (otherUnitInSeconds) {
        // If both operands are calendar duration quantities
        const thisConvFactor = FP_Quantity._yearMonthConversionFactor[this.unit];
        const otherConvFactor = FP_Quantity._yearMonthConversionFactor[otherQuantity.unit];
        if (thisConvFactor && otherConvFactor) {
          // If the values are indicated in years and months, we use the conversion factor: 1 year = 12 months
          return new FP_Quantity(this.value * thisConvFactor / (otherQuantity.value * otherConvFactor), "'1'");
        }
      } else if (otherQuantity.unit === "'1'") {
        // If the second operand is a number
        return new FP_Quantity(this.value / otherQuantity.value, this.unit);
      } else if (thisUnitInSeconds > 1) {
        // If the first operand is a calendar duration greater than seconds
        // and the other is not a calendar duration or number, return an empty result.
        return null;
      }
    } else if (otherUnitInSeconds > 1) {
      // If the first operands is not a calendar duration and the other is a
      // calendar duration greater than seconds, return an empty result.
      return null;
    }

    const thisQ = this.convToUcumUnits(this, thisUnitInSeconds);
    if (!thisQ) {
      // If the first operand is not a UCUM quantity or it has a special unit
      return null;
    }

    const otherQ = this.convToUcumUnits(otherQuantity, otherUnitInSeconds);
    if (!otherQ) {
      // If the second operand is not a UCUM quantity or it has a special unit
      return null;
    }

    const resultUnit = otherQ.unit === '1'
      ? thisQ.unit
      : `(${thisQ.unit})/(${otherQ.unit})`;

    const convResult = ucumUtils$1.convertToBaseUnits(resultUnit, thisQ.value / otherQ.value);
    if (convResult.status !== 'succeeded') {
      // If the result units are unclear
      return null;
    }
    return new FP_Quantity(
      convResult.magnitude,
      `'${Object.keys(convResult.unitToExp).map(key => key+convResult.unitToExp[key]).join('.') || "1"}'`
    );
  }

  /**
   * Converts a quantity to UCUM unit if possible, otherwise returns null.
   * @param {FP_Quantity} quantity - source quantity.
   * @param {number|undefined} unitInSeconds - if the source quantity is a
   *  calendar duration then the value of the quantity unit in seconds,
   *  otherwise undefined.
   * @return {{unit: string, value: number} | null}
   */
  convToUcumUnits(quantity, unitInSeconds) {
    if (unitInSeconds) {
      return {
        value: unitInSeconds * quantity.value,
        unit: 's'
      };
    } else {
      const unit = quantity.unit.replace(surroundingApostrophesRegex, '');
      const convRes = ucumUtils$1.convertToBaseUnits(unit, quantity.value);
      if (convRes.status !== 'succeeded' || convRes.fromUnitIsSpecial) {
        // If it is not a UCUM quantity or it has a special unit
        return null;
      }
      return {
        value: convRes.magnitude,
        unit: Object.keys(convRes.unitToExp).map(key => key+convRes.unitToExp[key]).join('.') || "1"
      };
    }
  }

  /**
   * If both quantities have one of these units: year or month,
   * then a special case will apply; otherwise returns null.
   * In the special case of comparison, the fact that 1 year = 12 months is used.
   *
   * Just note: in general, for a calendar duration:
   * 1 year = 365 days
   * 12 month = 12*30 days = 360 days
   * so, 1 year != 12 month
   * That's why this special case is needed
   *
   * @param {FP_Quantity} otherQuantity
   * @return {null|{isEqual: boolean}}
   * @private
   */
  _compareYearsAndMonths(otherQuantity) {
    const magnitude1 = FP_Quantity._yearMonthConversionFactor[this.unit],
      magnitude2 = FP_Quantity._yearMonthConversionFactor[otherQuantity.unit];

    if ( magnitude1 && magnitude2) {
      return {
        isEqual: numbers$1.isEqual(this.value*magnitude1, otherQuantity.value*magnitude2)
      };
    }

    return null;
  }

};

const  surroundingApostrophesRegex = /^'|'$/g;
/**
 * Converts a FHIR path unit to a UCUM unit code by converting a calendar duration keyword to an equivalent UCUM unit code
 * or removing single quotes for a UCUM unit.
 * @param {string} unit
 * @return {string}
 */
FP_Quantity$5.getEquivalentUcumUnitCode = function (unit) {
  return FP_Quantity$5.mapTimeUnitsToUCUMCode[unit] || unit.replace(surroundingApostrophesRegex, '');
};

/**
 * Converts FHIR path value/unit to UCUM value/unit. Usable for comparison.
 * @param {number} value
 * @param {string} unit
 * @returns { {value: number, unit: string} }
 */
FP_Quantity$5.toUcumQuantity = function (value, unit) {
  const magnitude = FP_Quantity$5._calendarDuration2Seconds[unit];
  if (magnitude) {
    return {
      value: magnitude * value,
      unit: 's'
    };
  }

  return {
    value,
    unit: unit.replace(surroundingApostrophesRegex, '')
  };
};


/**
 * Converts FHIRPath value/unit to other FHIRPath value/unit.
 * @param {string} fromUnit
 * @param {number} value
 * @param {string} toUnit
 * @return {FP_Quantity|null}
 */
FP_Quantity$5.convUnitTo = function (fromUnit, value, toUnit) {
  // 1 Year <-> 12 Months
  const fromYearMonthMagnitude = FP_Quantity$5._yearMonthConversionFactor[fromUnit],
    toYearMonthMagnitude = FP_Quantity$5._yearMonthConversionFactor[toUnit];
  if (fromYearMonthMagnitude && toYearMonthMagnitude) {
    return new FP_Quantity$5( fromYearMonthMagnitude*value/toYearMonthMagnitude, toUnit);
  }

  const fromMagnitude = FP_Quantity$5._calendarDuration2Seconds[fromUnit],
    toMagnitude = FP_Quantity$5._calendarDuration2Seconds[toUnit];

  // To FHIR path calendar duration
  if (toMagnitude) {
    if (fromMagnitude) {
      return new FP_Quantity$5( fromMagnitude*value/toMagnitude, toUnit);
    } else {
      const convResult = ucumUtils$1.convertUnitTo(fromUnit.replace(/^'|'$/g, ''), value, 's');

      if (convResult.status === 'succeeded') {
        return new FP_Quantity$5(convResult.toVal/toMagnitude, toUnit);
      }
    }
  // To Ucum unit
  } else {
    const convResult = fromMagnitude ? ucumUtils$1.convertUnitTo('s', fromMagnitude*value, toUnit.replace(/^'|'$/g, ''))
      : ucumUtils$1.convertUnitTo(fromUnit.replace(/^'|'$/g, ''), value, toUnit.replace(/^'|'$/g, ''));

    if(convResult.status === 'succeeded') {
      return new FP_Quantity$5(convResult.toVal, toUnit);
    }
  }

  return null;
};


// Defines conversion factors for calendar durations
FP_Quantity$5._calendarDuration2Seconds = {
  'years': 365*24*60*60,
  'months': 30*24*60*60,
  'weeks': 7*24*60*60,
  'days': 24*60*60,
  'hours': 60*60,
  'minutes': 60,
  'seconds': 1,
  'milliseconds': .001,
  'year': 365*24*60*60,
  'month': 30*24*60*60,
  'week': 7*24*60*60,
  'day': 24*60*60,
  'hour': 60*60,
  'minute': 60,
  'second': 1,
  'millisecond': .001
};

// Defines special case to compare years with months for calendar durations
FP_Quantity$5._yearMonthConversionFactor = {
  'years': 12,
  'months': 1,
  'year': 12,
  'month': 1
};

/**
 *  Defines a map from time units that are supported for date/time arithmetic
 *  (including some UCUM time based units) to FHIRPath time units.
 */
FP_Quantity$5.dateTimeArithmeticDurationUnits = {
  'years': "year",
  'months': "month",
  'weeks': "week",
  'days': "day",
  'hours': "hour",
  'minutes': "minute",
  'seconds': "second",
  'milliseconds': "millisecond",
  'year': "year",
  'month': "month",
  'week': "week",
  'day': "day",
  'hour': "hour",
  'minute': "minute",
  'second': "second",
  'millisecond': "millisecond",
  "'s'": "second",
  "'ms'": "millisecond"
};

/**
 *  Defines a map from UCUM code to FHIRPath time units.
 */
FP_Quantity$5.mapUCUMCodeToTimeUnits = {
  'a': "year",
  'mo': "month",
  'wk': "week",
  'd': "day",
  'h': "hour",
  'min': "minute",
  's': "second",
  'ms': "millisecond",
};

/**
 *  Defines a map from FHIRPath time units to UCUM code.
 */
FP_Quantity$5.mapTimeUnitsToUCUMCode = Object.keys(FP_Quantity$5.mapUCUMCodeToTimeUnits)
  .reduce(function (res, key) {
    res[FP_Quantity$5.mapUCUMCodeToTimeUnits[key]] = key;
    res[FP_Quantity$5.mapUCUMCodeToTimeUnits[key]+'s'] = key;
    return res;
  }, {});

class FP_TimeBase extends FP_Type$5 {
  constructor(timeStr) {
    super();
    this.asStr = timeStr;
  }

  /**
   *  Adds a time-based quantity to this date/time.
   * @param timeQuantity a quantity to be added to this date/time.  See the
   *  FHIRPath specification for supported units.
   */
  plus(timeQuantity) {
    const unit = timeQuantity.unit;
    let timeUnit = FP_Quantity$5.dateTimeArithmeticDurationUnits[unit];
    if (!timeUnit) {
      throw new Error('For date/time arithmetic, the unit of the quantity ' +
        'must be one of the following time-based units: ' +
        Object.keys(FP_Quantity$5.dateTimeArithmeticDurationUnits));
    }
    const cls = this.constructor;
    const unitPrecision = cls._timeUnitToDatePrecision[timeUnit];
    if (unitPrecision === undefined) {
      throw new Error('Unsupported unit for +.  The unit should be one of ' +
        Object.keys(cls._timeUnitToDatePrecision).join(', ') + '.');
    }
    let qVal = timeQuantity.value;
    const isTime = (cls === FP_Time$2);

    // From the FHIRPath specification: "For precisions above seconds, the
    // decimal portion of the time-valued quantity is ignored, since date/time
    // arithmetic above seconds is performed with calendar duration semantics."
    if (isTime ? unitPrecision < 2 : unitPrecision < 5) {
      qVal = Math.trunc(qVal);
    }

    // If the precision of the time quantity is higher than the precision of the
    // date, we need to convert the time quantity to the precision of the date.
    if (this._getPrecision() < unitPrecision) {
      const neededUnit = cls._datePrecisionToTimeUnit[
        this._getPrecision()];
      if (neededUnit !== 'second') {
        const newQuantity = FP_Quantity$5.convUnitTo(timeUnit, qVal, neededUnit);
        timeUnit = newQuantity.unit;
        qVal = Math.trunc(newQuantity.value);
      }
    }
    const newDate = FP_TimeBase.timeUnitToAddFn[timeUnit](this._getDateObj(), qVal);
    // newDate is a Date.  We need to make a string with the correct precision.
    let precision = this._getPrecision();
    if (isTime)
      precision += 3; // based on dateTimeRE, not timeRE
    let newDateStr = FP_DateTime$3.isoDateTime(newDate, precision);
    if (isTime) {
      // FP_Time just needs the time part of the string
      newDateStr = newDateStr.slice(newDateStr.indexOf('T') + 1);
    }

    return new cls(newDateStr);
  }


  /**
   *  Tests whether this object is equal to another.  Returns either true,
   *  false, or undefined (where in the FHIRPath specification empty would be
   *  returned).  The undefined return value indicates that the values were the
   *  same to the shared precision, but that they had differnent levels of
   *  precision.
   * @param otherDateTime any sub-type of FP_TimeBase, but it should be the same
   *  as the type of "this".
   */
  equals(otherDateTime) {
    // From the 2019May ballot:
    // For Date, DateTime and Time equality, the comparison is performed by
    // considering each precision in order, beginning with years (or hours for
    // time values), and respecting timezone offsets. If the values are the
    // same, comparison proceeds to the next precision; if the values are
    // different, the comparison stops and the result is false. If one input has
    // a value for the precision and the other does not, the comparison stops
    // and the result is empty ({ }); if neither input has a value for the
    // precision, or the last precision has been reached, the comparison stops
    // and the result is true.
    // Note:  Per the spec above
    //   2012-01 = 2012 //  empty
    //   2012-01 = 2011 //  false
    //   2012-01 ~ 2012 //  false
    var rtn;
    if (!(otherDateTime instanceof this.constructor) && !(this instanceof otherDateTime.constructor))
      rtn = false;
    else {
      var thisPrec  = this._getPrecision();
      var otherPrec = otherDateTime._getPrecision();

      if (thisPrec == otherPrec) {
        rtn = this._getDateObj().getTime() == otherDateTime._getDateObj().getTime();
      }
      else {
        // The dates are not equal, but decide whether to return empty or false.
        var commonPrec  = thisPrec <= otherPrec ? thisPrec : otherPrec;
        // Adjust for timezone offsets, if any, so they are at a common timezone
        var thisUTCStr  = this._getDateObj().toISOString();
        var otherUTCStr = otherDateTime._getDateObj().toISOString();

        if (this.constructor === FP_Time$2) {
          commonPrec += 3; // because we now have year, month, and day
          thisPrec += 3;
          otherPrec += 3;
        }

        // Now parse the strings and compare the adjusted time parts.
        // Dates without time specify no timezone and should be treated as already normalized to UTC. So we do not adjust the timezone, as this would change the date
        var thisAdj  = thisPrec > 2 ? (new FP_DateTime$3(thisUTCStr))._getTimeParts() : this._getTimeParts();
        var otherAdj = otherPrec > 2 ? (new FP_DateTime$3(otherUTCStr))._getTimeParts() : otherDateTime._getTimeParts();

        for (var i = 0; i <= commonPrec && rtn !== false; ++i) {
          rtn = thisAdj[i] == otherAdj[i];
        }
        // if rtn is still true, then return empty to indicate the difference in
        // precision.
        if (rtn)
          rtn = undefined;
      }
    }
    // else return undefined (empty)
    return rtn;
  }


  /**
   *  Tests whether this object is equivalant to another.  Returns either true
   *  or false.
   */
  equivalentTo(otherDateTime) {
    var rtn = otherDateTime instanceof this.constructor;
    if (rtn) {
      var thisPrec = this._getPrecision();
      var otherPrec = otherDateTime._getPrecision();
      rtn = thisPrec == otherPrec;
      if (rtn) {
        rtn = this._getDateObj().getTime() ==
          otherDateTime._getDateObj().getTime();
      }
    }
    return rtn;
  }


  /**
   *  Returns a number less than 0, equal to 0 or greater than 0
   *  if this (date) time is less than, equal to, or greater than otherTime.
   *  Comparisons are made at the lesser of the two time precisions.
   *  @param {FP_TimeBase} otherTime
   *  @return {number}
   */
  compare(otherTime) {
    var thisPrecision = this._getPrecision();
    var otherPrecision = otherTime._getPrecision();
    var thisTimeInt = thisPrecision <= otherPrecision ?
      this._getDateObj().getTime(): this._dateAtPrecision(otherPrecision).getTime();
    var otherTimeInt = otherPrecision <= thisPrecision ?
      otherTime._getDateObj().getTime(): otherTime._dateAtPrecision(thisPrecision).getTime();
    if (thisPrecision !== otherPrecision && thisTimeInt === otherTimeInt) {
      return null;
    }
    return thisTimeInt - otherTimeInt;
  }


  /**
   *  Returns a number representing the precision of the time string given to
   *  the constructor.  (Higher means more precise).  The number is the number
   *  of components of the time string (ignoring the time zone) produced by
   *  matching against the time regular expression, except that milliseconds
   *  and seconds are counted together as a single of level of precision.
   *  @return {number}
   */
  _getPrecision() {
    if (this.precision === undefined)
      this._getMatchData();
    return this.precision;
  }

  /**
   *  Returns the match data from matching the given RegExp against the
   *  date/time string given to the constructor.
   *  Also sets this.precision.
   * @param regEx The regular expression to match against the date/time string.
   * @param maxPrecision the maximum precision possible for the type
   */
  _getMatchData(regEx, maxPrecision) {
    if (this.timeMatchData === undefined) {
      this.timeMatchData = this.asStr.match(regEx);
      if (this.timeMatchData) {
        for (let i=maxPrecision; i>=0 && this.precision === undefined; --i) {
          if (this.timeMatchData[i])
            this.precision = i;
        }
      }
    }
    return this.timeMatchData;
  }

  /**
   *  Returns an array of the pieces of the given time string, for use in
   *  constructing lower precision versions of the time. The returned array will
   *  contain separate elements for the hour, minutes, seconds, and milliseconds
   *  (or as many of those are as present).  The length of the returned array
   *  will therefore be an indication of the precision.
   *  It will not include the timezone.
   * @timeMatchData the result of matching the time portion of the string passed
   *  into the constructor against the "timeRE" regular expression.
   */
  _getTimeParts(timeMatchData) {
    var timeParts = [];
    // Finish parsing the data into pieces, for later use in building
    // lower-precision versions of the date if needed.
    timeParts = [timeMatchData[0]];
    var timeZone = timeMatchData[4];
    if (timeZone) { // remove time zone from hours
      let hours = timeParts[0];
      timeParts[0] = hours.slice(0, hours.length-timeZone.length);
    }
    var min = timeMatchData[1];
    if (min) { // remove minutes from hours
      let hours = timeParts[0];
      timeParts[0] = hours.slice(0, hours.length-min.length);
      timeParts[1] = min;
      var sec = timeMatchData[2];
      if (sec) { // remove seconds from minutes
        timeParts[1] = min.slice(0, min.length-sec.length);
        timeParts[2] = sec;
        var ms = timeMatchData[3];
        if (ms) { // remove milliseconds from seconds
          timeParts[2] = sec.slice(0, sec.length-ms.length);
          timeParts[3] = ms;
        }
      }
    }
    return timeParts;
  }


  /**
   *  Returns a date object representing this time on a certain date.
   */
  _getDateObj() {
    if (!this.dateObj) {
      var precision = this._getPrecision();
      // We cannot directly pass the string into the date constructor because
      // (1) we don't want to introduce a time-dependent system date and (2) the
      // time string might not have contained minutes, which are required by the
      // Date constructor.
      this.dateObj = this._dateAtPrecision(precision);
    }
    return this.dateObj;
  }


  /**
   *  Creates a date object for the given timezone.  The returned date object
   *  will have the specified date and time in the specified timezone.
   * @param year...ms Just as in the Date constructor.
   * @param timezoneOffset (optional) a string in the format (+-)HH:mm or Z, representing the
   *  timezone offset.  If not provided, the local timzone will be assumed (as the
   *  Date constructor does).
   */
  _createDate(year, month, day, hour, minutes, seconds, ms, timezoneOffset) {
    var d = new Date(year, month, day, hour, minutes, seconds, ms);
    if (timezoneOffset) {
      // d is in local time.  Adjust for the timezone offset.
      // First adjust the date by the timezone offset before reducing its
      // precision.  Otherwise,
      // @2018-11-01T-04:00 < @2018T-05:00
      var localTimezoneMinutes = d.getTimezoneOffset();
      var timezoneMinutes = 0; // if Z
      if (timezoneOffset != 'Z') {
        var timezoneParts = timezoneOffset.split(':'); // (+-)hours:minutes
        var hours = parseInt(timezoneParts[0]);
        timezoneMinutes = parseInt(timezoneParts[1]);
        if (hours < 0)
          timezoneMinutes = -timezoneMinutes;
        timezoneMinutes += 60*hours;
      }
      // localTimezoneMinutes has the inverse sign of its timezone offset
      d = addMinutes(d, -localTimezoneMinutes-timezoneMinutes);
    }
    return d;
  }
}

/**
 *  A map from a FHIRPath time units to a function used to add that
 *  quantity to a date/time.
 */
FP_TimeBase.timeUnitToAddFn = {
  "year": requireAdd_years(),
  "month": requireAdd_months(),
  "week": requireAdd_weeks(),
  "day": requireAdd_days(),
  "hour": requireAdd_hours(),
  "minute": add_minutes,
  "second": requireAdd_seconds(),
  "millisecond": requireAdd_milliseconds()
};


let FP_DateTime$3 = class FP_DateTime extends FP_TimeBase {
  /**
   *  Constructs an FP_DateTime, assuming dateStr is valid.  If you don't know
   *  whether a string is a valid DateTime, use FP_DateTime.checkString instead.
   */
  constructor(dateStr) {
    super(dateStr);
  }


  /**
   *  Returns -1, 0, or 1 if this date time is less then, equal to, or greater
   *  than otherDateTime.  Comparisons are made at the lesser of the two date time
   *  precisions.
   */
  compare(otherDateTime) {
    if (!(otherDateTime instanceof FP_DateTime))
      throw 'Invalid comparison of a DateTime with something else';
    return super.compare(otherDateTime);
  }


  /**
   *  Returns the match data from matching dateTimeRE against the datetime string.
   *  Also sets this.precision.
   */
  _getMatchData() {
    return super._getMatchData(dateTimeRE, 5);
  }

  /**
   *  Returns an array of the pieces of the date time string passed into the
   *  constructor, for use in constructing lower precision versions of the
   *  date time. The returned array will contain separate elements for the year,
   *  month, day, hour, minutes, seconds, and milliseconds (or as many of those
   *  are as present).  The length of the returned array will therefore be an
   *  indication of the precision.  It will not include the timezone.
   */
  _getTimeParts() {
    if (!this.timeParts) {
      let timeMatchData =  this._getMatchData();
      let year = timeMatchData[0];
      this.timeParts = [year];
      var month = timeMatchData[1];
      if (month) { // Remove other information from year
        this.timeParts[0] = year.slice(0, year.length-month.length);
        this.timeParts[1] = month;
        let day = timeMatchData[2];
        if (day) { // Remove day information from month
          this.timeParts[1] = month.slice(0, month.length-day.length);
          this.timeParts[2] = day;
          let time = timeMatchData[3];
          if (time) { // Remove time from day
            this.timeParts[2] = day.slice(0, day.length-time.length);
            if (time[0] === 'T') // remove T from hour
              timeMatchData[3] = time.slice(1);
            this.timeParts = this.timeParts.concat(
              super._getTimeParts(timeMatchData.slice(3)));
          }
        }
      }
    }
    return this.timeParts;
  }


  /**
   *  Returns a new Date object for a time equal to what this time would be if
   *  the string passed into the constructor had the given precision.
   * @param precision the new precision, which is assumed to be less than
   *  or equal to the current precision.
   */
  _dateAtPrecision(precision) {
    var timeParts = this._getTimeParts();
    var timezoneOffset = this._getMatchData()[7];
    // Get the date object first at the current precision.
    var thisPrecision = this._getPrecision();
    var year = parseInt(timeParts[0]);
    var month = thisPrecision > 0 ? parseInt(timeParts[1].slice(1)) - 1 : 0;
    var day = thisPrecision > 1 ? parseInt(timeParts[2].slice(1)) : 1;
    var hour = thisPrecision > 2 ? parseInt(timeParts[3]) : 0;
    var minutes = thisPrecision > 3 ? parseInt(timeParts[4].slice(1)): 0;
    var seconds = thisPrecision > 4 ? parseInt(timeParts[5].slice(1)): 0;
    var ms = timeParts.length > 6 ? parseInt(timeParts[6].slice(1)): 0;
    var d = this._createDate(year, month, day, hour, minutes, seconds, ms,
      timezoneOffset);
    if (precision < thisPrecision) {
      // Adjust the precision
      year = d.getFullYear();
      month = precision > 0 ? d.getMonth() : 0;
      day = precision > 1 ? d.getDate() : 1;
      hour = precision > 2 ? d.getHours() : 0;
      minutes = precision > 3 ? d.getMinutes(): 0;
      // Here the precision will always be less than the maximum
      // due to the condition in the if statement: "precision < thisPrecision"
      d = new Date(year, month, day, hour, minutes);
    }
    return d;
  }
};

/**
 *  Tests str to see if it is convertible to a DateTime.
 * @return If str is convertible to a DateTime, returns an FP_DateTime;
 *  otherwise returns null.
 */
FP_DateTime$3.checkString = function(str) {
  let d = new FP_DateTime$3(str);
  if (!d._getMatchData())
    d = null;
  return d;
};

/**
 *  A map from FHIRPath time units to the internal DateTime "precision" number.
 */
FP_DateTime$3._timeUnitToDatePrecision = {
  "year": 0,
  "month": 1,
  "week": 2, // wk is just 7*d
  "day": 2,
  "hour": 3,
  "minute": 4,
  "second": 5,
  "millisecond": 6
};

/**
 *  The inverse of _timeUnitToDatePrecision.
 */
FP_DateTime$3._datePrecisionToTimeUnit = [
  "year", "month", "day", "hour", "minute", "second", "millisecond"
];



let FP_Time$2 = class FP_Time extends FP_TimeBase {
  /**
   *  Constructs an FP_Time, assuming dateStr is valid.  If you don't know
   *  whether a string is a valid DateTime, use FP_Time.checkString instead.
   */
  constructor(timeStr) {
    if (timeStr[0] == 'T')
      timeStr = timeStr.slice(1);
    super(timeStr);
  }


  /**
   *  Returns -1, 0, or 1 if this time is less then, equal to, or greater
   *  than otherTime.  Comparisons are made at the lesser of the two time
   *  precisions.
   */
  compare(otherTime) {
    if (!(otherTime instanceof FP_Time))
      throw 'Invalid comparison of a time with something else';
    return super.compare(otherTime);
  }


  /**
   *  Returns a new Date object for a time equal to what this time would be if
   *  the string passed into the constructor had the given precision.
   *  The "date" portion of the returned Date object is not meaningful, and
   *  should be ignored.
   * @param precision the new precision, which is assumed to be less than the
   *  or equal to the current precision.  A precision of 0 means the hour.
   */
  _dateAtPrecision(precision) {
    var timeParts = this._getTimeParts();
    var timezoneOffset = this._getMatchData()[4];
    // Get the date object first at the current precision.
    var thisPrecision = this._getPrecision();
    var year = 2010; // Have to pick some year for the date object
    var month = 0;
    var day = 1;
    var hour = parseInt(timeParts[0]);
    var minutes = thisPrecision > 0 ? parseInt(timeParts[1].slice(1)): 0;
    var seconds = thisPrecision > 1 ? parseInt(timeParts[2].slice(1)): 0;
    var ms = timeParts.length > 3 ? parseInt(timeParts[3].slice(1)): 0;
    var d = this._createDate(year, month, day, hour, minutes, seconds, ms,
      timezoneOffset);
    if (timezoneOffset) {
      // Keep the date the same (in the local timezone), so it is not a relevant
      // factor when comparing different times.
      d.setYear(year);
      d.setMonth(month);
      d.setDate(day);
    }
    if (precision < thisPrecision) {
      // Adjust the precision
      hour = d.getHours();
      minutes = precision > 0 ? d.getMinutes(): 0;
      // Here the precision will always be less than the maximum
      // due to the condition in the if statement: "precision < thisPrecision"
      d = new Date(year, month, day, hour, minutes);
    }
    return d;
  }


  /**
   *  Returns the match data from matching timeRE against the time string.
   *  Also sets this.precision.
   */
  _getMatchData() {
    return super._getMatchData(timeRE, 2);
  }

  /**
   *  Returns an array of the pieces of the time string passed into the
   *  constructor, for use in constructing lower precision versions of the
   *  time. The returned array will contain separate elements for the hour,
   *  minutes, seconds, and milliseconds (or as many of those are as present).
   *  The length of the returned array will therefore be an indication of the
   *  precision.  It will not include the timezone.
   */
  _getTimeParts() {
    if (!this.timeParts) {
      this.timeParts = super._getTimeParts(this._getMatchData());
    }
    return this.timeParts;
  }
};

/**
 *  Tests str to see if it is convertible to a Time.
 * @return If str is convertible to a Time, returns an FP_Time;
 *  otherwise returns null.
 */
FP_Time$2.checkString = function(str) {
  let d = new FP_Time$2(str);
  if (!d._getMatchData())
    d = null;
  return d;
};

/**
 *  A map from FHIRPath time units to the internal DateTime "precision" number.
 */
FP_Time$2._timeUnitToDatePrecision = {
  "hour": 0,
  "minute": 1,
  "second": 2,
  "millisecond": 3
};

/**
 *  The inverse of _timeUnitToDatePrecision.
 */
FP_Time$2._datePrecisionToTimeUnit = ["hour", "minute", "second", "millisecond"];


/**
 *  Returns either the given number or a string with the number prefixed by
 *  zeros if the given number is less than the given length.
 * @param num the nubmer to format
 * @param len the number of returned digits.  For now this must either be 2 or
 *  3. (Optional-- default is 2).
 */
function formatNum(num, len) {
  // Could use String.repeat, but that requires convertin num to an string first
  // to get its length.  This might be slightly faster given that we only need 2
  // or three 3 digit return values.
  var rtn = num;
  if (len === 3 && num < 100)
    rtn = '0' + num;
  if (num < 10)
    rtn = '0' + rtn;
  return rtn;
}


/**
 *  Formats the given date object into an ISO8601 datetime string, expressing it
 *  in the local timezone.
 * @date the date to format
 * @precision the precision at which to terminate string string.  (This is
 *  optional). If present, it will be an integer into the matching components of
 *  dateTimeRE.
 * @return a string in ISO8601 format.
 */
FP_DateTime$3.isoDateTime = function(date, precision) {
  if (precision === undefined)
    precision = 5; // maximum
  // YYYY-MM-DDTHH:mm:ss.sss[+-]HH:mm
  // Note:  Date.toISOString sets the timezone at 'Z', which I did not want.
  // Actually, I wanted to keep the original timezone given in the constructor,
  // but that is difficult due to daylight savings time changes.  (For instance,
  // if you add 6 months, the timezone offset could change).
  var rtn = '' + date.getFullYear();
  if (precision > 0) {
    rtn += '-' + formatNum(date.getMonth() + 1);
    if (precision > 1) {
      rtn += '-' + formatNum(date.getDate());
      if (precision > 2) {
        rtn += 'T' + FP_DateTime$3.isoTime(date, precision - 3);
      }
    }
  }
  // FHIRPath STU1 does not allow a timezone offset on a dateTime that does not
  // have a time part (except that the grammar allows 'Z', which is
  // inconsistent).
  if (precision > 2) {
    // Note:  getTimezoneoffset returns the offset for the local system at the
    // given date.
    var tzOffset = date.getTimezoneOffset();
    // tzOffset is a number of minutes, and is positive for negative timezones,
    // and negative for positive timezones.
    var tzSign = tzOffset < 0 ? '+' : '-';
    tzOffset = Math.abs(tzOffset);
    var tzMin = tzOffset % 60;
    var tzHour = (tzOffset - tzMin) / 60;
    rtn += tzSign + formatNum(tzHour) + ':' + formatNum(tzMin);
  }
  return rtn;
};


/**
 *  Returns a time string in ISO format at the given precision level.
 * @date the date to format
 * @precision the precision at which to terminate string.  (This is
 *  optional). If present, it will be an integer into the matching components of
 *  timeRE.
 * @return a string in ISO 8601 format.
 */
FP_DateTime$3.isoTime = function(date, precision) {
  if (precision === undefined)
    precision = 2; // maximum

  let rtn = '' + formatNum(date.getHours());
  if (precision > 0) {
    rtn += ':' + formatNum(date.getMinutes());
    if (precision > 1) {
      rtn += ':' + formatNum(date.getSeconds() );
      if (date.getMilliseconds())
        rtn += '.' + formatNum(date.getMilliseconds(), 3);
    }
  }
  return rtn;
};


let FP_Date$2 = class FP_Date extends FP_DateTime$3 {
  /**
   * Constructs an FP_Date, assuming dateStr is valid.  If you don't know
   * whether a string is a valid Date, use FP_Date.checkString instead.
   */
  constructor(dateStr) {
    super(dateStr);
  }


  /**
   * Returns the match data from matching dateRE against the date string.
   * Also sets this.precision.
   */
  _getMatchData() {
    return FP_TimeBase.prototype._getMatchData.apply(this, [dateRE, 2]);
  }
};


/**
 * Tests str to see if it is convertible to a Date.
 * @return If str is convertible to a Date, returns an FP_Date;
 *  otherwise returns null.
 */
FP_Date$2.checkString = function(str) {
  let d = new FP_Date$2(str);
  if (!d._getMatchData())
    d = null;
  return d;
};


/**
 * Returns a date string in ISO format at the given precision level.
 * @date the date to format
 * @precision the precision at which to terminate string.  (This is
 *  optional). If present, it will be an integer into the matching components of
 *  dateTimeRE.
 * @return a string in ISO8601 format.
 */
FP_Date$2.isoDate = function(date, precision) {
  if (precision === undefined || precision > 2)
    precision = 2;
  return FP_DateTime$3.isoDateTime(date, precision);
};

class FP_Instant extends FP_DateTime$3 {
  /**
   * Constructs an FP_Instant, assuming instantStr is valid.  If you don't know
   * whether a string is a valid "instant", use FP_Instant.checkString instead.
   */
  constructor(instantStr) {
    super(instantStr);
  }


  /**
   * Returns the match data from matching instantRE against the "instant" string.
   * Also sets this.precision.
   */
  _getMatchData() {
    return FP_TimeBase.prototype._getMatchData.apply(this, [instantRE, 5]);
  }
}


/**
 * Tests str to see if it is convertible to an "instant".
 * @return If str match the "instant" RegExp, returns an FP_Instant;
 *  otherwise returns null.
 */
FP_Instant.checkString = function(str) {
  let d = new FP_Instant(str);
  if (!d._getMatchData())
    d = null;
  return d;
};

/**
 *  A class that represents a node in a FHIR resource, with path and possibly type
 *  information.
 */
let ResourceNode$3 = class ResourceNode {
  /**
   *  Constructs a instance for the given node ("data") of a resource.  If the
   *  data is the top-level node of a resouce, the path and type parameters will
   *  be ignored in favor of the resource's resourceType field.
   * @param {*} data the node's data or value (which might be an object with
   *  sub-nodes, an array, or FHIR data type)
   * @param {string} path the node's path in the resource (e.g. Patient.name).
   *  If the data's type can be determined from data, that will take precedence
   *  over this parameter.
   * @param {*} _data additional data stored in a property named with "_"
   *  prepended, see https://www.hl7.org/fhir/element.html#json for details.
   * @param {string} fhirNodeDataType FHIR node data type, if the resource node
   *  is described in the FHIR model.
   */
  constructor(data, path, _data, fhirNodeDataType) {
    // If data is a resource (maybe a contained resource) reset the path
    // information to the resource type.
    if (data?.resourceType) {
      path = data.resourceType;
      fhirNodeDataType = data.resourceType;
    }
    this.path = path;
    this.data = data;
    this._data = _data || {};
    this.fhirNodeDataType = fhirNodeDataType;
  }

  /**
   * Returns resource node type info.
   * @return {TypeInfo}
   */
  getTypeInfo() {
    let result;

    if (TypeInfo$3.model) {
      if (/^System\.(.*)$/.test(this.fhirNodeDataType)) {
        result = new TypeInfo$3({namespace: TypeInfo$3.System, name: RegExp.$1});
      } else if (this.fhirNodeDataType) {
        result = new TypeInfo$3({
          namespace: TypeInfo$3.FHIR,
          name: this.fhirNodeDataType
        });
      }
    }

    return result
      // Resource object properties that are not defined in the model now have
      // System.* data types:
      || TypeInfo$3.createByValueInSystemNamespace(this.data);
  }

  toJSON() {
    return JSON.stringify(this.data);
  }

  /**
   * Converts a resource node value to an instance of the FHIRPath system type
   * (FP_Quantity, FP_Date, FP_DateTime, or FP_Time) for use in evaluating
   * a FHIRPath expression if the node path matches the specified type in the
   * model and when conversion is possible, otherwise returns the data as is.
   * Throws an exception if the data is a Quantity that has a comparator.
   * The Mapping from FHIR Quantity to FHIRPath System.Quantity is explained here:
   * https://www.hl7.org/fhir/fhirpath.html#quantity
   * this.data is not changed, but converted value is returned.
   * @return {FP_Type|any}
   */
  convertData() {
    var data = this.data;
    const cls = TypeInfo$3.typeToClassWithCheckString[this.path];
    if (cls) {
      data = cls.checkString(data) || data;
    } else if (TypeInfo$3.isType(this.path, 'Quantity')) {
      if (data?.system === ucumSystemUrl) {
        if (typeof data.value === 'number' && typeof data.code === 'string') {
          if (data.comparator !== undefined)
            throw new Error('Cannot convert a FHIR.Quantity that has a comparator');
          data = new FP_Quantity$5(
            data.value,
            FP_Quantity$5.mapUCUMCodeToTimeUnits[data.code] || '\'' + data.code + '\''
          );
        }
      }
    }

    return data;
  }

};


/**
 *  Returns a ResourceNode for the given data node, checking first to see if the
 *  given node is already a ResourceNode.  Takes the same arguments as the
 *  constructor for ResourceNode.
 */
ResourceNode$3.makeResNode = function(data, path, _data, fhirNodeDataType = null) {
  return (data instanceof ResourceNode$3) ? data : new ResourceNode$3(data, path, _data, fhirNodeDataType);
};

// The set of available data types in the System namespace
const availableSystemTypes = new Set();
// IE11 probably doesn't support `new Set(iterable)`
['Boolean', 'String', 'Integer', 'Decimal', 'Date', 'DateTime', 'Time', 'Quantity'].forEach(i => availableSystemTypes.add(i));

/**
 * Object class defining type information.
 * Used for minimal type support.
 * (see http://hl7.org/fhirpath/#types-and-reflection)
 */
let TypeInfo$3 = class TypeInfo {
  constructor({name, namespace}) {
    this.name = name;
    this.namespace = namespace;
  }

  // The "model" data object specific to a domain, e.g. R4.
  static model = null;

  /**
   * Checks for equality with another TypeInfo object, or that another TypeInfo
   * object specifies a superclass for the type specified by this object.
   * @param {TypeInfo} other
   * @return {boolean}
   */
  is(other) {
    if (
      other instanceof TypeInfo &&
      (!this.namespace || !other.namespace || this.namespace === other.namespace)
    ) {
      return TypeInfo.model && (!this.namespace || this.namespace === TypeInfo.FHIR)
        ? TypeInfo.isType(this.name, other.name)
        : this.name === other.name;
    }
    return false;
  }

  /**
   * Returns the string representation of type info.
   * @returns {string}
   */
  toString() {
    return (this.namespace ? this.namespace + '.' : '') + this.name;
  }

  /**
   * Returns true if type info represents a valid type identifier, false otherwise.
   * @returns {boolean}
   */
  isValid() {
    let result = false;
    if (this.namespace === 'System') {
      result = availableSystemTypes.has(this.name);
    } else if (this.namespace === 'FHIR') {
      result = TypeInfo.model?.availableTypes.has(this.name);
    } else if (!this.namespace) {
      result = availableSystemTypes.has(this.name)
        || TypeInfo.model?.availableTypes.has(this.name);
    }
    return result;
  }
};

/**
 * Defines a map from a datatype to a datatype class which has a checkString method.
 * @type {Object.<string, FP_DateTime | FP_Time>}
 */
TypeInfo$3.typeToClassWithCheckString = {
  date: FP_Date$2,
  dateTime: FP_DateTime$3,
  instant: FP_Instant,
  time: FP_Time$2
};

/**
 * Checks if the type name or its parent type name is equal to
 * the expected type name.
 * @param type - type name to check.
 * @param superType - expected type name.
 * @return {boolean}
 */
TypeInfo$3.isType = function(type, superType) {
  do {
    if (type === superType) {
      return true;
    }
  } while ((type = TypeInfo$3.model?.type2Parent[type]));
  return false;
};

// Available namespaces:
TypeInfo$3.System = 'System';
TypeInfo$3.FHIR = 'FHIR';

/**
 * Creates new TypeInfo object for specified value in the System namespace.
 * @param {*} value
 * @return {TypeInfo}
 */
TypeInfo$3.createByValueInSystemNamespace = function(value) {
  let name = typeof value;

  if (Number.isInteger(value)) {
    name = 'integer';
  } else if (name === "number") {
    name = 'decimal';
  } else if (value instanceof FP_Date$2) {
    name = 'date';
  } else if (value instanceof FP_DateTime$3) {
    name = 'dateTime';
  } else if (value instanceof FP_Time$2) {
    name = 'time';
  } else if (value instanceof FP_Quantity$5) {
    name = 'Quantity';
  }

  name = name.replace(/^\w/, c => c.toUpperCase());

  // Currently can return name = "Object" which is probably wrong,
  // but the isValid method allows you to check this.
  return new TypeInfo$3({namespace: TypeInfo$3.System, name}) ;
};

/**
 * Retrieves TypeInfo by value
 * @param {*} value
 * @return {TypeInfo}
 */
TypeInfo$3.fromValue = function (value) {
  return value instanceof ResourceNode$3
    ? value.getTypeInfo()
    : TypeInfo$3.createByValueInSystemNamespace(value);
};

/**
 * Basic "type()" function implementation
 * (see http://hl7.org/fhirpath/#reflection)
 * @param {Array<*>} coll - input collection
 * @return {Array<*>}
 */
function typeFn(coll) {
  return coll.map(value => {
    return TypeInfo$3.fromValue(value);
  });
}

/**
 * Implementation of function "is(type : type specifier)" and operator "is"
 * (see http://hl7.org/fhirpath/#is-type-specifier)
 * @param {Array<*>} coll - input collection
 * @param {TypeInfo} typeInfo
 * @return {boolean|[]}
 */
function isFn(coll, typeInfo) {
  if(coll.length === 0) {
    return [];
  }

  if(coll.length > 1) {
    throw new Error("Expected singleton on left side of 'is', got " + JSON.stringify(coll));
  }

  return TypeInfo$3.fromValue(coll[0]).is(typeInfo);
}

/**
 * Implementation of function "as(type : type specifier)" and operator "as"
 * (see http://hl7.org/fhirpath/#as-type-specifier)
 * @param {Array<*>} coll - input collection
 * @param {TypeInfo} typeInfo
 * @return {Array<*>}
 */
function asFn(coll, typeInfo) {
  if(coll.length === 0) {
    return [];
  }

  if(coll.length > 1) {
    throw new Error("Expected singleton on left side of 'as', got " + JSON.stringify(coll));
  }

  return TypeInfo$3.fromValue(coll[0]).is(typeInfo) ? coll : [];
}

var types$5 = {
  FP_Type: FP_Type$5,
  FP_TimeBase: FP_TimeBase,
  FP_Date: FP_Date$2,
  FP_DateTime: FP_DateTime$3,
  FP_Instant: FP_Instant,
  FP_Time: FP_Time$2,
  FP_Quantity: FP_Quantity$5,
  timeRE: timeRE,
  dateTimeRE: dateTimeRE,
  ResourceNode: ResourceNode$3,
  TypeInfo: TypeInfo$3,
  typeFn,
  isFn,
  asFn
};

// This file holds utility functions used in implementing the public functions.

const util$a =  {};
const types$4 = types$5;
const {ResourceNode: ResourceNode$2} = types$4;

/**
 *  Reports and error to the calling environment and stops processing.
 * @param message the error message
 * @param fnName the name of the function raising the error (optional)
 */
util$a.raiseError = function(message, fnName) {
  fnName = fnName ? fnName + ": " : "";
  throw fnName + message;
};

/**
 *  Throws an exception if the collection contains not one value.
 * @param collection the collection to be checked.
 * @param errorMsgPrefix An optional prefix for the error message to assist in
 *  debugging.
 */
util$a.assertOnlyOne = function (collection, errorMsgPrefix) {
  if (collection.length !== 1) {
    util$a.raiseError("Was expecting only one element but got " +
      JSON.stringify(collection), errorMsgPrefix);
  }
};

/**
 *  Throws an exception if the data is not one of the expected types.
 * @param data the value to be checked.  This may be a ResourceNode.
 * @param types an array of the permitted types
 * @param errorMsgPrefix An optional prefix for the error message to assist in
 *  debugging.
 * @return the value that was checked.  If "data" was a ResourceNode, this will
 *  be the ReourceNode's data.
 */
util$a.assertType = function(data, types, errorMsgPrefix) {
  let val = this.valData(data);
  if (types.indexOf(typeof val) < 0) {
    let typeList = types.length > 1 ? "one of "+types.join(", ") : types[0];
    util$a.raiseError("Found type '"+(typeof data)+"' but was expecting " +
      typeList, errorMsgPrefix);
  }
  return val;
};

util$a.isEmpty = function(x){
  return Array.isArray(x) && x.length == 0;
};

util$a.isSome = function(x){
  return x !== null && x !== undefined && !util$a.isEmpty(x);
};

util$a.isTrue = function(x){
  // We use util.valData because we can use a boolean node as a criterion
  return x !== null && x !== undefined && (x === true || (x.length == 1 && util$a.valData(x[0]) === true));
};

util$a.isCapitalized = function(x){
  return x && (x[0] === x[0].toUpperCase());
};

util$a.flatten = function(x){
  return x.reduce(function(acc, x) {
    if(Array.isArray(x)){
      // todo replace with array modification
      acc = acc.concat(x);
    } else {
      acc.push(x);
    }
    return acc;
  }, []);
};

util$a.arraify = function(x){
  if(Array.isArray(x)){ return x; }
  if(util$a.isSome(x)){ return [x]; }
  return [];
};

/**
 *  Returns the data value of the given parameter, which might be a ResourceNode.
 *  Otherwise, it returns the value that was passed in.
 */
util$a.valData = function(val) {
  return (val instanceof ResourceNode$2) ? val.data : val;
};

/**
 *  Returns the data value of the given parameter, which might be a ResourceNode.
 *  Otherwise, it returns the value that was passed in.  In the case of a
 *  ResourceNode that is a Quantity, the returned value will have been converted
 *  to an FP_Quantity.
 */
util$a.valDataConverted = function(val) {
  if (val instanceof ResourceNode$2) {
    val = val.convertData();
  }
  return val;
};

/**
 * Prepares a string for insertion into a regular expression
 * @param {string} str
 * @return {string}
 */
util$a.escapeStringForRegExp = function (str) {
  return str.replace(/[-[\]{}()*+?.,\\/^$|#\s]/g, '\\$&');
};

/**
 * Binding to the Array.prototype.push.apply function to define a function to
 * push the contents of the source array to the destination array.
 * @name pushFn
 * @function
 * @param {Array} destArray - destination array
 * @param {Array} sourceArray - source array
 * @returns the new length property of destArray
 */
util$a.pushFn = Function.prototype.apply.bind(Array.prototype.push);

/**
 * Creates child resource nodes for the specified resource node property.
 * @param {ResourceNode} parentResNode - resource node
 * @param {string} childProperty - name of property
 * @param {object} [model] - "model" data object
 * @return {ResourceNode[]}
 */
util$a.makeChildResNodes = function(parentResNode, childProperty, model) {
  let childPath = parentResNode.path + '.' + childProperty;

  if (model) {
    let defPath = model.pathsDefinedElsewhere[childPath];
    if (defPath)
      childPath = defPath;
  }
  let toAdd, _toAdd;
  let actualTypes = model && model.choiceTypePaths[childPath];
  if (actualTypes) {
    // Use actualTypes to find the field's value
    for (let t of actualTypes) {
      let field = childProperty + t;
      toAdd = parentResNode.data?.[field];
      _toAdd = parentResNode.data?.['_' + field];
      if (toAdd !== undefined || _toAdd !== undefined) {
        childPath += t;
        break;
      }
    }
  }
  else {
    toAdd = parentResNode.data?.[childProperty];
    _toAdd = parentResNode.data?.['_' + childProperty];
    if (toAdd === undefined && _toAdd === undefined) {
      toAdd = parentResNode._data[childProperty];
    }
    if (childProperty === 'extension') {
      childPath = 'Extension';
    }
  }

  const fhirNodeDataType = model && model.path2Type[childPath] || null;
  childPath = fhirNodeDataType === 'BackboneElement' || fhirNodeDataType === 'Element' ? childPath : fhirNodeDataType || childPath;

  let result;
  if (util$a.isSome(toAdd) || util$a.isSome(_toAdd)) {
    if(Array.isArray(toAdd)) {
      result = toAdd.map((x, i)=>
        ResourceNode$2.makeResNode(x, childPath, _toAdd && _toAdd[i], fhirNodeDataType));
      // Add items to the end of the ResourceNode list that have no value
      // but have associated data, such as extensions or ids.
      const _toAddLength = _toAdd?.length || 0;
      for (let i = toAdd.length; i < _toAddLength; ++i) {
        result.push(ResourceNode$2.makeResNode(null, childPath, _toAdd[i], fhirNodeDataType));
      }
    } else if (toAdd == null && Array.isArray(_toAdd)) {
      // Add items to the end of the ResourceNode list when there are no
      // values at all, but there is a list of associated data, such as
      // extensions or ids.
      result = _toAdd.map((x) => ResourceNode$2.makeResNode(null, childPath, x, fhirNodeDataType));
    } else {
      result = [ResourceNode$2.makeResNode(toAdd, childPath, _toAdd, fhirNodeDataType)];
    }
  } else {
    result = [];
  }
  return result;
};

var utilities = util$a;

// Binding the function Array.prototype.slice.call for convert Array-like objects/collections to a new Array.
const slice = Function.prototype.call.bind(Array.prototype.slice);

// isInteger (not in IE)
// From Mozilla docs
Number.isInteger = Number.isInteger || function(value) {
  return typeof value === 'number' &&
    isFinite(value) &&
    Math.floor(value) === value;
};


if (!String.prototype.startsWith) {
  // From Mozilla docs with little changes
  Object.defineProperty(String.prototype, 'startsWith', {
    value: function(searchString, position) {
      position = position || 0;
      return this.indexOf(searchString, position) === position;
    }
  });
}

if (!String.prototype.endsWith) {
  // From Mozilla docs with little changes
  Object.defineProperty(String.prototype, 'endsWith', {
    value: function(searchString, position) {
      var subjectString = this.toString();
      if (position === undefined || position > subjectString.length) {
        position = subjectString.length;
      }
      position -= searchString.length;
      var lastIndex = subjectString.indexOf(searchString, position);
      return lastIndex !== -1 && lastIndex === position;
    }
  });
}

if (!String.prototype.includes) {
  Object.defineProperty(String.prototype, 'includes', {
    value: function() {
      return this.indexOf.apply(this, arguments) !== -1;
    }
  });
}

if (!Object.assign) {
  // From Mozilla docs with little changes
  Object.defineProperty(Object, 'assign', {
    value: function(target) {
      if (target === undefined || target === null) {
        throw new TypeError('Cannot convert undefined or null to object');
      }

      return slice(arguments, 1).reduce(function (to, nextSource) {
        Object.keys(Object(nextSource)).forEach(function (nextKey) {
          to[nextKey] = nextSource[nextKey];
        });
        return to;
      },  Object(target));
    }
  });
}

// Define btoa for NodeJS
if (typeof btoa === 'undefined') {
  commonjsGlobal.btoa = function (str) {
    return new Buffer.from(str, 'binary').toString('base64');
  };
}

// Define atob for NodeJS
if (typeof atob === 'undefined') {
  commonjsGlobal.atob = function (b64Encoded) {
    return new Buffer.from(b64Encoded, 'base64').toString('binary');
  };
}

// These are values that should not change during an evaluation of a FHIRPath
// expression (e.g. the return value of today(), per the spec.)  They are
// constant during at least one evaluation.

var constants$2 = {
  /**
   *  Resets the constants.  Should be called when before the engine starts its
   *  processing.
   */
  reset: function() {
    this.nowDate = new Date(); // a Date object representing "now"
    this.today = null;
    this.now = null;
    this.timeOfDay = null;
    this.localTimezoneOffset = null;
  },

  /**
   *  The cached value of today().
   */
  today: null,

  /**
   *  The cached value of now().
   */
  now: null,

  /**
   *  The cached value of timeOfDay().
   */
  timeOfDay: null
};

const ucumUtils = requireUcumPkg().UcumLhcUtils.getInstance();
const {roundToMaxPrecision} = numbers$2;
const {valDataConverted} = utilities;
const {FP_Type: FP_Type$4, FP_Quantity: FP_Quantity$4} = types$5;

/**
 *  Returns a JSON version of the given object, but with the object's keys
 *  in sorted order (or at least stable order,
 *  see https://stackoverflow.com/a/35810961/360782) and the values in
 *  unified forms, e.g. "1 year" is converted to the same value as "12 months",
 *  "3 'min'" is converted to the same value as "120 'sec'".
 *  This function is used instead of deepEqual for optimization when you need
 *  to compare many objects.
 */
function hashObject$3(obj) {
  return JSON.stringify(prepareObject(obj));
}

/**
 * Brings an object to the unified form so that it can be serialized to JSON to
 * compare with other objects according to https://hl7.org/fhirpath/#equals
 * This function is following the logic from deepEqual (if changes are needed
 * here they are likely also needed there).
 */
function prepareObject(value) {
  value = valDataConverted(value);
  if (value === null) {
    return null;
  } else if (typeof value === 'number') {
    return roundToMaxPrecision(value);
  } else if (value instanceof Date) {
    return value.toISOString();
  } if (value instanceof FP_Quantity$4) {
    const magnitude = FP_Quantity$4._yearMonthConversionFactor[value.unit];
    if (magnitude) {
      return '_!yearMonth!_:' + magnitude * value.value;
    } else {
      const ucumQuantity = FP_Quantity$4.toUcumQuantity(value.value, value.unit);
      const unit = ucumUtils.getSpecifiedUnit(ucumQuantity.unit).unit;
      return '_!' + unit.property_ + '!_:' + unit.magnitude_ * ucumQuantity.value;
    }
  } else if (value instanceof FP_Type$4) {
    return value.toString();
  } else if (typeof value === 'object') {
    return Array.isArray(value) ?
      value.map(prepareObject) :
      Object.keys(value).sort().reduce(
        (o, key) => {
          const v = value[key];
          o[key] = prepareObject(v);
          return o;
        }, {});
  }

  return  value;
}

var hashObject_1 = hashObject$3;

// Originally copied from node-deep-equal
// (https://github.com/substack/node-deep-equal), with modifications.
// For the license for node-deep-equal, see the bottom of this file.

const {FP_Type: FP_Type$3, FP_Quantity: FP_Quantity$3} = types$5;
var util$9 = utilities;
var numbers = numbers$2;
var pSlice = Array.prototype.slice;
var objectKeys = Object.keys;
var isArguments = function (object) {
  return Object.prototype.toString.call(object) == '[object Arguments]';
};

function isString(myVar) {
  return (typeof myVar === 'string' || myVar instanceof String);
}

function isNumber(n) {
  return !isNaN(parseFloat(n)) && isFinite(n);
}

function normalizeStr(x) {
  return x.toUpperCase().replace(/\s+/, ' ');
}

/**
 * Performs a deep comparison between two values to determine if they are equal.
 * When you need to compare many objects, you can use hashObject instead for
 * optimization (if changes are needed here, they are likely also needed there).
 * @param {any} actual - one of the comparing objects
 * @param {any} expected - one of the comparing objects
 * @param {Object} [opts] - comparison options
 * @param {boolean} [opts.fuzzy] - false (by default), if comparing objects for
 *   equality (see https://hl7.org/fhirpath/#equals).
 *   true, if comparing objects for equivalence
 *   (see https://hl7.org/fhirpath/#equivalent).
 * @return {boolean}
 */
function deepEqual$5(actual, expected, opts) {
  actual = util$9.valDataConverted(actual);
  expected = util$9.valDataConverted(expected);
  if (!opts) opts = {};

  // 7.1. All identical values are equivalent, as determined by ===.
  if (actual === expected) {
    return true;
  }

  if (opts.fuzzy) {
    if(isString(actual) && isString(expected)) {
      return normalizeStr(actual) == normalizeStr(expected);
    }
    if(isNumber(actual) && isNumber(expected)) {
      return numbers.isEquivalent(actual, expected);
    }
  }
  else { // !opts.fuzzy
    // If these are numbers, they need to be rounded to the maximum supported
    // precision to remove floating point arithmetic errors (e.g. 0.1+0.1+0.1 should
    // equal 0.3) before comparing.
    if (typeof actual === 'number' && typeof expected === 'number') {
      return numbers.isEqual(actual, expected);
    }
  }

  if (actual instanceof Date && expected instanceof Date) {
    return actual.getTime() === expected.getTime();
  } else if (!actual || !expected || typeof actual != 'object' && typeof expected != 'object') {
    return actual === expected;
  }
  else {
    var actualIsFPT = actual instanceof FP_Type$3;
    var expectedIsFPT = expected instanceof FP_Type$3;
    if (actualIsFPT && expectedIsFPT) { // if both are FP_Type
      return opts.fuzzy ? actual.equivalentTo(expected) :
        actual.equals(expected); // May return undefined
    }
    else if (actualIsFPT || expectedIsFPT) { // if only one is an FP_Type
      let anotherIsNumber = false;
      if (typeof actual == 'number') {
        actual = new FP_Quantity$3(actual, "'1'");
        anotherIsNumber = true;
      }
      if (typeof expected == 'number') {
        expected = new FP_Quantity$3(expected, "'1'");
        anotherIsNumber = true;
      }
      if (anotherIsNumber) {
        return opts.fuzzy ? actual.equivalentTo(expected) :
          actual.equals(expected);
      }
      return false;
    }
    // 7.4. For all other Object pairs, including Array objects, equivalence is
    // determined by having the same number of owned properties (as verified
    // with Object.prototype.hasOwnProperty.call), the same set of keys
    // (although not necessarily the same order), equivalent values for every
    // corresponding key, and an identical 'prototype' property. Note: this
    // accounts for both named and indexed properties on Arrays.
    return objEquiv(actual, expected, opts);
  }
}

function isUndefinedOrNull(value) {
  return value === null || value === undefined;
}

function objEquiv(a, b, opts) {
  var i, key;
  if (isUndefinedOrNull(a) || isUndefinedOrNull(b))
    return false;
  // an identical 'prototype' property.
  if (a.prototype !== b.prototype) return false;
  //~~~I've managed to break Object.keys through screwy arguments passing.
  //   Converting to array solves the problem.
  if(isArguments(a) || isArguments(b)) {
    a = isArguments(a) ? pSlice.call(a) : a;
    b = isArguments(b) ? pSlice.call(b) : b;
    return deepEqual$5(a, b, opts);
  }
  try {
    var ka = objectKeys(a), kb = objectKeys(b);
  } catch (e) {//happens when one is a string literal and the other isn't
    return false;
  }
  // having the same number of owned properties (keys incorporates
  // hasOwnProperty)
  if (ka.length != kb.length)
    return false;
  //the same set of keys (although not necessarily the same order),
  ka.sort();
  kb.sort();
  //~~~cheap key test
  for (i = ka.length - 1; i >= 0; i--) {
    if (ka[i] != kb[i])
      return false;
  }
  //equivalent values for every corresponding key, and
  //~~~possibly expensive deep test
  // If the length of the array is one, return the value of deepEqual (which can
  // be "undefined".
  if (ka.length === 1) {
    key = ka[0];
    return deepEqual$5(a[key], b[key], opts);
  }
  for (i = ka.length - 1; i >= 0; i--) {
    key = ka[i];
    if (!deepEqual$5(a[key], b[key], opts)) return false;
  }
  return typeof a === typeof b;
}

var deepEqual_1 = {
  deepEqual: deepEqual$5,
  // Maximum collection length to use deepEqual(). When comparing a large number
  // of collection items, it is more efficient to convert the items to strings
  // using the hashObject() function and compare them.
  maxCollSizeForDeepEqual: 6
};

// Contains the FHIRPath Filtering and Projection functions.  (Section 5.2 of
// the FHIRPath 1.0.0 specification).

/**
 *  Adds the filtering and projection functions to the given FHIRPath engine.
 */
const util$8 = utilities;
const {TypeInfo: TypeInfo$2, ResourceNode: ResourceNode$1} = types$5;
const hashObject$2 = hashObject_1;
const { deepEqual: deepEqual$4, maxCollSizeForDeepEqual: maxCollSizeForDeepEqual$2 } = deepEqual_1;

var engine$b = {};
engine$b.whereMacro = function(parentData, expr) {
  if(parentData !== false && ! parentData) { return []; }

  return util$8.flatten(parentData.filter((x, i) => {
    this.$index = i;
    return expr(x)[0];
  }));
};

engine$b.extension = function(parentData, url) {
  if(parentData !== false && ! parentData || !url) { return []; }

  return util$8.flatten(parentData.map((x, i) => {
    this.$index = i;
    const extensions = (x && (x.data && x.data.extension || x._data && x._data.extension));
    if (extensions) {
      return extensions
        .filter(extension => extension.url === url)
        .map(x => ResourceNode$1.makeResNode(x, 'Extension', null, 'Extension'));
    }
    return [];
  }));
};

engine$b.selectMacro = function(data, expr) {
  if(data !== false && ! data) { return []; }
  return util$8.flatten(data.map((x, i) => {
    this.$index = i;
    return expr(x);
  }));
};

engine$b.repeatMacro = function(parentData, expr) {
  if(parentData !== false && ! parentData) { return []; }

  let res = [];
  const unique = {};
  const length = parentData.length;
  for(let i = 0; i < length; ++i) {
    let newItems = parentData[i];
    do {
      newItems = expr(newItems)
        .filter(item => {
          const key = hashObject$2(item);
          const isUnique = !unique[key];
          if (isUnique) {
            unique[key] = true;
          }
          return isUnique;
        });
    } while (res.length < res.push.apply(res, newItems));
  }
  return res;
};

//TODO: behavior on object?
engine$b.singleFn = function(x) {
  if(x.length == 1){
    return x;
  } else if (x.length == 0) {
    return [];
  } else {
    throw new Error("Expected single");
  }
};


engine$b.firstFn = function(x) {
  return x[0];
};

engine$b.lastFn = function(x) {
  return x[x.length - 1];
};

engine$b.tailFn = function(x) {
  return x.slice(1, x.length);
};

engine$b.takeFn = function(x, n) {
  return x.slice(0, n);
};

engine$b.skipFn = function(x, num) {
  return x.slice(num, x.length);
};

engine$b.ofTypeFn = function(coll, typeInfo) {
  return coll.filter(value => {
    return TypeInfo$2.fromValue(value).is(typeInfo);
  });
};

engine$b.distinctFn = function(x) {
  let unique = [];
  if (x.length > 0) {
    if (x.length > maxCollSizeForDeepEqual$2) {
      // When we have more than maxCollSizeForDeepEqual items in input collection,
      // we use a hash table (on JSON strings) for efficiency.
      let uniqueHash = {};
      for (let i = 0, len = x.length; i < len; ++i) {
        let xObj = x[i];
        let xStr = hashObject$2(xObj);
        if (!uniqueHash[xStr]) {
          unique.push(xObj);
          uniqueHash[xStr] = true;
        }
      }
    } else {
      // Otherwise, it is more efficient to perform a deep comparison.
      // Use reverse() + pop() instead of shift() to improve performance and
      // maintain order.
      x = x.concat().reverse();
      do {
        let xObj = x.pop();
        unique.push(xObj);
        x = x.filter(o => !deepEqual$4(xObj, o));
      } while (x.length);
    }
  }
  return unique;
};

var filtering$1 = engine$b;

// This file holds code to hande the FHIRPath Existence functions (5.1 in the
// specification).

var util$7 = utilities;
var types$3 = types$5;

const { FP_Quantity: FP_Quantity$2, TypeInfo: TypeInfo$1 } = types$3;

var engine$a = {};

engine$a.iifMacro = function(data, cond, ok, fail) {
  if(util$7.isTrue(cond(data))) {
    return ok(data);
  } else {
    return fail ? fail(data) : [];
  }
};

engine$a.traceFn = function (x, label, expr) {
  if (this.customTraceFn) {
    if (expr){
      this.customTraceFn(expr(x), label ?? "");
    }
    else {
      this.customTraceFn(x, label ?? "");
    }
  }
  else {
    if (expr){
      console.log("TRACE:[" + (label || "") + "]", JSON.stringify(expr(x), null, " "));
    }
    else {
      console.log("TRACE:[" + (label || "") + "]", JSON.stringify(x, null, " "));
    }
  }
  return x;
};

var intRegex = /^[+-]?\d+$/;
engine$a.toInteger = function(coll){
  if(coll.length !== 1) { return []; }
  var v = util$7.valData(coll[0]);
  if(v === false) {return 0;}
  if(v === true) {return 1;}
  if(typeof v === "number") {
    if(Number.isInteger(v)) {
      return v;
    } else {
      return [];
    }
  }
  if(typeof v === "string" && intRegex.test(v)) {
    return parseInt(v);
  }
  return [];
};

const quantityRegex = /^((\+|-)?\d+(\.\d+)?)\s*(('[^']+')|([a-zA-Z]+))?$/,
  quantityRegexMap = {value:1,unit:5,time:6};
engine$a.toQuantity = function (coll, toUnit) {
  let result;

  if (coll.length > 1) {
    throw new Error("Could not convert to quantity: input collection contains multiple items");
  } else if (coll.length === 1) {
    if (toUnit) {
      const thisUnitInSeconds = FP_Quantity$2._calendarDuration2Seconds[this.unit];
      const toUnitInSeconds = FP_Quantity$2._calendarDuration2Seconds[toUnit];
      if (
        !thisUnitInSeconds !== !toUnitInSeconds &&
        (thisUnitInSeconds > 1 || toUnitInSeconds > 1)
      ) {
        // Conversion from calendar duration quantities greater than seconds to
        // time-valued UCUM quantities greater than seconds or vice versa is not
        // allowed.
        return null;
      }

      // Surround UCUM unit code in the toUnit parameter with single quotes
      if (!FP_Quantity$2.mapTimeUnitsToUCUMCode[toUnit]) {
        toUnit = `'${toUnit}'`;
      }
    }

    var v = util$7.valDataConverted(coll[0]);
    let quantityRegexRes;

    if (typeof v === "number") {
      result = new FP_Quantity$2(v, '\'1\'');
    } else if (v instanceof FP_Quantity$2) {
      result = v;
    } else if (typeof v === 'boolean') {
      result = new FP_Quantity$2(v ? 1 : 0, '\'1\'');
    } else if (typeof v === "string" && (quantityRegexRes = quantityRegex.exec(v)) ) {
      const value = quantityRegexRes[quantityRegexMap.value],
        unit = quantityRegexRes[quantityRegexMap.unit],
        time = quantityRegexRes[quantityRegexMap.time];

      // UCUM unit code in the input string must be surrounded with single quotes
      if (!time || FP_Quantity$2.mapTimeUnitsToUCUMCode[time]) {
        result = new FP_Quantity$2(Number(value), unit || time || '\'1\'');
      }
    }

    if (result && toUnit && result.unit !== toUnit) {
      result = FP_Quantity$2.convUnitTo(result.unit, result.value, toUnit);
    }
  }

  return result || [];
};

var numRegex = /^[+-]?\d+(\.\d+)?$/;
engine$a.toDecimal = function(coll){
  if(coll.length !== 1) { return []; }
  var v = util$7.valData(coll[0]);
  if(v === false) {return 0;}
  if(v === true) {return 1.0;}
  if(typeof v === "number") {
    return v;
  }
  if(typeof v === "string" && numRegex.test(v)) {
    return parseFloat(v);
  }
  return [];
};

engine$a.toString = function(coll){
  if(coll.length !== 1) { return []; }
  var v = util$7.valDataConverted(coll[0]);
  if (v == null) { return []; }
  return v.toString();
};


/**
 *  Defines a function on engine called to+timeType (e.g., toDateTime, etc.).
 * @param timeType The string name of a class for a time type (e.g. "FP_DateTime").
 */
function defineTimeConverter(timeType) {
  let timeName = timeType.slice(3); // Remove 'FP_'
  engine$a['to'+timeName] = function(coll) {
    var rtn = [];
    if (coll.length > 1)
      throw Error('to '+timeName+' called for a collection of length '+coll.length);
    if (coll.length === 1) {
      var v = util$7.valData(coll[0]);
      if (typeof v === "string") {
        var t = types$3[timeType].checkString(v);
        if (t) {
          rtn = t;
        }
      }
    }
    return rtn;
  };
}
defineTimeConverter('FP_Date');
defineTimeConverter('FP_DateTime');
defineTimeConverter('FP_Time');

// Possible string values convertible to the true boolean value
const trueStrings = ['true', 't', 'yes', 'y', '1', '1.0'].reduce((acc, val) => {
  acc[val] = true;
  return acc;
}, {});

// Possible string values convertible to the false boolean value
const falseStrings = ['false', 'f', 'no', 'n', '0', '0.0'].reduce((acc, val) => {
  acc[val] = true;
  return acc;
}, {});

engine$a.toBoolean = function (coll) {
  if(coll.length !== 1) {
    return [];
  }

  const v = util$7.valData(coll[0]);
  switch (typeof v) {
    case 'boolean':
      return v;
    case 'number':
      if (v === 1) {
        return true;
      }
      if (v === 0) {
        return false;
      }
      break;
    case 'string':
      // eslint-disable-next-line no-case-declarations
      const lowerCaseValue = v.toLowerCase();
      if (trueStrings[lowerCaseValue]) {
        return true;
      }
      if (falseStrings[lowerCaseValue]) {
        return false;
      }
  }
  return [];
};

/**
 * Creates function that checks if toFunction returns specified type
 * @param {function(coll: array): <type|[]>} toFunction
 * @param {string|class} type - specifies type, for example: 'string' or FP_Quantity
 * @return {function(coll: array)}
 */
engine$a.createConvertsToFn = function (toFunction, type) {
  if (typeof type === 'string') {
    return function (coll) {
      if (coll.length !== 1) {
        return [];
      }

      return typeof toFunction(coll) === type;
    };
  }

  return function (coll) {
    if (coll.length !== 1) {
      return [];
    }

    return toFunction(coll) instanceof type;
  };
};

const singletonEvalByType = {
  "Integer": function(d){
    if (Number.isInteger(d)) {
      return d;
    }
  },
  "Boolean": function(d){
    if (d === true || d === false) {
      return d;
    } else {
      return true;
    }
  },
  "Number": function(d) {
    if (typeof d === "number") {
      return d;
    }
  },
  "String": function(d){
    if (typeof d === "string") {
      return d;
    }
  }
};

/**
 * Converts a collection to a singleton of the specified type.
 * The result can be an empty array if input collection is empty.
 * See http://hl7.org/fhirpath/#singleton-evaluation-of-collections for details.
 * @param {Array} coll - collection
 * @param {string} type - 'Integer', 'Boolean', 'Number' or 'String'
 * @throws {Error}  if there is more than one item in input collection,
 *   or an item that is not a specified type
 * @return {*|[]} the value of specified type or empty array
 */
engine$a.singleton = function (coll, type) {
  if(coll.length > 1){
    throw new Error("Unexpected collection" + JSON.stringify(coll) +
      "; expected singleton of type " + type);
  } else if (coll.length === 0) {
    return [];
  }
  const v = util$7.valData(coll[0]);
  if (v == null) {
    return [];
  }
  const toSingleton = singletonEvalByType[type];
  if (toSingleton) {
    const value = toSingleton(v);
    if (value !== undefined) {
      return value;
    }
    throw new Error(`Expected ${type.toLowerCase()}, but got: ${JSON.stringify(coll)}`);
  }
  throw new Error('Not supported type ' + type);
};

/**
 * Checks whether a primitve value is present
 */
const primitives = new Set();
// IE11 probably doesn't support `new Set(iterable)`
[
  "instant",
  "time",
  "date",
  "dateTime",
  "base64Binary",
  "decimal",
  "integer64",
  "boolean",
  "string",
  "code",
  "markdown",
  "id",
  "integer",
  "unsignedInt",
  "positiveInt",
  "uri",
  "oid",
  "uuid",
  "canonical",
  "url",
  "Integer",
  "Decimal",
  "String",
  "Date",
  "DateTime",
  "Time"
].forEach(i => primitives.add(i));

engine$a.hasValueFn = function(coll) {
  return coll.length === 1 && util$7.valData(coll[0]) != null
    && primitives.has(TypeInfo$1.fromValue(coll[0]).name);
};

var misc$3 = engine$a;

// This file holds code to hande the FHIRPath Existence functions (5.1 in the
// specification).

const util$6 = utilities;
const {whereMacro, distinctFn: distinctFn$1} = filtering$1;
const misc$2 = misc$3;
const hashObject$1 = hashObject_1;
const { deepEqual: deepEqual$3, maxCollSizeForDeepEqual: maxCollSizeForDeepEqual$1 } = deepEqual_1;

const engine$9 = {};
engine$9.emptyFn = util$6.isEmpty;

engine$9.notFn = function(coll) {
  let d = misc$2.singleton(coll, 'Boolean');
  return (typeof (d) === 'boolean') ? !d : [];
};

engine$9.existsMacro  = function(coll, expr) {
  var vec = coll;
  if (expr) {
    return engine$9.existsMacro(whereMacro.call(this, coll, expr));
  }
  return !util$6.isEmpty(vec);
};

engine$9.allMacro = function(coll, expr) {
  for (let i=0, len=coll.length; i<len; ++i) {
    this.$index = i;
    if(!util$6.isTrue(expr(coll[i]))){
      return [false];
    }
  }
  return [true];
};

engine$9.allTrueFn  = function(x) {
  let rtn = true;
  for (let i=0, len=x.length; i<len && rtn; ++i) {
    let xi = util$6.assertType(x[i], ["boolean"], "allTrue");
    rtn = xi === true;
  }
  return [rtn];
};

engine$9.anyTrueFn  = function(x) {
  let rtn = false;
  for (let i=0, len=x.length; i<len && !rtn; ++i) {
    let xi = util$6.assertType(x[i], ["boolean"], "anyTrue");
    rtn = xi === true;
  }
  return [rtn];
};

engine$9.allFalseFn  = function(x) {
  let rtn = true;
  for (let i=0, len=x.length; i<len && rtn; ++i) {
    let xi = util$6.assertType(x[i], ["boolean"], "allFalse");
    rtn = xi === false;
  }
  return [rtn];
};

engine$9.anyFalseFn  = function(x) {
  let rtn = false;
  for (let i=0, len=x.length; i<len && !rtn; ++i) {
    let xi = util$6.assertType(x[i], ["boolean"], "anyFalse");
    rtn = xi === false;
  }
  return [rtn];
};


/**
 *  Returns true if coll1 is a subset of coll2.
 */
function subsetOf(coll1, coll2) {
  const coll1Length = coll1.length;
  const coll2Length = coll2.length;
  let rtn = coll1Length <= coll2Length;
  if (rtn) {
    if (coll1Length + coll2Length > maxCollSizeForDeepEqual$1) {
      // When we have more than maxCollSizeForDeepEqual items in input collections,
      // we use a hash table (on JSON strings) for efficiency.
      const c2Hash = coll2.reduce((hash, item) => {
        hash[hashObject$1(item)] = true;
        return hash;
      }, {});
      rtn = !coll1.some(item => !c2Hash[hashObject$1(item)]);
    } else {
      // Otherwise, it is more efficient to perform a deep comparison.
      for (let p=0, pLen=coll1.length; p<pLen && rtn; ++p) {
        let obj1 = util$6.valData(coll1[p]);
        rtn = coll2.some(obj2 => deepEqual$3(obj1, util$6.valData(obj2)));
      }
    }
  }
  return rtn;
}

engine$9.subsetOfFn = function(coll1, coll2) {
  return [subsetOf(coll1, coll2)];
};

engine$9.supersetOfFn = function(coll1, coll2) {
  return [subsetOf(coll2, coll1)];
};

engine$9.isDistinctFn = function(x) {
  return [x.length === distinctFn$1(x).length];
};

var existence$1 = engine$9;

// This file holds code to hande the FHIRPath Math functions.

const {FP_Quantity: FP_Quantity$1, FP_Type: FP_Type$2} = types$5;
const util$5 = utilities;

/**
 *  Adds the math functions to the given FHIRPath engine.
 */
const engine$8 = {};

/**
 * Checks if input collection is a number singleton and runs the passed function.
 * @param {Array<ResourceNode|number|any>} x - input collection
 * @param {Function} fn - math function
 * @throws Error
 * @return {number}
 */
function callFnForNumericSingleton(x, fn){
  let res;
  if (isEmpty(x)){
    res = [];
  } else if (x.length !== 1) {
    throw new Error("Unexpected collection" + JSON.stringify(x) +
      "; expected singleton of type number");
  } else {
    const num = util$5.valData(x[0]);
    if (num == null) {
      res = [];
    } else if (typeof num === 'number') {
      res = fn(num);
    } else {
      throw new Error("Expected number, but got " + JSON.stringify(num));
    }
  }
  return res;
}

function isEmpty(x) {
  if(typeof(x) == 'number'){
    return false;
  }
  return x.length === 0;
}

engine$8.amp = function(x, y){
  return (x || "") + (y || "");
};

//HACK: for only polymorphic function
//  Actually, "minus" is now also polymorphic
engine$8.plus = function(xs, ys){
  let res;
  if(xs.length === 1 && ys.length === 1) {
    const x = util$5.valDataConverted(xs[0]);
    const y = util$5.valDataConverted(ys[0]);
    // In the future, this and other functions might need to return ResourceNode
    // to preserve the type information (integer vs decimal, and maybe decimal
    // vs string if decimals are represented as strings), in order to support
    // "as" and "is", but that support is deferred for now.
    if (x == null || y == null) {
      res = [];
    } else if (typeof x == "string" && typeof y == "string") {
      res = x + y;
    } else if(typeof x == "number") {
      if (typeof y == "number") {
        res = x + y;
      } else if (y instanceof FP_Quantity$1) {
        res = (new FP_Quantity$1(x, "'1'")).plus(y);
      }
    } else if(x instanceof FP_Type$2) {
      if (y instanceof FP_Quantity$1) {
        res = x.plus(y);
      } else if (y instanceof FP_Type$2) {
        res = y.plus(x);
      } else if (typeof y == "number") {
        res = x.plus(new FP_Quantity$1(y, "'1'"));
      }
    }
  }
  if (res === undefined) {
    throw new Error("Cannot " + JSON.stringify(xs) + " + " + JSON.stringify(ys));
  }
  return res;
};

engine$8.minus = function(xs, ys){
  if(xs.length === 1 && ys.length === 1) {
    const x = util$5.valDataConverted(xs[0]);
    const y = util$5.valDataConverted(ys[0]);
    if (x == null || y == null) {
      return [];
    }
    if(typeof x == "number") {
      if (typeof y == "number") {
        return x - y;
      }
      if (y instanceof FP_Quantity$1) {
        return (new FP_Quantity$1(x, "'1'")).plus(new FP_Quantity$1(-y.value, y.unit));
      }
    }

    if(x instanceof FP_Type$2) {
      if (y instanceof FP_Quantity$1) {
        return x.plus(new FP_Quantity$1(-y.value, y.unit));
      }
      if (typeof y == "number") {
        return x.plus(new FP_Quantity$1(-y, "'1'"));
      }
    }
  }
  throw new Error("Cannot " + JSON.stringify(xs) + " - " + JSON.stringify(ys));
};


engine$8.mul = function(xs, ys){
  if(xs.length === 1 && ys.length === 1) {
    const x = util$5.valDataConverted(xs[0]);
    const y = util$5.valDataConverted(ys[0]);
    if (x == null || y == null) {
      return [];
    }
    if(typeof x == "number") {
      if (typeof y == "number") {
        return x * y;
      }
      if (y instanceof FP_Quantity$1) {
        return (new FP_Quantity$1(x, "'1'")).mul(y);
      }
    }

    if(x instanceof FP_Type$2) {
      if (y instanceof FP_Quantity$1) {
        return x.mul(y);
      }
      if (typeof y == 'number') {
        return x.mul(new FP_Quantity$1(y, "'1'"));
      }
    }
  }
  throw new Error("Cannot " + JSON.stringify(xs) + " * " + JSON.stringify(ys));
};

engine$8.div = function(xs, ys){
  if(xs.length === 1 && ys.length === 1) {
    const x = util$5.valDataConverted(xs[0]);
    const y = util$5.valDataConverted(ys[0]);
    if (x == null || y == null) {
      return [];
    }
    if(typeof x == "number") {
      if (typeof y == "number") {
        if (y === 0) return [];
        return x / y;
      }
      if (y instanceof FP_Quantity$1) {
        return (new FP_Quantity$1(x, "'1'")).div(y);
      }
    }

    if(x instanceof FP_Type$2) {
      if (y instanceof FP_Quantity$1) {
        return x.div(y);
      }
      if (typeof y == "number") {
        return x.div(new FP_Quantity$1(y, "'1'"));
      }
    }
  }
  throw new Error("Cannot " + JSON.stringify(xs) + " / " + JSON.stringify(ys));

};

engine$8.intdiv = function(x, y){
  if (y === 0) return [];
  return Math.floor(x / y);
};

engine$8.mod = function(x, y){
  if (y === 0) return [];
  return x % y;
};

engine$8.abs = function(x){
  let res;

  if (isEmpty(x)) {
    res = [];
  } else if (x.length !== 1) {
    throw new Error("Unexpected collection" + JSON.stringify(x) +
      "; expected singleton of type number or Quantity");
  } else {
    var val = util$5.valData(x[0]);
    if (val == null) {
      res = [];
    } else if (typeof val === 'number') {
      res = Math.abs(val);
    } else if (val instanceof FP_Quantity$1) {
      res = new FP_Quantity$1(Math.abs(val.value), val.unit);
    } else {
      throw new Error("Expected number or Quantity, but got " + JSON.stringify(val || x));
    }
  }

  return res;
};

engine$8.ceiling = function(x) {
  return callFnForNumericSingleton(x, Math.ceil);
};

engine$8.exp = function(x){
  return callFnForNumericSingleton(x, Math.exp);
};

engine$8.floor = function(x){
  return callFnForNumericSingleton(x, Math.floor);
};

engine$8.ln = function(x){
  return callFnForNumericSingleton(x, Math.log);
};

engine$8.log = function(x, base){
  return callFnForNumericSingleton(x, (num) => {
    return (Math.log(num) / Math.log(base));
  });
};

engine$8.power = function(x, exponent){
  return callFnForNumericSingleton(x, (num) => {
    const res = Math.pow(num, exponent);
    return isNaN(res) ? [] : res;
  });
};

/**
 * Implements the "round" function documented at
 * https://hl7.org/fhirpath/#roundprecision-integer-decimal
 * @param {Array} x - input collection
 * @param {integer} [precision] - determines what decimal place to round to
 * @return {number}
 */
engine$8.round = function(x, precision){
  return callFnForNumericSingleton(x, (num) => {
    if (precision === undefined) {
      return (Math.round(num));
    } else {
      let degree = Math.pow(10, precision);
      return (Math.round(num * degree) / degree);
    }
  });
};

engine$8.sqrt = function(x){
  return callFnForNumericSingleton(x, (num) => {
    if (num < 0) {
      return [];
    } else {
      return Math.sqrt(num);
    }
  });
};

engine$8.truncate = function(x){
  return callFnForNumericSingleton(x, Math.trunc);
};

var math$2 = engine$8;

// This file holds code to handle the FHIRPath Math functions.

const util$4 = utilities;
const { deepEqual: deepEqual$2 } = deepEqual_1;
const types$2 = types$5;
const FP_Type$1 = types$2.FP_Type;
const FP_DateTime$2 = types$2.FP_DateTime;

var engine$7 = {};

function equality$2(x,y){
  if(util$4.isEmpty(x) || util$4.isEmpty(y)) { return []; }
  return deepEqual$2(x, y);
}

function equivalence(x,y){
  if(util$4.isEmpty(x) && util$4.isEmpty(y)) { return [true]; }
  if(util$4.isEmpty(x) || util$4.isEmpty(y)) { return []; }
  return deepEqual$2(x, y, {fuzzy: true});
}

engine$7.equal = function(a, b){
  return equality$2(a, b);
};

engine$7.unequal = function(a, b){
  var eq = equality$2(a, b);
  return eq === undefined ? undefined : !eq;
};

engine$7.equival = function(a, b){
  return equivalence(a, b);
};

engine$7.unequival = function(a, b){
  return !equivalence(a, b);
};

/**
 *  Checks that the types of a and b are suitable for comparison in an
 *  inequality expression.
 * @param a the left side of the inequality expression (which should be an array of
 *  one value).
 * @param b the right side of the inequality expression (which should be an array of
 *  one value).
 * @return the singleton values of the arrays a, and b.  If one was an FP_Type
 *  and the other was convertible, the converted value will be returned.
 */
function typecheck(a, b){
  util$4.assertOnlyOne(a, "Singleton was expected");
  util$4.assertOnlyOne(b, "Singleton was expected");
  a = util$4.valDataConverted(a[0]);
  b = util$4.valDataConverted(b[0]);
  if (a != null && b != null) {
    let lClass = a instanceof FP_DateTime$2 ? FP_DateTime$2 : a.constructor;
    let rClass = b instanceof FP_DateTime$2 ? FP_DateTime$2 : b.constructor;
    if (lClass !== rClass) {
      util$4.raiseError('Type of "' + a + '" (' + lClass.name + ') did not match type of "' +
        b + '" (' + rClass.name + ')', 'InequalityExpression');
    }
  }
  return [a, b];
}

engine$7.lt = function(a, b){
  const [a0, b0] = typecheck(a,b);
  if (a0 == null || b0 == null) {
    return [];
  }
  if (a0 instanceof FP_Type$1) {
    const compare = a0.compare(b0);
    return compare === null ? [] : compare < 0;
  }
  return a0 < b0;
};

engine$7.gt = function(a, b){
  const [a0, b0] = typecheck(a,b);
  if (a0 == null || b0 == null) {
    return [];
  }
  if (a0 instanceof FP_Type$1) {
    const compare = a0.compare(b0);
    return compare === null ? [] : compare > 0;
  }
  return a0 > b0;
};

engine$7.lte = function(a, b){
  const [a0, b0] = typecheck(a,b);
  if (a0 == null || b0 == null) {
    return [];
  }
  if (a0 instanceof FP_Type$1) {
    const compare = a0.compare(b0);
    return compare === null ? [] : compare <= 0;
  }
  return  a0 <= b0;
};

engine$7.gte = function(a, b){
  const [a0, b0] = typecheck(a,b);
  if (a0 == null || b0 == null) {
    return [];
  }
  if (a0 instanceof FP_Type$1) {
    const compare = a0.compare(b0);
    return compare === null ? [] : compare >= 0;
  }
  return a0 >= b0;
};


var equality_1 = engine$7;

// Contains the FHIRPath Aggregate functions.
// (Section 7 of the FHIRPath 2.0.0 (N1) specification).

let engine$6 = {};
const math$1 = math$2;
const equality$1  = equality_1;
const util$3 = utilities;

engine$6.aggregateMacro = function(data, expr, initialValue) {
  return data.reduce((total, x, i) => {
    this.$index = i;
    return this.$total = expr(x);
  }, this.$total = initialValue);
};

engine$6.countFn = function(x) {
  if (x && x.length) {
    return x.length;
  } else {
    return 0;
  }
};

// Shortcut for "value.tail().aggregate($this+$total, value.first())" `
engine$6.sumFn = function(data) {
  return engine$6.aggregateMacro.apply(this, [data.slice(1), ($this) => {
    let x = util$3.arraify($this).filter(i => util$3.valData(i) != null);
    let y = util$3.arraify(this.$total).filter(i => util$3.valData(i) != null);
    if (x.length === 0 || y.length === 0) {
      return [];
    }
    return math$1.plus(x, y);
  }, data[0]]);
};

/**
 * Shortcut for "[source collection].aggregate(iif($total.empty(), $this, iif($this [operator] $total, $this, $total)))"
 * Used for functions min() and max().
 * @param {Array} data - source collection
 * @param {Function} fn - operator function
 * @return {Array}
 */
function minMaxShortcutTemplate(data, fn) {
  let $total;
  if (data.length === 0 || util$3.valData(data[0]) == null) {
    $total = [];
  } else {
    $total = [data[0]];
    for (let i = 1; i < data.length; i++) {
      if (util$3.valData(data[i]) == null) {
        $total = [];
        break;
      }
      const $this = [data[i]];
      $total = util$3.isTrue(fn($this, $total)) ? $this : $total;
    }
  }
  return $total;
}

// Shortcut for "value.aggregate(iif($total.empty(), $this, iif($this < $total, $this, $total)))"
engine$6.minFn = function (data) {
  return minMaxShortcutTemplate(data, equality$1.lt);
};

// Shortcut for "value.aggregate(iif($total.empty(), $this, iif($this > $total, $this, $total)))"
engine$6.maxFn = function (data) {
  return minMaxShortcutTemplate(data, equality$1.gt);
};

// Shortcut for "value.sum()/value.count()"
engine$6.avgFn = function (data) {
  const x = util$3.arraify(engine$6.sumFn(data));
  const y = util$3.arraify(engine$6.countFn(data));
  if (x.length === 0 || y.length === 0) {
    return [];
  }
  return math$1.div(x, y);
};

var aggregate$1 = engine$6;

// This file holds code to hande the FHIRPath Combining functions.

const combineFns = {};
const { distinctFn } = filtering$1;
const hashObject = hashObject_1;
const { deepEqual: deepEqual$1, maxCollSizeForDeepEqual } = deepEqual_1;

combineFns.union = function(coll1, coll2){
  return distinctFn(coll1.concat(coll2));
};

combineFns.combineFn = function(coll1, coll2){
  return coll1.concat(coll2);
};

combineFns.intersect = function(coll1, coll2) {
  let result = [];
  const coll1Length = coll1.length;
  let uncheckedLength = coll2.length;

  if (coll1Length && uncheckedLength) {
    if (coll1Length + uncheckedLength > maxCollSizeForDeepEqual) {
      // When we have more than maxCollSizeForDeepEqual items in input collections,
      // we use a hash table (on JSON strings) for efficiency.
      let coll2hash = {};
      coll2.forEach(item => {
        const hash = hashObject(item);
        if (coll2hash[hash]) {
          uncheckedLength--;
        } else {
          coll2hash[hash] = true;
        }
      });

      for (let i = 0; i < coll1Length && uncheckedLength > 0; ++i) {
        let item = coll1[i];
        let hash = hashObject(item);
        if (coll2hash[hash]) {
          result.push(item);
          coll2hash[hash] = false;
          uncheckedLength--;
        }
      }
    } else {
      // Otherwise, it is more efficient to perform a deep comparison.
      result = distinctFn(coll1).filter(
        obj1 => coll2.some(obj2 => deepEqual$1(obj1, obj2))
      );
    }
  }

  return result;
};


combineFns.exclude = function(coll1, coll2) {
  let result = [];

  const coll1Length = coll1.length;
  const coll2Length = coll2.length;

  if (!coll2Length) {
    return coll1;
  }
  if (coll1Length) {
    if (coll1Length + coll2Length > maxCollSizeForDeepEqual) {
      // When we have more than maxCollSizeForDeepEqual items in input collections,
      // we use a hash table (on JSON strings) for efficiency.
      let coll2hash = {};
      coll2.forEach(item => {
        const hash = hashObject(item);
        coll2hash[hash] = true;
      });

      result = coll1.filter(item => !coll2hash[hashObject(item)]);
    } else {
      // Otherwise, it is more efficient to perform a deep comparison.
      result = coll1.filter(item => {
        return !coll2.some(item2 => deepEqual$1(item, item2));
      });
    }
  }

  return result;
};


var combining$1 = combineFns;

// This file holds code to hande the FHIRPath Math functions.

const { deepEqual } = deepEqual_1;

const engine$5 = {};


// "b" is assumed to have one element and it tests whether "b[0]" is in "a"
function containsImpl(a,b){
  for(var i = 0; i < a.length; i++){
    if(deepEqual(a[i], b[0])) { return true; }
  }
  return false;
}

engine$5.contains = function(a, b){
  if(b.length == 0) { return []; }
  if(a.length == 0) { return false; }
  if(b.length > 1) {
    throw new Error("Expected singleton on right side of contains, got " + JSON.stringify(b));
  }
  return containsImpl(a,b);
};

engine$5.in = function(a, b){
  if(a.length == 0) { return []; }
  if(b.length == 0) { return false; }
  if(a.length > 1) {
    throw new Error("Expected singleton on right side of in, got " + JSON.stringify(b));
  }
  return containsImpl(b,a);
};

var collections$1 = engine$5;

const util$2 = utilities;
const misc$1 = misc$3;

const engine$4 = {};

// Cache for rewritten RegExp patterns
const cachedRegExp = {};

/**
 * Rewrites RegExp pattern to support single-line mode (dotAll) in IE11:
 * To do that we replace "." with "[^]" in source RegExp pattern,
 * except where "." is escaped or is inside unescaped [].
 * Another way to do the same is using package regexpu-core
 * or packages regjsparser/regjsgen.
 * @param {string} pattern - source RegExp pattern
 * @return {string}
 */
function rewritePatternForDotAll(pattern) {
  if (!cachedRegExp[pattern]) {
    cachedRegExp[pattern] = pattern.replace(/\./g, (_, offset, entirePattern) => {
      // The preceding part of the string
      const precedingPart = entirePattern.substr(0, offset);
      // The preceding part of the string without escaped characters: '\', '[' or ']'
      const cleanPrecedingPart = precedingPart
        .replace(/\\\\/g, '')
        .replace(/\\[\][]/g, '');
      // Check if '.' is escaped
      const escaped = cleanPrecedingPart[cleanPrecedingPart.length - 1] === '\\';
      // The last index of unescaped '['
      const lastIndexOfOpenBracket = cleanPrecedingPart.lastIndexOf('[');
      // The last index of unescaped ']'
      const lastIndexOfCloseBracket = cleanPrecedingPart.lastIndexOf(']');
      return escaped ||
        (lastIndexOfOpenBracket > lastIndexOfCloseBracket)
        ? '.'
        : '[^]';
    });
  }

  return cachedRegExp[pattern];
}

engine$4.indexOf = function (coll, substr) {
  const str = misc$1.singleton(coll, 'String');
  return util$2.isEmpty(substr) || util$2.isEmpty(str) ? [] : str.indexOf(substr);
};

engine$4.substring = function (coll, start, length) {
  const str = misc$1.singleton(coll, 'String');
  if (util$2.isEmpty(str) || util$2.isEmpty(start) || start < 0 || start >= str.length) {
    return [];
  }
  if (length === undefined || util$2.isEmpty(length)) {
    return str.substring(start);
  }
  return str.substring(start, start + length);
};

engine$4.startsWith = function (coll, prefix) {
  const str = misc$1.singleton(coll, 'String');
  return util$2.isEmpty(prefix) || util$2.isEmpty(str) ? [] : str.startsWith(prefix);
};

engine$4.endsWith = function (coll, postfix) {
  const str = misc$1.singleton(coll, 'String');
  return util$2.isEmpty(postfix) || util$2.isEmpty(str) ? [] : str.endsWith(postfix);
};

engine$4.containsFn = function (coll, substr) {
  const str = misc$1.singleton(coll, 'String');
  return util$2.isEmpty(substr) || util$2.isEmpty(str) ? [] : str.includes(substr);
};

engine$4.upper = function (coll) {
  const str = misc$1.singleton(coll, 'String');
  return util$2.isEmpty(str) ? [] : str.toUpperCase();
};

engine$4.lower = function (coll) {
  const str = misc$1.singleton(coll, 'String');
  return util$2.isEmpty(str) ? [] : str.toLowerCase();
};

// See https://build.fhir.org/ig/HL7/FHIRPath/#joinseparator-string-string
engine$4.joinFn = function (coll, separator) {
  const stringValues = [];
  coll.forEach((n) => {
    const d = util$2.valData(n);
    if (typeof d === "string") {
      stringValues.push(d);
    } else if (d != null) {
      throw new Error('Join requires a collection of strings.');
    }
  });
  if (util$2.isEmpty(stringValues)) {
    return [];
  }
  if (separator === undefined) {
    separator = "";
  }
  return stringValues.join(separator);
};

engine$4.splitFn = function (coll, separator) {
  const strToSplit = misc$1.singleton(coll, 'String');
  return util$2.isEmpty(strToSplit) ? [] : strToSplit.split(separator);
};

engine$4.trimFn = function (coll) {
  const strToTrim = misc$1.singleton(coll, 'String');
  return util$2.isEmpty(strToTrim) ? [] : strToTrim.trim();
};

// encoding/decoding
engine$4.encodeFn = function (coll, format) {
  const strToEncode = misc$1.singleton(coll, 'String');
  if (util$2.isEmpty(strToEncode)){
    return [];
  }
  if (format === 'urlbase64' || format === 'base64url'){
    return btoa(strToEncode).replace(/\+/g, '-').replace(/\//g, '_');
  }
  if (format === 'base64'){
    return btoa(strToEncode);
  }
  if (format === 'hex'){
    return  Array.from(strToEncode).map(c => 
      c.charCodeAt(0) < 128 ? c.charCodeAt(0).toString(16) : 
        encodeURIComponent(c).replace(/%/g,'')
    ).join('');
  }
  return [];
};

engine$4.decodeFn = function (coll, format) {
  const strDecode = misc$1.singleton(coll, 'String');
  if (util$2.isEmpty(strDecode)){
    return [];
  }
  if (format === 'urlbase64' || format === 'base64url'){
    return atob(strDecode.replace(/-/g, '+').replace(/_/g, '/'));
  }
  if (format === 'base64'){
    return atob(strDecode);
  }
  if (format === 'hex'){
    if (strDecode.length % 2 !== 0){
      throw new Error('Decode \'hex\' requires an even number of characters.');
    }
    return decodeURIComponent('%' + strDecode.match(/.{2}/g).join('%'));
  }
  return [];
};

// Check if dotAll is supported.
// See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp/dotAll for details.
const dotAllIsSupported = (new RegExp('')).dotAll === false;

if (dotAllIsSupported) {
  engine$4.matches = function (coll, regex) {
    const str = misc$1.singleton(coll, 'String');
    if (util$2.isEmpty(regex) || util$2.isEmpty(str)) {
      return [];
    }
    const reg = new RegExp(regex, 's');
    return reg.test(str);
  };
} else {
  engine$4.matches = function (coll, regex) {
    const str = misc$1.singleton(coll, 'String');
    if (util$2.isEmpty(regex) || util$2.isEmpty(str)) {
      return [];
    }
    const reg = new RegExp(rewritePatternForDotAll(regex));
    return reg.test(str);
  };
}

engine$4.replace = function (coll, pattern, repl) {
  const str = misc$1.singleton(coll, 'String');
  if (util$2.isEmpty(pattern) || util$2.isEmpty(repl) || util$2.isEmpty(str)) {
    return [];
  }
  const reg = new RegExp(util$2.escapeStringForRegExp(pattern), 'g');
  return str.replace(reg, repl);
};

engine$4.replaceMatches = function (coll, regex, repl) {
  const str = misc$1.singleton(coll, 'String');
  if (util$2.isEmpty(regex) || util$2.isEmpty(repl) || util$2.isEmpty(str)) {
    return [];
  }
  const reg = new RegExp(regex, 'g');
  return str.replace(reg, repl);
};

engine$4.length = function (coll) {
  const str = misc$1.singleton(coll, 'String');
  return util$2.isEmpty(str) ? [] : str.length;
};

engine$4.toChars = function (coll) {
  const str = misc$1.singleton(coll, 'String');
  return util$2.isEmpty(str) ? [] : str.split('');
};

var strings$1 = engine$4;

const util$1 = utilities;

var engine$3 = {};

engine$3.children = function(coll){
  let model = this.model; // "this" is the context object
  return coll.reduce(function(acc, x){
    let d = util$1.valData(x);
    if (d == null) {
      return acc;
    } else if (typeof d === 'object') {
      for (var prop of Object.keys(d)) {
        util$1.pushFn(acc, util$1.makeChildResNodes(x, prop, model));
      }
      return acc;
    } else {
      return acc;
    }
  }, []);
};

engine$3.descendants = function(coll){
  var ch = engine$3.children.call(this, coll); // "this" is the context object
  var res = [];
  while(ch.length > 0){
    util$1.pushFn(res, ch);
    ch = engine$3.children.call(this, ch);
  }
  return res;
};

var navigation$1 = engine$3;

var engine$2 = {};
const types$1 = types$5;
const constants$1 = constants$2;
const FP_Date$1 = types$1.FP_Date;
const FP_DateTime$1 = types$1.FP_DateTime;
const FP_Time$1 = types$1.FP_Time;

/**
 *  Implements FHIRPath now().
 */
engine$2.now = function(){
  if (!constants$1.now) {
    // return new FP_DateTime((new Date()).toISOString());
    // The above would construct an FP_DateTime with a timezone of "Z", which
    // would not make a difference for computation, but if the end result of an
    // expression is "now()", then it would look different when output to a user.
    // Construct it ourselves to preserve timezone
    var now = constants$1.nowDate; // a JS Date
    var isoStr = FP_DateTime$1.isoDateTime(now);
    constants$1.now = new FP_DateTime$1(isoStr);
  }
  return constants$1.now;
};


/**
 *  Implements FHIRPath today().  See comments in now(). This does not
 *  include a timezone offset.
 */
engine$2.today = function(){
  if (!constants$1.today) {
    // Construct the string ourselves to preserve timezone
    var now = constants$1.nowDate; // a JS Date
    var isoStr = FP_Date$1.isoDate(now);
    constants$1.today = new FP_Date$1(isoStr);
  }
  return constants$1.today;
};

/**
 *  Implements FHIRPath timeOfDay().  See comments in now(). This does not
 *  include a timezone offset.
 */
engine$2.timeOfDay = function() {
  if (!constants$1.timeOfDay) {
    // Construct the string ourselves to preserve timezone
    const now = constants$1.nowDate; // a JS Date
    const isoStr = FP_DateTime$1.isoTime(now);
    constants$1.timeOfDay = new FP_Time$1(isoStr);
  }
  return constants$1.timeOfDay;
};

var datetime$1 = engine$2;

var engine$1 = {};

engine$1.orOp = function(a, b) {
  if(Array.isArray(b)){
    if(a === true){
      return true;
    } else if (a === false) {
      return [];
    } else if (Array.isArray(a)) {
      return [];
    }
  }
  if(Array.isArray(a)){
    if(b === true ){
      return true;
    } else {
      return [];
    }
  }
  return a || b;
};

engine$1.andOp = function(a, b) {
  if(Array.isArray(b)){
    if(a === true){
      return [];
    } else if (a === false) {
      return false;
    } else if (Array.isArray(a)) {
      return [];
    }
  }
  if(Array.isArray(a)){
    if(b === true ){
      return [];
    } else {
      return false;
    }
  }
  return a && b;
};

engine$1.xorOp = function(a, b) {
  // If a or b are arrays, they must be the empty set.
  // In that case, the result is always the empty set.
  if (Array.isArray(a) || Array.isArray(b))
    return [];
  return ( a && !b ) || ( !a && b );
};

engine$1.impliesOp = function(a, b) {
  if(Array.isArray(b)){
    if(a === true){
      return [];
    } else if (a === false) {
      return true;
    } else if (Array.isArray(a)) {
      return [];
    }
  }
  if(Array.isArray(a)){
    if(b === true ){
      return true;
    } else {
      return [];
    }
  }
  if(a === false) { return true; }
  return (a && b);
};


var logic$1 = engine$1;

// This is fhirpath interpreter
// everything starts at evaluate function,
// which is passed  fhirpath AST and resource.
//
// We reduce/eval recursively each node in AST
// passing the context and current data
//
// each AST node has eval function, which should be registered in evalTable
// and named after node type
// if node needs to eval father it's children it has to call `doEval` function
//
// most of nodes do function or operator invocation at the end
//
// For invocation's and operator's there is one lookup table -
// invocationTable and two helper functions doInvoke and infixInvoke for
// operators
// 1. operator or function is looked up in table
// 2. using signature (in  .arity property) unpack parameters
// 3. check params types
// 4. do call function
// 5. wrap result by util.arraify
//
// if function is nullable
// and one of parameters is empty/null - function will not be invoked and empty
// result returned
//
// Not solved problem is overloading functions by types - for example + operator defined
// for strings and numbers
// we can make dispatching params type dependent - let see

const {version} = require$$0;
const parser = parser$1;
const util = utilities;

const constants = constants$2;

let engine    = {}; // the object with all FHIRPath functions and operations
let existence = existence$1;
let filtering = filtering$1;
let aggregate = aggregate$1;
let combining = combining$1;
let misc      = misc$3;
let equality  = equality_1;
let collections  = collections$1;
let math      = math$2;
let strings   = strings$1;
let navigation= navigation$1;
let datetime  = datetime$1;
let logic  = logic$1;
const types = types$5;
const {
  FP_Date, FP_DateTime, FP_Time, FP_Quantity,
  FP_Type, ResourceNode, TypeInfo
} = types;
let makeResNode = ResourceNode.makeResNode;

// * fn: handler
// * arity: is index map with type signature
//   if type is in array (like [Boolean]) - this means
//   function accepts value of this type or empty value {}
// * nullable - means propagate empty result, i.e. instead
//   calling function if one of params is  empty return empty

engine.invocationTable = {
  empty:        {fn: existence.emptyFn},
  not:          {fn: existence.notFn},
  exists:       {fn: existence.existsMacro, arity: {0: [], 1: ["Expr"]}},
  all:          {fn: existence.allMacro, arity: {1: ["Expr"]}},
  allTrue:      {fn: existence.allTrueFn},
  anyTrue:      {fn: existence.anyTrueFn},
  allFalse:     {fn: existence.allFalseFn},
  anyFalse:     {fn: existence.anyFalseFn},
  subsetOf:     {fn: existence.subsetOfFn, arity: {1: ["AnyAtRoot"]}},
  supersetOf:   {fn: existence.supersetOfFn, arity: {1: ["AnyAtRoot"]}},
  isDistinct:   {fn: existence.isDistinctFn},
  distinct:     {fn: filtering.distinctFn},
  count:        {fn: aggregate.countFn},
  where:        {fn: filtering.whereMacro, arity: {1: ["Expr"]}},
  extension:    {fn: filtering.extension, arity: {1: ["String"]}},
  select:       {fn: filtering.selectMacro, arity: {1: ["Expr"]}},
  aggregate:    {fn: aggregate.aggregateMacro, arity: {1: ["Expr"], 2: ["Expr", "AnyAtRoot"]}},
  sum:          {fn: aggregate.sumFn},
  min:          {fn: aggregate.minFn},
  max:          {fn: aggregate.maxFn},
  avg:          {fn: aggregate.avgFn},
  single:       {fn: filtering.singleFn},
  first:        {fn: filtering.firstFn},
  last:         {fn: filtering.lastFn},
  type:         {fn: types.typeFn, arity: {0: []}},
  ofType:       {fn: filtering.ofTypeFn, arity: {1: ["TypeSpecifier"]}},
  is:           {fn: types.isFn, arity: {1: ["TypeSpecifier"]}},
  as:           {fn: types.asFn, arity: {1: ["TypeSpecifier"]}},
  tail:         {fn: filtering.tailFn},
  take:         {fn: filtering.takeFn, arity: {1: ["Integer"]}},
  skip:         {fn: filtering.skipFn, arity: {1: ["Integer"]}},
  combine:      {fn: combining.combineFn, arity: {1: ["AnyAtRoot"]}},
  union:        {fn: combining.union,   arity: {1: ["AnyAtRoot"]}},
  intersect:    {fn: combining.intersect,   arity: {1: ["AnyAtRoot"]}},
  exclude:      {fn: combining.exclude,   arity: {1: ["AnyAtRoot"]}},
  iif:          {fn: misc.iifMacro,    arity: {2: ["Expr", "Expr"], 3: ["Expr", "Expr", "Expr"]}},
  trace:        {fn: misc.traceFn,     arity: {1: ["String"], 2: ["String", "Expr"]}},
  toInteger:    {fn: misc.toInteger},
  toDecimal:    {fn: misc.toDecimal},
  toString:     {fn: misc.toString},
  toDate:       {fn: misc.toDate},
  toDateTime:   {fn: misc.toDateTime},
  toTime:       {fn: misc.toTime},
  toBoolean:    {fn: misc.toBoolean},
  toQuantity:   {fn: misc.toQuantity, arity: {0: [], 1: ["String"]}},
  // TODO: The hasValue function should be taken into account in a separate request
  hasValue:     {fn: misc.hasValueFn},
  convertsToBoolean:    {fn: misc.createConvertsToFn(misc.toBoolean, 'boolean')},
  convertsToInteger:    {fn: misc.createConvertsToFn(misc.toInteger, 'number')},
  convertsToDecimal:    {fn: misc.createConvertsToFn(misc.toDecimal, 'number')},
  convertsToString:     {fn: misc.createConvertsToFn(misc.toString, 'string')},
  convertsToDate:       {fn: misc.createConvertsToFn(misc.toDate, FP_Date)},
  convertsToDateTime:   {fn: misc.createConvertsToFn(misc.toDateTime, FP_DateTime)},
  convertsToTime:       {fn: misc.createConvertsToFn(misc.toTime, FP_Time)},
  convertsToQuantity:   {fn: misc.createConvertsToFn(misc.toQuantity, FP_Quantity)},

  indexOf:        {fn: strings.indexOf,          arity: {1: ["String"]}},
  substring:      {fn: strings.substring,        arity: {1: ["Integer"], 2: ["Integer","Integer"]}},
  startsWith:     {fn: strings.startsWith,       arity: {1: ["String"]}},
  endsWith:       {fn: strings.endsWith,         arity: {1: ["String"]}},
  contains:       {fn: strings.containsFn,       arity: {1: ["String"]}},
  upper:          {fn: strings.upper},
  lower:          {fn: strings.lower},
  replace:        {fn: strings.replace,          arity: {2: ["String", "String"]}},
  matches:        {fn: strings.matches,          arity: {1: ["String"]}},
  replaceMatches: {fn: strings.replaceMatches,   arity: {2: ["String", "String"]}},
  length:         {fn: strings.length },
  toChars:        {fn: strings.toChars },
  join:           {fn: strings.joinFn,           arity: {0: [], 1: ["String"]}},
  split:          {fn: strings.splitFn,          arity: {1: ["String"]}},
  trim:           {fn: strings.trimFn},

  encode:         {fn: strings.encodeFn,         arity: {1: ["String"]}},
  decode:         {fn: strings.decodeFn,         arity: {1: ["String"]}},

  abs:            {fn: math.abs},
  ceiling:        {fn: math.ceiling},
  exp:            {fn: math.exp},
  floor:          {fn: math.floor},
  ln:             {fn: math.ln},
  log:            {fn: math.log, arity:  {1: ["Number"]}, nullable: true},
  power:          {fn: math.power, arity:  {1: ["Number"]}, nullable: true},
  round:          {fn: math.round, arity:  {0: [], 1: ["Number"]}},
  sqrt:           {fn: math.sqrt},
  truncate:       {fn: math.truncate},

  now:            {fn: datetime.now },
  today:          {fn: datetime.today },
  timeOfDay:      {fn: datetime.timeOfDay },

  repeat:          {fn: filtering.repeatMacro, arity: {1: ["Expr"]}},
  children:        {fn: navigation.children },
  descendants:     {fn: navigation.descendants },

  "|":          {fn: combining.union,   arity: {2: ["Any", "Any"]}},
  "=":          {fn: equality.equal,   arity: {2: ["Any", "Any"]}, nullable: true},
  "!=":         {fn: equality.unequal,   arity: {2: ["Any", "Any"]}, nullable: true},
  "~":          {fn: equality.equival,   arity: {2: ["Any", "Any"]}},
  "!~":         {fn: equality.unequival,   arity: {2: ["Any", "Any"]}},
  "<":          {fn: equality.lt,   arity: {2: ["Any", "Any"]}, nullable: true},
  ">":          {fn: equality.gt,   arity: {2: ["Any", "Any"]}, nullable: true},
  "<=":         {fn: equality.lte,  arity: {2: ["Any", "Any"]}, nullable: true},
  ">=":         {fn: equality.gte,  arity: {2: ["Any", "Any"]}, nullable: true},
  "containsOp": {fn: collections.contains,   arity: {2: ["Any", "Any"]}},
  "inOp":       {fn: collections.in,  arity: {2: ["Any", "Any"]}},
  "isOp":       {fn: types.isFn,  arity: {2: ["Any", "TypeSpecifier"]}},
  "asOp":       {fn: types.asFn,  arity: {2: ["Any", "TypeSpecifier"]}},
  "&":          {fn: math.amp,     arity:  {2: ["String", "String"]}},
  "+":          {fn: math.plus,    arity:  {2: ["Any", "Any"]}, nullable: true},
  "-":          {fn: math.minus,   arity:  {2: ["Any", "Any"]}, nullable: true},
  "*":          {fn: math.mul,     arity:  {2: ["Any", "Any"]}, nullable: true},
  "/":          {fn: math.div,     arity:  {2: ["Any", "Any"]}, nullable: true},
  "mod":        {fn: math.mod,     arity:  {2: ["Number", "Number"]}, nullable: true},
  "div":        {fn: math.intdiv,  arity:  {2: ["Number", "Number"]}, nullable: true},

  "or":        {fn: logic.orOp,  arity:       {2: [["Boolean"], ["Boolean"]]}},
  "and":       {fn: logic.andOp,  arity:      {2: [["Boolean"], ["Boolean"]]}},
  "xor":       {fn: logic.xorOp,  arity:      {2: [["Boolean"], ["Boolean"]]}},
  "implies":   {fn: logic.impliesOp,  arity:  {2: [["Boolean"], ["Boolean"]]}},
};

engine.InvocationExpression = function(ctx, parentData, node) {
  return node.children.reduce(function(acc, ch) {
    return engine.doEval(ctx, acc, ch);
  }, parentData);
};

engine.TermExpression = function(ctx, parentData, node) {
  if (parentData) {
    parentData = parentData.map((x) => {
      if (x instanceof Object && x.resourceType) {
        return makeResNode(x, x.resourceType, null, x.resourceType);
      }
      return x;
    });
  }

  return engine.doEval(ctx,parentData, node.children[0]);
};

engine.PolarityExpression = function(ctx, parentData, node) {
  var sign = node.terminalNodeText[0]; // either - or + per grammar
  var rtn = engine.doEval(ctx,parentData, node.children[0]);
  if (rtn.length !== 1) {  // not yet in spec, but per Bryn Rhodes
    throw new Error('Unary ' + sign +
     ' can only be applied to an individual number or Quantity.');
  }
  if (rtn[0] instanceof FP_Quantity) {
    if (sign === '-') {
      rtn[0] = new FP_Quantity(-rtn[0].value, rtn[0].unit);
    }
  } else if (typeof rtn[0] === 'number' && !isNaN(rtn[0])) {
    if (sign === '-') {
      rtn[0] = -rtn[0];
    }
  } else {
    throw new Error('Unary ' + sign + ' can only be applied to a number or Quantity.');
  }

  return rtn;
};

engine.TypeSpecifier = function(ctx, parentData, node) {
  let namespace, name;
  const identifiers = node.text.split('.').map(i => i.replace(/(^`|`$)/g, ""));
  switch (identifiers.length) {
    case 2:
      [namespace, name] = identifiers;
      break;
    case 1:
      [name] = identifiers;
      break;
    default:
      throw new Error("Expected TypeSpecifier node, got " + JSON.stringify(node));
  }

  const typeInfo =  new TypeInfo({ namespace, name });
  if (!typeInfo.isValid()) {
    throw new Error('"' + typeInfo + '" cannot be resolved to a valid type identifier');
  }
  return typeInfo;
};

engine.ExternalConstantTerm = function(ctx, parentData, node) {
  var extConstant = node.children[0];
  var identifier = extConstant.children[0];
  var varName = engine.Identifier(ctx, parentData, identifier)[0];
  var value = ctx.vars[varName];
  if (!(varName in ctx.vars)) {
    throw new Error(
      "Attempting to access an undefined environment variable: " + varName
    );
  }
  // For convenience, we all variable values to be passed in without their array
  // wrapper.  However, when evaluating, we need to put the array back in.
  return value === undefined || value === null
    ? []
    : value instanceof Array ? value : [value];
};

engine.LiteralTerm = function(ctx, parentData, node) {
  var term = node.children[0];
  if(term){
    return engine.doEval(ctx, parentData, term);
  } else {
    return [node.text];
  }
};

engine.StringLiteral = function(ctx, parentData, node) {
  // Remove the beginning and ending quotes.
  var rtn = node.text.replace(/(^'|'$)/g, "");
  rtn = rtn.replace(/\\(u\d{4}|.)/g, function(match, submatch) {
    switch(match) {
      case '\\r':
        return '\r';
      case '\\n':
        return "\n";
      case '\\t':
        return '\t';
      case '\\f':
        return '\f';
      default:
        if (submatch.length > 1)
          return String.fromCharCode('0x'+submatch.slice(1));
        else
          return submatch;
    }
  });
  return [rtn];
};

engine.BooleanLiteral = function(ctx, parentData, node) {
  if(node.text  === "true") {
    return [true];
  } else {
    return [false];
  }
};

engine.QuantityLiteral = function(ctx, parentData, node) {
  var valueNode = node.children[0];
  var value = Number(valueNode.terminalNodeText[0]);
  var unitNode = valueNode.children[0];
  var unit = unitNode.terminalNodeText[0];
  // Sometimes the unit is in a child node of the child
  if (!unit && unitNode.children)
    unit = unitNode.children[0].terminalNodeText[0];

  return [new FP_Quantity(value, unit)];
};

engine.DateTimeLiteral = function(ctx, parentData, node) {
  var dateStr = node.text.slice(1); // Remove the @
  return [new FP_DateTime(dateStr)];
};

engine.TimeLiteral = function(ctx, parentData, node) {
  var timeStr = node.text.slice(1); // Remove the @
  return [new FP_Time(timeStr)];
};

engine.NumberLiteral = function(ctx, parentData, node) {
  return [Number(node.text)];
};

engine.Identifier = function(ctx, parentData, node) {
  return [node.text.replace(/(^`|`$)/g, "")];
};

engine.InvocationTerm = function(ctx, parentData, node) {
  return engine.doEval(ctx,parentData, node.children[0]);
};


engine.MemberInvocation = function(ctx, parentData, node ) {
  const key = engine.doEval(ctx, parentData, node.children[0])[0];
  const model = ctx.model;

  if (parentData) {
    if(util.isCapitalized(key)) {
      return parentData
        .filter((x) => x instanceof ResourceNode && x.path === key);
    } else {
      return parentData.reduce(function(acc, res) {
        res = makeResNode(res, res.__path__?.path || null, null,
          res.__path__?.fhirNodeDataType || null);
        util.pushFn(acc, util.makeChildResNodes(res, key, model));
        return acc;
      }, []);
    }
  } else {
    return [];
  }
};

engine.IndexerExpression = function(ctx, parentData, node) {
  const coll_node = node.children[0];
  const idx_node = node.children[1];
  var coll = engine.doEval(ctx, parentData, coll_node);
  var idx = engine.doEval(ctx, parentData, idx_node);

  if(util.isEmpty(idx)) {
    return [];
  }

  var idxNum = parseInt(idx[0]);
  if(coll && util.isSome(idxNum) && coll.length>idxNum && idxNum>=0) {
    return [coll[idxNum]];
  } else {
    return [];
  }
};

engine.Functn = function(ctx, parentData, node) {
  return node.children.map(function(x) {
    return engine.doEval(ctx, parentData, x);
  });
};

engine.realizeParams = function(ctx, parentData, args) {
  if(args && args[0] && args[0].children) {
    return args[0].children.map(function(x) {
      return engine.doEval(ctx, parentData, x);
    });
  } else {
    return [];
  }
};

function makeParam(ctx, parentData, type, param) {
  if(type === "Expr"){
    return function(data) {
      const $this = util.arraify(data);
      return engine.doEval({ ...ctx, $this }, $this, param);
    };
  }
  if(type === "AnyAtRoot"){
    const $this = ctx.$this || ctx.dataRoot;
    return engine.doEval({ ...ctx, $this}, $this, param);
  }
  if(type === "Identifier"){
    if(param.type === "TermExpression") {
      return param.text;
    } else {
      throw new Error("Expected identifier node, got " + JSON.stringify(param));
    }
  }

  if(type === "TypeSpecifier") {
    return engine.TypeSpecifier(ctx, parentData, param);
  }

  let res = engine.doEval(ctx, parentData, param);
  if(type === "Any") {
    return res;
  }
  if(Array.isArray(type)) {
    if(res.length === 0) {
      return [];
    } else {
      type = type[0];
    }
  }
  return misc.singleton(res, type);
}

function doInvoke(ctx, fnName, data, rawParams){
  var invoc = ctx.userInvocationTable?.[fnName] ?? engine.invocationTable[fnName];
  var res;
  if(invoc) {
    if(!invoc.arity){
      if(!rawParams){
        res = invoc.fn.call(ctx, data);
        return util.arraify(res);
      } else {
        throw new Error(fnName + " expects no params");
      }
    } else {
      var paramsNumber = rawParams ? rawParams.length : 0;
      var argTypes = invoc.arity[paramsNumber];
      if(argTypes){
        var params = [];
        for(var i = 0; i < paramsNumber; i++){
          var tp = argTypes[i];
          var pr = rawParams[i];
          params.push(makeParam(ctx, data, tp, pr));
        }
        params.unshift(data);
        if(invoc.nullable) {
          if(params.some(isNullable)){
            return [];
          }
        }
        res = invoc.fn.apply(ctx, params);
        return util.arraify(res);
      } else {
        console.log(fnName + " wrong arity: got " + paramsNumber );
        return [];
      }
    }
  } else {
    throw new Error("Not implemented: " + fnName);
  }
}
function isNullable(x) {
  return x === null || x === undefined || util.isEmpty(x);
}

function infixInvoke(ctx, fnName, data, rawParams){
  var invoc = engine.invocationTable[fnName];
  if(invoc && invoc.fn) {
    var paramsNumber = rawParams ? rawParams.length : 0;
    if(paramsNumber !== 2) { throw new Error("Infix invoke should have arity 2"); }
    var argTypes = invoc.arity[paramsNumber];
    if(argTypes){
      var params = [];
      for(var i = 0; i < paramsNumber; i++){
        var tp = argTypes[i];
        var pr = rawParams[i];
        params.push(makeParam(ctx, data, tp, pr));
      }
      if(invoc.nullable) {
        if(params.some(isNullable)){
          return [];
        }
      }
      var res = invoc.fn.apply(ctx, params);
      return util.arraify(res);
    } else {
      console.log(fnName + " wrong arity: got " + paramsNumber );
      return [];
    }
  } else {
    throw new Error("Not impl " + fnName);
  }
}

engine.FunctionInvocation = function(ctx, parentData, node) {
  var args = engine.doEval(ctx, parentData, node.children[0]);
  const fnName = args[0];
  args.shift();
  var rawParams = args && args[0] && args[0].children;
  return doInvoke(ctx, fnName, parentData, rawParams);
};

engine.ParamList = function(ctx, parentData, node) {
  // we do not eval param list because sometimes it should be passed as
  // lambda/macro (for example in case of where(...)
  return node;
};


engine.UnionExpression = function(ctx, parentData, node) {
  return infixInvoke(ctx, '|', parentData, node.children);
};

engine.ThisInvocation = function(ctx) {
  return ctx.$this;
};

engine.TotalInvocation = function(ctx) {
  return util.arraify(ctx.$total);
};

engine.IndexInvocation = function(ctx) {
  return util.arraify(ctx.$index);
};

engine.OpExpression = function(ctx, parentData, node) {
  var op = node.terminalNodeText[0];
  return infixInvoke(ctx, op, parentData, node.children);
};

engine.AliasOpExpression = function(map){
  return function(ctx, parentData, node) {
    var op = node.terminalNodeText[0];
    var alias = map[op];
    if(!alias) { throw new Error("Do not know how to alias " + op + " by " + JSON.stringify(map)); }
    return infixInvoke(ctx, alias, parentData, node.children);
  };
};

engine.NullLiteral = function() {
  return [];
};

engine.ParenthesizedTerm = function(ctx, parentData, node) {
  return engine.doEval(ctx, parentData, node.children[0]);
};


engine.evalTable = { // not every evaluator is listed if they are defined on engine
  BooleanLiteral: engine.BooleanLiteral,
  EqualityExpression: engine.OpExpression,
  FunctionInvocation: engine.FunctionInvocation,
  Functn: engine.Functn,
  Identifier: engine.Identifier,
  IndexerExpression: engine.IndexerExpression,
  InequalityExpression: engine.OpExpression,
  InvocationExpression: engine.InvocationExpression,
  AdditiveExpression: engine.OpExpression,
  MultiplicativeExpression: engine.OpExpression,
  TypeExpression: engine.AliasOpExpression({"is": "isOp", "as": "asOp"}),
  MembershipExpression: engine.AliasOpExpression({"contains": "containsOp", "in": "inOp"}),
  NullLiteral: engine.NullLiteral,
  EntireExpression: engine.InvocationTerm,
  InvocationTerm: engine.InvocationTerm,
  LiteralTerm: engine.LiteralTerm,
  MemberInvocation: engine.MemberInvocation,
  NumberLiteral: engine.NumberLiteral,
  ParamList: engine.ParamList,
  ParenthesizedTerm: engine.ParenthesizedTerm,
  StringLiteral: engine.StringLiteral,
  TermExpression: engine.TermExpression,
  ThisInvocation: engine.ThisInvocation,
  TotalInvocation: engine.TotalInvocation,
  IndexInvocation: engine.IndexInvocation,
  UnionExpression: engine.UnionExpression,
  OrExpression: engine.OpExpression,
  ImpliesExpression: engine.OpExpression,
  AndExpression: engine.OpExpression,
  XorExpression: engine.OpExpression
};


engine.doEval = function(ctx, parentData, node) {
  const evaluator = engine.evalTable[node.type] || engine[node.type];
  if(evaluator){
    return evaluator.call(engine, ctx, parentData, node);
  } else {
    throw new Error("No " + node.type + " evaluator ");
  }
};

function parse(path) {
  return parser.parse(path);
}


/**
 *  Applies the given parsed FHIRPath expression to the given resource,
 *  returning the result of doEval.
 * @param {(object|object[])} resource -  FHIR resource, bundle as js object or array of resources
 *  This resource will be modified by this function to add type information.
 * @param {object} parsedPath - a special object created by the parser that describes the structure of a fhirpath expression.
 * @param {object} context - a hash of variable name/value pairs.
 * @param {object} model - The "model" data object specific to a domain, e.g. R4.
 *  For example, you could pass in the result of require("fhirpath/fhir-context/r4");
 * @param {object} options - additional options:
 * @param {boolean} [options.resolveInternalTypes] - whether values of internal
 *  types should be converted to strings, true by default.
 * @param {function} [options.traceFn] - An optional trace function to call when tracing.
 * @param {object} [options.userInvocationTable] - a user invocation table used
 *  to replace any existing or define new functions.
 */
function applyParsedPath(resource, parsedPath, context, model, options) {
  constants.reset();
  let dataRoot = util.arraify(resource).map(
    i => i?.__path__
      ? makeResNode(i, i.__path__.path, null,
        i.__path__.fhirNodeDataType || null)
      : i );
  // doEval takes a "ctx" object, and we store things in that as we parse, so we
  // need to put user-provided variable data in a sub-object, ctx.vars.
  // Set up default standard variables, and allow override from the variables.
  // However, we'll keep our own copy of dataRoot for internal processing.
  let vars = {context: dataRoot, ucum: 'http://unitsofmeasure.org'};
  // Restore the ResourceNodes for the top-level objects of the context
  // variables. The nested objects will be converted to ResourceNodes
  // in the MemberInvocation method.
  if (context) {
    context = Object.keys(context).reduce((restoredContext, key) => {
      if (Array.isArray(context[key])) {
        restoredContext[key] = context[key].map(
          i => i?.__path__
            ? makeResNode(i, i.__path__.path || null, null,
              i.__path__.fhirNodeDataType || null)
            : i );
      } else {
        restoredContext[key] = context[key]?.__path__
          ? makeResNode(context[key], context[key].__path__.path || null, null,
            context[key].__path__.fhirNodeDataType || null)
          : context[key];
      }
      return restoredContext;
    }, {});
  }
  let ctx = {dataRoot, vars: Object.assign(vars, context), model};
  if (options.traceFn) {
    ctx.customTraceFn = options.traceFn;
  }
  if (options.userInvocationTable) {
    ctx.userInvocationTable = options.userInvocationTable;
  }
  return  engine.doEval(ctx, dataRoot, parsedPath.children[0])
    // engine.doEval returns array of "ResourceNode" and/or "FP_Type" instances.
    // "ResourceNode" or "FP_Type" instances are not created for sub-items.
    // Resolve any internal "ResourceNode" instances to plain objects and if
    // options.resolveInternalTypes is true, resolve any internal "FP_Type"
    // instances to strings.
    .reduce((acc,n) => {
      // Path for the data extracted from the resource.
      let path;
      let fhirNodeDataType;
      if (n instanceof ResourceNode) {
        path = n.path;
        fhirNodeDataType = n.fhirNodeDataType;
      }
      n = util.valData(n);
      if (n instanceof FP_Type) {
        if (options.resolveInternalTypes) {
          n = n.toString();
        }
      }
      // Exclude nulls
      if (n != null) {
        // Add a hidden (non-enumerable) property with the path to the data extracted
        // from the resource.
        if (path && typeof n === 'object' && !n.__path__) {
          Object.defineProperty(n, '__path__', { value: {path, fhirNodeDataType} });
        }
        acc.push(n);
      }
      return acc;
    }, []);
}

/**
 * Resolves any internal "FP_Type" instances in a result of FHIRPath expression
 * evaluation to standard JavaScript types.
 * @param {any} val - a result of FHIRPath expression evaluation
 * @returns {any} a new object with resolved values.
 */
function resolveInternalTypes(val) {
  if (Array.isArray(val)) {
    for (let i=0, len=val.length; i<len; ++i)
      val[i] = resolveInternalTypes(val[i]);
  }
  else if (val instanceof FP_Type) {
    val = val.toString();
  }
  else if (typeof val === 'object') {
    for (let k of Object.keys(val))
      val[k] = resolveInternalTypes(val[k]);
  }
  return val;
}

/**
 *  Evaluates the "path" FHIRPath expression on the given resource or part of the resource,
 *  using data from "context" for variables mentioned in the "path" expression.
 * @param {(object|object[])} fhirData -  FHIR resource, part of a resource (in this case
 *  path.base should be provided), bundle as js object or array of resources.
 *  This object/array will be modified by this function to add type information.
 * @param {string|object} path - string with FHIRPath expression, sample 'Patient.name.given',
 *  or object, if fhirData represents the part of the FHIR resource:
 * @param {string} path.base - base path in resource from which fhirData was extracted
 * @param {string} path.expression - FHIRPath expression relative to path.base
 * @param {object} [context] - a hash of variable name/value pairs.
 * @param {object} [model] - The "model" data object specific to a domain, e.g. R4.
 *  For example, you could pass in the result of require("fhirpath/fhir-context/r4");
 * @param {object} [options] - additional options:
 * @param {boolean} [options.resolveInternalTypes] - whether values of internal
 *  types should be converted to standard JavaScript types (true by default).
 *  If false is passed, this conversion can be done later by calling
 *  resolveInternalTypes().
 * @param {function} [options.traceFn] - An optional trace function to call when tracing.
 * @param {object} [options.userInvocationTable] - a user invocation table used
 *  to replace any existing or define new functions.
 */
function evaluate(fhirData, path, context, model, options) {
  return compile(path, model, options)(fhirData, context);
}

/**
 *  Returns a function that takes a resource or part of the resource and an
 *  optional context hash (see "evaluate"), and returns the result of evaluating
 *  the given FHIRPath expression on that resource.  The advantage of this
 *  function over "evaluate" is that if you have multiple resources, the given
 *  FHIRPath expression will only be parsed once.
 * @param {string|object} path - string with FHIRPath expression to be parsed or object:
 * @param {string} path.base - base path in resource from which a part of
 *   the resource was extracted
 * @param {string} path.expression - FHIRPath expression relative to path.base
 * @param {object} [model] - The "model" data object specific to a domain, e.g. R4.
 *  For example, you could pass in the result of require("fhirpath/fhir-context/r4");
 * @param {object} [options] - additional options:
 * @param {boolean} [options.resolveInternalTypes] - whether values of internal
 *  types should be converted to strings, true by default.
 * @param {function} [options.traceFn] - An optional trace function to call when tracing.
 * @param {object} [options.userInvocationTable] - a user invocation table used
 *  to replace any existing or define new functions.
 */
function compile(path, model, options) {
  options = {
    resolveInternalTypes: true,
    ... options
  };

  const userInvocationTable = options.userInvocationTable;
  if (userInvocationTable) {
    options.userInvocationTable = Object.keys(userInvocationTable).reduce(
      (invocationTable, fnName) => {
        if (userInvocationTable[fnName].internalStructures) {
          invocationTable[fnName] = userInvocationTable[fnName];
        } else {
          invocationTable[fnName] = {
            ...userInvocationTable[fnName],
            fn: (...args) => {
              return userInvocationTable[fnName].fn.apply(
                // When we check Array.isArray(arg), we are checking if the
                // singleton function has been called. An alternative to this is
                // to check that the type of the argument is Integer, Boolean,
                // Number, or String.
                this, args.map(arg => Array.isArray(arg) ? arg.map(item => util.valData(item)) : arg)
              );
            }
          };
        }
        return invocationTable;
      }, {});
  }

  if (typeof path === 'object') {
    const node = parse(path.expression);
    return function (fhirData, context) {
      if (path.base) {
        let basePath = model.pathsDefinedElsewhere[path.base] || path.base;
        const baseFhirNodeDataType = model && model.path2Type[basePath] || null;
        basePath = baseFhirNodeDataType === 'BackboneElement' || baseFhirNodeDataType === 'Element' ? basePath : baseFhirNodeDataType || basePath;

        fhirData = makeResNode(fhirData, basePath, null, baseFhirNodeDataType);
      }
      // Globally set model before applying parsed FHIRPath expression
      TypeInfo.model = model;
      return applyParsedPath(fhirData, node, context, model, options);
    };
  } else {
    const node = parse(path);
    return function (fhirData, context) {
      // Globally set model before applying parsed FHIRPath expression
      TypeInfo.model = model;
      return applyParsedPath(fhirData, node, context, model, options);
    };
  }
}

/**
 * Returns the type of each element in fhirpathResult array which was obtained
 * from evaluate() with option resolveInternalTypes=false.
 * @param {any} fhirpathResult - a result of FHIRPath expression evaluation.
 * @returns {string[]} an array of types, e.g. ['FHIR.Quantity', 'FHIR.date', 'System.String'].
 */
function typesFn(fhirpathResult) {
  return util.arraify(fhirpathResult).map(value => {
    const ti = TypeInfo.fromValue(
      value?.__path__
        ? new ResourceNode(value, value.__path__?.path, null,
          value.__path__?.fhirNodeDataType)
        : value );
    return `${ti.namespace}.${ti.name}`;
  });
}

var fhirpath = {
  version,
  parse,
  compile,
  evaluate,
  resolveInternalTypes,
  types: typesFn,
  // Might as well export the UCUM library, since we are using it.
  ucumUtils: requireUcumPkg().UcumLhcUtils.getInstance(),
  // Utility functions that can be used to implement custom functions
  util
};

class Bonfhir {
    constructor() {
        this.description = {
            displayName: "bonFHIR",
            name: "bonfhir",
            version: 1,
            subtitle: '={{ $parameter["operation"] + ($parameter["operation"] == "Resolve" ? " references" : ": " + $parameter["resourceType"])}}',
            icon: "file:Bonfhir.svg",
            group: ["output"],
            description: "Perform operations on FHIR resources",
            defaults: {
                name: "bonFHIR",
            },
            inputs: ["main"],
            outputs: ["main"],
            credentials: Functions.credentials,
            properties: [
                Functions.authenticationField,
                {
                    displayName: "Base URL",
                    name: "baseUrl",
                    type: "string",
                    description: "The base URL of the FHIR server API",
                    required: true,
                    default: "",
                    placeholder: "http://example.com/fhir",
                },
                {
                    displayName: "Operation",
                    name: "operation",
                    type: "options",
                    noDataExpression: true,
                    default: "Read",
                    options: [
                        {
                            name: "Create",
                            value: "Create",
                            action: "Create a FHIR Resource",
                            description: "Create a FHIR Resource",
                        },
                        {
                            name: "Delete",
                            value: "Delete",
                            action: "Delete a FHIR Resource",
                            description: "Delete a FHIR Resource",
                        },
                        {
                            name: "History",
                            value: "History",
                            action: "Get the history of a FHIR Resource",
                            description: "Get the history of a FHIR Resource",
                        },
                        {
                            name: "Patch",
                            value: "Patch",
                            action: "Patch a FHIR Resource",
                            description: "Patch a FHIR Resource",
                        },
                        {
                            name: "Read",
                            value: "Read",
                            action: "Read a FHIR Resource",
                            description: "Read a FHIR Resource",
                        },
                        {
                            name: "Resolve",
                            value: "Resolve",
                            action: "Resolve FHIR references",
                            description: "Resolve FHIR references",
                        },
                        {
                            name: "Search",
                            value: "Search",
                            action: "Search FHIR Resources",
                            description: "Search FHIR Resources",
                        },
                        {
                            name: "Update",
                            value: "Update",
                            action: "Update a FHIR Resource",
                            description: "Update a FHIR Resource",
                        },
                        {
                            name: "VRead",
                            value: "VRead",
                            action: "Get a specific version of a FHIR Resource",
                            description: "Get a specific version of a FHIR Resource",
                        },
                    ],
                },
                {
                    displayName: "Retrieve All Pages?",
                    description: "Whether to retrieve all pages of search results. Be careful as the result set may be large.",
                    name: "allPages",
                    type: "boolean",
                    default: false,
                    displayOptions: {
                        show: {
                            operation: ["Search"],
                        },
                    },
                },
                {
                    displayName: "Normalize Next URL to Base URL",
                    description: "Whether to try to normalize the next URL to the base URL. This is useful when the next URL is configured for a different base URL.",
                    name: "normalizeNextUrlToBaseUrl",
                    type: "boolean",
                    default: false,
                    displayOptions: {
                        show: {
                            operation: ["Search"],
                        },
                        hide: {
                            allPages: [false],
                        },
                    },
                },
                {
                    displayName: "Error if More than One Result",
                    description: "Whether this will return an error if there is more than one result in the search Bundle",
                    name: "errorIfMoreThanOneResult",
                    type: "boolean",
                    default: false,
                    displayOptions: {
                        show: {
                            operation: ["Search"],
                        },
                        hide: {
                            allPages: [true],
                        },
                    },
                },
                {
                    displayName: "Resource Type",
                    name: "resourceType",
                    type: "options",
                    required: true,
                    default: "",
                    options: [
                        ...Functions.DomainResourceTypes.map((resourceType) => ({
                            name: resourceType,
                            value: resourceType,
                        })),
                        { name: "- Custom -", value: "customResourceType" },
                    ],
                    displayOptions: {
                        hide: {
                            operation: ["Resolve"],
                        },
                    },
                },
                {
                    displayName: "Custom Resource Type",
                    name: "customResourceType",
                    type: "string",
                    required: true,
                    default: "",
                    displayOptions: {
                        show: {
                            resourceType: ["customResourceType"],
                        },
                    },
                },
                {
                    displayName: "ID",
                    name: "id",
                    type: "string",
                    required: true,
                    default: "",
                    displayOptions: {
                        show: {
                            operation: [
                                "Delete",
                                "History",
                                "Patch",
                                "Read",
                                "Update",
                                "VRead",
                            ],
                        },
                    },
                },
                {
                    displayName: "Version ID",
                    name: "vid",
                    type: "string",
                    required: true,
                    default: "",
                    displayOptions: {
                        show: {
                            operation: ["VRead"],
                        },
                    },
                },
                {
                    displayName: "Specify Patch Body",
                    name: "specifyPatchBody",
                    type: "options",
                    options: [
                        {
                            name: "Using Fields Below",
                            value: "keypair",
                        },
                        {
                            name: "Using JSON",
                            value: "json",
                        },
                    ],
                    default: "keypair",
                    displayOptions: {
                        show: {
                            operation: ["Patch"],
                        },
                    },
                },
                {
                    displayName: "Body",
                    name: "body",
                    type: "json",
                    required: true,
                    default: "",
                    displayOptions: {
                        show: {
                            operation: ["Create", "Patch", "Update"],
                        },
                        hide: {
                            specifyPatchBody: ["keypair"],
                        },
                    },
                },
                {
                    displayName: "Patch Parameters",
                    name: "patchParameters",
                    type: "fixedCollection",
                    displayOptions: {
                        show: {
                            specifyPatchBody: ["keypair"],
                        },
                    },
                    typeOptions: {
                        multipleValues: true,
                    },
                    placeholder: "Add Parameter",
                    default: {
                        parameters: [],
                    },
                    options: [
                        {
                            name: "parameters",
                            displayName: "Parameter",
                            values: [
                                {
                                    displayName: "Op",
                                    name: "op",
                                    type: "options",
                                    default: "add",
                                    options: [
                                        {
                                            name: "Add",
                                            description: "Adds a value to an object or inserts it into an array",
                                            value: "add",
                                        },
                                        {
                                            name: "Copy",
                                            description: "Copies a value from one location to another within the JSON document. Both from and path are JSON Pointers.",
                                            value: "copy",
                                        },
                                        {
                                            name: "Move",
                                            description: "Moves a value from one location to the other. Both from and path are JSON Pointers.",
                                            value: "move",
                                        },
                                        {
                                            name: "Remove",
                                            description: "Removes a value from an object or array",
                                            value: "remove",
                                        },
                                        {
                                            name: "Replace",
                                            description: "Replaces a value. Equivalent to a remove followed by an add.",
                                            value: "replace",
                                        },
                                        {
                                            name: "Test",
                                            description: "Tests that the specified value is set in the document. If the test fails, then the patch as a whole should not apply.",
                                            value: "test",
                                        },
                                    ],
                                },
                                {
                                    displayName: "From",
                                    name: "from",
                                    type: "string",
                                    default: "",
                                    placeholder: "{Only for Copy, Move, or Test}",
                                },
                                {
                                    displayName: "Path",
                                    name: "path",
                                    type: "string",
                                    default: "",
                                    placeholder: "/path/to/element",
                                },
                                {
                                    displayName: "Value",
                                    name: "value",
                                    type: "json",
                                    default: "",
                                },
                            ],
                        },
                    ],
                },
                {
                    displayName: "Reference",
                    description: "Either a string, a Reference object, or an array of Reference objects",
                    name: "reference",
                    type: "json",
                    required: true,
                    default: "",
                    displayOptions: {
                        show: {
                            operation: ["Resolve"],
                        },
                    },
                },
                {
                    displayName: "Specify Query Parameters",
                    name: "specifyQuery",
                    type: "options",
                    options: [
                        {
                            name: "Using Fields Below",
                            value: "keypair",
                        },
                        {
                            name: "Using JSON",
                            value: "json",
                        },
                    ],
                    default: "keypair",
                },
                {
                    displayName: "Query Parameters",
                    name: "queryParameters",
                    type: "fixedCollection",
                    displayOptions: {
                        show: {
                            specifyQuery: ["keypair"],
                        },
                    },
                    typeOptions: {
                        multipleValues: true,
                    },
                    placeholder: "Add Parameter",
                    default: {
                        parameters: [],
                    },
                    options: [
                        {
                            name: "parameters",
                            displayName: "Parameter",
                            values: [
                                {
                                    displayName: "Name",
                                    name: "name",
                                    type: "string",
                                    default: "",
                                },
                                {
                                    displayName: "Value",
                                    name: "value",
                                    type: "string",
                                    default: "",
                                },
                            ],
                        },
                    ],
                },
                {
                    displayName: "JSON",
                    name: "jsonQuery",
                    type: "json",
                    displayOptions: {
                        show: {
                            specifyQuery: ["json"],
                        },
                    },
                    default: "",
                },
                {
                    displayName: "FHIR Path",
                    name: "fhirPath",
                    type: "string",
                    description: "A FHIR Path expression to extract data from the output",
                    default: "",
                },
                {
                    displayName: "Ignore SSL Issues",
                    name: "allowUnauthorizedCerts",
                    type: "boolean",
                    default: false,
                    description: "Whether to connect even if SSL certificate validation is not possible",
                },
            ],
        };
    }
    async execute() {
        var _a;
        const items = this.getInputData();
        const resultItems = [];
        const authParameters = await Functions.getAuthParameters(this);
        for (let itemIndex = 0; itemIndex < items.length; itemIndex++) {
            const builtRequestOptions = await buildRequestOptions(this, itemIndex);
            for (const { requestOptions, operation, baseUrl, resourceType, } of builtRequestOptions) {
                try {
                    let response = await Functions.requestWithAuth(this, requestOptions, authParameters);
                    const errorIfMoreThanOneResult = this.getNodeParameter("errorIfMoreThanOneResult", itemIndex, false);
                    if (operation === "Search" &&
                        errorIfMoreThanOneResult &&
                        response.resourceType === "Bundle" &&
                        response.entry.filter((e) => { var _a; return isSearchMatch(e, (_a = response.entry) === null || _a === void 0 ? void 0 : _a[0]); }).length > 1) {
                        throw new n8nWorkflow.NodeApiError(this.getNode(), { operation, response }, {
                            message: `The search returned more than one result (${(_a = response.total) !== null && _a !== void 0 ? _a : response.entry.filter((e) => { var _a; return isSearchMatch(e, (_a = response.entry) === null || _a === void 0 ? void 0 : _a[0]); }).length})`,
                        });
                    }
                    const fhirPath = this.getNodeParameter("fhirPath", itemIndex, "");
                    if (fhirPath) {
                        response = fhirpath.evaluate(response, fhirPath);
                        if (Array.isArray(response)) {
                            resultItems.push(...response.flatMap((x) => processResponseIntoItems(x, itemIndex)));
                        }
                        else {
                            resultItems.push(...processResponseIntoItems(response, itemIndex));
                        }
                        continue;
                    }
                    resultItems.push(...processResponseIntoItems(response, itemIndex));
                    const allPages = this.getNodeParameter("allPages", itemIndex, false);
                    const normalizeNextUrlToBaseUrl = this.getNodeParameter("normalizeNextUrlToBaseUrl", itemIndex, false);
                    if (operation === "Search" && allPages) {
                        let nextUrl = getNextUrl(response);
                        while (nextUrl) {
                            if (normalizeNextUrlToBaseUrl &&
                                nextUrl &&
                                !nextUrl.startsWith(baseUrl)) {
                                const [, ...restUrl] = nextUrl.split(resourceType);
                                nextUrl = `${baseUrl}/${resourceType}${restUrl.join(resourceType)}`;
                            }
                            const pageRequestOptions = {
                                headers: {
                                    "content-type": `application/fhir+json`,
                                },
                                method: "GET",
                                uri: nextUrl,
                                json: true,
                                rejectUnauthorized: requestOptions.rejectUnauthorized,
                            };
                            let response = await Functions.requestWithAuth(this, pageRequestOptions, authParameters);
                            nextUrl = getNextUrl(response);
                            if (fhirPath) {
                                response = fhirpath.evaluate(response, fhirPath);
                            }
                            resultItems.push(...processResponseIntoItems(response, itemIndex));
                        }
                    }
                }
                catch (error) {
                    if (this.continueOnFail()) {
                        const item = {
                            error,
                            json: this.getInputData(itemIndex),
                            pairedItem: {
                                item: itemIndex,
                            },
                        };
                        resultItems.push(item);
                        continue;
                    }
                    throw error;
                }
            }
        }
        return [resultItems];
    }
}
async function buildRequestOptions(node, itemIndex) {
    var _a;
    let baseUrl = (_a = node.getNodeParameter("baseUrl", itemIndex)) === null || _a === void 0 ? void 0 : _a.trim();
    if (baseUrl.endsWith("/")) {
        baseUrl = baseUrl.slice(0, -1);
    }
    const operation = node.getNodeParameter("operation", itemIndex);
    let resourceType = node.getNodeParameter("resourceType", itemIndex, "");
    if (resourceType === "customResourceType") {
        resourceType = node.getNodeParameter("customResourceType", itemIndex, "");
    }
    const id = node.getNodeParameter("id", itemIndex, "");
    const vid = node.getNodeParameter("vid", itemIndex, "");
    const specifyPatchBody = node.getNodeParameter("specifyPatchBody", itemIndex, "keypair");
    const patchParameters = node.getNodeParameter("patchParameters.parameters", itemIndex, []);
    let bodyParameter = node.getNodeParameter("body", itemIndex, "");
    if (bodyParameter &&
        typeof bodyParameter === "string" &&
        (bodyParameter === null || bodyParameter === void 0 ? void 0 : bodyParameter.trim())) {
        bodyParameter = JSON.parse(bodyParameter);
    }
    const specifyQuery = node.getNodeParameter("specifyQuery", itemIndex, "keypair");
    const queryParameters = node.getNodeParameter("queryParameters.parameters", itemIndex, []);
    const jsonQueryParameter = node.getNodeParameter("jsonQuery", itemIndex, "");
    let qs;
    if (specifyQuery === "keypair" && queryParameters.length > 0) {
        qs = queryParameters.reduce((acc, { name, value }) => {
            acc[name] = value;
            return acc;
        }, {});
    }
    else if (specifyQuery === "json" && jsonQueryParameter) {
        try {
            qs = JSON.parse(jsonQueryParameter);
        }
        catch {
            throw new n8nWorkflow.NodeOperationError(node.getNode(), "JSON parameter need to be an valid JSON", {
                itemIndex,
            });
        }
    }
    const allowUnauthorizedCerts = node.getNodeParameter("allowUnauthorizedCerts", itemIndex, false);
    const requestOptions = {
        headers: {
            "content-type": operation === "Patch"
                ? `application/json-patch+json`
                : `application/fhir+json`,
        },
        uri: "",
        qs,
        json: true,
        rejectUnauthorized: !allowUnauthorizedCerts,
    };
    switch (operation) {
        case "Create": {
            return [
                {
                    requestOptions: {
                        ...requestOptions,
                        method: "POST",
                        uri: `${baseUrl}/${resourceType}`,
                        body: bodyParameter,
                    },
                    operation,
                    baseUrl,
                    resourceType,
                },
            ];
        }
        case "Delete": {
            return [
                {
                    requestOptions: {
                        ...requestOptions,
                        method: "DELETE",
                        uri: `${baseUrl}/${resourceType}/${id}`,
                    },
                    operation,
                    baseUrl,
                    resourceType,
                },
            ];
        }
        case "History": {
            return [
                {
                    requestOptions: {
                        ...requestOptions,
                        method: "GET",
                        uri: `${baseUrl}/${resourceType}/${id}/_history`,
                    },
                    operation,
                    baseUrl,
                    resourceType,
                },
            ];
        }
        case "Patch": {
            return [
                {
                    requestOptions: {
                        ...requestOptions,
                        method: "PATCH",
                        uri: `${baseUrl}/${resourceType}/${id}`,
                        body: specifyPatchBody === "keypair" ? patchParameters : bodyParameter,
                    },
                    operation,
                    baseUrl,
                    resourceType,
                },
            ];
        }
        case "Read": {
            return [
                {
                    requestOptions: {
                        ...requestOptions,
                        method: "GET",
                        uri: `${baseUrl}/${resourceType}/${id}`,
                    },
                    operation,
                    baseUrl,
                    resourceType,
                },
            ];
        }
        case "Resolve": {
            const reference = node.getNodeParameter("reference", itemIndex, "");
            if (!reference) {
                return [];
            }
            let allReferences = [];
            if (typeof reference === "string") {
                allReferences = [reference];
            }
            else if (Array.isArray(reference)) {
                allReferences = reference.map((ref) => ref === null || ref === void 0 ? void 0 : ref.reference).filter(Boolean);
            }
            else if (typeof reference === "object") {
                allReferences = [reference.reference];
            }
            return allReferences.map((ref) => {
                const [refResourceType, ...refId] = ref.split("/");
                return {
                    requestOptions: {
                        ...requestOptions,
                        method: "GET",
                        uri: `${baseUrl}/${refResourceType}/${refId}`,
                    },
                    operation,
                    baseUrl,
                    resourceType,
                };
            });
        }
        case "Search": {
            return [
                {
                    requestOptions: {
                        ...requestOptions,
                        method: "GET",
                        uri: `${baseUrl}/${resourceType}`,
                    },
                    operation,
                    baseUrl,
                    resourceType,
                },
            ];
        }
        case "Update": {
            return [
                {
                    requestOptions: {
                        ...requestOptions,
                        method: "PUT",
                        uri: `${baseUrl}/${resourceType}/${id || bodyParameter.id}`,
                        body: bodyParameter,
                    },
                    operation,
                    baseUrl,
                    resourceType,
                },
            ];
        }
        case "VRead": {
            return [
                {
                    requestOptions: {
                        ...requestOptions,
                        method: "GET",
                        uri: `${baseUrl}/${resourceType}/${id}/_history/${vid}`,
                    },
                    operation,
                    baseUrl,
                    resourceType,
                },
            ];
        }
        default: {
            throw new n8nWorkflow.NodeApiError(node.getNode(), { operation }, { message: `The operation "${operation}" is not supported` });
        }
    }
}
function getNextUrl(bundle) {
    var _a, _b;
    return (_b = (_a = bundle.link) === null || _a === void 0 ? void 0 : _a.find((link) => link.relation === "next")) === null || _b === void 0 ? void 0 : _b.url;
}
function processResponseIntoItems(response, itemIndex) {
    var _a, _b;
    const resultItems = [];
    if (response.resourceType === "Bundle") {
        const allResources = new Map();
        for (const entry of ((_a = response.entry) === null || _a === void 0 ? void 0 : _a.map((entry) => entry.resource).filter(Boolean)) || []) {
            allResources.set(`${entry.resourceType}/${entry.id}`, entry);
            if ((_b = entry.meta) === null || _b === void 0 ? void 0 : _b.versionId) {
                allResources.set(`${entry.resourceType}/${entry.id}/_history/${entry.meta.versionId}`, entry);
            }
        }
        for (const entry of response.entry.filter((e) => { var _a; return isSearchMatch(e, (_a = response.entry) === null || _a === void 0 ? void 0 : _a[0]); })) {
            resolveInternalReferences(entry, allResources);
            resultItems.push({
                json: entry.resource,
                pairedItem: {
                    item: itemIndex,
                },
            });
        }
    }
    else if (response != undefined) {
        resultItems.push({
            json: response,
            pairedItem: {
                item: itemIndex,
            },
        });
    }
    return resultItems;
}
function isSearchMatch(entry, firstEntry) {
    var _a, _b, _c;
    return ((_a = entry.search) === null || _a === void 0 ? void 0 : _a.mode)
        ? entry.search.mode === "match"
        : ((_b = entry.resource) === null || _b === void 0 ? void 0 : _b.resourceType) === ((_c = firstEntry.resource) === null || _c === void 0 ? void 0 : _c.resourceType);
}
function resolveInternalReferences(entry, allResources) {
    if (!entry) {
        return;
    }
    if (Array.isArray(entry)) {
        for (const e of entry)
            resolveInternalReferences(e, allResources);
        return;
    }
    if (typeof entry !== "object") {
        return;
    }
    if (entry.reference && allResources.has(entry.reference)) {
        entry.included = allResources.get(entry.reference);
    }
    for (const key in entry) {
        resolveInternalReferences(entry[key], allResources);
    }
}

exports.Bonfhir = Bonfhir;
//# sourceMappingURL=Bonfhir.node.js.map
