{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ab7c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from urllib.parse import urlparse\n",
    "import hashlib\n",
    "import pdfkit\n",
    "import requests\n",
    "from playwright.sync_api import sync_playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ef56b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/cptaswadu/RESCUE-n8n/insurance'\n",
    "load_dotenv(dotenv_path=os.path.join(path, \".env\"))\n",
    "openai_api_key = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "perplexity_api_key = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "gpt_client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e53cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_RESULT_DIR = \"/home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval\"\n",
    "LLM_FOLDER_ROOT = os.path.join(BASE_RESULT_DIR, \"llm_searched\")\n",
    "MANUAL_FOLDER = \"/home/cptaswadu/RESCUE-n8n/insurance/insurance_policy\"\n",
    "RETRIEVAL_SUMMARY_CSV = f\"{BASE_RESULT_DIR}/retrieval_summary.csv\"\n",
    "MD5_COMPARISON_CSV = f\"{BASE_RESULT_DIR}/md5_comparison.csv\"\n",
    "\n",
    "os.makedirs(BASE_RESULT_DIR, exist_ok=True)\n",
    "os.makedirs(LLM_FOLDER_ROOT, exist_ok=True)\n",
    "os.makedirs(os.path.join(BASE_RESULT_DIR, \"retrieval\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(BASE_RESULT_DIR, \"md5\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaa1149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/cptaswadu/RESCUE-n8n/insurance/In-Network_providers.csv')\n",
    "provider_list = df[\"In-network Provider\"].dropna().str.strip().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b850dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_retrieval_prompt_baseline(provider_name):\n",
    "    \"\"\"\n",
    "    Retrieves all official links to genetic testing coverage policies for a provider without keyword filtering.\n",
    "    Returns strictly formatted JSON with 'pdf_links' and 'webpage_links'.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        f\"Find and list all the links to official policy documents that contain genetic testing coverage policies \"\n",
    "        f\"for the insurance provider '{provider_name}'. \"\n",
    "        \"Include both PDF files and webpage URLs if the information is only available on the website. \"\n",
    "        \"Only include links from official sources such as the insurance company's website or regulatory bodies. \"\n",
    "        \"Exclude links from news articles, blog posts, or discussion forums. \"\n",
    "        \"If the policy is available as a PDF, return the direct PDF link under the key \\\"pdf_links\\\". \"\n",
    "        \"If the policy is available only as an HTML webpage, return the webpage URL under the key \\\"webpage_links\\\". \"\n",
    "        \"The response must be strictly in JSON format with two single keys: \"\n",
    "        \"\\\"pdf_links\\\", containing an array of valid PDF URLs, and \"\n",
    "        \"\\\"webpage_links\\\", containing an array of valid webpage URLs. \"\n",
    "        \"Do not include any additional text or explanations—only the JSON object.\"\n",
    "    )\n",
    "\n",
    "def policy_retrieval_prompt_keyword_checked_document(provider_name):\n",
    "    \"\"\"\n",
    "    Retrieves links only if the documents contain specific genetic-related keywords and excludes irrelevant content.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        f\"Find and list all official links to policy documents that describe genetic testing coverage for the insurance provider '{provider_name}'. \"\n",
    "        \"Only include documents if they contain at least one of the following key terms: \"\n",
    "        \"'coverage policy', 'medical policy', 'clinical policy', 'WES', 'WGS', 'BRCA', 'Duchenne muscular dystrophy', \"\n",
    "        \"'hereditary cancer', 'genetic testing', 'lynch syndrome', or 'pharmacogenetic'. \"\n",
    "        \"Exclude any documents that contain the phrase 'providal guideline', or that are press releases, claim forms, newsletters, blog posts, or provider manuals.\"\n",
    "        \"Only include links from official sources such as the insurance company’s website or regulatory bodies. \"\n",
    "        \"If a document is available as a downloadable PDF, return the full direct PDF link under the key 'pdf_links'. \"\n",
    "        \"If the document is only available as a webpage, return the full URL under the key 'webpage_links'. \"\n",
    "        \"The JSON response must follow this exact format: \"\n",
    "        \"{\\\"pdf_links\\\": [list of direct PDF links], \\\"webpage_links\\\": [list of webpage URLs]}. \"\n",
    "        \"If no qualifying documents are found, return empty lists. \"\n",
    "        \"Do not include any explanation, markdown, natural language, or formatting — only return the raw JSON object.\"\n",
    "    )\n",
    "\n",
    "def policy_retrieval_prompt_keyword_verified_links(provider_name):\n",
    "    \"\"\"\n",
    "    Added stricter requirements for URL validity and official policy page confirmation.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        f\"Find and list all official links to policy documents that describe genetic testing coverage for the insurance provider '{provider_name}'. \"\n",
    "        \"Only include documents if they contain at least one of the following key terms: \"\n",
    "        \"'coverage policy', 'medical policy', 'clinical policy', 'WES', 'WGS', 'BRCA', 'Duchenne muscular dystrophy', \"\n",
    "        \"'hereditary cancer', 'genetic testing', 'lynch syndrome', or 'pharmacogenetic'. \"\n",
    "        \"Exclude any documents that contain the phrase 'providal guideline', or that are press releases, claim forms, newsletters, blog posts, or provider manuals.\"\n",
    "        \"Only include links from official sources such as the insurance company’s website or regulatory bodies. with direct PDF links and ofiicial HTML policy pages.\"\n",
    "        \"If a document is available as a downloadable PDF, return the full direct PDF link under the key 'pdf_links'. \"\n",
    "        \"If the document is only available as a webpage, return the full URL under the key 'webpage_links'. \"\n",
    "        \"The JSON response must follow this exact format: \"\n",
    "        \"{\\\"pdf_links\\\": [list of direct PDF links], \\\"webpage_links\\\": [list of webpage URLs]}. \"\n",
    "        \"Make sure the lists contain only valid, existing URLs. If no documents are found, return empty lists. \"\n",
    "        \"Do not include any explanation, markdown, natural language, or formatting — only return the raw JSON object.\"\n",
    "    )\n",
    "\n",
    "prompt_functions = {\n",
    "    \"baseline\": policy_retrieval_prompt_baseline,\n",
    "    \"keyword\": policy_retrieval_prompt_keyword_checked_document,\n",
    "    \"verified\": policy_retrieval_prompt_keyword_verified_links\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0510cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(url, save_path):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"✅ Downloaded PDF: {save_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to download PDF from {url}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def save_webpage_as_pdf(url, save_path):\n",
    "    try:\n",
    "        pdfkit.from_url(url, save_path)\n",
    "        print(f\"✅ Saved webpage as PDF: {save_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to save {url} as PDF: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcaa3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm_for_providers(messages, model=\"openai\", openai_client=None, perplexity_api_key=None, max_retries=3):\n",
    "    def call_openai():\n",
    "        prompt = messages[-1][\"content\"]  # Extract user prompt for OpenAI web search\n",
    "        response = openai_client.responses.create(\n",
    "            model=\"gpt-4o\",\n",
    "            input=messages,\n",
    "            tools=[{\"type\": \"web_search_preview\"}]\n",
    "        )\n",
    "        return response.output_text.strip()\n",
    "\n",
    "    def call_perplexity():\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {perplexity_api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        data = {\n",
    "            \"model\": \"sonar-pro\",\n",
    "            \"messages\": messages\n",
    "        }\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        res = requests.post(url, headers=headers, json=data)\n",
    "        if res.status_code == 200:\n",
    "            return res.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        else:\n",
    "            raise Exception(f\"Perplexity error: {res.status_code} - {res.text}\")\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            print(f\"🔁 Attempt {attempt} ({model})...\")\n",
    "            return call_perplexity() if model == \"perplexity\" else call_openai()\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Attempt {attempt} failed: {e}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56775966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_provider_json(response_text):\n",
    "    original = response_text.strip()\n",
    "\n",
    "    # Step 1: Try direct JSON\n",
    "    try:\n",
    "        result = json.loads(original)\n",
    "        if isinstance(result, dict) and \"pdf_links\" in result:\n",
    "            return result\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # Step 2: Try cleanup of ```json blocks\n",
    "    response_text = re.sub(r\"^```json\\s*|\\s*```$\", \"\", original, flags=re.IGNORECASE).strip()\n",
    "    \n",
    "    # Step 3: Try parsing again\n",
    "    try:\n",
    "        result = json.loads(response_text)\n",
    "        if isinstance(result, dict) and \"pdf_links\" in result:\n",
    "            return result\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # Step 4: Find first JSON block in messy response\n",
    "    json_match = re.search(r\"(\\{[\\s\\S]*?\\})\", original)\n",
    "    if json_match:\n",
    "        try:\n",
    "            result = json.loads(json_match.group(1))\n",
    "            if isinstance(result, dict) and \"pdf_links\" in result:\n",
    "                return result\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"⚠️ Still invalid JSON block:\", e)\n",
    "\n",
    "    print(\"⚠️ Could not parse JSON. Using fallback empty provider list.\")\n",
    "    return {\n",
    "        \"pdf_links\": [],\n",
    "        \"webpage_links\": []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f702ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_save_policy(provider, prompt_fn, model=\"openai\", prompt_name=\"baseline\", openai_client=None, perplexity_api_key=None):\n",
    "    '''\n",
    "    Retrieves genetic testing policy links for the given provider using the specified prompt.\n",
    "    Returns a dictionary containing retrieval result summary.\n",
    "    '''\n",
    "    print(f\"\\n🔍 Searching for: {provider}\")\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful and precise research assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt_fn(provider)}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response_text = query_llm_for_providers(\n",
    "            messages, model=model, openai_client=openai_client, perplexity_api_key=perplexity_api_key\n",
    "        )\n",
    "        print(f\"\\n🧾 {model.upper()} raw response for '{provider}':\\n{response_text}\\n\")\n",
    "        result_json = extract_provider_json(response_text)\n",
    "\n",
    "        pdf_links = result_json.get(\"pdf_links\", [])\n",
    "        webpage_links = result_json.get(\"webpage_links\", [])\n",
    "        all_links = pdf_links + webpage_links\n",
    "\n",
    "        folder = os.path.join(LLM_FOLDER_ROOT, model, prompt_name, provider.replace(\" \", \"_\"))\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "        downloaded_pdfs = sum(\n",
    "            download_pdf(link, os.path.join(folder, os.path.basename(link.split(\"?\")[0])))\n",
    "            for link in pdf_links\n",
    "        )\n",
    "\n",
    "        saved_webpages = sum(\n",
    "            save_webpage_as_pdf(\n",
    "                link,\n",
    "                os.path.join(folder, f\"{os.path.basename(link.split('?')[0]).split('.')[0] or 'webpage'}.pdf\")\n",
    "            ) for link in webpage_links\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"Provider\": provider,\n",
    "            \"PDF Links\": json.dumps(pdf_links),\n",
    "            \"PDF Count\": len(pdf_links),\n",
    "            \"Downloaded PDFs\": downloaded_pdfs,\n",
    "            \"Webpage Links\": json.dumps(webpage_links),\n",
    "            \"Webpage Count\": len(webpage_links),\n",
    "            \"Saved Webpages as PDF\": saved_webpages,\n",
    "            \"All Links\": json.dumps(all_links),\n",
    "            \"Total Count\": len(all_links)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {provider}: {e}\")\n",
    "        return {\n",
    "            \"Provider\": provider,\n",
    "            \"PDF Links\": \"[]\",\n",
    "            \"PDF Count\": 0,\n",
    "            \"Downloaded PDFs\": 0,\n",
    "            \"Webpage Links\": \"[]\",\n",
    "            \"Webpage Count\": 0,\n",
    "            \"Saved Webpages as PDF\": 0,\n",
    "            \"All Links\": \"[]\",\n",
    "            \"Total Count\": 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498f5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_policy_retrieval(providers, prompt_fn, model=\"openai\", prompt_name=\"baseline\", experiment_id=1,\n",
    "                                openai_client=None, perplexity_api_key=None, base_output_dir=\"llm_results\"):\n",
    "    \"\"\"\n",
    "    Summarizes retrieval results from OpenAI or Perplexity.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for provider in providers:\n",
    "        result = retrieve_and_save_policy(\n",
    "            provider,\n",
    "            prompt_fn,\n",
    "            model=model,\n",
    "            prompt_name=prompt_name,\n",
    "            openai_client=openai_client,\n",
    "            perplexity_api_key=perplexity_api_key\n",
    "        )\n",
    "        results.append(result)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    numeric_cols = [\"PDF Count\", \"Downloaded PDFs\", \"Webpage Count\", \"Saved Webpages as PDF\", \"Total Count\"]\n",
    "\n",
    "    sum_row = df[numeric_cols].sum().to_dict()\n",
    "    sum_row[\"Provider\"] = \"TOTAL_SUM\"\n",
    "\n",
    "    avg_row = df[numeric_cols].mean().round(2).to_dict()\n",
    "    avg_row[\"Provider\"] = \"AVERAGE\"\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame([sum_row, avg_row])], ignore_index=True)\n",
    "    print(f\"📊 Summary DataFrame:\\n{df}\")\n",
    "\n",
    "    model_folder = os.path.join(base_output_dir, model)\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "    output_path = os.path.join(model_folder, f\"{prompt_name}_experiment{experiment_id}.csv\")\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"📄 Combined results saved to: {output_path}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16bff69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_md5_comparisons(results, model=\"openai\", prompt_name=\"baseline\",\n",
    "                              manual_folder=MANUAL_FOLDER,\n",
    "                              llm_root=LLM_FOLDER_ROOT,\n",
    "                              output_dir=BASE_RESULT_DIR,\n",
    "                              return_stats=False,\n",
    "                              custom_output_path=None):\n",
    "    \"\"\"\n",
    "    Compares MD5 hashes of LLM-downloaded files with manually curated ones.\n",
    "\n",
    "    Args:\n",
    "        results: List of retrieval result dicts.\n",
    "        model: \"openai\" or \"perplexity\" to locate correct LLM folder.\n",
    "        prompt_name: Name of the prompt, used for folder disambiguation.\n",
    "        manual_folder: Path to manually curated documents.\n",
    "        llm_root: Root folder containing LLM-generated content.\n",
    "        output_dir: Where to save the MD5 comparison results.\n",
    "        return_stats: If True, return match counts.\n",
    "        custom_output_path: Optional override for CSV save path.\n",
    "\n",
    "    Returns:\n",
    "        Updated results with MD5 stats added or summary dict (if return_stats=True).\n",
    "    \"\"\"\n",
    "    matched_rows = []\n",
    "    llm_only_rows = []\n",
    "    md5_stats = {}\n",
    "\n",
    "    def compute_md5(file_path):\n",
    "        hasher = hashlib.md5()\n",
    "        with open(file_path, 'rb') as f:\n",
    "            while chunk := f.read(8192):\n",
    "                hasher.update(chunk)\n",
    "        return hasher.hexdigest()\n",
    "\n",
    "    def get_md5_map(folder):\n",
    "        md5_map = {}\n",
    "        for root, _, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                path = os.path.join(root, file)\n",
    "                md5_map[file] = compute_md5(path)\n",
    "        return md5_map\n",
    "\n",
    "    llm_root_model = os.path.join(llm_root, model, prompt_name)\n",
    "    global_key = f\"{model}_{prompt_name}\"\n",
    "    global_md5_set = set()\n",
    "\n",
    "    for row in results:\n",
    "        provider = row[\"Provider\"]\n",
    "        if provider in [\"TOTAL_SUM\", \"AVERAGE\"]:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n📂 Comparing files for '{provider}'...\")\n",
    "        llm_folder = os.path.join(llm_root_model, provider.replace(\" \", \"_\"))\n",
    "\n",
    "        manual_hashes = get_md5_map(manual_folder)\n",
    "        llm_hashes = get_md5_map(llm_folder)\n",
    "\n",
    "        manual_md5_set = set(manual_hashes.values())\n",
    "        llm_md5_set = set(llm_hashes.values())\n",
    "        global_md5_set |= llm_md5_set\n",
    "\n",
    "        matched = manual_md5_set & llm_md5_set\n",
    "        only_llm = llm_md5_set - manual_md5_set\n",
    "\n",
    "        md5_stats[provider] = {\n",
    "            \"MD5 Matched\": len(matched),\n",
    "            \"LLM Only\": len(only_llm)\n",
    "        }\n",
    "\n",
    "        link_map = {}\n",
    "        try:\n",
    "            pdf_links = json.loads(row.get(\"PDF Links\", \"[]\"))\n",
    "            webpage_links = json.loads(row.get(\"Webpage Links\", \"[]\"))\n",
    "            for link in pdf_links + webpage_links:\n",
    "                fname = os.path.basename(link.split(\"?\")[0])\n",
    "                link_map[fname] = link\n",
    "        except Exception:\n",
    "            print(f\"⚠️ Could not parse links for {provider}\")\n",
    "\n",
    "        for filename, md5 in llm_hashes.items():\n",
    "            link = link_map.get(filename, \"\")\n",
    "            entry = {\n",
    "                \"Provider\": provider,\n",
    "                \"Filename\": filename,\n",
    "                \"MD5\": md5,\n",
    "                \"Link\": link\n",
    "            }\n",
    "            if md5 in matched:\n",
    "                print(f\"✔️ MATCHED: {filename}\")\n",
    "                entry[\"Status\"] = \"MATCHED\"\n",
    "                matched_rows.append(entry)\n",
    "            elif md5 in only_llm:\n",
    "                print(f\"❌ UNMATCHED (LLM-only): {filename}\")\n",
    "                entry[\"Status\"] = \"LLM_ONLY\"\n",
    "                llm_only_rows.append(entry)\n",
    "\n",
    "    for row in results:\n",
    "        provider = row[\"Provider\"]\n",
    "        row[\"MD5 Matched\"] = md5_stats.get(provider, {}).get(\"MD5 Matched\", 0)\n",
    "        row[\"LLM Only\"] = md5_stats.get(provider, {}).get(\"LLM Only\", 0)\n",
    "\n",
    "    if matched_rows or llm_only_rows:\n",
    "        md5_df = pd.DataFrame(matched_rows + llm_only_rows)\n",
    "        output_path = (\n",
    "            custom_output_path\n",
    "            if custom_output_path\n",
    "            else os.path.join(output_dir, \"md5\", model, prompt_name, f\"{model}_md5_comparison.csv\")\n",
    "        )\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        md5_df.to_csv(output_path, index=False)\n",
    "        print(f\"📄 MD5 results saved to: {output_path}\")\n",
    "\n",
    "    if return_stats:\n",
    "        total_match = sum(stat[\"MD5 Matched\"] for stat in md5_stats.values())\n",
    "        total_llm = sum(stat[\"LLM Only\"] for stat in md5_stats.values())\n",
    "\n",
    "        stats_df = pd.DataFrame([\n",
    "            {\"Provider\": k, **v} for k, v in md5_stats.items()\n",
    "        ])\n",
    "        stats_path = os.path.join(output_dir, \"md5\", model, prompt_name, f\"{model}_md5_stats_summary.csv\")\n",
    "        os.makedirs(os.path.dirname(stats_path), exist_ok=True)\n",
    "        stats_df.to_csv(stats_path, index=False)\n",
    "        print(f\"📄 MD5 stats summary saved to: {stats_path}\")\n",
    "\n",
    "        return {\n",
    "            \"match_count\": total_match,\n",
    "            \"llm_only_count\": total_llm\n",
    "        }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d280f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_md5_set_for_model_prompt(model_path):\n",
    "    import hashlib, os\n",
    "\n",
    "    md5_set = set()\n",
    "\n",
    "    def compute_md5(file_path):\n",
    "        hasher = hashlib.md5()\n",
    "        with open(file_path, 'rb') as f:\n",
    "            while chunk := f.read(8192):\n",
    "                hasher.update(chunk)\n",
    "        return hasher.hexdigest()\n",
    "\n",
    "    for root, _, files in os.walk(model_path):\n",
    "        for f in files:\n",
    "            path = os.path.join(root, f)\n",
    "            md5_set.add(compute_md5(path))\n",
    "    return md5_set\n",
    "\n",
    "def compare_md5_union_intersection(model_a, model_b, prompt_name, output_dir):\n",
    "    path_a = os.path.join(LLM_FOLDER_ROOT, model_a, prompt_name)\n",
    "    path_b = os.path.join(LLM_FOLDER_ROOT, model_b, prompt_name)\n",
    "\n",
    "    set_a = compute_md5_set_for_model_prompt(path_a)\n",
    "    set_b = compute_md5_set_for_model_prompt(path_b)\n",
    "\n",
    "    union = set_a | set_b\n",
    "    intersection = set_a & set_b\n",
    "\n",
    "    print(f\"\\n🔬 MD5 UNION COUNT between {model_a} and {model_b} ({prompt_name}): {len(union)}\")\n",
    "    print(f\"🔬 MD5 INTERSECTION COUNT: {len(intersection)}\")\n",
    "\n",
    "    os.makedirs(os.path.join(output_dir, \"md5\", prompt_name), exist_ok=True)\n",
    "    union_path = os.path.join(output_dir, \"md5\", prompt_name, f\"md5_union_intersection_{prompt_name}.csv\")\n",
    "    pd.DataFrame([{\n",
    "        \"Prompt\": prompt_name,\n",
    "        \"Model A\": model_a,\n",
    "        \"Model B\": model_b,\n",
    "        \"MD5 Union Count\": len(union),\n",
    "        \"MD5 Intersection Count\": len(intersection)\n",
    "    }]).to_csv(union_path, index=False)\n",
    "    print(f\"📄 Cross-model MD5 union/intersection saved to: {union_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "799563e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running OPENAI for prompt 'baseline' ===\n",
      "\n",
      "🔍 Searching for: United Healthcare\n",
      "🔁 Attempt 1 (openai)...\n",
      "\n",
      "🧾 OPENAI raw response for 'United Healthcare':\n",
      "```json\n",
      "{\n",
      "  \"pdf_links\": [\n",
      "    \"https://www.uhcprovider.com/content/dam/provider/docs/public/policies/index/commercial/pharmacogenetic-panel-testing-01012025.pdf\"\n",
      "  ],\n",
      "  \"webpage_links\": [\n",
      "    \"https://www.uhcprovider.com/en/prior-auth-advance-notification/genetic-molecular-lab.html\",\n",
      "    \"https://www.uhcprovider.com/en/resource-library/news/2024/changes-genetic-molecular-testing-coverage-pa-requirements.html\",\n",
      "    \"https://www.uhcprovider.com/en/policies-protocols/commercial-policies/umr-medical-drug-policies.html\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "✅ Downloaded PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/baseline/United_Healthcare/pharmacogenetic-panel-testing-01012025.pdf\n",
      "✅ Saved webpage as PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/baseline/United_Healthcare/genetic-molecular-lab.pdf\n",
      "✅ Saved webpage as PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/baseline/United_Healthcare/changes-genetic-molecular-testing-coverage-pa-requirements.pdf\n",
      "✅ Saved webpage as PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/baseline/United_Healthcare/umr-medical-drug-policies.pdf\n",
      "📊 Summary DataFrame:\n",
      "            Provider                                          PDF Links  \\\n",
      "0  United Healthcare  [\"https://www.uhcprovider.com/content/dam/prov...   \n",
      "1          TOTAL_SUM                                                NaN   \n",
      "2            AVERAGE                                                NaN   \n",
      "\n",
      "   PDF Count  Downloaded PDFs  \\\n",
      "0        1.0              1.0   \n",
      "1        1.0              1.0   \n",
      "2        1.0              1.0   \n",
      "\n",
      "                                       Webpage Links  Webpage Count  \\\n",
      "0  [\"https://www.uhcprovider.com/en/prior-auth-ad...            3.0   \n",
      "1                                                NaN            3.0   \n",
      "2                                                NaN            3.0   \n",
      "\n",
      "   Saved Webpages as PDF                                          All Links  \\\n",
      "0                    3.0  [\"https://www.uhcprovider.com/content/dam/prov...   \n",
      "1                    3.0                                                NaN   \n",
      "2                    3.0                                                NaN   \n",
      "\n",
      "   Total Count  \n",
      "0          4.0  \n",
      "1          4.0  \n",
      "2          4.0  \n",
      "📄 Combined results saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/retrieval/openai/baseline_experiment1.csv\n",
      "\n",
      "📂 Comparing files for 'United Healthcare'...\n",
      "❌ UNMATCHED (LLM-only): genetic-molecular-lab.pdf\n",
      "❌ UNMATCHED (LLM-only): umr-medical-drug-policies.pdf\n",
      "❌ UNMATCHED (LLM-only): changes-genetic-molecular-testing-coverage-pa-requirements.pdf\n",
      "❌ UNMATCHED (LLM-only): pharmacogenetic-panel-testing-01012025.pdf\n",
      "📄 MD5 results saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/openai/baseline/openai_md5_comparison_baseline_experiment1.csv\n",
      "📁 MD5 comparison CSV saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/openai/baseline/openai_md5_comparison_baseline_experiment1.csv\n",
      "\n",
      "=== Running PERPLEXITY for prompt 'baseline' ===\n",
      "\n",
      "🔍 Searching for: United Healthcare\n",
      "🔁 Attempt 1 (perplexity)...\n",
      "\n",
      "🧾 PERPLEXITY raw response for 'United Healthcare':\n",
      "Based on the search results provided, I can identify the official policy documents related to genetic testing coverage from UnitedHealthcare. I'll format this as requested in JSON format.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"pdf_links\": [\n",
      "    \"https://www.uhcprovider.com/content/dam/provider/docs/public/policies/comm-medical-drug/genetic-testing-hereditary-cancer.pdf\",\n",
      "    \"https://www.uhcprovider.com/content/dam/provider/docs/public/prior-auth/genetic-paan-faq.pdf\"\n",
      "  ],\n",
      "  \"webpage_links\": []\n",
      "}\n",
      "```\n",
      "\n",
      "✅ Downloaded PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/perplexity/baseline/United_Healthcare/genetic-testing-hereditary-cancer.pdf\n",
      "✅ Downloaded PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/perplexity/baseline/United_Healthcare/genetic-paan-faq.pdf\n",
      "📊 Summary DataFrame:\n",
      "            Provider                                          PDF Links  \\\n",
      "0  United Healthcare  [\"https://www.uhcprovider.com/content/dam/prov...   \n",
      "1          TOTAL_SUM                                                NaN   \n",
      "2            AVERAGE                                                NaN   \n",
      "\n",
      "   PDF Count  Downloaded PDFs Webpage Links  Webpage Count  \\\n",
      "0        2.0              2.0            []            0.0   \n",
      "1        2.0              2.0           NaN            0.0   \n",
      "2        2.0              2.0           NaN            0.0   \n",
      "\n",
      "   Saved Webpages as PDF                                          All Links  \\\n",
      "0                    0.0  [\"https://www.uhcprovider.com/content/dam/prov...   \n",
      "1                    0.0                                                NaN   \n",
      "2                    0.0                                                NaN   \n",
      "\n",
      "   Total Count  \n",
      "0          2.0  \n",
      "1          2.0  \n",
      "2          2.0  \n",
      "📄 Combined results saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/retrieval/perplexity/baseline_experiment1.csv\n",
      "\n",
      "📂 Comparing files for 'United Healthcare'...\n",
      "❌ UNMATCHED (LLM-only): genetic-paan-faq.pdf\n",
      "❌ UNMATCHED (LLM-only): genetic-testing-hereditary-cancer.pdf\n",
      "📄 MD5 results saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/perplexity/baseline/perplexity_md5_comparison_baseline_experiment1.csv\n",
      "📁 MD5 comparison CSV saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/perplexity/baseline/perplexity_md5_comparison_baseline_experiment1.csv\n",
      "\n",
      "🔬 MD5 UNION COUNT between openai and perplexity (baseline): 6\n",
      "🔬 MD5 INTERSECTION COUNT: 0\n",
      "📄 Cross-model MD5 union/intersection saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/baseline/md5_union_intersection_baseline.csv\n",
      "\n",
      "=== Running OPENAI for prompt 'keyword' ===\n",
      "\n",
      "🔍 Searching for: United Healthcare\n",
      "🔁 Attempt 1 (openai)...\n",
      "\n",
      "🧾 OPENAI raw response for 'United Healthcare':\n",
      "{\"pdf_links\": [\"https://www.uhcprovider.com/content/dam/provider/docs/public/policies/index/commercial/pharmacogenetic-panel-testing-01012025.pdf\"], \"webpage_links\": [\"https://www.uhcprovider.com/en/prior-auth-advance-notification/genetic-molecular-lab.html\", \"https://www.uhcprovider.com/en/resource-library/news/2024/changes-genetic-molecular-testing-coverage-pa-requirements.html\", \"https://www.uhcprovider.com/en/resource-library/news/2023/co-medicaid-prior-auth-genetic-test-prostate-cancer.html\", \"https://www.dbp.com/content/provider/en/resource-library/news/2025/prior-auth-non-invasive-prenatal.html\", \"https://www.uhcprovider.com/en/policies-protocols/commercial-policies/umr-medical-drug-policies.html\"]}\n",
      "\n",
      "✅ Downloaded PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/keyword/United_Healthcare/pharmacogenetic-panel-testing-01012025.pdf\n",
      "✅ Saved webpage as PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/keyword/United_Healthcare/genetic-molecular-lab.pdf\n",
      "✅ Saved webpage as PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/keyword/United_Healthcare/changes-genetic-molecular-testing-coverage-pa-requirements.pdf\n",
      "✅ Saved webpage as PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/keyword/United_Healthcare/co-medicaid-prior-auth-genetic-test-prostate-cancer.pdf\n",
      "✅ Saved webpage as PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/keyword/United_Healthcare/prior-auth-non-invasive-prenatal.pdf\n",
      "✅ Saved webpage as PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/keyword/United_Healthcare/umr-medical-drug-policies.pdf\n",
      "📊 Summary DataFrame:\n",
      "            Provider                                          PDF Links  \\\n",
      "0  United Healthcare  [\"https://www.uhcprovider.com/content/dam/prov...   \n",
      "1          TOTAL_SUM                                                NaN   \n",
      "2            AVERAGE                                                NaN   \n",
      "\n",
      "   PDF Count  Downloaded PDFs  \\\n",
      "0        1.0              1.0   \n",
      "1        1.0              1.0   \n",
      "2        1.0              1.0   \n",
      "\n",
      "                                       Webpage Links  Webpage Count  \\\n",
      "0  [\"https://www.uhcprovider.com/en/prior-auth-ad...            5.0   \n",
      "1                                                NaN            5.0   \n",
      "2                                                NaN            5.0   \n",
      "\n",
      "   Saved Webpages as PDF                                          All Links  \\\n",
      "0                    5.0  [\"https://www.uhcprovider.com/content/dam/prov...   \n",
      "1                    5.0                                                NaN   \n",
      "2                    5.0                                                NaN   \n",
      "\n",
      "   Total Count  \n",
      "0          6.0  \n",
      "1          6.0  \n",
      "2          6.0  \n",
      "📄 Combined results saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/retrieval/openai/keyword_experiment1.csv\n",
      "\n",
      "📂 Comparing files for 'United Healthcare'...\n",
      "❌ UNMATCHED (LLM-only): genetic-molecular-lab.pdf\n",
      "❌ UNMATCHED (LLM-only): co-medicaid-prior-auth-genetic-test-prostate-cancer.pdf\n",
      "❌ UNMATCHED (LLM-only): umr-medical-drug-policies.pdf\n",
      "❌ UNMATCHED (LLM-only): changes-genetic-molecular-testing-coverage-pa-requirements.pdf\n",
      "❌ UNMATCHED (LLM-only): pharmacogenetic-panel-testing-01012025.pdf\n",
      "❌ UNMATCHED (LLM-only): prior-auth-non-invasive-prenatal.pdf\n",
      "📄 MD5 results saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/openai/keyword/openai_md5_comparison_keyword_experiment1.csv\n",
      "📁 MD5 comparison CSV saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/openai/keyword/openai_md5_comparison_keyword_experiment1.csv\n",
      "\n",
      "=== Running PERPLEXITY for prompt 'keyword' ===\n",
      "\n",
      "🔍 Searching for: United Healthcare\n",
      "🔁 Attempt 1 (perplexity)...\n",
      "\n",
      "🧾 PERPLEXITY raw response for 'United Healthcare':\n",
      "Based on the search results provided, I can identify two official policy documents from UnitedHealthcare that meet your criteria for genetic testing coverage:\n",
      "\n",
      "{\"pdf_links\": [\"https://www.uhcprovider.com/content/dam/provider/docs/public/policies/comm-medical-drug/genetic-testing-hereditary-cancer.pdf\", \"https://www.uhcprovider.com/content/dam/provider/docs/public/prior-auth/genetic-paan-faq.pdf\"], \"webpage_links\": []}\n",
      "\n",
      "✅ Downloaded PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/perplexity/keyword/United_Healthcare/genetic-testing-hereditary-cancer.pdf\n",
      "✅ Downloaded PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/perplexity/keyword/United_Healthcare/genetic-paan-faq.pdf\n",
      "📊 Summary DataFrame:\n",
      "            Provider                                          PDF Links  \\\n",
      "0  United Healthcare  [\"https://www.uhcprovider.com/content/dam/prov...   \n",
      "1          TOTAL_SUM                                                NaN   \n",
      "2            AVERAGE                                                NaN   \n",
      "\n",
      "   PDF Count  Downloaded PDFs Webpage Links  Webpage Count  \\\n",
      "0        2.0              2.0            []            0.0   \n",
      "1        2.0              2.0           NaN            0.0   \n",
      "2        2.0              2.0           NaN            0.0   \n",
      "\n",
      "   Saved Webpages as PDF                                          All Links  \\\n",
      "0                    0.0  [\"https://www.uhcprovider.com/content/dam/prov...   \n",
      "1                    0.0                                                NaN   \n",
      "2                    0.0                                                NaN   \n",
      "\n",
      "   Total Count  \n",
      "0          2.0  \n",
      "1          2.0  \n",
      "2          2.0  \n",
      "📄 Combined results saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/retrieval/perplexity/keyword_experiment1.csv\n",
      "\n",
      "📂 Comparing files for 'United Healthcare'...\n",
      "❌ UNMATCHED (LLM-only): genetic-paan-faq.pdf\n",
      "❌ UNMATCHED (LLM-only): genetic-testing-hereditary-cancer.pdf\n",
      "📄 MD5 results saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/perplexity/keyword/perplexity_md5_comparison_keyword_experiment1.csv\n",
      "📁 MD5 comparison CSV saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/perplexity/keyword/perplexity_md5_comparison_keyword_experiment1.csv\n",
      "\n",
      "🔬 MD5 UNION COUNT between openai and perplexity (keyword): 8\n",
      "🔬 MD5 INTERSECTION COUNT: 0\n",
      "📄 Cross-model MD5 union/intersection saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/keyword/md5_union_intersection_keyword.csv\n",
      "\n",
      "=== Running OPENAI for prompt 'strict' ===\n",
      "\n",
      "🔍 Searching for: United Healthcare\n",
      "🔁 Attempt 1 (openai)...\n",
      "\n",
      "🧾 OPENAI raw response for 'United Healthcare':\n",
      "{\"pdf_links\": [\"https://www.uhcprovider.com/content/dam/provider/docs/public/policies/index/commercial/pharmacogenetic-panel-testing-01012025.pdf\"], \"webpage_links\": [\"https://www.uhcprovider.com/en/prior-auth-advance-notification/genetic-molecular-lab.html\", \"https://www.uhcprovider.com/en/resource-library/news/2024/changes-genetic-molecular-testing-coverage-pa-requirements.html\", \"https://www.uhcprovider.com/en/policies-protocols/commercial-policies/umr-medical-drug-policies.html\"]}\n",
      "\n",
      "✅ Downloaded PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/strict/United_Healthcare/pharmacogenetic-panel-testing-01012025.pdf\n",
      "✅ Saved webpage as PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/strict/United_Healthcare/genetic-molecular-lab.pdf\n",
      "✅ Saved webpage as PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/strict/United_Healthcare/changes-genetic-molecular-testing-coverage-pa-requirements.pdf\n",
      "✅ Saved webpage as PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/openai/strict/United_Healthcare/umr-medical-drug-policies.pdf\n",
      "📊 Summary DataFrame:\n",
      "            Provider                                          PDF Links  \\\n",
      "0  United Healthcare  [\"https://www.uhcprovider.com/content/dam/prov...   \n",
      "1          TOTAL_SUM                                                NaN   \n",
      "2            AVERAGE                                                NaN   \n",
      "\n",
      "   PDF Count  Downloaded PDFs  \\\n",
      "0        1.0              1.0   \n",
      "1        1.0              1.0   \n",
      "2        1.0              1.0   \n",
      "\n",
      "                                       Webpage Links  Webpage Count  \\\n",
      "0  [\"https://www.uhcprovider.com/en/prior-auth-ad...            3.0   \n",
      "1                                                NaN            3.0   \n",
      "2                                                NaN            3.0   \n",
      "\n",
      "   Saved Webpages as PDF                                          All Links  \\\n",
      "0                    3.0  [\"https://www.uhcprovider.com/content/dam/prov...   \n",
      "1                    3.0                                                NaN   \n",
      "2                    3.0                                                NaN   \n",
      "\n",
      "   Total Count  \n",
      "0          4.0  \n",
      "1          4.0  \n",
      "2          4.0  \n",
      "📄 Combined results saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/retrieval/openai/strict_experiment1.csv\n",
      "\n",
      "📂 Comparing files for 'United Healthcare'...\n",
      "❌ UNMATCHED (LLM-only): genetic-molecular-lab.pdf\n",
      "❌ UNMATCHED (LLM-only): umr-medical-drug-policies.pdf\n",
      "❌ UNMATCHED (LLM-only): changes-genetic-molecular-testing-coverage-pa-requirements.pdf\n",
      "❌ UNMATCHED (LLM-only): pharmacogenetic-panel-testing-01012025.pdf\n",
      "📄 MD5 results saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/openai/strict/openai_md5_comparison_strict_experiment1.csv\n",
      "📁 MD5 comparison CSV saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/openai/strict/openai_md5_comparison_strict_experiment1.csv\n",
      "\n",
      "=== Running PERPLEXITY for prompt 'strict' ===\n",
      "\n",
      "🔍 Searching for: United Healthcare\n",
      "🔁 Attempt 1 (perplexity)...\n",
      "\n",
      "🧾 PERPLEXITY raw response for 'United Healthcare':\n",
      "{\"pdf_links\": [\"https://www.uhcprovider.com/content/dam/provider/docs/public/policies/comm-medical-drug/genetic-testing-hereditary-cancer.pdf\", \"https://www.uhcprovider.com/content/dam/provider/docs/public/prior-auth/genetic-paan-faq.pdf\"], \"webpage_links\": []}\n",
      "\n",
      "✅ Downloaded PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/perplexity/strict/United_Healthcare/genetic-testing-hereditary-cancer.pdf\n",
      "✅ Downloaded PDF: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/llm_searched/perplexity/strict/United_Healthcare/genetic-paan-faq.pdf\n",
      "📊 Summary DataFrame:\n",
      "            Provider                                          PDF Links  \\\n",
      "0  United Healthcare  [\"https://www.uhcprovider.com/content/dam/prov...   \n",
      "1          TOTAL_SUM                                                NaN   \n",
      "2            AVERAGE                                                NaN   \n",
      "\n",
      "   PDF Count  Downloaded PDFs Webpage Links  Webpage Count  \\\n",
      "0        2.0              2.0            []            0.0   \n",
      "1        2.0              2.0           NaN            0.0   \n",
      "2        2.0              2.0           NaN            0.0   \n",
      "\n",
      "   Saved Webpages as PDF                                          All Links  \\\n",
      "0                    0.0  [\"https://www.uhcprovider.com/content/dam/prov...   \n",
      "1                    0.0                                                NaN   \n",
      "2                    0.0                                                NaN   \n",
      "\n",
      "   Total Count  \n",
      "0          2.0  \n",
      "1          2.0  \n",
      "2          2.0  \n",
      "📄 Combined results saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/retrieval/perplexity/strict_experiment1.csv\n",
      "\n",
      "📂 Comparing files for 'United Healthcare'...\n",
      "❌ UNMATCHED (LLM-only): genetic-paan-faq.pdf\n",
      "❌ UNMATCHED (LLM-only): genetic-testing-hereditary-cancer.pdf\n",
      "📄 MD5 results saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/perplexity/strict/perplexity_md5_comparison_strict_experiment1.csv\n",
      "📁 MD5 comparison CSV saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/perplexity/strict/perplexity_md5_comparison_strict_experiment1.csv\n",
      "\n",
      "🔬 MD5 UNION COUNT between openai and perplexity (strict): 6\n",
      "🔬 MD5 INTERSECTION COUNT: 0\n",
      "📄 Cross-model MD5 union/intersection saved to: /home/cptaswadu/RESCUE-n8n/insurance/results/policy_retrieval/md5/strict/md5_union_intersection_strict.csv\n"
     ]
    }
   ],
   "source": [
    "providers = [\"United Healthcare\"]\n",
    "experiment_id = 1\n",
    "base_output_dir = f\"{BASE_RESULT_DIR}/retrieval\"\n",
    "\n",
    "for prompt_name, prompt_fn in prompt_functions.items():\n",
    "    for model in [\"openai\", \"perplexity\"]:\n",
    "        print(f\"\\n=== Running {model.upper()} for prompt '{prompt_name}' ===\")\n",
    "\n",
    "        df = summarize_policy_retrieval(\n",
    "            providers=providers,\n",
    "            prompt_fn=prompt_fn,\n",
    "            model=model,\n",
    "            prompt_name=prompt_name,\n",
    "            experiment_id=experiment_id,\n",
    "            openai_client=gpt_client,\n",
    "            perplexity_api_key=perplexity_api_key,\n",
    "            base_output_dir=base_output_dir\n",
    "        )\n",
    "\n",
    "        df_clean = df[~df[\"Provider\"].isin([\"TOTAL_SUM\", \"AVERAGE\"])]\n",
    "\n",
    "        md5_output_path = os.path.join(\n",
    "            BASE_RESULT_DIR,\n",
    "            \"md5\",\n",
    "            model,\n",
    "            prompt_name,\n",
    "            f\"{model}_md5_comparison_{prompt_name}_experiment{experiment_id}.csv\"\n",
    "        )\n",
    "\n",
    "        md5_result = evaluate_md5_comparisons(\n",
    "            df_clean.to_dict(orient=\"records\"),\n",
    "            model=model,\n",
    "            prompt_name=prompt_name,\n",
    "            manual_folder=MANUAL_FOLDER,\n",
    "            llm_root=LLM_FOLDER_ROOT,\n",
    "            output_dir=BASE_RESULT_DIR,\n",
    "            custom_output_path=md5_output_path\n",
    "        )\n",
    "\n",
    "        print(f\"📁 MD5 comparison CSV saved to: {md5_output_path}\")\n",
    "\n",
    "    # Run MD5 union/intersection comparison between openai and perplexity for this prompt\n",
    "    compare_md5_union_intersection(\"openai\", \"perplexity\", prompt_name, BASE_RESULT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_policy_experiments_multiple_times(n_trials=3):\n",
    "    for trial_id in range(1, n_trials + 1):\n",
    "        print(f\"\\n🚀 Running policy retrieval trial {trial_id}...\\n\")\n",
    "\n",
    "        for model in [\"ChatGPT\", \"perplexity\"]:\n",
    "            for prompt_name, prompt_fn in {\n",
    "                \"baseline\": policy_retrieval_prompt_baseline,\n",
    "                \"keyword\": policy_retrieval_prompt_keyword_checked_document,\n",
    "                \"strict\": policy_retrieval_prompt_keyword_verified_links,\n",
    "            }.items():\n",
    "                print(f\"→ Model: {model}, Prompt: {prompt_name}\")\n",
    "                retrieve_and_save_policy(model=model, prompt_name=prompt_name, prompt_fn=prompt_fn, trial_id=trial_id)\n",
    "\n",
    "    # After all trials, summarize\n",
    "    summarize_policy_retrieval()\n",
    "    evaluate_md5_comparisons()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
